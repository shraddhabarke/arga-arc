{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating tfcoder completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/ubuntu/arga-arc/tf_coder\n",
      "Root directory: /home/ubuntu/arga-arc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "CURRENT_DIRECTORY = Path(os.getcwd())\n",
    "ROOT_DIRECTORY = (CURRENT_DIRECTORY / \"..\").absolute().resolve()\n",
    "\n",
    "print(f\"Current directory: {CURRENT_DIRECTORY}\")\n",
    "print(f\"Root directory: {ROOT_DIRECTORY}\")\n",
    "\n",
    "sys.path.append(str(ROOT_DIRECTORY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t\n",
    "import json\n",
    "from pprint import pprint\n",
    "from dataclasses import dataclass\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 72 outputs and 72 tasks\n",
      "Task: google_01\n",
      "{'constants': '[]',\n",
      " 'description': 'Convert index tensor into pairs for SparseTensor indexing',\n",
      " 'examples': {'inputs': '[[0, 0, 0, 1, 3, 3],]',\n",
      "              'outputs': '[[0, 0], [0, 1], [0, 2], [1, 0], [3, 0], [3, 1]]'},\n",
      " 'name': 'google_01',\n",
      " 'source': 'From an internal Google chat room, 09/07/2018',\n",
      " 'target_program': 'tf.cast(tf.where(tf.sequence_mask(tf.math.bincount(in1))), '\n",
      "                   'tf.int32)'}\n",
      "{'completions': ['return tf.stack([tf.math.bincount(in1), in1], axis=1)',\n",
      "                 'return tf.stack([tf.divide(in1, tf.shape(in1)[0]), '\n",
      "                 'tf.mod(in1, tf.shape(in1)[0])], axis=1)',\n",
      "                 'return tf.stack([tf.math.floor_div(in1, tf.constant(2, '\n",
      "                 'dtype=tf.int32)), tf.math.floormod(in1, tf.constant(2, '\n",
      "                 'dtype=tf.int32))], axis=1)',\n",
      "                 'return tf.stack([tf.floor_div(in1, 2), tf.mod(in1, 2)], '\n",
      "                 'axis=1)',\n",
      "                 'return tf.stack([tf.math.floor_divide(in1, '\n",
      "                 'tf.shape(in1)[0]), tf.math.mod(in1, tf.shape(in1)[0])], '\n",
      "                 'axis=1)',\n",
      "                 'return tf.stack([tf.math.floor_divide(in1, '\n",
      "                 'tf.reduce_max(in1) + 1), tf.math.floormod(in1, '\n",
      "                 'tf.reduce_max(in1) + 1)], axis=1)',\n",
      "                 'return tf.stack([tf.math.floor_div(in1, tf.reduce_max(in1) + '\n",
      "                 '1), tf.math.floormod(in1, tf.reduce_max(in1) + 1)], axis=1)',\n",
      "                 'return tf.stack([tf.math.floor_div(in1, tf.reduce_max(in1) + '\n",
      "                 '1), tf.math.floormod(in1, tf.reduce_max(in1) + 1)], axis=1)',\n",
      "                 'return tf.stack([tf.math.bincount(in1), tf.cast(in1, '\n",
      "                 'tf.int32)], axis=1)',\n",
      "                 'return tf.stack([tf.divide(in1, tf.shape(in1)[0]), '\n",
      "                 'tf.math.bincount(in1)], axis=1)'],\n",
      " 'coverage_percentage': 60.0,\n",
      " 'description': 'Convert index tensor into pairs for SparseTensor indexing',\n",
      " 'target-program': 'tf.cast(tf.where(tf.sequence_mask(tf.math.bincount(in1))), '\n",
      "                   'tf.int32)',\n",
      " 'task_id': 'google_01',\n",
      " 'tf_operators': {'tf.cast': 1,\n",
      "                  'tf.constant': 1,\n",
      "                  'tf.divide': 2,\n",
      "                  'tf.floor_div': 1,\n",
      "                  'tf.int32': 2,\n",
      "                  'tf.math.bincount': 3,\n",
      "                  'tf.math.floor_div': 3,\n",
      "                  'tf.math.floor_divide': 2,\n",
      "                  'tf.math.floormod': 4,\n",
      "                  'tf.math.mod': 1,\n",
      "                  'tf.mod': 2,\n",
      "                  'tf.reduce_max': 3,\n",
      "                  'tf.shape': 3,\n",
      "                  'tf.stack': 10},\n",
      " 'total_covered': 3,\n",
      " 'total_in_target': 5}\n",
      "\n",
      "Task: google_03\n",
      "{'constants': '[]',\n",
      " 'description': 'Slice the first dimension of a SparseTensor',\n",
      " 'examples': {'inputs': 'tf.SparseTensor(indices=[[0, 0, 0], [0, 1, 1], [1, 1, '\n",
      "                        '1], [1, 1, 2]], values=[1., 1., 1., 1.], '\n",
      "                        'dense_shape=[2, 2, 800])',\n",
      "              'outputs': 'tf.SparseTensor(indices=[[0, 0, 0], [0, 1, 1]], '\n",
      "                         'values=[1., 1.], dense_shape=[1, 2, 800])'},\n",
      " 'name': 'google_03',\n",
      " 'source': 'Real task encountered by Googler, 11/01/2018',\n",
      " 'target_program': 'tf.divide(in1, tf.expand_dims(tf.reduce_sum(in1, axis=1), '\n",
      "                   '1))'}\n",
      "{'completions': ['return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])',\n",
      "                 'return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])',\n",
      "                 'return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])',\n",
      "                 'return tf.sparse.slice(in1, [0, 0, 0], [1, -1, -1])',\n",
      "                 'return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])',\n",
      "                 'return tf.sparse.slice(in1, [0,0,0], [1,-1,-1])',\n",
      "                 'return tf.sparse.slice(in1, start=[0, 0, 0], size=[1, -1, '\n",
      "                 '-1])',\n",
      "                 'return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])',\n",
      "                 'return tf.sparse.slice(in1, [0, 0, 0], [1, -1, -1])',\n",
      "                 'return tf.sparse.slice(in1, start=[0,0,0], size=[1, -1, '\n",
      "                 '-1])'],\n",
      " 'coverage_percentage': 0.0,\n",
      " 'description': 'Slice the first dimension of a SparseTensor',\n",
      " 'target-program': 'tf.divide(in1, tf.expand_dims(tf.reduce_sum(in1, axis=1), '\n",
      "                   '1))',\n",
      " 'task_id': 'google_03',\n",
      " 'tf_operators': {'tf.sparse.slice': 10},\n",
      " 'total_covered': 0,\n",
      " 'total_in_target': 3}\n",
      "\n",
      "Task: google_04\n",
      "{'constants': '[]',\n",
      " 'description': 'Reshape a flat array into a rank 3 tensor',\n",
      " 'examples': {'inputs': '[[111, 112, 121, 122, 131, 132, 211, 212, 221, 222, '\n",
      "                        '231, 232, 311, 312, 321, 322, 331, 332, 411, 412, '\n",
      "                        '421, 422, 431, 432],]',\n",
      "              'outputs': '[[[111, 112], [121, 122], [131, 132]],    [[211, '\n",
      "                         '212], [221, 222], [231, 232]],    [[311, 312], [321, '\n",
      "                         '322], [331, 332]],    [[411, 412], [421, 422], [431, '\n",
      "                         '432]]]'},\n",
      " 'name': 'google_04',\n",
      " 'source': 'Real task encountered by Googler, 3/21/2019',\n",
      " 'target_program': 'tf.reshape(in1, shape=(4, 3, 2))'}\n",
      "{'completions': ['return tf.reshape(in1, [4, 3, 2])',\n",
      "                 'return tf.reshape(in1, (4, 3, 2))',\n",
      "                 'return tf.reshape(in1, [4, 3, 2])',\n",
      "                 'return tf.reshape(in1, [4, 3, 2])',\n",
      "                 'return tf.reshape(in1, (4, 3, 2))',\n",
      "                 'return tf.reshape(in1, (4, 3, 2))',\n",
      "                 'return tf.reshape(in1, [4, 3, 2])',\n",
      "                 'return tf.reshape(in1, [4, 3, 2])',\n",
      "                 'return tf.reshape(in1, [4, 3, 2])',\n",
      "                 'return tf.reshape(in1, (4, 3, 2))'],\n",
      " 'coverage_percentage': 100.0,\n",
      " 'description': 'Reshape a flat array into a rank 3 tensor',\n",
      " 'target-program': 'tf.reshape(in1, shape=(4, 3, 2))',\n",
      " 'task_id': 'google_04',\n",
      " 'tf_operators': {'tf.reshape': 10},\n",
      " 'total_covered': 1,\n",
      " 'total_in_target': 1}\n",
      "\n",
      "Task: google_05\n",
      "{'constants': '[6]',\n",
      " 'description': 'Repeat each input entry 6 times',\n",
      " 'examples': {'inputs': '[[[1, 2, 3, 4], [5, 6, 7, 8]],]',\n",
      "              'outputs': '[[[1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4],     [1, '\n",
      "                         '2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4]],    [[5, 6, 7, '\n",
      "                         '8], [5, 6, 7, 8], [5, 6, 7, 8],     [5, 6, 7, 8], '\n",
      "                         '[5, 6, 7, 8], [5, 6, 7, 8]]]'},\n",
      " 'name': 'google_05',\n",
      " 'source': 'Real task encountered by Googler, 3/22/2019',\n",
      " 'target_program': 'tf.tile(tf.expand_dims(in1, 1), (1, 6, 1))'}\n",
      "{'completions': ['return tf.expand_dims(in1, 1)\\n'\n",
      "                 '    return tf.tile(in1, [1, 6, 1])',\n",
      "                 'return tf.tile(tf.expand_dims(in1, 1), [1, 6, 1])',\n",
      "                 'return tf.expand_dims(in1, axis=1)\\n'\n",
      "                 '    repeated = tf.tile(repeated, [1, 6, 1]) \\n'\n",
      "                 '    return repeated',\n",
      "                 'return tf.expand_dims(in1, 1)\\n'\n",
      "                 '    in1 = tf.repeat(in1, 6, axis=1)\\n'\n",
      "                 '    return in1',\n",
      "                 'return tf.expand_dims(in1,1)\\n'\n",
      "                 '    return tf.tile(in1, [1, 6, 1])',\n",
      "                 'return tf.expand_dims(in1, axis=1) + tf.zeros([1, 6, 1], '\n",
      "                 'tf.int32)',\n",
      "                 'return tf.expand_dims(in1, 1)\\n'\n",
      "                 '    repeat_data = tf.tile(in1, [1, 6, 1])\\n'\n",
      "                 '    return tf.cast(repeat_data, tf.int32)',\n",
      "                 'return tf.reshape(tf.repeat(in1, 6, axis=0), (-1, 6, '\n",
      "                 'in1.shape[1]))',\n",
      "                 'return tf.expand_dims(in1, 1)\\n'\n",
      "                 '    in1 = tf.repeat(in1, 6, axis=1)\\n'\n",
      "                 '    return in1',\n",
      "                 'return tf.expand_dims(in1, -1)\\n'\n",
      "                 '    return tf.tile(in1, [1, 1, 6])'],\n",
      " 'coverage_percentage': 100.0,\n",
      " 'description': 'Repeat each input entry 6 times',\n",
      " 'target-program': 'tf.tile(tf.expand_dims(in1, 1), (1, 6, 1))',\n",
      " 'task_id': 'google_05',\n",
      " 'tf_operators': {'tf.cast': 1,\n",
      "                  'tf.expand_dims': 9,\n",
      "                  'tf.int32': 2,\n",
      "                  'tf.repeat': 3,\n",
      "                  'tf.reshape': 1,\n",
      "                  'tf.tile': 6,\n",
      "                  'tf.zeros': 1},\n",
      " 'total_covered': 2,\n",
      " 'total_in_target': 2}\n",
      "\n",
      "Task: google_06\n",
      "{'constants': '[]',\n",
      " 'description': 'Take the max from each group of elements',\n",
      " 'examples': {'inputs': '[[0, 1, 1, 2, 3, 3, 3, 3],[1, 3, 4, 5, 10, 8, 9, 4],]',\n",
      "              'outputs': '[1, 4, 5, 10]'},\n",
      " 'name': 'google_06',\n",
      " 'source': 'Real task encountered by Googler, 3/28/2019',\n",
      " 'target_program': 'tf.math.segment_max(in2, in1)'}\n",
      "{'completions': ['return tf.math.segment_max(in2, in1)',\n",
      "                 'return tf.math.unsorted_segment_max(in2, in1, '\n",
      "                 'tf.reduce_max(in1) + 1)',\n",
      "                 'return tf.math.unsorted_segment_max(in2, in1, '\n",
      "                 'tf.reduce_max(in1) + 1)',\n",
      "                 'return tf.math.unsorted_segment_max(in2, in1, '\n",
      "                 'tf.reduce_max(in1) + 1)',\n",
      "                 'return tf.math.segment_max(in2, in1)',\n",
      "                 'return tf.math.segment_max(in2, in1)',\n",
      "                 'return tf.math.unsorted_segment_max(in2, in1, '\n",
      "                 'tf.reduce_max(in1) + 1)',\n",
      "                 'return tf.math.segment_max(in2, in1)',\n",
      "                 'return tf.math.segment_max(in2, in1)',\n",
      "                 'return tf.math.unsorted_segment_max(in2, in1, '\n",
      "                 'tf.reduce_max(in1)+1)'],\n",
      " 'coverage_percentage': 100.0,\n",
      " 'description': 'Take the max from each group of elements',\n",
      " 'target-program': 'tf.math.segment_max(in2, in1)',\n",
      " 'task_id': 'google_06',\n",
      " 'tf_operators': {'tf.math.segment_max': 5,\n",
      "                  'tf.math.unsorted_segment_max': 5,\n",
      "                  'tf.reduce_max': 5},\n",
      " 'total_covered': 1,\n",
      " 'total_in_target': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class OutputJSON(t.TypedDict):\n",
    "    task_id: str\n",
    "    completions: t.List[str]\n",
    "    coverage_percentage: float\n",
    "    description: str\n",
    "    tf_operators: t.Dict[str, int]\n",
    "    total_covered: int\n",
    "    total_in_target: int\n",
    "\n",
    "class ExamplesJSON(t.TypedDict):\n",
    "    inputs: str\n",
    "    outputs: str\n",
    "\n",
    "class TaskJSON(t.TypedDict):\n",
    "    constants: str\n",
    "    description: str\n",
    "    name: str\n",
    "    source: str\n",
    "    target_program: str\n",
    "    examples: ExamplesJSON\n",
    "\n",
    "class TaskWithOutputJSON(t.TypedDict):\n",
    "    constants: str\n",
    "    description: str\n",
    "    name: str\n",
    "    source: str\n",
    "    target_program: str\n",
    "    examples: ExamplesJSON\n",
    "    response: OutputJSON\n",
    "\n",
    "\n",
    "\n",
    "OUTPUT_FILE = CURRENT_DIRECTORY / \"tfcoder_dataset_with_completions.in_context_ordered_by_weight.json\"\n",
    "DATASET_FILE = CURRENT_DIRECTORY / \"tfcoder_dataset.json\"\n",
    "\n",
    "TASK_WITH_RESPONSE: t.List[TaskWithOutputJSON] = json.loads(OUTPUT_FILE.read_text())\n",
    "OUTPUT = [task[\"response\"] if 'response' in task else None for task in TASK_WITH_RESPONSE]\n",
    "DATASET: t.List[TaskJSON] = json.loads(DATASET_FILE.read_text())\n",
    "\n",
    "print(f\"Loaded {len(OUTPUT)} outputs and {len(DATASET)} tasks\")\n",
    "\n",
    "TASK_JSONS = {task[\"name\"]: task for task in DATASET}\n",
    "OUTPUTS = {output[\"task_id\"]: output for output in OUTPUT if output is not None}\n",
    "\n",
    "keys = list(OUTPUTS.keys())[0:5]\n",
    "for key in keys:\n",
    "    print(f\"Task: {key}\")\n",
    "    pprint(TASK_JSONS[key])\n",
    "    pprint(OUTPUTS[key])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task name: google_01\n",
      "Example(inputs=[array([0, 0, 0, 1, 3, 3])],\n",
      "        output=array([[0, 0],\n",
      "       [0, 1],\n",
      "       [0, 2],\n",
      "       [1, 0],\n",
      "       [3, 0],\n",
      "       [3, 1]]))\n",
      "\n",
      "Task name: google_02\n",
      "Example(inputs=[array([[0., 1., 0., 0.],\n",
      "       [0., 1., 1., 0.],\n",
      "       [1., 1., 1., 1.]])],\n",
      "        output=array([[0.  , 1.  , 0.  , 0.  ],\n",
      "       [0.  , 0.5 , 0.5 , 0.  ],\n",
      "       [0.25, 0.25, 0.25, 0.25]]))\n",
      "\n",
      "Task name: google_03\n",
      "Example(inputs=[SparseTensor(indices=tf.Tensor(\n",
      "[[0 0 0]\n",
      " [0 1 1]\n",
      " [1 1 1]\n",
      " [1 1 2]], shape=(4, 3), dtype=int64), values=tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32), dense_shape=tf.Tensor([  2   2 800], shape=(3,), dtype=int64))],\n",
      "        output=SparseTensor(indices=tf.Tensor(\n",
      "[[0 0 0]\n",
      " [0 1 1]], shape=(2, 3), dtype=int64), values=tf.Tensor([1. 1.], shape=(2,), dtype=float32), dense_shape=tf.Tensor([  1   2 800], shape=(3,), dtype=int64)))\n",
      "\n",
      "Task name: google_04\n",
      "Example(inputs=[array([111, 112, 121, 122, 131, 132, 211, 212, 221, 222, 231, 232, 311,\n",
      "       312, 321, 322, 331, 332, 411, 412, 421, 422, 431, 432])],\n",
      "        output=array([[[111, 112],\n",
      "        [121, 122],\n",
      "        [131, 132]],\n",
      "\n",
      "       [[211, 212],\n",
      "        [221, 222],\n",
      "        [231, 232]],\n",
      "\n",
      "       [[311, 312],\n",
      "        [321, 322],\n",
      "        [331, 332]],\n",
      "\n",
      "       [[411, 412],\n",
      "        [421, 422],\n",
      "        [431, 432]]]))\n",
      "\n",
      "Task name: google_05\n",
      "Example(inputs=[array([[1, 2, 3, 4],\n",
      "       [5, 6, 7, 8]])],\n",
      "        output=array([[[1, 2, 3, 4],\n",
      "        [1, 2, 3, 4],\n",
      "        [1, 2, 3, 4],\n",
      "        [1, 2, 3, 4],\n",
      "        [1, 2, 3, 4],\n",
      "        [1, 2, 3, 4]],\n",
      "\n",
      "       [[5, 6, 7, 8],\n",
      "        [5, 6, 7, 8],\n",
      "        [5, 6, 7, 8],\n",
      "        [5, 6, 7, 8],\n",
      "        [5, 6, 7, 8],\n",
      "        [5, 6, 7, 8]]]))\n",
      "\n",
      "Task name: google_06\n",
      "Example(inputs=[array([0, 1, 1, 2, 3, 3, 3, 3]),\n",
      "                array([ 1,  3,  4,  5, 10,  8,  9,  4])],\n",
      "        output=array([ 1,  4,  5, 10]))\n",
      "\n",
      "Task name: google_07\n",
      "Example(inputs=[array([0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 4, 4, 5, 5]),\n",
      "                array([ 4,  1,  8,  2,  5,  7,  9,  3,  7,  3,  1, 42,  1,  2,  4,  0])],\n",
      "        output=array([2, 3, 1, 0, 1, 0]))\n",
      "\n",
      "Task name: google_08\n",
      "Example(inputs=[array([3, 4, 2, 1])],\n",
      "        output=array([[1, 1, 1, 0, 0],\n",
      "       [1, 1, 1, 1, 0],\n",
      "       [1, 1, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0]]))\n",
      "\n",
      "Task name: google_09\n",
      "Example(inputs=[array([1, 1, 1, 0, 0, 2]), array([10, 20, 30, 14, 15, 26])],\n",
      "        output=array([14, 15, 10, 20, 30, 26]))\n",
      "\n",
      "Task name: google_10\n",
      "Example(inputs=[array([10, 20,  0, 40,  0, 30]), array([1, 1, 0, 1, 0, 1])],\n",
      "        output=array([10, 20, 40, 30]))\n",
      "\n",
      "Task name: google_11\n",
      "Example(inputs=[array([[ 1.  ,  0.3 , -4.2 ,  0.  ,  2.1 ,  0.4 ],\n",
      "       [-0.1 ,  0.  ,  1.4 , -1.  ,  0.4 ,  0.  ],\n",
      "       [ 0.1 ,  0.  ,  0.7 , -0.3 ,  0.5 , -0.1 ],\n",
      "       [ 1.4 ,  2.5 ,  0.3 ,  0.01,  0.  ,  1.2 ]])],\n",
      "        output=array([4, 2, 3, 5]))\n",
      "\n",
      "Task name: google_12\n",
      "Example(inputs=[array([[ 1. ,  0.3, -4.2,  0. ,  2.1],\n",
      "       [-0.1,  0. ,  1.4, -1. ,  0.4],\n",
      "       [ 0.1,  0. ,  0.7, -0.3,  0.5],\n",
      "       [ 1.4,  2.5,  0.3, -0.1,  0. ]])],\n",
      "        output=array([[1, 1, 0, 1, 0],\n",
      "       [0, 1, 0, 0, 1],\n",
      "       [1, 1, 1, 0, 1],\n",
      "       [0, 0, 1, 0, 1]]))\n",
      "\n",
      "Task name: google_13\n",
      "Example(inputs=[array([[ 1,  2],\n",
      "       [10, 20]]),\n",
      "                array([[ 3,  4,  5],\n",
      "       [30, 40, 50]])],\n",
      "        output=array([[ 1,  2,  3,  4,  5],\n",
      "       [10, 20, 30, 40, 50]]))\n",
      "\n",
      "Task name: google_14\n",
      "Example(inputs=[array([[1, 3, 2, 0, 0],\n",
      "       [4, 6, 5, 0, 0],\n",
      "       [8, 7, 9, 0, 0]])],\n",
      "        output=array([[0, 1, 3, 2, 0],\n",
      "       [0, 4, 6, 5, 0],\n",
      "       [0, 8, 7, 9, 0]]))\n",
      "\n",
      "Task name: google_15\n",
      "Example(inputs=[array([[1, 3, 5, 7],\n",
      "       [2, 4, 6, 8]])],\n",
      "        output=array([[1, 3, 5, 7, 0],\n",
      "       [2, 4, 6, 8, 0]]))\n",
      "\n",
      "Task name: google_16\n",
      "Example(inputs=[array([1, 2, 0, 3]), array([2, 1, 2, 3])],\n",
      "        output=array([1, 1, 2, 0, 0, 3, 3, 3]))\n",
      "\n",
      "Task name: google_17\n",
      "Example(inputs=[array([ True, False, False,  True, False]),\n",
      "                array([1, 2, 3, 4, 5])],\n",
      "        output=array([  1, -20, -30,   4, -50]))\n",
      "\n",
      "Task name: google_18\n",
      "Example(inputs=[array([  5,   7, -12,  10,  20]), array([1, 2, 3, 1, 2])],\n",
      "        output=array([ 15,  27, -12,  15,  27]))\n",
      "\n",
      "Task name: google_19\n",
      "Example(inputs=[array([[11, 12, 13],\n",
      "       [30, 20, 10],\n",
      "       [77, 88, 99]]),\n",
      "                array([[2, 0, 1],\n",
      "       [1, 0, 2],\n",
      "       [0, 2, 1]])],\n",
      "        output=array([[12, 13, 11],\n",
      "       [20, 30, 10],\n",
      "       [77, 99, 88]]))\n",
      "\n",
      "Task name: google_20\n",
      "Example(inputs=[array([10,  7,  4,  3,  2,  8])],\n",
      "        output=array([5, 3, 2, 1, 0, 4]))\n",
      "\n",
      "Task name: google_21\n",
      "Example(inputs=[{'indices': [[0, 0], [0, 2], [1, 1], [1, 3], [2, 2], [2, 4]],\n",
      "                 'tensor': [[1, 2, 3, 4, 5],\n",
      "                            [4, 5, 6, 7, 8],\n",
      "                            [7, 8, 9, 10, 11]],\n",
      "                 'updates': [[0, -2], [-1, -3], [-2, -4]]}],\n",
      "        output=array([[ 0,  2, -2,  4,  5],\n",
      "       [ 4, -1,  6, -3,  8],\n",
      "       [ 7,  8, -2, 10, -4]]))\n",
      "\n",
      "Task name: google_22\n",
      "Example(inputs=[array([[0, 2],\n",
      "       [1, 3],\n",
      "       [2, 4]])],\n",
      "        output=array([[0, 0],\n",
      "       [0, 2],\n",
      "       [1, 1],\n",
      "       [1, 3],\n",
      "       [2, 2],\n",
      "       [2, 4]]))\n",
      "\n",
      "Task name: stackoverflow_01\n",
      "Example(inputs=[array([[ 5.,  2.],\n",
      "       [ 1.,  3.],\n",
      "       [ 0., -1.]])],\n",
      "        output=array([[[ 5.,  5.],\n",
      "        [ 1.,  1.],\n",
      "        [ 0.,  0.]],\n",
      "\n",
      "       [[ 2.,  2.],\n",
      "        [ 3.,  3.],\n",
      "        [-1., -1.]]]))\n",
      "\n",
      "Task name: stackoverflow_02\n",
      "Example(inputs=[array([  5,   1,   0,   3,   0,  -1,   2, -10,   2])],\n",
      "        output=array([[  1,   1,   0,   1,   0,  -1,   1, -10,   1]]))\n",
      "\n",
      "Task name: stackoverflow_03\n",
      "Example(inputs=[array([[11, 22, 33, 44, 55, 66, 77],\n",
      "       [70, 60, 50, 40, 30, 20, 10]]),\n",
      "                array([[-9, -8, -7, -6, -5, -4, -3],\n",
      "       [11, 12, 13, 14, 15, 16, 17]])],\n",
      "        output=array([[[11, 22, 33, -6, -5, 66, 77],\n",
      "        [70, 60, 50, 14, 15, 20, 10]]]))\n",
      "\n",
      "Task name: stackoverflow_04\n",
      "Example(inputs=[array([[ 5.,  2.],\n",
      "       [ 1.,  3.],\n",
      "       [ 0., -1.]])],\n",
      "        output=array([[[ 5.,  5.],\n",
      "        [ 1.,  1.],\n",
      "        [ 0.,  0.]],\n",
      "\n",
      "       [[ 2.,  2.],\n",
      "        [ 3.,  3.],\n",
      "        [-1., -1.]]]))\n",
      "\n",
      "Task name: stackoverflow_05\n",
      "Example(inputs=[array([[4, 3, 1],\n",
      "       [6, 5, 2]]),\n",
      "                array([[[5, 5]],\n",
      "\n",
      "       [[1, 5]],\n",
      "\n",
      "       [[6, 0]]])],\n",
      "        output=array([[[29, 35]],\n",
      "\n",
      "       [[47, 55]]]))\n",
      "\n",
      "Task name: stackoverflow_06\n",
      "Example(inputs=[array([3, 5, 0, 2, 3, 3, 0])],\n",
      "        output=array([[1., 0., 0., 0., 1., 1., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 1., 1., 0.],\n",
      "       [1., 0., 0., 0., 1., 1., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 1.]]))\n",
      "\n",
      "Task name: stackoverflow_07\n",
      "Example(inputs=[array([[[ 8,  4,  6],\n",
      "        [ 2, 12,  3]],\n",
      "\n",
      "       [[11, 12,  5],\n",
      "        [ 9, 12, 12]],\n",
      "\n",
      "       [[ 9,  2, 13],\n",
      "        [ 7,  0,  7]],\n",
      "\n",
      "       [[ 2, 10,  5],\n",
      "        [ 7,  1,  2]]])],\n",
      "        output=array([[[ 8,  4,  6],\n",
      "        [11, 12,  5],\n",
      "        [ 9,  2, 13],\n",
      "        [ 2, 10,  5]],\n",
      "\n",
      "       [[ 2, 12,  3],\n",
      "        [ 9, 12, 12],\n",
      "        [ 7,  0,  7],\n",
      "        [ 7,  1,  2]]]))\n",
      "\n",
      "Task name: stackoverflow_08\n",
      "Example(inputs=[array([-1,  0, -3,  2,  1,  3,  5, -1, -9,  2, 10]),\n",
      "                array([12,  3, 45,  6,  7,  8,  9, 87, 65,  4, 32])],\n",
      "        output=array([ 6,  8,  9,  4, 32]))\n",
      "\n",
      "Task name: stackoverflow_09\n",
      "Example(inputs=[array([37, 42, 42, 37, 28, 15, 42, 15])],\n",
      "        output=array([0, 1, 1, 0, 2, 3, 1, 3]))\n",
      "\n",
      "Task name: stackoverflow_10\n",
      "Example(inputs=[array([[15, 10],\n",
      "       [20, -5]]),\n",
      "                array([[ 2,  3,  1],\n",
      "       [-2,  5,  0]])],\n",
      "        output=array([[[ 30,  45,  15],\n",
      "        [ 20,  30,  10]],\n",
      "\n",
      "       [[-40, 100,   0],\n",
      "        [ 10, -25,   0]]]))\n",
      "\n",
      "Task name: stackoverflow_11\n",
      "Example(inputs=[array([4, 0, 1, 1, 0, 4, 0, 0, 3, 4, 1])],\n",
      "        output=array([4, 3, 0, 1, 3]))\n",
      "\n",
      "Task name: stackoverflow_12\n",
      "Example(inputs=[array([[12, 34, 56],\n",
      "       [33, 22, 11]])],\n",
      "        output=array([[12, 56],\n",
      "       [33, 11]]))\n",
      "\n",
      "Task name: stackoverflow_13\n",
      "Example(inputs=[array([[ 3,  5],\n",
      "       [10,  2]]),\n",
      "                array([[[ 1,  0],\n",
      "        [ 5,  4]],\n",
      "\n",
      "       [[ 3, 10],\n",
      "        [ 2, -2]]])],\n",
      "        output=array([[[28, 20],\n",
      "        [19, 20]],\n",
      "\n",
      "       [[20,  8],\n",
      "        [34, 96]]]))\n",
      "\n",
      "Task name: stackoverflow_14\n",
      "Example(inputs=[array([[[False, False,  True],\n",
      "        [False, False, False],\n",
      "        [ True, False,  True],\n",
      "        [False,  True, False],\n",
      "        [False, False, False],\n",
      "        [ True,  True,  True],\n",
      "        [ True,  True, False]]])],\n",
      "        output=array([[ True, False,  True,  True, False,  True,  True]]))\n",
      "\n",
      "Task name: stackoverflow_15\n",
      "Example(inputs=[array([  3,   1,   2,   0,   1,  -1,  10,   1, -10])],\n",
      "        output=array([  3,   0,   2,   0,   0,  -1,  10,   0, -10]))\n",
      "\n",
      "Task name: stackoverflow_16\n",
      "Example(inputs=[array([[ 2,  5],\n",
      "       [ 3,  0],\n",
      "       [ 8, -7]]),\n",
      "                array([ 4, 10, -6])],\n",
      "        output=array([[  8,  20],\n",
      "       [ 30,   0],\n",
      "       [-48,  42]]))\n",
      "\n",
      "Task name: stackoverflow_17\n",
      "Example(inputs=[array([ 17, -32,  99])],\n",
      "        output=array([[ 17,  17],\n",
      "       [-32, -32],\n",
      "       [ 99,  99]]))\n",
      "\n",
      "Task name: stackoverflow_18\n",
      "Example(inputs=[array([[[1, 1, 1],\n",
      "        [1, 0, 1]],\n",
      "\n",
      "       [[1, 2, 3],\n",
      "        [4, 5, 6]]]),\n",
      "                array([[1, 1, 1, 1],\n",
      "       [1, 2, 3, 4],\n",
      "       [5, 6, 7, 8]]),\n",
      "                array([100, 200, 300, 400])],\n",
      "        output=array([[[107, 209, 311, 413],\n",
      "        [106, 207, 308, 409]],\n",
      "\n",
      "       [[118, 223, 328, 433],\n",
      "        [139, 250, 361, 472]]]))\n",
      "\n",
      "Task name: stackoverflow_19\n",
      "Example(inputs=[array([[3, 1, 2],\n",
      "       [1, 0, 4],\n",
      "       [1, 2, 3],\n",
      "       [0, 5, 1],\n",
      "       [1, 1, 2],\n",
      "       [2, 3, 1],\n",
      "       [2, 1, 0]])],\n",
      "        output=array([[0, 5, 1],\n",
      "       [1, 0, 4],\n",
      "       [1, 1, 2],\n",
      "       [1, 2, 3],\n",
      "       [2, 1, 0],\n",
      "       [2, 3, 1],\n",
      "       [3, 1, 2]]))\n",
      "\n",
      "Task name: stackoverflow_20\n",
      "Example(inputs=[array([[0.7, 0.2, 0.1],\n",
      "       [0.4, 0.5, 0.1],\n",
      "       [0.4, 0.4, 0.2],\n",
      "       [0.3, 0.4, 0.3],\n",
      "       [0. , 0. , 1. ]])],\n",
      "        output=array([[1, 0, 0],\n",
      "       [0, 1, 0],\n",
      "       [1, 0, 0],\n",
      "       [0, 1, 0],\n",
      "       [0, 0, 1]]))\n",
      "\n",
      "Task name: stackoverflow_21\n",
      "Example(inputs=[array([[2],\n",
      "       [0],\n",
      "       [1],\n",
      "       [0]]),\n",
      "                array([[0.2, 0.5, 0.3],\n",
      "       [0.1, 0.3, 0.6],\n",
      "       [0.1, 0.6, 0.3],\n",
      "       [0.7, 0. , 0.3]])],\n",
      "        output=array([[0.3],\n",
      "       [0.1],\n",
      "       [0.6],\n",
      "       [0.7]]))\n",
      "\n",
      "Task name: stackoverflow_22\n",
      "Example(inputs=[array([ 3,  1, 10]),\n",
      "                array([[0.6, 0.4],\n",
      "       [0.5, 1. ],\n",
      "       [3. , 4. ]])],\n",
      "        output=array([32.3, 42.2]))\n",
      "\n",
      "Task name: stackoverflow_23\n",
      "Example(inputs=[array([[0, 5, 2],\n",
      "       [3, 1, 4],\n",
      "       [5, 1, 5]])],\n",
      "        output=array([[1, 0, 1, 0, 0, 1, 0, 0, 0],\n",
      "       [0, 1, 0, 1, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 1, 0, 0, 0]]))\n",
      "\n",
      "Task name: stackoverflow_24\n",
      "Example(inputs=[array([ 3.,  1.,  4.,  5.,  2.,  8., -6., -7.]),\n",
      "                array([ 0.5,  0. , -2. ,  0. ,  1. , -1. ,  0. ,  2. ])],\n",
      "        output=array([ 6. ,  1. , -2. ,  5. ,  2. , -8. , -6. , -3.5]))\n",
      "\n",
      "Task name: stackoverflow_25\n",
      "Example(inputs=[array(3), array(4)],\n",
      "        output=array([[1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.]]))\n",
      "\n",
      "Task name: stackoverflow_26\n",
      "Example(inputs=[array([[[  3,   4],\n",
      "        [  1,   2]],\n",
      "\n",
      "       [[  5,  -2],\n",
      "        [-10,   3]],\n",
      "\n",
      "       [[ 10,  20],\n",
      "        [ -4,   7]]])],\n",
      "        output=array([10, -4, 33]))\n",
      "\n",
      "Task name: stackoverflow_27\n",
      "Example(inputs=[array([0, 3, 5, 6]), array(8)],\n",
      "        output=array([1, 0, 0, 1, 0, 1, 1, 0]))\n",
      "\n",
      "Task name: stackoverflow_28\n",
      "Example(inputs=[array([[[ 5,  3],\n",
      "        [ 0,  2]],\n",
      "\n",
      "       [[ 7,  4],\n",
      "        [ 5,  1]],\n",
      "\n",
      "       [[10, 20],\n",
      "        [15, 30]],\n",
      "\n",
      "       [[11, 16],\n",
      "        [14, 12]],\n",
      "\n",
      "       [[-2, -7],\n",
      "        [-4,  6]]]),\n",
      "                array([1, 0, 1, 1, 0])],\n",
      "        output=array([[ 3,  2],\n",
      "       [ 7,  5],\n",
      "       [20, 30],\n",
      "       [16, 12],\n",
      "       [-2, -4]]))\n",
      "\n",
      "Task name: stackoverflow_29\n",
      "Example(inputs=[array([-1. , -0.8, -0.6, -0.4, -0.2,  0. ,  0.2,  0.4,  0.6,  0.8,  1. ]),\n",
      "                array([  0.1 , -10.  ,  -0.1 ,   1.1 ,   0.41])],\n",
      "        output=array([ 6,  0,  5, 11,  8]))\n",
      "\n",
      "Task name: stackoverflow_30\n",
      "Example(inputs=[array([[1., 2.],\n",
      "       [3., 4.],\n",
      "       [5., 6.]]),\n",
      "                array([[9., 4.],\n",
      "       [8., 5.],\n",
      "       [7., 6.]])],\n",
      "        output=array([[8.24621125, 7.61577311, 7.21110255],\n",
      "       [6.        , 5.09901951, 4.47213595],\n",
      "       [4.47213595, 3.16227766, 2.        ]]))\n",
      "\n",
      "Task name: stackoverflow_31\n",
      "Example(inputs=[(SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [1 1]], shape=(3, 2), dtype=int64), values=tf.Tensor([ 1.   1.5 -2. ], shape=(3,), dtype=float32), dense_shape=tf.Tensor([2 2], shape=(2,), dtype=int64)),\n",
      "                 [[3.0, 1.0], [0.2, -1.0]])],\n",
      "        output=5.29)\n",
      "\n",
      "Task name: stackoverflow_32\n",
      "Example(inputs=[array([[0.1, 0.6, 0.2, 0.1],\n",
      "       [0.3, 0.1, 0.4, 0.2],\n",
      "       [0.2, 0.1, 0.2, 0.5]])],\n",
      "        output=array([1.3, 1.5, 2. ]))\n",
      "\n",
      "Task name: stackoverflow_33\n",
      "Example(inputs=[array([[0.3, 0.1, 0.4],\n",
      "       [0.1, 0.5, 0.9],\n",
      "       [0.2, 0.6, 0.5],\n",
      "       [0.3, 0.5, 0.8],\n",
      "       [0.9, 0.7, 0.9]]),\n",
      "                array([[0.3, 0.2, 0.3],\n",
      "       [0.8, 0.4, 0.6],\n",
      "       [0.2, 0.6, 0.4],\n",
      "       [0.3, 0.3, 0.8]])],\n",
      "        output=array([0.02, 0.19, 0.01, 0.04]))\n",
      "\n",
      "Task name: stackoverflow_34\n",
      "Example(inputs=[array([[[ 1,  2],\n",
      "        [ 3,  4]],\n",
      "\n",
      "       [[ 5,  6],\n",
      "        [ 7,  8]],\n",
      "\n",
      "       [[10, 20],\n",
      "        [30, 40]]]),\n",
      "                array([ 3,  5, 10])],\n",
      "        output=array([[128, 236],\n",
      "       [344, 452]]))\n",
      "\n",
      "Task name: stackoverflow_35\n",
      "Example(inputs=[array([[[ 1.,  2.],\n",
      "        [ 3.,  4.],\n",
      "        [ 5.,  6.]],\n",
      "\n",
      "       [[10., 20.],\n",
      "        [30., 40.],\n",
      "        [50., 60.]]]),\n",
      "                array([[[ 9.,  8.],\n",
      "        [ 7.,  6.],\n",
      "        [ 5.,  4.]],\n",
      "\n",
      "       [[90., 80.],\n",
      "        [70., 60.],\n",
      "        [50., 40.]]]),\n",
      "                array([0.1, 0.4, 0.8])],\n",
      "        output=array([[[ 8.2,  7.4],\n",
      "        [ 5.4,  5.2],\n",
      "        [ 5. ,  5.6]],\n",
      "\n",
      "       [[82. , 74. ],\n",
      "        [54. , 52. ],\n",
      "        [50. , 56. ]]]))\n",
      "\n",
      "Task name: stackoverflow_36\n",
      "Example(inputs=[array([1, 0, 1, 1, 0, 1, 0, 1])],\n",
      "        output=array([1.      , 0.      , 0.333333, 0.25    , 0.      , 0.166667,\n",
      "       0.      , 0.125   ]))\n",
      "\n",
      "Task name: stackoverflow_37\n",
      "Example(inputs=[array([[[[1. , 2. , 3. ],\n",
      "         [4. , 5. , 6. ]],\n",
      "\n",
      "        [[1.2, 3.4, 5.6],\n",
      "         [7.8, 9.8, 7.6]]]]),\n",
      "                array([0.5, 1. , 2. ])],\n",
      "        output=array([[[ 8.5, 19. ],\n",
      "        [15.2, 28.9]]]))\n",
      "\n",
      "Task name: stackoverflow_38\n",
      "Example(inputs=[array([9, 2, 5, 3, 7, 4]),\n",
      "                array([[0, 0, 1, 0, 1, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 1, 0, 1]])],\n",
      "        output=array([ 35,   9, 120]))\n",
      "\n",
      "Task name: stackoverflow_39\n",
      "Example(inputs=[array([[-1.5,  1. ,  0.9,  2. ],\n",
      "       [ 1.1,  0. , -0.1, -0.9],\n",
      "       [-1. ,  0.1, -1.1,  2.5]])],\n",
      "        output=array([[2.25, 1.  , 0.  , 4.  ],\n",
      "       [1.21, 0.  , 0.  , 0.  ],\n",
      "       [1.  , 0.  , 1.21, 6.25]]))\n",
      "\n",
      "Task name: stackoverflow_40\n",
      "Example(inputs=[array([4, 5, 2, 7, 8, 6]),\n",
      "                array([[0, 2],\n",
      "       [0, 4],\n",
      "       [1, 1],\n",
      "       [1, 3],\n",
      "       [2, 0],\n",
      "       [2, 3]])],\n",
      "        output=array([[0, 0, 4, 0, 5],\n",
      "       [0, 2, 0, 7, 0],\n",
      "       [8, 0, 0, 6, 0]]))\n",
      "\n",
      "Task name: stackoverflow_41\n",
      "Example(inputs=[array([5, 2, 8, 2, 4, 1, 1, 0, 2, 1]), array(3)],\n",
      "        output=array([5, 2, 8, 4, 1, 1, 0, 2, 1]))\n",
      "\n",
      "Task name: stackoverflow_42\n",
      "Example(inputs=[array([ 4,  6,  2,  6,  7,  3, -3])],\n",
      "        output=array([0, 0, 0, 0, 1, 0, 0]))\n",
      "\n",
      "Task name: stackoverflow_43\n",
      "Example(inputs=[array([[12, 34, 56, 78, 90, 10],\n",
      "       [99, 88, 77, 55, 44, 33],\n",
      "       [-1, -2, -3, -4, -5, -6]]),\n",
      "                array([0, 1, 1, 0, 2, 0])],\n",
      "        output=array([12, 88, 77, 78, -5, 10]))\n",
      "\n",
      "Task name: stackoverflow_44\n",
      "Example(inputs=[array([[ 3,  5,  2],\n",
      "       [ 6,  2,  3],\n",
      "       [ 8,  7,  1],\n",
      "       [ 0, -3,  5],\n",
      "       [-4,  7,  3],\n",
      "       [ 2,  1,  6],\n",
      "       [10, 20, 30],\n",
      "       [ 4,  5,  6]])],\n",
      "        output=array([[ 9,  7,  5],\n",
      "       [ 8,  4,  6],\n",
      "       [-2,  8,  9],\n",
      "       [14, 25, 36]]))\n",
      "\n",
      "Task name: stackoverflow_45\n",
      "Example(inputs=[array([[[12, 34],\n",
      "        [56, 78],\n",
      "        [23, 54],\n",
      "        [76, 78],\n",
      "        [42, 24]]]),\n",
      "                array([1, 0, 1, 0, 1])],\n",
      "        output=array([[[34, 12],\n",
      "        [56, 78],\n",
      "        [54, 23],\n",
      "        [76, 78],\n",
      "        [24, 42]]]))\n",
      "\n",
      "Task name: stackoverflow_46\n",
      "Example(inputs=[array([3, 4, 1])], output=array([0, 0, 0, 1, 1, 1, 1, 2]))\n",
      "\n",
      "Task name: stackoverflow_47\n",
      "Example(inputs=[array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16]),\n",
      "                array([[ True,  True,  True, False, False],\n",
      "       [ True,  True, False, False, False],\n",
      "       [ True,  True,  True,  True,  True],\n",
      "       [ True,  True,  True,  True, False],\n",
      "       [ True, False, False, False, False],\n",
      "       [ True,  True, False, False, False]])],\n",
      "        output=array([[ 0,  1,  2,  0,  0],\n",
      "       [ 3,  4,  0,  0,  0],\n",
      "       [ 5,  6,  7,  8,  9],\n",
      "       [10, 11, 12, 13,  0],\n",
      "       [14,  0,  0,  0,  0],\n",
      "       [15, 16,  0,  0,  0]]))\n",
      "\n",
      "Task name: stackoverflow_48\n",
      "Example(inputs=[array([32, 53, 45, 38, 29, 89, 64, 23]),\n",
      "                array([38, 53, 89, 38, 32, 64])],\n",
      "        output=array([3, 1, 5, 3, 0, 6]))\n",
      "\n",
      "Task name: stackoverflow_49\n",
      "Example(inputs=[array([[[[0.1, 0.2, 0.3],\n",
      "         [0.4, 0.5, 0.6]]],\n",
      "\n",
      "\n",
      "       [[[0.8, 1. , 0. ],\n",
      "         [0.6, 0.4, 0.2]]],\n",
      "\n",
      "\n",
      "       [[[0.9, 0.8, 0.7],\n",
      "         [0.1, 0.2, 0.3]]]]),\n",
      "                array([2. , 0.5, 1. ])],\n",
      "        output=array([[[[0.2, 0.4, 0.6],\n",
      "         [0.8, 1. , 1.2]]],\n",
      "\n",
      "\n",
      "       [[[0.4, 0.5, 0. ],\n",
      "         [0.3, 0.2, 0.1]]],\n",
      "\n",
      "\n",
      "       [[[0.9, 0.8, 0.7],\n",
      "         [0.1, 0.2, 0.3]]]]))\n",
      "\n",
      "Task name: stackoverflow_50\n",
      "Example(inputs=[array(5)],\n",
      "        output=array([[0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0]]))\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 21:49:58.656353: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Example:\n",
    "    inputs: t.List[np.ndarray]\n",
    "    output: t.Union[np.ndarray, tf.SparseTensor]\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, examples: ExamplesJSON):\n",
    "        try:\n",
    "            evaluated_inputs = eval(examples[\"inputs\"])\n",
    "            if isinstance(evaluated_inputs, list):\n",
    "                inputs = [np.array(i) for i in evaluated_inputs]\n",
    "            else:\n",
    "                inputs = [evaluated_inputs]\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating inputs: {e}\")\n",
    "            print(f\"Inputs: {examples['inputs']}\")\n",
    "            raise e\n",
    "\n",
    "        try:\n",
    "            evaluated_outputs = eval(examples[\"outputs\"])\n",
    "            if isinstance(evaluated_outputs, list):\n",
    "                outputs = np.array(evaluated_outputs)\n",
    "            elif isinstance(evaluated_outputs, tf.SparseTensor):\n",
    "                outputs = evaluated_outputs\n",
    "            elif isinstance(evaluated_outputs, tf.Tensor):\n",
    "                outputs = evaluated_outputs.numpy()\n",
    "            else:\n",
    "                outputs = evaluated_outputs\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating outputs: {e}\")\n",
    "            print(f\"Outputs: {examples['outputs']}\")\n",
    "            raise e\n",
    "\n",
    "        return cls(inputs, outputs)\n",
    "\n",
    "SKIP_TASKS = [] # [\"google_13\", \"stackoverflow_05\", \"stackoverflow_10\", \"stackoverflow_13\"]\n",
    "\n",
    "# for each task in dataset, show inputs and outputs\n",
    "for task in DATASET:\n",
    "    if task[\"name\"] in SKIP_TASKS:\n",
    "        continue\n",
    "    print(f\"Task name: {task['name']}\")\n",
    "    pprint(Example.from_json(task[\"examples\"]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<string>, line 2)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/arga-arc/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3553\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[15], line 49\u001b[0m\n    pprint([evaluate_completion(completion) for completion in TEST_COMPLETIONS])\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[15], line 49\u001b[0m in \u001b[1;35m<listcomp>\u001b[0m\n    pprint([evaluate_completion(completion) for completion in TEST_COMPLETIONS])\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 14\u001b[0;36m in \u001b[0;35mevaluate_completion\u001b[0;36m\n\u001b[0;31m    return [eval(completion)]\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>:2\u001b[0;36m\u001b[0m\n\u001b[0;31m    input = tf.constant([[1, 2, 3, 4], [5, 6, 7, 8]])\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "TEST_COMPLETIONS = [\n",
    "\"\"\"\n",
    "input = tf.constant([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "\n",
    "output = tf.repeat(input, repeats=6, axis=0)\n",
    "\"\"\"\n",
    "]\n",
    "\n",
    "def evaluate_completion(completion: str) -> t.List[t.Union[np.ndarray, tf.SparseTensor]]:\n",
    "    \"\"\"\n",
    "    evaluates the completion, returning any local variables with an \n",
    "    array-like value\n",
    "    \"\"\"\n",
    "    \n",
    "    locals_dict = {}\n",
    "    try:\n",
    "        exec(completion, None, locals_dict)\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating completion: {e}\")\n",
    "        print(f\"Completion: {completion}\")\n",
    "        return []\n",
    "    \n",
    "    ans = []\n",
    "\n",
    "    for key, value in locals_dict.items():\n",
    "        try:\n",
    "            if isinstance(value, np.ndarray) or isinstance(value, tf.SparseTensor):\n",
    "                ans.append(value)\n",
    "            elif isinstance(value, tf.Tensor):\n",
    "                ans.append(value.numpy())\n",
    "            elif isinstance(value, list):\n",
    "                ans.append(np.array(value))\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding value: {e}\")\n",
    "            print(f\"Key: {key}\")\n",
    "            print(\"value:\")\n",
    "            pprint(value)\n",
    "            print(f\"Type: {type(value)}\")\n",
    "    return ans\n",
    "\n",
    "def matches_expected_value(actual: t.Union[np.ndarray, tf.SparseTensor], expected: t.Union[np.ndarray, tf.SparseTensor]) -> bool:\n",
    "    if isinstance(actual, np.ndarray) and isinstance(expected, np.ndarray):\n",
    "        return np.array_equal(actual, expected)\n",
    "    elif isinstance(actual, tf.SparseTensor) and isinstance(expected, tf.SparseTensor):\n",
    "        return tf.sparse.equal(actual, expected)\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "pprint([evaluate_completion(completion) for completion in TEST_COMPLETIONS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def transform():\n",
      "   weights = tf.range(0, tf.shape(in1)[1], 1)\n",
      "   in1_weighted = tf.multiply(in1, tf.cast(weights, tf.float32))\n",
      "   return tf.reduce_sum(in1_weighted, axis=1)\n",
      "\n",
      "def transform():\n",
      "   dense_in1 = tf.sparse.to_dense(in1[0], validate_indices=False)\n",
      "   return tf.reduce_sum(tf.math.squared_difference(in1[1], dense_in1))\n",
      "\n",
      "def transform():\n",
      "   result = tf.zeros_like(in2, dtype=tf.int32)\n",
      "   counter = tf.constant([0])\n",
      "   for i in range(in2.shape[0]):\n",
      "       for j in range(in2.shape[1]):\n",
      "           if in2[i][j]:\n",
      "               result[i,j].assign(in1[counter])\n",
      "               counter += 1\n",
      "   return result\n",
      "\n",
      "def transform():\n",
      "   segments = tf.math.bincount(in1)\n",
      "   order = tf.argsort(in1, stable=True)\n",
      "   sorted_values = tf.gather(in2, order)\n",
      "   segment_marks = tf.cumsum(segments)\n",
      "   \n",
      "   starts = tf.pad(segment_marks[:-1], [[1,0]])\n",
      "   ends = tf.pad(segment_marks[1:], [[0,1]])\n",
      "   \n",
      "   segments = []\n",
      "   for i in range(len(starts)):\n",
      "       segment = sorted_values[starts[i]:ends[i]]\n",
      "       segments.append(segment)\n",
      "   \n",
      "   return tf.concat(segments, 0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FIXUP_EXAMPLE_COMPLETIONS = [\n",
    "    \"\"\"weights = tf.range(0, tf.shape(in1)[1], 1)\n",
    "in1_weighted = tf.multiply(in1, tf.cast(weights, tf.float32))\n",
    "return tf.reduce_sum(in1_weighted, axis=1)\"\"\",\n",
    "    \"\"\"dense_in1 = tf.sparse.to_dense(in1[0], validate_indices=False)\n",
    "     return tf.reduce_sum(tf.math.squared_difference(in1[1], dense_in1))\"\"\",\n",
    "    \"\"\"result = tf.zeros_like(in2, dtype=tf.int32)\n",
    "counter = tf.constant([0])\n",
    "for i in range(in2.shape[0]):\n",
    "    for j in range(in2.shape[1]):\n",
    "        if in2[i][j]:\n",
    "            result[i,j].assign(in1[counter])\n",
    "            counter += 1\n",
    "return result\"\"\",\n",
    "    \"\"\"segments = tf.math.bincount(in1)\n",
    "order = tf.argsort(in1, stable=True)\n",
    "sorted_values = tf.gather(in2, order)\n",
    "segment_marks = tf.cumsum(segments)\n",
    "\n",
    "starts = tf.pad(segment_marks[:-1], [[1,0]])\n",
    "ends = tf.pad(segment_marks[1:], [[0,1]])\n",
    "\n",
    "segments = []\n",
    "for i in range(len(starts)):\n",
    "    segment = sorted_values[starts[i]:ends[i]]\n",
    "    segments.append(segment)\n",
    "\n",
    "return tf.concat(segments, 0)\"\"\"\n",
    "]\n",
    "\n",
    "def fixup_completion(prefix: str, completion: str) -> str:\n",
    "    lines = completion.split(\"\\n\")\n",
    "\n",
    "    def combine_lines_and_prefix(ls):\n",
    "        return prefix + \"\\n\" + \"\\n\".join([f\"   {line}\" for line in ls])\n",
    "\n",
    "    # if the completion contains a loop or conditional, keep indentation as is\n",
    "    if \"for \" in completion or \"while \" in completion or \"if \" in completion:\n",
    "        return combine_lines_and_prefix(lines)\n",
    "    \n",
    "    stripped_lines = [line.lstrip() for line in lines]\n",
    "    return combine_lines_and_prefix(stripped_lines)\n",
    "\n",
    "for completion in FIXUP_EXAMPLE_COMPLETIONS:\n",
    "    print(fixup_completion(\"def transform():\", completion))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: google_01\n",
      "return tf.stack([tf.math.bincount(in1), in1], axis=1)\n",
      "{{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [4] != values[1].shape = [6] [Op:Pack] name: stack\n",
      "\n",
      "return tf.stack([tf.divide(in1, tf.shape(in1)[0]), tf.mod(in1, tf.shape(in1)[0])], axis=1)\n",
      "module 'tensorflow' has no attribute 'mod'\n",
      "\n",
      "return tf.stack([tf.math.floor_div(in1, tf.constant(2, dtype=tf.int32)), tf.math.floormod(in1, tf.constant(2, dtype=tf.int32))], axis=1)\n",
      "module 'tensorflow._api.v2.math' has no attribute 'floor_div'\n",
      "\n",
      "return tf.stack([tf.floor_div(in1, 2), tf.mod(in1, 2)], axis=1)\n",
      "module 'tensorflow' has no attribute 'floor_div'\n",
      "\n",
      "return tf.stack([tf.math.floor_divide(in1, tf.shape(in1)[0]), tf.math.mod(in1, tf.shape(in1)[0])], axis=1)\n",
      "module 'tensorflow._api.v2.math' has no attribute 'floor_divide'\n",
      "\n",
      "return tf.stack([tf.math.floor_divide(in1, tf.reduce_max(in1) + 1), tf.math.floormod(in1, tf.reduce_max(in1) + 1)], axis=1)\n",
      "module 'tensorflow._api.v2.math' has no attribute 'floor_divide'\n",
      "\n",
      "return tf.stack([tf.math.floor_div(in1, tf.reduce_max(in1) + 1), tf.math.floormod(in1, tf.reduce_max(in1) + 1)], axis=1)\n",
      "module 'tensorflow._api.v2.math' has no attribute 'floor_div'\n",
      "\n",
      "return tf.stack([tf.math.floor_div(in1, tf.reduce_max(in1) + 1), tf.math.floormod(in1, tf.reduce_max(in1) + 1)], axis=1)\n",
      "module 'tensorflow._api.v2.math' has no attribute 'floor_div'\n",
      "\n",
      "return tf.stack([tf.math.bincount(in1), tf.cast(in1, tf.int32)], axis=1)\n",
      "{{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [4] != values[1].shape = [6] [Op:Pack] name: stack\n",
      "\n",
      "return tf.stack([tf.divide(in1, tf.shape(in1)[0]), tf.math.bincount(in1)], axis=1)\n",
      "cannot compute Pack as input #1(zero-based) was expected to be a double tensor but is a int32 tensor [Op:Pack] name: stack\n",
      "\n",
      "0\n",
      "\n",
      "Task: google_03\n",
      "return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, [0, 0, 0], [1, -1, -1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, [0,0,0], [1,-1,-1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, start=[0, 0, 0], size=[1, -1, -1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, [0, 0, 0], [1, -1, -1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, start=[0,0,0], size=[1, -1, -1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "0\n",
      "\n",
      "Task: google_04\n",
      "0\n",
      "\n",
      "Task: google_05\n",
      "return tf.expand_dims(in1, axis=1) + tf.zeros([1, 6, 1], tf.int32)\n",
      "cannot compute AddV2 as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:AddV2] name: \n",
      "\n",
      "0\n",
      "\n",
      "Task: google_06\n",
      "0\n",
      "\n",
      "Task: google_07\n",
      "0\n",
      "\n",
      "Task: google_08\n",
      "0\n",
      "\n",
      "Task: google_09\n",
      "max_idx = tf.reduce_max(in1)+1\n",
      "segment_min = tf.math.unsorted_segment_min(in2, in1, max_idx)\n",
      "segment_max = tf.math.unsorted_segment_max(in2, in1, max_idx)\n",
      "sort_base = tf.cast(in1, tf.float32) + tf.divide(in2 - segment_min, segment_max - segment_min + 1) / 10 \n",
      "idx = tf.argsort(sort_base)\n",
      "return tf.gather(in2, idx)\n",
      "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [6] vs. [3] [Op:Sub] name: \n",
      "\n",
      "return tf.unsorted_segment_min(in2, in1, tf.reduce_max(in1)+1)\n",
      "module 'tensorflow' has no attribute 'unsorted_segment_min'\n",
      "\n",
      "segments = tf.argsort(tf.unique_with_counts(in1)[0])\n",
      "segment_ids = tf.cast(tf.searchsorted(segments, in1), tf.float32)\n",
      "sorted_values = tf.math.segment_min(in2, segment_ids)\n",
      "combined = tf.stack([segment_ids, sorted_values], axis=-1)\n",
      "perm = tf.argsort(combined[:, 0])\n",
      "return tf.gather(combined[:, 1], perm)\n",
      "cannot compute LowerBound as input #1(zero-based) was expected to be a int32 tensor but is a int64 tensor [Op:LowerBound] name: \n",
      "\n",
      "0\n",
      "\n",
      "Task: google_11\n",
      "0\n",
      "\n",
      "Task: google_12\n",
      "0\n",
      "\n",
      "Task: google_13\n",
      "0\n",
      "\n",
      "Task: google_14\n",
      "0\n",
      "\n",
      "Task: google_15\n",
      "0\n",
      "\n",
      "Task: google_16\n",
      "0\n",
      "\n",
      "Task: google_17\n",
      "return tf.where(in1, in2, tf.multiply(-10, tf.range(tf.shape(in2)[0]));\n",
      "invalid syntax (<string>, line 2)\n",
      "\n",
      "0\n",
      "\n",
      "Task: google_18\n",
      "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + 1)[in2 - 1]\n",
      "Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([0, 1, 2, 0, 1])\n",
      "\n",
      "0\n",
      "\n",
      "Task: google_19\n",
      "indices = tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1)\n",
      "    return tf.gather_nd(in1, indices)\n",
      "{{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [3] != values[1].shape = [3,3] [Op:Pack] name: stack\n",
      "\n",
      "0\n",
      "\n",
      "Task: google_20\n",
      "1\n",
      "\n",
      "Task: google_21\n",
      "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(tf.constant(in1['tensor'], dtype=tf.int32), tf.constant(in1['indices'], dtype=tf.int32), tf.constant(in1['updates'], dtype=tf.int32))\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate] name: \n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1[\"tensor\"], in1[\"indices\"], in1[\"updates\"])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(tf.constant(in1['tensor'], tf.int32), tf.constant(in1['indices'], tf.int32), tf.constant(in1['updates'], tf.int32))\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate] name: \n",
      "\n",
      "0\n",
      "\n",
      "Task: google_22\n",
      "ind = tf.reshape(tf.range(tf.shape(in1)[0]), (-1, 1))\n",
      " return tf.reshape(tf.concat([tf.tile(ind, [1, tf.shape(in1)[1]]), in1], axis=2), [-1, 2])\n",
      "{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Expected concatenating dimensions in the range [-2, 2), but got 2 [Op:ConcatV2] name: concat\n",
      "\n",
      "return tf.reshape(tf.transpose(tf.stack([tf.repeat(tf.range(tf.shape(in1)[0]), tf.shape(in1)[1]), tf.reshape(in1, [-1])])), [-1, 2])\n",
      "cannot compute Pack as input #1(zero-based) was expected to be a int32 tensor but is a int64 tensor [Op:Pack] name: stack\n",
      "\n",
      "return tf.reshape(tf.concat([tf.expand_dims(tf.range(tf.shape(in1)[0]), axis=1), in1], axis=2), [-1, 2])\n",
      "{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Expected concatenating dimensions in the range [-2, 2), but got 2 [Op:ConcatV2] name: concat\n",
      "\n",
      "indices = tf.range(tf.shape(in1)[0])\n",
      "    return tf.reshape(tf.stack([tf.repeat(indices, tf.shape(in1)[1]), tf.reshape(in1, [-1])], axis=1), [-1,2])\n",
      "cannot compute Pack as input #1(zero-based) was expected to be a int32 tensor but is a int64 tensor [Op:Pack] name: stack\n",
      "\n",
      "return tf.reshape(tf.transpose(tf.stack([tf.repeat(tf.range(tf.shape(in1)[0]), tf.shape(in1)[1]), tf.reshape(in1, [-1])])), [-1, 2])\n",
      "cannot compute Pack as input #1(zero-based) was expected to be a int32 tensor but is a int64 tensor [Op:Pack] name: stack\n",
      "\n",
      "return tf.concat([tf.expand_dims(tf.cast(tf.range(tf.shape(in1)[0]), tf.int32), 1), tf.reshape(in1, [-1, 1])], axis=1)\n",
      "cannot compute ConcatV2 as input #1(zero-based) was expected to be a int32 tensor but is a int64 tensor [Op:ConcatV2] name: concat\n",
      "\n",
      "0\n",
      "\n",
      "Task: stackoverflow_01\n",
      "0\n",
      "\n",
      "Task: stackoverflow_02\n",
      "return tf.clip_by_value(in1, -tf.constant(1e10), tf.constant(1))\n",
      "cannot compute Minimum as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:Minimum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(np.inf), tf.constant(1.))\n",
      "cannot compute Minimum as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:Minimum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(float('inf')), 1)\n",
      "cannot compute Maximum as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:Maximum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(float('inf')), tf.constant(1))\n",
      "cannot compute Minimum as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:Minimum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(float('inf')), 1)\n",
      "cannot compute Maximum as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:Maximum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(np.inf), 1)\n",
      "cannot compute Maximum as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:Maximum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(np.inf), tf.constant(1))\n",
      "cannot compute Minimum as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:Minimum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(float('inf')), 1)\n",
      "cannot compute Maximum as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:Maximum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(float('inf')), 1)\n",
      "cannot compute Maximum as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:Maximum] name: \n",
      "\n",
      "0\n",
      "\n",
      "Task: stackoverflow_03\n",
      "return tf.tensor_scatter_nd_update(in1, [[0,3], [0,4], [1,3], [1,4]], tf.gather(in2, [3,4,3,4]))\n",
      "{{function_node __wrapped__GatherV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[0] = 3 is not in [0, 2) [Op:GatherV2]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1, [[0,3], [0,4], [1,3], [1,4]], tf.gather(in2, [3,4], axis=1))\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [4,2], updates shape:[2,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "indices = tf.constant([[3,4]])\n",
      "return tf.tensor_scatter_nd_update(in1, indices, tf.gather(in2, indices))\n",
      "{{function_node __wrapped__GatherV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[0,0] = 3 is not in [0, 2) [Op:GatherV2] name: \n",
      "\n",
      "0\n",
      "\n",
      "Task: stackoverflow_04\n",
      "0\n",
      "\n",
      "Task: stackoverflow_05\n",
      "0\n",
      "\n",
      "Task: stackoverflow_06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 23:58:53.498181: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:58:53.498852: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:58:53.499561: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:58:53.500530: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:58:53.501146: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:58:53.501738: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:58:53.502338: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:58:53.502985: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:58:53.503595: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:58:53.504197: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "/home/ubuntu/arga-arc/.venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:103: RuntimeWarning: invalid value encountered in cast\n",
      "  return ops.EagerTensor(value, ctx.device_name, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "Task: stackoverflow_08\n",
      "0\n",
      "\n",
      "Task: stackoverflow_09\n",
      "_, idx, count = tf.unique_with_counts(in1)\n",
      "return tf.gather(idx, in1)\n",
      "{{function_node __wrapped__GatherV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[0] = 37 is not in [0, 8) [Op:GatherV2] name: \n",
      "\n",
      "_, idx = tf.unique_with_counts(in1)\n",
      "return idx\n",
      "too many values to unpack (expected 2)\n",
      "\n",
      "_, idx = tf.unique_with_counts(in1)\n",
      " return tf.gather(idx, in1)\n",
      "too many values to unpack (expected 2)\n",
      "\n",
      "1\n",
      "\n",
      "Task: stackoverflow_10\n",
      "return tf.matmul(tf.expand_dims(in1, 0), tf.expand_dims(in2, -1))\n",
      "{{function_node __wrapped__BatchMatMulV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [1,2,2], In[1]: [2,3,1] [Op:BatchMatMulV2] name: \n",
      "\n",
      "return tf.matmul(tf.expand_dims(in1,axis =2), tf.reshape(in2,[in1.shape[1],-1,1]))\n",
      "{{function_node __wrapped__BatchMatMulV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [2,2,1], In[1]: [2,3,1] [Op:BatchMatMulV2] name: \n",
      "\n",
      "return tf.matmul(tf.expand_dims(in1, 0), tf.expand_dims(in2, -1))\n",
      "{{function_node __wrapped__BatchMatMulV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [1,2,2], In[1]: [2,3,1] [Op:BatchMatMulV2] name: \n",
      "\n",
      "0\n",
      "\n",
      "Task: stackoverflow_11\n",
      "0\n",
      "\n",
      "Task: stackoverflow_12\n",
      "0\n",
      "\n",
      "Task: stackoverflow_13\n",
      "return tf.matmul(in1, tf.cast(in2, tf.int32))\n",
      "cannot compute BatchMatMulV2 as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:BatchMatMulV2] name: \n",
      "\n",
      "return tf.matmul(in2, tf.cast(tf.transpose(in1), tf.int32))\n",
      "cannot compute BatchMatMulV2 as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:BatchMatMulV2] name: \n",
      "\n",
      "0\n",
      "\n",
      "Task: stackoverflow_14\n",
      "0\n",
      "\n",
      "Task: stackoverflow_15\n",
      "0\n",
      "\n",
      "Task: stackoverflow_16\n",
      "0\n",
      "\n",
      "Task: stackoverflow_17\n",
      "return tf.expand_dims(in1, 1) * tf.ones((1, 2), dtype=tf.int32)\n",
      "cannot compute Mul as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:Mul] name: \n",
      "\n",
      "return tf.expand_dims(in1, 1) * tf.ones([1,2], dtype=tf.int32)\n",
      "cannot compute Mul as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:Mul] name: \n",
      "\n",
      "return tf.expand_dims(in1, axis=1) * tf.ones([1, 2])\n",
      "cannot compute Mul as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:Mul] name: \n",
      "\n",
      "return tf.expand_dims(in1, 1) * tf.ones([1, 2], dtype=tf.int32)\n",
      "cannot compute Mul as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:Mul] name: \n",
      "\n",
      "0\n",
      "\n",
      "Task: stackoverflow_18\n",
      "return tf.add(tf.tensordot(in1, in2, axes=([2],[0])), tf.cast(in3, tf.int32))\n",
      "cannot compute AddV2 as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:AddV2] name: \n",
      "\n",
      "0\n",
      "\n",
      "Task: stackoverflow_19\n",
      "0\n",
      "\n",
      "Task: stackoverflow_20\n",
      "return tf.one_hot(tf.argmax(in1, axis=1), depth=in1.get_shape().as_list()[1])\n",
      "'numpy.ndarray' object has no attribute 'get_shape'\n",
      "\n",
      "return tf.one_hot(tf.argmax(in1, axis=1), depth=in1.get_shape()[1])\n",
      "'numpy.ndarray' object has no attribute 'get_shape'\n",
      "\n",
      "0\n",
      "\n",
      "Task: stackoverflow_21\n",
      "0\n",
      "\n",
      "Task: stackoverflow_22\n",
      "return tf.tensordot(in1, in2, axes=1)\n",
      "cannot compute MatMul as input #1(zero-based) was expected to be a int64 tensor but is a double tensor [Op:MatMul] name: \n",
      "\n",
      "return tf.matmul(tf.cast(in1, tf.float32), in2)\n",
      "{{function_node __wrapped____MklMatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} In[0] ndims must be >= 2 [Op:MatMul] name: \n",
      "\n",
      "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3] vs. [3,2] [Op:Mul] name: \n",
      "\n",
      "return tf.reduce_sum(tf.multiply(tf.cast(in1, tf.float32), in2), axis=0)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3] vs. [3,2] [Op:Mul] name: \n",
      "\n",
      "return tf.reduce_sum(tf.multiply(tf.cast(in1, tf.float32), in2), axis=0)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3] vs. [3,2] [Op:Mul] name: \n",
      "\n",
      "return tf.reduce_sum(tf.multiply(tf.cast(in1, dtype=tf.float32), in2), axis=0)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3] vs. [3,2] [Op:Mul] name: \n",
      "\n",
      "return tf.tensordot(in1, in2, axes=1)\n",
      "cannot compute MatMul as input #1(zero-based) was expected to be a int64 tensor but is a double tensor [Op:MatMul] name: \n",
      "\n",
      "return tf.reduce_sum(tf.multiply(tf.cast(in1, tf.float32), in2), 0)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3] vs. [3,2] [Op:Mul] name: \n",
      "\n",
      "0\n",
      "\n",
      "Task: stackoverflow_23\n",
      "return tf.cast(tf.one_hot(in1, tf.reduce_max(in1)+1), tf.int32)\n",
      "cannot compute OneHot as input #1(zero-based) was expected to be a int32 tensor but is a int64 tensor [Op:OneHot] name: \n",
      "\n",
      "return tf.reduce_any(tf.one_hot(in1, 9), axis=1, keepdims=False)\n",
      "cannot compute Any as input #0(zero-based) was expected to be a bool tensor but is a float tensor [Op:Any] name: \n",
      "\n",
      "0\n",
      "\n",
      "Task: stackoverflow_24\n",
      "0\n",
      "\n",
      "Task: stackoverflow_25\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.reshape(tf.tile(tf.eye(in1), [in2, 1]), [-1, in1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.reshape(tf.tile(tf.eye(in1), [in2, 1]), [-1, in1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "0\n",
      "\n",
      "Task: stackoverflow_26\n",
      "0\n",
      "\n",
      "Task: stackoverflow_27\n",
      "return tf.cast(tf.sequence_mask(in1, in2), int)\n",
      "Cannot convert the argument `type_value`: <class 'int'> to a TensorFlow DType.\n",
      "\n",
      "0\n",
      "\n",
      "Task: stackoverflow_28\n",
      "0\n",
      "\n",
      "Task: stackoverflow_29\n",
      "0\n",
      "\n",
      "Task: stackoverflow_30\n",
      "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.transpose(in2))), axis=1))\n",
      "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3,2] vs. [2,3] [Op:Sub] name: \n",
      "\n",
      "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.transpose(in2))), axis=1))\n",
      "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3,2] vs. [2,3] [Op:Sub] name: \n",
      "\n",
      "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.transpose(in2))), axis=1))\n",
      "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3,2] vs. [2,3] [Op:Sub] name: \n",
      "\n",
      "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.transpose(in2))), axis=1))\n",
      "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3,2] vs. [2,3] [Op:Sub] name: \n",
      "\n",
      "0\n",
      "\n",
      "Task: stackoverflow_31\n",
      "return tf.reduce_sum(tf.math.squared_difference(in1.values, tf.gather_nd(in2, in1.indices)))\n",
      "'tuple' object has no attribute 'values'\n",
      "\n",
      "dense1 = tf.sparse.to_dense(in1)\n",
      "return tf.reduce_sum(tf.math.squared_difference(dense1, in1))\n",
      "Input must be a SparseTensor.\n",
      "\n",
      "return tf.reduce_sum(tf.math.squared_difference(in1[0], tf.cast(in1[1], tf.float32)))\n",
      "Attempt to convert a value (SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [1 1]], shape=(3, 2), dtype=int64), values=tf.Tensor([ 1.   1.5 -2. ], shape=(3,), dtype=float32), dense_shape=tf.Tensor([2 2], shape=(2,), dtype=int64))) with an unsupported type (<class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>) to a Tensor.\n",
      "\n",
      "return tf.reduce_sum(tf.math.squared_difference(in1.values, tf.gather_nd(in2, in1.indices)))\n",
      "'tuple' object has no attribute 'values'\n",
      "\n",
      "return tf.reduce_sum(tf.square(tf.subtract(in1.values, tf.gather_nd(in1.indices))))\n",
      "'tuple' object has no attribute 'values'\n",
      "\n",
      "dense_tensor = tf.sparse.to_dense(in1)\n",
      "return tf.reduce_sum(tf.math.squared_difference(in1, dense_tensor))\n",
      "Input must be a SparseTensor.\n",
      "\n",
      "0\n",
      "\n",
      "Task: stackoverflow_32\n",
      "0\n",
      "\n",
      "Task: stackoverflow_33\n",
      "return tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=2), tf.expand_dims(in2, axis=1))), axis=-1)), axis=-1)\n",
      "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [5,3,1] vs. [4,1,3] [Op:Sub] name: \n",
      "\n",
      "0\n",
      "\n",
      "Task: stackoverflow_34\n",
      "return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(in2, axis=-1)), axis=0)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3,2,2] vs. [3,1] [Op:Mul] name: \n",
      "\n",
      "return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(tf.cast(in2, tf.float32), -1)), axis=0)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3,2,2] vs. [3,1] [Op:Mul] name: \n",
      "\n",
      "return tf.tensordot(in1, in2, axes=[0])\n",
      "`axes` must be an integer or have length 2. Received [0].\n",
      "\n",
      "0\n",
      "\n",
      "Task: stackoverflow_35\n",
      "return tf.add(tf.multiply(in1, tf.expand_dims(tf.expand_dims(1 - in3, 1), 2)), tf.multiply(in2, tf.expand_dims(tf.expand_dims(in3, 1), 2)))\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [2,3,2] vs. [3,1,1] [Op:Mul] name: \n",
      "\n",
      "return tf.add(tf.multiply(tf.subtract(in2, in1), tf.expand_dims(tf.expand_dims(in3, 1), 2)), in1)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [2,3,2] vs. [3,1,1] [Op:Mul] name: \n",
      "\n",
      "return tf.add(tf.multiply(in1, tf.reshape(1 - in3, (-1, 1, 1))), tf.multiply(in2, tf.reshape(in3, (-1, 1, 1))))\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [2,3,2] vs. [3,1,1] [Op:Mul] name: \n",
      "\n",
      "return tf.add(tf.multiply(in1, tf.expand_dims(tf.expand_dims(tf.subtract(tf.constant(1.0), in3), 1), 2)), tf.multiply(in2, tf.expand_dims(tf.expand_dims(in3, 1), 2)))\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [2,3,2] vs. [3,1,1] [Op:Mul] name: \n",
      "\n",
      "return tf.add(tf.multiply(tf.expand_dims(in3, axis=[1,2]), tf.subtract(in2, in1)), in1)\n",
      "{{function_node __wrapped__ExpandDims_device_/job:localhost/replica:0/task:0/device:CPU:0}} 'dim' must be a tensor with a single value [Op:ExpandDims]\n",
      "\n",
      "return tf.add(tf.multiply(in1, tf.reshape(1 - in3, [-1, 1, 1])), tf.multiply(in2, tf.reshape(in3, [-1, 1, 1])))\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [2,3,2] vs. [3,1,1] [Op:Mul] name: \n",
      "\n",
      "return tf.add(tf.multiply(in1, tf.reshape(1. - in3, [in3.shape[0], 1, 1])), tf.multiply(in2, tf.reshape(in3, [in3.shape[0], 1, 1])))\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [2,3,2] vs. [3,1,1] [Op:Mul] name: \n",
      "\n",
      "return tf.add(tf.multiply(in1, tf.subtract(1.0, tf.expand_dims(tf.expand_dims(in3, 1), 2))), tf.multiply(in2, tf.expand_dims(tf.expand_dims(in3, 1), 2)))\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [2,3,2] vs. [3,1,1] [Op:Mul] name: \n",
      "\n",
      "0\n",
      "\n",
      "Task: stackoverflow_36\n",
      "0\n",
      "\n",
      "Task: stackoverflow_37\n",
      "return tf.tensordot(in1, tf.expand_dims(in2, 0), [[-1], [0]])\n",
      "{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [4,3], In[1]: [1,3] [Op:MatMul] name: \n",
      "\n",
      "0\n",
      "\n",
      "Task: stackoverflow_38\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.reshape(tf.boolean_mask(in1, tf.concat(in2, axis=0)), [tf.shape(in2)[0], -1]), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "0\n",
      "\n",
      "Task: stackoverflow_39\n",
      "0\n",
      "\n",
      "Task: stackoverflow_40\n",
      "0\n",
      "\n",
      "Task: stackoverflow_41\n",
      "0\n",
      "\n",
      "Task: stackoverflow_42\n",
      "0\n",
      "\n",
      "Task: stackoverflow_43\n",
      "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1))\n",
      "{{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd [Op:GatherNd] name: \n",
      "\n",
      "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in1)[1]), in2], axis=1))\n",
      "{{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd [Op:GatherNd] name: \n",
      "\n",
      "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1))\n",
      "{{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd [Op:GatherNd] name: \n",
      "\n",
      "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1))\n",
      "{{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd [Op:GatherNd] name: \n",
      "\n",
      "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1))\n",
      "{{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd [Op:GatherNd] name: \n",
      "\n",
      "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1))\n",
      "{{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd [Op:GatherNd] name: \n",
      "\n",
      "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1))\n",
      "{{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd [Op:GatherNd] name: \n",
      "\n",
      "1\n",
      "\n",
      "Task: stackoverflow_44\n",
      "0\n",
      "\n",
      "Task: stackoverflow_45\n",
      "return tf.where(tf.equal(in2, 1), tf.reverse(in1, axis=[2]), in1)\n",
      "{{function_node __wrapped__SelectV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} condition [5], then [1,5,2], and else [1,5,2] must be broadcastable [Op:SelectV2] name: \n",
      "\n",
      "return tf.where(tf.expand_dims(in2, axis=-1), tf.reverse(in1, axis=[1]), in1)\n",
      "cannot compute SelectV2 as input #0(zero-based) was expected to be a bool tensor but is a int64 tensor [Op:SelectV2] name: \n",
      "\n",
      "return tf.where(tf.expand_dims(in2, -1), tf.reverse(in1, axis=[2]), in1)\n",
      "cannot compute SelectV2 as input #0(zero-based) was expected to be a bool tensor but is a int64 tensor [Op:SelectV2] name: \n",
      "\n",
      "return tf.where(tf.cast(in2, tf.bool), tf.reverse(in1, [-1]), in1)\n",
      "{{function_node __wrapped__SelectV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} condition [5], then [1,5,2], and else [1,5,2] must be broadcastable [Op:SelectV2] name: \n",
      "\n",
      "return tf.where(tf.cast(in2, tf.bool), in1[:, ::-1], in1)\n",
      "{{function_node __wrapped__SelectV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} condition [5], then [1,5,2], and else [1,5,2] must be broadcastable [Op:SelectV2] name: \n",
      "\n",
      "return tf.where(tf.expand_dims(in2, -1), tf.reverse(in1, axis=[2]), in1)\n",
      "cannot compute SelectV2 as input #0(zero-based) was expected to be a bool tensor but is a int64 tensor [Op:SelectV2] name: \n",
      "\n",
      "return tf.where(tf.equal(in2, 1), in1[:,:,::-1], in1)\n",
      "{{function_node __wrapped__SelectV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} condition [5], then [1,5,2], and else [1,5,2] must be broadcastable [Op:SelectV2] name: \n",
      "\n",
      "0\n",
      "\n",
      "Task: stackoverflow_46\n",
      "0\n",
      "\n",
      "Task: stackoverflow_47\n",
      "return tf.reshape(tf.boolean_mask(in1, tf.reshape(in2, [-1])), tf.shape(in2))\n",
      "Shapes (17,) and (30,) are incompatible\n",
      "\n",
      "indices = tf.where(in2)\n",
      " updates = tf.gather(in1, tf.range(tf.reduce_sum(tf.cast(in2, tf.int32))))\n",
      " return tf.scatter_nd(indices, updates, tf.shape(in2))\n",
      "cannot compute ScatterNd as input #2(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:ScatterNd] name: \n",
      "\n",
      "return tf.scatter_nd(tf.where(in2), in1[:tf.math.count_nonzero(in2)], tf.shape(in2))\n",
      "cannot compute ScatterNd as input #2(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:ScatterNd] name: \n",
      "\n",
      "return tf.boolean_mask(in1, tf.cast(tf.reshape(in2, [-1]), tf.bool), axis=0)\n",
      "Shapes (17,) and (30,) are incompatible\n",
      "\n",
      "shape = tf.shape(in2)\n",
      "in1 = tf.reshape(in1[:tf.reduce_sum(shape)], shape)\n",
      "result = tf.where(in2,in1,0)\n",
      "return result\n",
      "{{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 11 values, but the requested shape has 30 [Op:Reshape] name: \n",
      "\n",
      "mask = tf.cast(in2, tf.int32)\n",
      "idx = tf.reshape(tf.where(mask), [-1])\n",
      "val = tf.gather(in1, idx)\n",
      "padding = tf.fill(tf.shape(in2), 0)\n",
      "out = tf.where(mask, val, padding)\n",
      "return out\n",
      "cannot compute SelectV2 as input #0(zero-based) was expected to be a bool tensor but is a int32 tensor [Op:SelectV2] name: \n",
      "\n",
      "result = tf.zeros_like(in2, dtype=tf.int32)\n",
      "counter = tf.constant([0])\n",
      "for i in range(in2.shape[0]):\n",
      "    for j in range(in2.shape[1]):\n",
      "        if in2[i][j]:\n",
      "            result[i,j].assign(in1[counter])\n",
      "            counter += 1\n",
      "return result\n",
      "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'\n",
      "\n",
      "return tf.reshape(tf.boolean_mask(in1, tf.cast(tf.reshape(in2, [-1]), tf.bool)), tf.shape(in2))\n",
      "Shapes (17,) and (30,) are incompatible\n",
      "\n",
      "mask = tf.cast(in2, tf.int32)\n",
      "indices = tf.repeat(tf.range(tf.shape(mask)[1]), tf.reduce_sum(mask, axis=0))\n",
      "updates = tf.boolean_mask(in1, tf.reshape(mask, [-1]))\n",
      "shape = tf.shape(mask)\n",
      "return tf.scatter_nd(tf.expand_dims(indices, axis=-1), updates, shape)\n",
      "Shapes (17,) and (30,) are incompatible\n",
      "\n",
      "0\n",
      "\n",
      "Task: stackoverflow_48\n",
      "0\n",
      "\n",
      "Task: stackoverflow_49\n",
      "0\n",
      "\n",
      "Task: stackoverflow_50\n",
      "return tf.one_hot(in1, 2*in1, axis=1)\n",
      "{{function_node __wrapped__OneHot_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected axis to be -1 or between [0, 1).  But received: 1 [Op:OneHot]\n",
      "\n",
      "return tf.one_hot(in1, depth=in1*2, axis=1)\n",
      "{{function_node __wrapped__OneHot_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected axis to be -1 or between [0, 1).  But received: 1 [Op:OneHot]\n",
      "\n",
      "return tf.scatter_nd([[in1]], [1], [6, 6])\n",
      "{{function_node __wrapped__ScatterNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimensions [1,2) of input[shape=[6,6]] must match dimensions [1,1) of updates[shape=[1]] [Op:ScatterNd]\n",
      "\n",
      "return tf.one_hot(in1, 2*in1 + 1)[:, 3]\n",
      "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Index out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: strided_slice/\n",
      "\n",
      "return tf.one_hot(in1, in1*2)[:, in1]\n",
      "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Index out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: strided_slice/\n",
      "\n",
      "return tf.one_hot(in1, 2 * in1 + 1)[:, in1]\n",
      "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Index out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: strided_slice/\n",
      "\n",
      "return tf.pad(tf.expand_dims(tf.eye(in1, in1+1)[:, 3],-1), [[0,0],[0,0],[0,in1-1]])[:,:,0]\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=5, num_columns=6\n",
      "\n",
      "return tf.one_hot(in1, 2 * in1 + 1, dtype=tf.int32)[:, in1]\n",
      "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Index out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: strided_slice/\n",
      "\n",
      "0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 23:58:53.940496: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at gather_nd_op.cc:48 : INVALID_ARGUMENT: indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd\n",
      "2024-03-27 23:58:53.941473: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at gather_nd_op.cc:48 : INVALID_ARGUMENT: indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd\n",
      "2024-03-27 23:58:53.942684: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at gather_nd_op.cc:48 : INVALID_ARGUMENT: indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd\n",
      "2024-03-27 23:58:53.943494: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at gather_nd_op.cc:48 : INVALID_ARGUMENT: indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd\n",
      "2024-03-27 23:58:53.945010: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at gather_nd_op.cc:48 : INVALID_ARGUMENT: indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd\n",
      "2024-03-27 23:58:53.945793: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at gather_nd_op.cc:48 : INVALID_ARGUMENT: indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd\n",
      "2024-03-27 23:58:53.946586: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at gather_nd_op.cc:48 : INVALID_ARGUMENT: indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd\n",
      "2024-03-27 23:58:54.012120: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: Index out of range using input dim 1; input has only 1 dims\n",
      "2024-03-27 23:58:54.012838: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: Index out of range using input dim 1; input has only 1 dims\n",
      "2024-03-27 23:58:54.013457: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: Index out of range using input dim 1; input has only 1 dims\n",
      "2024-03-27 23:58:54.014239: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: Index out of range using input dim 1; input has only 1 dims\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Task:\n",
    "    name: str\n",
    "    description: str\n",
    "    target_program: str\n",
    "    examples: Example\n",
    "    completions: t.List[str]\n",
    "\n",
    "    @property\n",
    "    def completion_prefix(self) -> str:\n",
    "        formals_str = [f\"in{i+1}\" for i in range(len(self.examples.inputs))]\n",
    "        return f\"def transform({', '.join(formals_str)}):\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, task: TaskJSON, output: OutputJSON):\n",
    "        assert task[\"name\"] == output[\"task_id\"]\n",
    "        return cls(\n",
    "            task[\"name\"],\n",
    "            task[\"description\"],\n",
    "            task[\"target_program\"],\n",
    "            Example.from_json(task[\"examples\"]),\n",
    "            output[\"completions\"]\n",
    "        )\n",
    "\n",
    "    def num_correct_completions(self) -> int:\n",
    "        ans = 0\n",
    "        for completion in self.completions:\n",
    "            # evaluated = evaluate_completion(self.completion_prefix + completion)\n",
    "            evaluable_completion = fixup_completion(self.completion_prefix, completion)\n",
    "            try:\n",
    "                exec(evaluable_completion)\n",
    "                result = locals()[\"transform\"](*self.examples.inputs)\n",
    "                if matches_expected_value(result, self.examples.output):\n",
    "                    ans += 1\n",
    "            except Exception as e:\n",
    "                print(completion)\n",
    "                print(str(e))\n",
    "                print()\n",
    "                continue\n",
    "        return ans\n",
    "\n",
    "TASKS = {\n",
    "    task[\"name\"]: Task.from_json(task, OUTPUTS[task[\"name\"]])\n",
    "    for task in DATASET\n",
    "    if task[\"name\"] in OUTPUTS\n",
    "}\n",
    "\n",
    "# pprint 5 tasks\n",
    "keys = list(TASKS.keys())\n",
    "for key in keys:\n",
    "    print(f\"Task: {key}\")\n",
    "    # pprint(TASKS[key])\n",
    "    pprint(TASKS[key].num_correct_completions())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: google_01\n",
      "return tf.stack([tf.math.bincount(in1), in1], axis=1)\n",
      "{{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [4] != values[1].shape = [6] [Op:Pack] name: stack\n",
      "\n",
      "return tf.stack([tf.divide(in1, tf.shape(in1)[0]), tf.mod(in1, tf.shape(in1)[0])], axis=1)\n",
      "module 'tensorflow' has no attribute 'mod'\n",
      "\n",
      "return tf.stack([tf.math.floor_div(in1, tf.constant(2, dtype=tf.int32)), tf.math.floormod(in1, tf.constant(2, dtype=tf.int32))], axis=1)\n",
      "module 'tensorflow._api.v2.math' has no attribute 'floor_div'\n",
      "\n",
      "return tf.stack([tf.floor_div(in1, 2), tf.mod(in1, 2)], axis=1)\n",
      "module 'tensorflow' has no attribute 'floor_div'\n",
      "\n",
      "return tf.stack([tf.math.floor_divide(in1, tf.shape(in1)[0]), tf.math.mod(in1, tf.shape(in1)[0])], axis=1)\n",
      "module 'tensorflow._api.v2.math' has no attribute 'floor_divide'\n",
      "\n",
      "return tf.stack([tf.math.floor_divide(in1, tf.reduce_max(in1) + 1), tf.math.floormod(in1, tf.reduce_max(in1) + 1)], axis=1)\n",
      "module 'tensorflow._api.v2.math' has no attribute 'floor_divide'\n",
      "\n",
      "return tf.stack([tf.math.floor_div(in1, tf.reduce_max(in1) + 1), tf.math.floormod(in1, tf.reduce_max(in1) + 1)], axis=1)\n",
      "module 'tensorflow._api.v2.math' has no attribute 'floor_div'\n",
      "\n",
      "return tf.stack([tf.math.floor_div(in1, tf.reduce_max(in1) + 1), tf.math.floormod(in1, tf.reduce_max(in1) + 1)], axis=1)\n",
      "module 'tensorflow._api.v2.math' has no attribute 'floor_div'\n",
      "\n",
      "return tf.stack([tf.math.bincount(in1), tf.cast(in1, tf.int32)], axis=1)\n",
      "{{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [4] != values[1].shape = [6] [Op:Pack] name: stack\n",
      "\n",
      "return tf.stack([tf.divide(in1, tf.shape(in1)[0]), tf.math.bincount(in1)], axis=1)\n",
      "cannot compute Pack as input #1(zero-based) was expected to be a double tensor but is a int32 tensor [Op:Pack] name: stack\n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: google_03\n",
      "return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, [0, 0, 0], [1, -1, -1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, [0,0,0], [1,-1,-1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, start=[0, 0, 0], size=[1, -1, -1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, [0, 0, 0], [1, -1, -1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, start=[0,0,0], size=[1, -1, -1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: google_04\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: google_05\n",
      "return tf.expand_dims(in1, axis=1) + tf.zeros([1, 6, 1], tf.int32)\n",
      "cannot compute AddV2 as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:AddV2] name: \n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: google_06\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: google_07\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: google_08\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: google_09\n",
      "max_idx = tf.reduce_max(in1)+1\n",
      "segment_min = tf.math.unsorted_segment_min(in2, in1, max_idx)\n",
      "segment_max = tf.math.unsorted_segment_max(in2, in1, max_idx)\n",
      "sort_base = tf.cast(in1, tf.float32) + tf.divide(in2 - segment_min, segment_max - segment_min + 1) / 10 \n",
      "idx = tf.argsort(sort_base)\n",
      "return tf.gather(in2, idx)\n",
      "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [6] vs. [3] [Op:Sub] name: \n",
      "\n",
      "return tf.unsorted_segment_min(in2, in1, tf.reduce_max(in1)+1)\n",
      "module 'tensorflow' has no attribute 'unsorted_segment_min'\n",
      "\n",
      "segments = tf.argsort(tf.unique_with_counts(in1)[0])\n",
      "segment_ids = tf.cast(tf.searchsorted(segments, in1), tf.float32)\n",
      "sorted_values = tf.math.segment_min(in2, segment_ids)\n",
      "combined = tf.stack([segment_ids, sorted_values], axis=-1)\n",
      "perm = tf.argsort(combined[:, 0])\n",
      "return tf.gather(combined[:, 1], perm)\n",
      "cannot compute LowerBound as input #1(zero-based) was expected to be a int32 tensor but is a int64 tensor [Op:LowerBound] name: \n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: google_11\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: google_12\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: google_13\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: google_14\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: google_15\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: google_16\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: google_17\n",
      "return tf.where(in1, in2, tf.multiply(-10, tf.range(tf.shape(in2)[0]));\n",
      "invalid syntax (<string>, line 2)\n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: google_18\n",
      "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + 1)[in2 - 1]\n",
      "Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([0, 1, 2, 0, 1])\n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: google_19\n",
      "indices = tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1)\n",
      "    return tf.gather_nd(in1, indices)\n",
      "{{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [3] != values[1].shape = [3,3] [Op:Pack] name: stack\n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: google_20\n",
      "GPT-4 Successfully solved: 1\n",
      "\n",
      "Task: google_21\n",
      "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(tf.constant(in1['tensor'], dtype=tf.int32), tf.constant(in1['indices'], dtype=tf.int32), tf.constant(in1['updates'], dtype=tf.int32))\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate] name: \n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1[\"tensor\"], in1[\"indices\"], in1[\"updates\"])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(tf.constant(in1['tensor'], tf.int32), tf.constant(in1['indices'], tf.int32), tf.constant(in1['updates'], tf.int32))\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate] name: \n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: google_22\n",
      "ind = tf.reshape(tf.range(tf.shape(in1)[0]), (-1, 1))\n",
      " return tf.reshape(tf.concat([tf.tile(ind, [1, tf.shape(in1)[1]]), in1], axis=2), [-1, 2])\n",
      "{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Expected concatenating dimensions in the range [-2, 2), but got 2 [Op:ConcatV2] name: concat\n",
      "\n",
      "return tf.reshape(tf.transpose(tf.stack([tf.repeat(tf.range(tf.shape(in1)[0]), tf.shape(in1)[1]), tf.reshape(in1, [-1])])), [-1, 2])\n",
      "cannot compute Pack as input #1(zero-based) was expected to be a int32 tensor but is a int64 tensor [Op:Pack] name: stack\n",
      "\n",
      "return tf.reshape(tf.concat([tf.expand_dims(tf.range(tf.shape(in1)[0]), axis=1), in1], axis=2), [-1, 2])\n",
      "{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Expected concatenating dimensions in the range [-2, 2), but got 2 [Op:ConcatV2] name: concat\n",
      "\n",
      "indices = tf.range(tf.shape(in1)[0])\n",
      "    return tf.reshape(tf.stack([tf.repeat(indices, tf.shape(in1)[1]), tf.reshape(in1, [-1])], axis=1), [-1,2])\n",
      "cannot compute Pack as input #1(zero-based) was expected to be a int32 tensor but is a int64 tensor [Op:Pack] name: stack\n",
      "\n",
      "return tf.reshape(tf.transpose(tf.stack([tf.repeat(tf.range(tf.shape(in1)[0]), tf.shape(in1)[1]), tf.reshape(in1, [-1])])), [-1, 2])\n",
      "cannot compute Pack as input #1(zero-based) was expected to be a int32 tensor but is a int64 tensor [Op:Pack] name: stack\n",
      "\n",
      "return tf.concat([tf.expand_dims(tf.cast(tf.range(tf.shape(in1)[0]), tf.int32), 1), tf.reshape(in1, [-1, 1])], axis=1)\n",
      "cannot compute ConcatV2 as input #1(zero-based) was expected to be a int32 tensor but is a int64 tensor [Op:ConcatV2] name: concat\n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_01\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_02\n",
      "return tf.clip_by_value(in1, -tf.constant(1e10), tf.constant(1))\n",
      "cannot compute Minimum as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:Minimum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(np.inf), tf.constant(1.))\n",
      "cannot compute Minimum as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:Minimum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(float('inf')), 1)\n",
      "cannot compute Maximum as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:Maximum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(float('inf')), tf.constant(1))\n",
      "cannot compute Minimum as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:Minimum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(float('inf')), 1)\n",
      "cannot compute Maximum as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:Maximum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(np.inf), 1)\n",
      "cannot compute Maximum as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:Maximum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(np.inf), tf.constant(1))\n",
      "cannot compute Minimum as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:Minimum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(float('inf')), 1)\n",
      "cannot compute Maximum as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:Maximum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(float('inf')), 1)\n",
      "cannot compute Maximum as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:Maximum] name: \n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_03\n",
      "return tf.tensor_scatter_nd_update(in1, [[0,3], [0,4], [1,3], [1,4]], tf.gather(in2, [3,4,3,4]))\n",
      "{{function_node __wrapped__GatherV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[0] = 3 is not in [0, 2) [Op:GatherV2]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1, [[0,3], [0,4], [1,3], [1,4]], tf.gather(in2, [3,4], axis=1))\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [4,2], updates shape:[2,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "indices = tf.constant([[3,4]])\n",
      "return tf.tensor_scatter_nd_update(in1, indices, tf.gather(in2, indices))\n",
      "{{function_node __wrapped__GatherV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[0,0] = 3 is not in [0, 2) [Op:GatherV2] name: \n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_04\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_05\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_06\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_08\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_09\n",
      "_, idx, count = tf.unique_with_counts(in1)\n",
      "return tf.gather(idx, in1)\n",
      "{{function_node __wrapped__GatherV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[0] = 37 is not in [0, 8) [Op:GatherV2] name: \n",
      "\n",
      "_, idx = tf.unique_with_counts(in1)\n",
      "return idx\n",
      "too many values to unpack (expected 2)\n",
      "\n",
      "_, idx = tf.unique_with_counts(in1)\n",
      " return tf.gather(idx, in1)\n",
      "too many values to unpack (expected 2)\n",
      "\n",
      "GPT-4 Successfully solved: 1\n",
      "\n",
      "Task: stackoverflow_10\n",
      "return tf.matmul(tf.expand_dims(in1, 0), tf.expand_dims(in2, -1))\n",
      "{{function_node __wrapped__BatchMatMulV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [1,2,2], In[1]: [2,3,1] [Op:BatchMatMulV2] name: \n",
      "\n",
      "return tf.matmul(tf.expand_dims(in1,axis =2), tf.reshape(in2,[in1.shape[1],-1,1]))\n",
      "{{function_node __wrapped__BatchMatMulV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [2,2,1], In[1]: [2,3,1] [Op:BatchMatMulV2] name: \n",
      "\n",
      "return tf.matmul(tf.expand_dims(in1, 0), tf.expand_dims(in2, -1))\n",
      "{{function_node __wrapped__BatchMatMulV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [1,2,2], In[1]: [2,3,1] [Op:BatchMatMulV2] name: \n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 23:59:33.207396: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:59:33.207904: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:59:33.208442: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:59:33.209242: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:59:33.209744: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:59:33.210217: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:59:33.210696: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:59:33.211190: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:59:33.211663: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:59:33.212139: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_12\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_13\n",
      "return tf.matmul(in1, tf.cast(in2, tf.int32))\n",
      "cannot compute BatchMatMulV2 as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:BatchMatMulV2] name: \n",
      "\n",
      "return tf.matmul(in2, tf.cast(tf.transpose(in1), tf.int32))\n",
      "cannot compute BatchMatMulV2 as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:BatchMatMulV2] name: \n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_14\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_15\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_16\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_17\n",
      "return tf.expand_dims(in1, 1) * tf.ones((1, 2), dtype=tf.int32)\n",
      "cannot compute Mul as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:Mul] name: \n",
      "\n",
      "return tf.expand_dims(in1, 1) * tf.ones([1,2], dtype=tf.int32)\n",
      "cannot compute Mul as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:Mul] name: \n",
      "\n",
      "return tf.expand_dims(in1, axis=1) * tf.ones([1, 2])\n",
      "cannot compute Mul as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:Mul] name: \n",
      "\n",
      "return tf.expand_dims(in1, 1) * tf.ones([1, 2], dtype=tf.int32)\n",
      "cannot compute Mul as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:Mul] name: \n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_18\n",
      "return tf.add(tf.tensordot(in1, in2, axes=([2],[0])), tf.cast(in3, tf.int32))\n",
      "cannot compute AddV2 as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:AddV2] name: \n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_19\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_20\n",
      "return tf.one_hot(tf.argmax(in1, axis=1), depth=in1.get_shape().as_list()[1])\n",
      "'numpy.ndarray' object has no attribute 'get_shape'\n",
      "\n",
      "return tf.one_hot(tf.argmax(in1, axis=1), depth=in1.get_shape()[1])\n",
      "'numpy.ndarray' object has no attribute 'get_shape'\n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_21\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_22\n",
      "return tf.tensordot(in1, in2, axes=1)\n",
      "cannot compute MatMul as input #1(zero-based) was expected to be a int64 tensor but is a double tensor [Op:MatMul] name: \n",
      "\n",
      "return tf.matmul(tf.cast(in1, tf.float32), in2)\n",
      "{{function_node __wrapped____MklMatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} In[0] ndims must be >= 2 [Op:MatMul] name: \n",
      "\n",
      "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3] vs. [3,2] [Op:Mul] name: \n",
      "\n",
      "return tf.reduce_sum(tf.multiply(tf.cast(in1, tf.float32), in2), axis=0)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3] vs. [3,2] [Op:Mul] name: \n",
      "\n",
      "return tf.reduce_sum(tf.multiply(tf.cast(in1, tf.float32), in2), axis=0)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3] vs. [3,2] [Op:Mul] name: \n",
      "\n",
      "return tf.reduce_sum(tf.multiply(tf.cast(in1, dtype=tf.float32), in2), axis=0)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3] vs. [3,2] [Op:Mul] name: \n",
      "\n",
      "return tf.tensordot(in1, in2, axes=1)\n",
      "cannot compute MatMul as input #1(zero-based) was expected to be a int64 tensor but is a double tensor [Op:MatMul] name: \n",
      "\n",
      "return tf.reduce_sum(tf.multiply(tf.cast(in1, tf.float32), in2), 0)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3] vs. [3,2] [Op:Mul] name: \n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_23\n",
      "return tf.cast(tf.one_hot(in1, tf.reduce_max(in1)+1), tf.int32)\n",
      "cannot compute OneHot as input #1(zero-based) was expected to be a int32 tensor but is a int64 tensor [Op:OneHot] name: \n",
      "\n",
      "return tf.reduce_any(tf.one_hot(in1, 9), axis=1, keepdims=False)\n",
      "cannot compute Any as input #0(zero-based) was expected to be a bool tensor but is a float tensor [Op:Any] name: \n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_24\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_25\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.reshape(tf.tile(tf.eye(in1), [in2, 1]), [-1, in1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.reshape(tf.tile(tf.eye(in1), [in2, 1]), [-1, in1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_26\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_27\n",
      "return tf.cast(tf.sequence_mask(in1, in2), int)\n",
      "Cannot convert the argument `type_value`: <class 'int'> to a TensorFlow DType.\n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_28\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_29\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_30\n",
      "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.transpose(in2))), axis=1))\n",
      "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3,2] vs. [2,3] [Op:Sub] name: \n",
      "\n",
      "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.transpose(in2))), axis=1))\n",
      "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3,2] vs. [2,3] [Op:Sub] name: \n",
      "\n",
      "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.transpose(in2))), axis=1))\n",
      "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3,2] vs. [2,3] [Op:Sub] name: \n",
      "\n",
      "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.transpose(in2))), axis=1))\n",
      "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3,2] vs. [2,3] [Op:Sub] name: \n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_31\n",
      "return tf.reduce_sum(tf.math.squared_difference(in1.values, tf.gather_nd(in2, in1.indices)))\n",
      "'tuple' object has no attribute 'values'\n",
      "\n",
      "dense1 = tf.sparse.to_dense(in1)\n",
      "return tf.reduce_sum(tf.math.squared_difference(dense1, in1))\n",
      "Input must be a SparseTensor.\n",
      "\n",
      "return tf.reduce_sum(tf.math.squared_difference(in1[0], tf.cast(in1[1], tf.float32)))\n",
      "Attempt to convert a value (SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [1 1]], shape=(3, 2), dtype=int64), values=tf.Tensor([ 1.   1.5 -2. ], shape=(3,), dtype=float32), dense_shape=tf.Tensor([2 2], shape=(2,), dtype=int64))) with an unsupported type (<class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>) to a Tensor.\n",
      "\n",
      "return tf.reduce_sum(tf.math.squared_difference(in1.values, tf.gather_nd(in2, in1.indices)))\n",
      "'tuple' object has no attribute 'values'\n",
      "\n",
      "return tf.reduce_sum(tf.square(tf.subtract(in1.values, tf.gather_nd(in1.indices))))\n",
      "'tuple' object has no attribute 'values'\n",
      "\n",
      "dense_tensor = tf.sparse.to_dense(in1)\n",
      "return tf.reduce_sum(tf.math.squared_difference(in1, dense_tensor))\n",
      "Input must be a SparseTensor.\n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_32\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_33\n",
      "return tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=2), tf.expand_dims(in2, axis=1))), axis=-1)), axis=-1)\n",
      "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [5,3,1] vs. [4,1,3] [Op:Sub] name: \n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_34\n",
      "return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(in2, axis=-1)), axis=0)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3,2,2] vs. [3,1] [Op:Mul] name: \n",
      "\n",
      "return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(tf.cast(in2, tf.float32), -1)), axis=0)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3,2,2] vs. [3,1] [Op:Mul] name: \n",
      "\n",
      "return tf.tensordot(in1, in2, axes=[0])\n",
      "`axes` must be an integer or have length 2. Received [0].\n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_35\n",
      "return tf.add(tf.multiply(in1, tf.expand_dims(tf.expand_dims(1 - in3, 1), 2)), tf.multiply(in2, tf.expand_dims(tf.expand_dims(in3, 1), 2)))\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [2,3,2] vs. [3,1,1] [Op:Mul] name: \n",
      "\n",
      "return tf.add(tf.multiply(tf.subtract(in2, in1), tf.expand_dims(tf.expand_dims(in3, 1), 2)), in1)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [2,3,2] vs. [3,1,1] [Op:Mul] name: \n",
      "\n",
      "return tf.add(tf.multiply(in1, tf.reshape(1 - in3, (-1, 1, 1))), tf.multiply(in2, tf.reshape(in3, (-1, 1, 1))))\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [2,3,2] vs. [3,1,1] [Op:Mul] name: \n",
      "\n",
      "return tf.add(tf.multiply(in1, tf.expand_dims(tf.expand_dims(tf.subtract(tf.constant(1.0), in3), 1), 2)), tf.multiply(in2, tf.expand_dims(tf.expand_dims(in3, 1), 2)))\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [2,3,2] vs. [3,1,1] [Op:Mul] name: \n",
      "\n",
      "return tf.add(tf.multiply(tf.expand_dims(in3, axis=[1,2]), tf.subtract(in2, in1)), in1)\n",
      "{{function_node __wrapped__ExpandDims_device_/job:localhost/replica:0/task:0/device:CPU:0}} 'dim' must be a tensor with a single value [Op:ExpandDims]\n",
      "\n",
      "return tf.add(tf.multiply(in1, tf.reshape(1 - in3, [-1, 1, 1])), tf.multiply(in2, tf.reshape(in3, [-1, 1, 1])))\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [2,3,2] vs. [3,1,1] [Op:Mul] name: \n",
      "\n",
      "return tf.add(tf.multiply(in1, tf.reshape(1. - in3, [in3.shape[0], 1, 1])), tf.multiply(in2, tf.reshape(in3, [in3.shape[0], 1, 1])))\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [2,3,2] vs. [3,1,1] [Op:Mul] name: \n",
      "\n",
      "return tf.add(tf.multiply(in1, tf.subtract(1.0, tf.expand_dims(tf.expand_dims(in3, 1), 2))), tf.multiply(in2, tf.expand_dims(tf.expand_dims(in3, 1), 2)))\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [2,3,2] vs. [3,1,1] [Op:Mul] name: \n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_36\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_37\n",
      "return tf.tensordot(in1, tf.expand_dims(in2, 0), [[-1], [0]])\n",
      "{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [4,3], In[1]: [1,3] [Op:MatMul] name: \n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_38\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.reshape(tf.boolean_mask(in1, tf.concat(in2, axis=0)), [tf.shape(in2)[0], -1]), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_39\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_40\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_41\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_42\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_43\n",
      "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1))\n",
      "{{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd [Op:GatherNd] name: \n",
      "\n",
      "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in1)[1]), in2], axis=1))\n",
      "{{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd [Op:GatherNd] name: \n",
      "\n",
      "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1))\n",
      "{{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd [Op:GatherNd] name: \n",
      "\n",
      "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1))\n",
      "{{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd [Op:GatherNd] name: \n",
      "\n",
      "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1))\n",
      "{{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd [Op:GatherNd] name: \n",
      "\n",
      "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1))\n",
      "{{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd [Op:GatherNd] name: \n",
      "\n",
      "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1))\n",
      "{{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd [Op:GatherNd] name: \n",
      "\n",
      "GPT-4 Successfully solved: 1\n",
      "\n",
      "Task: stackoverflow_44\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_45\n",
      "return tf.where(tf.equal(in2, 1), tf.reverse(in1, axis=[2]), in1)\n",
      "{{function_node __wrapped__SelectV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} condition [5], then [1,5,2], and else [1,5,2] must be broadcastable [Op:SelectV2] name: \n",
      "\n",
      "return tf.where(tf.expand_dims(in2, axis=-1), tf.reverse(in1, axis=[1]), in1)\n",
      "cannot compute SelectV2 as input #0(zero-based) was expected to be a bool tensor but is a int64 tensor [Op:SelectV2] name: \n",
      "\n",
      "return tf.where(tf.expand_dims(in2, -1), tf.reverse(in1, axis=[2]), in1)\n",
      "cannot compute SelectV2 as input #0(zero-based) was expected to be a bool tensor but is a int64 tensor [Op:SelectV2] name: \n",
      "\n",
      "return tf.where(tf.cast(in2, tf.bool), tf.reverse(in1, [-1]), in1)\n",
      "{{function_node __wrapped__SelectV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} condition [5], then [1,5,2], and else [1,5,2] must be broadcastable [Op:SelectV2] name: \n",
      "\n",
      "return tf.where(tf.cast(in2, tf.bool), in1[:, ::-1], in1)\n",
      "{{function_node __wrapped__SelectV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} condition [5], then [1,5,2], and else [1,5,2] must be broadcastable [Op:SelectV2] name: \n",
      "\n",
      "return tf.where(tf.expand_dims(in2, -1), tf.reverse(in1, axis=[2]), in1)\n",
      "cannot compute SelectV2 as input #0(zero-based) was expected to be a bool tensor but is a int64 tensor [Op:SelectV2] name: \n",
      "\n",
      "return tf.where(tf.equal(in2, 1), in1[:,:,::-1], in1)\n",
      "{{function_node __wrapped__SelectV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} condition [5], then [1,5,2], and else [1,5,2] must be broadcastable [Op:SelectV2] name: \n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_46\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_47\n",
      "return tf.reshape(tf.boolean_mask(in1, tf.reshape(in2, [-1])), tf.shape(in2))\n",
      "Shapes (17,) and (30,) are incompatible\n",
      "\n",
      "indices = tf.where(in2)\n",
      " updates = tf.gather(in1, tf.range(tf.reduce_sum(tf.cast(in2, tf.int32))))\n",
      " return tf.scatter_nd(indices, updates, tf.shape(in2))\n",
      "cannot compute ScatterNd as input #2(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:ScatterNd] name: \n",
      "\n",
      "return tf.scatter_nd(tf.where(in2), in1[:tf.math.count_nonzero(in2)], tf.shape(in2))\n",
      "cannot compute ScatterNd as input #2(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:ScatterNd] name: \n",
      "\n",
      "return tf.boolean_mask(in1, tf.cast(tf.reshape(in2, [-1]), tf.bool), axis=0)\n",
      "Shapes (17,) and (30,) are incompatible\n",
      "\n",
      "shape = tf.shape(in2)\n",
      "in1 = tf.reshape(in1[:tf.reduce_sum(shape)], shape)\n",
      "result = tf.where(in2,in1,0)\n",
      "return result\n",
      "{{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 11 values, but the requested shape has 30 [Op:Reshape] name: \n",
      "\n",
      "mask = tf.cast(in2, tf.int32)\n",
      "idx = tf.reshape(tf.where(mask), [-1])\n",
      "val = tf.gather(in1, idx)\n",
      "padding = tf.fill(tf.shape(in2), 0)\n",
      "out = tf.where(mask, val, padding)\n",
      "return out\n",
      "cannot compute SelectV2 as input #0(zero-based) was expected to be a bool tensor but is a int32 tensor [Op:SelectV2] name: \n",
      "\n",
      "result = tf.zeros_like(in2, dtype=tf.int32)\n",
      "counter = tf.constant([0])\n",
      "for i in range(in2.shape[0]):\n",
      "    for j in range(in2.shape[1]):\n",
      "        if in2[i][j]:\n",
      "            result[i,j].assign(in1[counter])\n",
      "            counter += 1\n",
      "return result\n",
      "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'\n",
      "\n",
      "return tf.reshape(tf.boolean_mask(in1, tf.cast(tf.reshape(in2, [-1]), tf.bool)), tf.shape(in2))\n",
      "Shapes (17,) and (30,) are incompatible\n",
      "\n",
      "mask = tf.cast(in2, tf.int32)\n",
      "indices = tf.repeat(tf.range(tf.shape(mask)[1]), tf.reduce_sum(mask, axis=0))\n",
      "updates = tf.boolean_mask(in1, tf.reshape(mask, [-1]))\n",
      "shape = tf.shape(mask)\n",
      "return tf.scatter_nd(tf.expand_dims(indices, axis=-1), updates, shape)\n",
      "Shapes (17,) and (30,) are incompatible\n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_48\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_49\n",
      "GPT-4 Successfully solved: 0\n",
      "\n",
      "Task: stackoverflow_50\n",
      "return tf.one_hot(in1, 2*in1, axis=1)\n",
      "{{function_node __wrapped__OneHot_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected axis to be -1 or between [0, 1).  But received: 1 [Op:OneHot]\n",
      "\n",
      "return tf.one_hot(in1, depth=in1*2, axis=1)\n",
      "{{function_node __wrapped__OneHot_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected axis to be -1 or between [0, 1).  But received: 1 [Op:OneHot]\n",
      "\n",
      "return tf.scatter_nd([[in1]], [1], [6, 6])\n",
      "{{function_node __wrapped__ScatterNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimensions [1,2) of input[shape=[6,6]] must match dimensions [1,1) of updates[shape=[1]] [Op:ScatterNd]\n",
      "\n",
      "return tf.one_hot(in1, 2*in1 + 1)[:, 3]\n",
      "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Index out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: strided_slice/\n",
      "\n",
      "return tf.one_hot(in1, in1*2)[:, in1]\n",
      "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Index out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: strided_slice/\n",
      "\n",
      "return tf.one_hot(in1, 2 * in1 + 1)[:, in1]\n",
      "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Index out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: strided_slice/\n",
      "\n",
      "return tf.pad(tf.expand_dims(tf.eye(in1, in1+1)[:, 3],-1), [[0,0],[0,0],[0,in1-1]])[:,:,0]\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=5, num_columns=6\n",
      "\n",
      "return tf.one_hot(in1, 2 * in1 + 1, dtype=tf.int32)[:, in1]\n",
      "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Index out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: strided_slice/\n",
      "\n",
      "GPT-4 Successfully solved: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 23:59:33.546820: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at gather_nd_op.cc:48 : INVALID_ARGUMENT: indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd\n",
      "2024-03-27 23:59:33.547772: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at gather_nd_op.cc:48 : INVALID_ARGUMENT: indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd\n",
      "2024-03-27 23:59:33.548952: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at gather_nd_op.cc:48 : INVALID_ARGUMENT: indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd\n",
      "2024-03-27 23:59:33.549695: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at gather_nd_op.cc:48 : INVALID_ARGUMENT: indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd\n",
      "2024-03-27 23:59:33.551119: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at gather_nd_op.cc:48 : INVALID_ARGUMENT: indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd\n",
      "2024-03-27 23:59:33.551956: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at gather_nd_op.cc:48 : INVALID_ARGUMENT: indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd\n",
      "2024-03-27 23:59:33.552729: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at gather_nd_op.cc:48 : INVALID_ARGUMENT: indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd\n",
      "2024-03-27 23:59:33.619866: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: Index out of range using input dim 1; input has only 1 dims\n",
      "2024-03-27 23:59:33.620557: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: Index out of range using input dim 1; input has only 1 dims\n",
      "2024-03-27 23:59:33.621175: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: Index out of range using input dim 1; input has only 1 dims\n",
      "2024-03-27 23:59:33.621947: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: Index out of range using input dim 1; input has only 1 dims\n"
     ]
    }
   ],
   "source": [
    "for task in TASKS.values():\n",
    "    print(f\"Task: {task.name}\")\n",
    "    print(f\"GPT-4 Successfully solved: {task.num_correct_completions()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return tf.stack([tf.math.bincount(in1), in1], axis=1)\n",
      "{{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [4] != values[1].shape = [6] [Op:Pack] name: stack\n",
      "\n",
      "return tf.stack([tf.divide(in1, tf.shape(in1)[0]), tf.mod(in1, tf.shape(in1)[0])], axis=1)\n",
      "module 'tensorflow' has no attribute 'mod'\n",
      "\n",
      "return tf.stack([tf.math.floor_div(in1, tf.constant(2, dtype=tf.int32)), tf.math.floormod(in1, tf.constant(2, dtype=tf.int32))], axis=1)\n",
      "module 'tensorflow._api.v2.math' has no attribute 'floor_div'\n",
      "\n",
      "return tf.stack([tf.floor_div(in1, 2), tf.mod(in1, 2)], axis=1)\n",
      "module 'tensorflow' has no attribute 'floor_div'\n",
      "\n",
      "return tf.stack([tf.math.floor_divide(in1, tf.shape(in1)[0]), tf.math.mod(in1, tf.shape(in1)[0])], axis=1)\n",
      "module 'tensorflow._api.v2.math' has no attribute 'floor_divide'\n",
      "\n",
      "return tf.stack([tf.math.floor_divide(in1, tf.reduce_max(in1) + 1), tf.math.floormod(in1, tf.reduce_max(in1) + 1)], axis=1)\n",
      "module 'tensorflow._api.v2.math' has no attribute 'floor_divide'\n",
      "\n",
      "return tf.stack([tf.math.floor_div(in1, tf.reduce_max(in1) + 1), tf.math.floormod(in1, tf.reduce_max(in1) + 1)], axis=1)\n",
      "module 'tensorflow._api.v2.math' has no attribute 'floor_div'\n",
      "\n",
      "return tf.stack([tf.math.floor_div(in1, tf.reduce_max(in1) + 1), tf.math.floormod(in1, tf.reduce_max(in1) + 1)], axis=1)\n",
      "module 'tensorflow._api.v2.math' has no attribute 'floor_div'\n",
      "\n",
      "return tf.stack([tf.math.bincount(in1), tf.cast(in1, tf.int32)], axis=1)\n",
      "{{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [4] != values[1].shape = [6] [Op:Pack] name: stack\n",
      "\n",
      "return tf.stack([tf.divide(in1, tf.shape(in1)[0]), tf.math.bincount(in1)], axis=1)\n",
      "cannot compute Pack as input #1(zero-based) was expected to be a double tensor but is a int32 tensor [Op:Pack] name: stack\n",
      "\n",
      "return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, [0, 0, 0], [1, -1, -1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, [0,0,0], [1,-1,-1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, start=[0, 0, 0], size=[1, -1, -1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, [0, 0, 0], [1, -1, -1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.sparse.slice(in1, start=[0,0,0], size=[1, -1, -1])\n",
      "{{function_node __wrapped__SparseSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected a non-negative size, got -1 [Op:SparseSlice] name: \n",
      "\n",
      "return tf.expand_dims(in1, axis=1) + tf.zeros([1, 6, 1], tf.int32)\n",
      "cannot compute AddV2 as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:AddV2] name: \n",
      "\n",
      "max_idx = tf.reduce_max(in1)+1\n",
      "segment_min = tf.math.unsorted_segment_min(in2, in1, max_idx)\n",
      "segment_max = tf.math.unsorted_segment_max(in2, in1, max_idx)\n",
      "sort_base = tf.cast(in1, tf.float32) + tf.divide(in2 - segment_min, segment_max - segment_min + 1) / 10 \n",
      "idx = tf.argsort(sort_base)\n",
      "return tf.gather(in2, idx)\n",
      "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [6] vs. [3] [Op:Sub] name: \n",
      "\n",
      "return tf.unsorted_segment_min(in2, in1, tf.reduce_max(in1)+1)\n",
      "module 'tensorflow' has no attribute 'unsorted_segment_min'\n",
      "\n",
      "segments = tf.argsort(tf.unique_with_counts(in1)[0])\n",
      "segment_ids = tf.cast(tf.searchsorted(segments, in1), tf.float32)\n",
      "sorted_values = tf.math.segment_min(in2, segment_ids)\n",
      "combined = tf.stack([segment_ids, sorted_values], axis=-1)\n",
      "perm = tf.argsort(combined[:, 0])\n",
      "return tf.gather(combined[:, 1], perm)\n",
      "cannot compute LowerBound as input #1(zero-based) was expected to be a int32 tensor but is a int64 tensor [Op:LowerBound] name: \n",
      "\n",
      "return tf.where(in1, in2, tf.multiply(-10, tf.range(tf.shape(in2)[0]));\n",
      "invalid syntax (<string>, line 2)\n",
      "\n",
      "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + 1)[in2 - 1]\n",
      "Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([0, 1, 2, 0, 1])\n",
      "\n",
      "indices = tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1)\n",
      "    return tf.gather_nd(in1, indices)\n",
      "{{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [3] != values[1].shape = [3,3] [Op:Pack] name: stack\n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(tf.constant(in1['tensor'], dtype=tf.int32), tf.constant(in1['indices'], dtype=tf.int32), tf.constant(in1['updates'], dtype=tf.int32))\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate] name: \n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1[\"tensor\"], in1[\"indices\"], in1[\"updates\"])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(tf.constant(in1['tensor'], tf.int32), tf.constant(in1['indices'], tf.int32), tf.constant(in1['updates'], tf.int32))\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [6,2], updates shape:[3,2] [Op:TensorScatterUpdate] name: \n",
      "\n",
      "ind = tf.reshape(tf.range(tf.shape(in1)[0]), (-1, 1))\n",
      " return tf.reshape(tf.concat([tf.tile(ind, [1, tf.shape(in1)[1]]), in1], axis=2), [-1, 2])\n",
      "{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Expected concatenating dimensions in the range [-2, 2), but got 2 [Op:ConcatV2] name: concat\n",
      "\n",
      "return tf.reshape(tf.transpose(tf.stack([tf.repeat(tf.range(tf.shape(in1)[0]), tf.shape(in1)[1]), tf.reshape(in1, [-1])])), [-1, 2])\n",
      "cannot compute Pack as input #1(zero-based) was expected to be a int32 tensor but is a int64 tensor [Op:Pack] name: stack\n",
      "\n",
      "return tf.reshape(tf.concat([tf.expand_dims(tf.range(tf.shape(in1)[0]), axis=1), in1], axis=2), [-1, 2])\n",
      "{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Expected concatenating dimensions in the range [-2, 2), but got 2 [Op:ConcatV2] name: concat\n",
      "\n",
      "indices = tf.range(tf.shape(in1)[0])\n",
      "    return tf.reshape(tf.stack([tf.repeat(indices, tf.shape(in1)[1]), tf.reshape(in1, [-1])], axis=1), [-1,2])\n",
      "cannot compute Pack as input #1(zero-based) was expected to be a int32 tensor but is a int64 tensor [Op:Pack] name: stack\n",
      "\n",
      "return tf.reshape(tf.transpose(tf.stack([tf.repeat(tf.range(tf.shape(in1)[0]), tf.shape(in1)[1]), tf.reshape(in1, [-1])])), [-1, 2])\n",
      "cannot compute Pack as input #1(zero-based) was expected to be a int32 tensor but is a int64 tensor [Op:Pack] name: stack\n",
      "\n",
      "return tf.concat([tf.expand_dims(tf.cast(tf.range(tf.shape(in1)[0]), tf.int32), 1), tf.reshape(in1, [-1, 1])], axis=1)\n",
      "cannot compute ConcatV2 as input #1(zero-based) was expected to be a int32 tensor but is a int64 tensor [Op:ConcatV2] name: concat\n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(1e10), tf.constant(1))\n",
      "cannot compute Minimum as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:Minimum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(np.inf), tf.constant(1.))\n",
      "cannot compute Minimum as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:Minimum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(float('inf')), 1)\n",
      "cannot compute Maximum as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:Maximum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(float('inf')), tf.constant(1))\n",
      "cannot compute Minimum as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:Minimum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(float('inf')), 1)\n",
      "cannot compute Maximum as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:Maximum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(np.inf), 1)\n",
      "cannot compute Maximum as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:Maximum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(np.inf), tf.constant(1))\n",
      "cannot compute Minimum as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:Minimum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(float('inf')), 1)\n",
      "cannot compute Maximum as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:Maximum] name: \n",
      "\n",
      "return tf.clip_by_value(in1, -tf.constant(float('inf')), 1)\n",
      "cannot compute Maximum as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:Maximum] name: \n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1, [[0,3], [0,4], [1,3], [1,4]], tf.gather(in2, [3,4,3,4]))\n",
      "{{function_node __wrapped__GatherV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[0] = 3 is not in [0, 2) [Op:GatherV2]\n",
      "\n",
      "return tf.tensor_scatter_nd_update(in1, [[0,3], [0,4], [1,3], [1,4]], tf.gather(in2, [3,4], axis=1))\n",
      "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} Outer dimensions of indices and update must match. Indices shape: [4,2], updates shape:[2,2] [Op:TensorScatterUpdate]\n",
      "\n",
      "indices = tf.constant([[3,4]])\n",
      "return tf.tensor_scatter_nd_update(in1, indices, tf.gather(in2, indices))\n",
      "{{function_node __wrapped__GatherV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[0,0] = 3 is not in [0, 2) [Op:GatherV2] name: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 23:59:36.106679: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:59:36.107236: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:59:36.107700: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:59:36.108502: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:59:36.108958: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:59:36.109409: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:59:36.109871: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:59:36.110335: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:59:36.110779: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n",
      "2024-03-27 23:59:36.111299: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at sparse_slice_op.cc:60 : INVALID_ARGUMENT: Expected a non-negative size, got -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_, idx, count = tf.unique_with_counts(in1)\n",
      "return tf.gather(idx, in1)\n",
      "{{function_node __wrapped__GatherV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[0] = 37 is not in [0, 8) [Op:GatherV2] name: \n",
      "\n",
      "_, idx = tf.unique_with_counts(in1)\n",
      "return idx\n",
      "too many values to unpack (expected 2)\n",
      "\n",
      "_, idx = tf.unique_with_counts(in1)\n",
      " return tf.gather(idx, in1)\n",
      "too many values to unpack (expected 2)\n",
      "\n",
      "return tf.matmul(tf.expand_dims(in1, 0), tf.expand_dims(in2, -1))\n",
      "{{function_node __wrapped__BatchMatMulV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [1,2,2], In[1]: [2,3,1] [Op:BatchMatMulV2] name: \n",
      "\n",
      "return tf.matmul(tf.expand_dims(in1,axis =2), tf.reshape(in2,[in1.shape[1],-1,1]))\n",
      "{{function_node __wrapped__BatchMatMulV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [2,2,1], In[1]: [2,3,1] [Op:BatchMatMulV2] name: \n",
      "\n",
      "return tf.matmul(tf.expand_dims(in1, 0), tf.expand_dims(in2, -1))\n",
      "{{function_node __wrapped__BatchMatMulV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [1,2,2], In[1]: [2,3,1] [Op:BatchMatMulV2] name: \n",
      "\n",
      "return tf.matmul(in1, tf.cast(in2, tf.int32))\n",
      "cannot compute BatchMatMulV2 as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:BatchMatMulV2] name: \n",
      "\n",
      "return tf.matmul(in2, tf.cast(tf.transpose(in1), tf.int32))\n",
      "cannot compute BatchMatMulV2 as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:BatchMatMulV2] name: \n",
      "\n",
      "return tf.expand_dims(in1, 1) * tf.ones((1, 2), dtype=tf.int32)\n",
      "cannot compute Mul as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:Mul] name: \n",
      "\n",
      "return tf.expand_dims(in1, 1) * tf.ones([1,2], dtype=tf.int32)\n",
      "cannot compute Mul as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:Mul] name: \n",
      "\n",
      "return tf.expand_dims(in1, axis=1) * tf.ones([1, 2])\n",
      "cannot compute Mul as input #1(zero-based) was expected to be a int64 tensor but is a float tensor [Op:Mul] name: \n",
      "\n",
      "return tf.expand_dims(in1, 1) * tf.ones([1, 2], dtype=tf.int32)\n",
      "cannot compute Mul as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:Mul] name: \n",
      "\n",
      "return tf.add(tf.tensordot(in1, in2, axes=([2],[0])), tf.cast(in3, tf.int32))\n",
      "cannot compute AddV2 as input #1(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:AddV2] name: \n",
      "\n",
      "return tf.one_hot(tf.argmax(in1, axis=1), depth=in1.get_shape().as_list()[1])\n",
      "'numpy.ndarray' object has no attribute 'get_shape'\n",
      "\n",
      "return tf.one_hot(tf.argmax(in1, axis=1), depth=in1.get_shape()[1])\n",
      "'numpy.ndarray' object has no attribute 'get_shape'\n",
      "\n",
      "return tf.tensordot(in1, in2, axes=1)\n",
      "cannot compute MatMul as input #1(zero-based) was expected to be a int64 tensor but is a double tensor [Op:MatMul] name: \n",
      "\n",
      "return tf.matmul(tf.cast(in1, tf.float32), in2)\n",
      "{{function_node __wrapped____MklMatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} In[0] ndims must be >= 2 [Op:MatMul] name: \n",
      "\n",
      "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3] vs. [3,2] [Op:Mul] name: \n",
      "\n",
      "return tf.reduce_sum(tf.multiply(tf.cast(in1, tf.float32), in2), axis=0)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3] vs. [3,2] [Op:Mul] name: \n",
      "\n",
      "return tf.reduce_sum(tf.multiply(tf.cast(in1, tf.float32), in2), axis=0)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3] vs. [3,2] [Op:Mul] name: \n",
      "\n",
      "return tf.reduce_sum(tf.multiply(tf.cast(in1, dtype=tf.float32), in2), axis=0)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3] vs. [3,2] [Op:Mul] name: \n",
      "\n",
      "return tf.tensordot(in1, in2, axes=1)\n",
      "cannot compute MatMul as input #1(zero-based) was expected to be a int64 tensor but is a double tensor [Op:MatMul] name: \n",
      "\n",
      "return tf.reduce_sum(tf.multiply(tf.cast(in1, tf.float32), in2), 0)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3] vs. [3,2] [Op:Mul] name: \n",
      "\n",
      "return tf.cast(tf.one_hot(in1, tf.reduce_max(in1)+1), tf.int32)\n",
      "cannot compute OneHot as input #1(zero-based) was expected to be a int32 tensor but is a int64 tensor [Op:OneHot] name: \n",
      "\n",
      "return tf.reduce_any(tf.one_hot(in1, 9), axis=1, keepdims=False)\n",
      "cannot compute Any as input #0(zero-based) was expected to be a bool tensor but is a float tensor [Op:Any] name: \n",
      "\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.reshape(tf.tile(tf.eye(in1), [in2, 1]), [-1, in1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.reshape(tf.tile(tf.eye(in1), [in2, 1]), [-1, in1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.tile(tf.eye(in1), [in2, 1])\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=3, num_columns=3\n",
      "\n",
      "return tf.cast(tf.sequence_mask(in1, in2), int)\n",
      "Cannot convert the argument `type_value`: <class 'int'> to a TensorFlow DType.\n",
      "\n",
      "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.transpose(in2))), axis=1))\n",
      "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3,2] vs. [2,3] [Op:Sub] name: \n",
      "\n",
      "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.transpose(in2))), axis=1))\n",
      "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3,2] vs. [2,3] [Op:Sub] name: \n",
      "\n",
      "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.transpose(in2))), axis=1))\n",
      "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3,2] vs. [2,3] [Op:Sub] name: \n",
      "\n",
      "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.transpose(in2))), axis=1))\n",
      "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3,2] vs. [2,3] [Op:Sub] name: \n",
      "\n",
      "return tf.reduce_sum(tf.math.squared_difference(in1.values, tf.gather_nd(in2, in1.indices)))\n",
      "'tuple' object has no attribute 'values'\n",
      "\n",
      "dense1 = tf.sparse.to_dense(in1)\n",
      "return tf.reduce_sum(tf.math.squared_difference(dense1, in1))\n",
      "Input must be a SparseTensor.\n",
      "\n",
      "return tf.reduce_sum(tf.math.squared_difference(in1[0], tf.cast(in1[1], tf.float32)))\n",
      "Attempt to convert a value (SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [1 1]], shape=(3, 2), dtype=int64), values=tf.Tensor([ 1.   1.5 -2. ], shape=(3,), dtype=float32), dense_shape=tf.Tensor([2 2], shape=(2,), dtype=int64))) with an unsupported type (<class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>) to a Tensor.\n",
      "\n",
      "return tf.reduce_sum(tf.math.squared_difference(in1.values, tf.gather_nd(in2, in1.indices)))\n",
      "'tuple' object has no attribute 'values'\n",
      "\n",
      "return tf.reduce_sum(tf.square(tf.subtract(in1.values, tf.gather_nd(in1.indices))))\n",
      "'tuple' object has no attribute 'values'\n",
      "\n",
      "dense_tensor = tf.sparse.to_dense(in1)\n",
      "return tf.reduce_sum(tf.math.squared_difference(in1, dense_tensor))\n",
      "Input must be a SparseTensor.\n",
      "\n",
      "return tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=2), tf.expand_dims(in2, axis=1))), axis=-1)), axis=-1)\n",
      "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [5,3,1] vs. [4,1,3] [Op:Sub] name: \n",
      "\n",
      "return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(in2, axis=-1)), axis=0)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3,2,2] vs. [3,1] [Op:Mul] name: \n",
      "\n",
      "return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(tf.cast(in2, tf.float32), -1)), axis=0)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [3,2,2] vs. [3,1] [Op:Mul] name: \n",
      "\n",
      "return tf.tensordot(in1, in2, axes=[0])\n",
      "`axes` must be an integer or have length 2. Received [0].\n",
      "\n",
      "return tf.add(tf.multiply(in1, tf.expand_dims(tf.expand_dims(1 - in3, 1), 2)), tf.multiply(in2, tf.expand_dims(tf.expand_dims(in3, 1), 2)))\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [2,3,2] vs. [3,1,1] [Op:Mul] name: \n",
      "\n",
      "return tf.add(tf.multiply(tf.subtract(in2, in1), tf.expand_dims(tf.expand_dims(in3, 1), 2)), in1)\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [2,3,2] vs. [3,1,1] [Op:Mul] name: \n",
      "\n",
      "return tf.add(tf.multiply(in1, tf.reshape(1 - in3, (-1, 1, 1))), tf.multiply(in2, tf.reshape(in3, (-1, 1, 1))))\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [2,3,2] vs. [3,1,1] [Op:Mul] name: \n",
      "\n",
      "return tf.add(tf.multiply(in1, tf.expand_dims(tf.expand_dims(tf.subtract(tf.constant(1.0), in3), 1), 2)), tf.multiply(in2, tf.expand_dims(tf.expand_dims(in3, 1), 2)))\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [2,3,2] vs. [3,1,1] [Op:Mul] name: \n",
      "\n",
      "return tf.add(tf.multiply(tf.expand_dims(in3, axis=[1,2]), tf.subtract(in2, in1)), in1)\n",
      "{{function_node __wrapped__ExpandDims_device_/job:localhost/replica:0/task:0/device:CPU:0}} 'dim' must be a tensor with a single value [Op:ExpandDims]\n",
      "\n",
      "return tf.add(tf.multiply(in1, tf.reshape(1 - in3, [-1, 1, 1])), tf.multiply(in2, tf.reshape(in3, [-1, 1, 1])))\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [2,3,2] vs. [3,1,1] [Op:Mul] name: \n",
      "\n",
      "return tf.add(tf.multiply(in1, tf.reshape(1. - in3, [in3.shape[0], 1, 1])), tf.multiply(in2, tf.reshape(in3, [in3.shape[0], 1, 1])))\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [2,3,2] vs. [3,1,1] [Op:Mul] name: \n",
      "\n",
      "return tf.add(tf.multiply(in1, tf.subtract(1.0, tf.expand_dims(tf.expand_dims(in3, 1), 2))), tf.multiply(in2, tf.expand_dims(tf.expand_dims(in3, 1), 2)))\n",
      "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [2,3,2] vs. [3,1,1] [Op:Mul] name: \n",
      "\n",
      "return tf.tensordot(in1, tf.expand_dims(in2, 0), [[-1], [0]])\n",
      "{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [4,3], In[1]: [1,3] [Op:MatMul] name: \n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.reshape(tf.boolean_mask(in1, tf.concat(in2, axis=0)), [tf.shape(in2)[0], -1]), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)\n",
      "Shapes (6,) and (3, 6) are incompatible\n",
      "\n",
      "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1))\n",
      "{{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd [Op:GatherNd] name: \n",
      "\n",
      "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in1)[1]), in2], axis=1))\n",
      "{{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd [Op:GatherNd] name: \n",
      "\n",
      "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1))\n",
      "{{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd [Op:GatherNd] name: \n",
      "\n",
      "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1))\n",
      "{{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd [Op:GatherNd] name: \n",
      "\n",
      "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1))\n",
      "{{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd [Op:GatherNd] name: \n",
      "\n",
      "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1))\n",
      "{{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd [Op:GatherNd] name: \n",
      "\n",
      "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1))\n",
      "{{function_node __wrapped__GatherNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd [Op:GatherNd] name: \n",
      "\n",
      "return tf.where(tf.equal(in2, 1), tf.reverse(in1, axis=[2]), in1)\n",
      "{{function_node __wrapped__SelectV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} condition [5], then [1,5,2], and else [1,5,2] must be broadcastable [Op:SelectV2] name: \n",
      "\n",
      "return tf.where(tf.expand_dims(in2, axis=-1), tf.reverse(in1, axis=[1]), in1)\n",
      "cannot compute SelectV2 as input #0(zero-based) was expected to be a bool tensor but is a int64 tensor [Op:SelectV2] name: \n",
      "\n",
      "return tf.where(tf.expand_dims(in2, -1), tf.reverse(in1, axis=[2]), in1)\n",
      "cannot compute SelectV2 as input #0(zero-based) was expected to be a bool tensor but is a int64 tensor [Op:SelectV2] name: \n",
      "\n",
      "return tf.where(tf.cast(in2, tf.bool), tf.reverse(in1, [-1]), in1)\n",
      "{{function_node __wrapped__SelectV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} condition [5], then [1,5,2], and else [1,5,2] must be broadcastable [Op:SelectV2] name: \n",
      "\n",
      "return tf.where(tf.cast(in2, tf.bool), in1[:, ::-1], in1)\n",
      "{{function_node __wrapped__SelectV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} condition [5], then [1,5,2], and else [1,5,2] must be broadcastable [Op:SelectV2] name: \n",
      "\n",
      "return tf.where(tf.expand_dims(in2, -1), tf.reverse(in1, axis=[2]), in1)\n",
      "cannot compute SelectV2 as input #0(zero-based) was expected to be a bool tensor but is a int64 tensor [Op:SelectV2] name: \n",
      "\n",
      "return tf.where(tf.equal(in2, 1), in1[:,:,::-1], in1)\n",
      "{{function_node __wrapped__SelectV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} condition [5], then [1,5,2], and else [1,5,2] must be broadcastable [Op:SelectV2] name: \n",
      "\n",
      "return tf.reshape(tf.boolean_mask(in1, tf.reshape(in2, [-1])), tf.shape(in2))\n",
      "Shapes (17,) and (30,) are incompatible\n",
      "\n",
      "indices = tf.where(in2)\n",
      " updates = tf.gather(in1, tf.range(tf.reduce_sum(tf.cast(in2, tf.int32))))\n",
      " return tf.scatter_nd(indices, updates, tf.shape(in2))\n",
      "cannot compute ScatterNd as input #2(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:ScatterNd] name: \n",
      "\n",
      "return tf.scatter_nd(tf.where(in2), in1[:tf.math.count_nonzero(in2)], tf.shape(in2))\n",
      "cannot compute ScatterNd as input #2(zero-based) was expected to be a int64 tensor but is a int32 tensor [Op:ScatterNd] name: \n",
      "\n",
      "return tf.boolean_mask(in1, tf.cast(tf.reshape(in2, [-1]), tf.bool), axis=0)\n",
      "Shapes (17,) and (30,) are incompatible\n",
      "\n",
      "shape = tf.shape(in2)\n",
      "in1 = tf.reshape(in1[:tf.reduce_sum(shape)], shape)\n",
      "result = tf.where(in2,in1,0)\n",
      "return result\n",
      "{{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 11 values, but the requested shape has 30 [Op:Reshape] name: \n",
      "\n",
      "mask = tf.cast(in2, tf.int32)\n",
      "idx = tf.reshape(tf.where(mask), [-1])\n",
      "val = tf.gather(in1, idx)\n",
      "padding = tf.fill(tf.shape(in2), 0)\n",
      "out = tf.where(mask, val, padding)\n",
      "return out\n",
      "cannot compute SelectV2 as input #0(zero-based) was expected to be a bool tensor but is a int32 tensor [Op:SelectV2] name: \n",
      "\n",
      "result = tf.zeros_like(in2, dtype=tf.int32)\n",
      "counter = tf.constant([0])\n",
      "for i in range(in2.shape[0]):\n",
      "    for j in range(in2.shape[1]):\n",
      "        if in2[i][j]:\n",
      "            result[i,j].assign(in1[counter])\n",
      "            counter += 1\n",
      "return result\n",
      "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'\n",
      "\n",
      "return tf.reshape(tf.boolean_mask(in1, tf.cast(tf.reshape(in2, [-1]), tf.bool)), tf.shape(in2))\n",
      "Shapes (17,) and (30,) are incompatible\n",
      "\n",
      "mask = tf.cast(in2, tf.int32)\n",
      "indices = tf.repeat(tf.range(tf.shape(mask)[1]), tf.reduce_sum(mask, axis=0))\n",
      "updates = tf.boolean_mask(in1, tf.reshape(mask, [-1]))\n",
      "shape = tf.shape(mask)\n",
      "return tf.scatter_nd(tf.expand_dims(indices, axis=-1), updates, shape)\n",
      "Shapes (17,) and (30,) are incompatible\n",
      "\n",
      "return tf.one_hot(in1, 2*in1, axis=1)\n",
      "{{function_node __wrapped__OneHot_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected axis to be -1 or between [0, 1).  But received: 1 [Op:OneHot]\n",
      "\n",
      "return tf.one_hot(in1, depth=in1*2, axis=1)\n",
      "{{function_node __wrapped__OneHot_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected axis to be -1 or between [0, 1).  But received: 1 [Op:OneHot]\n",
      "\n",
      "return tf.scatter_nd([[in1]], [1], [6, 6])\n",
      "{{function_node __wrapped__ScatterNd_device_/job:localhost/replica:0/task:0/device:CPU:0}} Dimensions [1,2) of input[shape=[6,6]] must match dimensions [1,1) of updates[shape=[1]] [Op:ScatterNd]\n",
      "\n",
      "return tf.one_hot(in1, 2*in1 + 1)[:, 3]\n",
      "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Index out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: strided_slice/\n",
      "\n",
      "return tf.one_hot(in1, in1*2)[:, in1]\n",
      "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Index out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: strided_slice/\n",
      "\n",
      "return tf.one_hot(in1, 2 * in1 + 1)[:, in1]\n",
      "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Index out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: strided_slice/\n",
      "\n",
      "return tf.pad(tf.expand_dims(tf.eye(in1, in1+1)[:, 3],-1), [[0,0],[0,0],[0,in1-1]])[:,:,0]\n",
      "Arguments `num_rows` and `num_columns` must be positive integer values. Received: num_rows=5, num_columns=6\n",
      "\n",
      "return tf.one_hot(in1, 2 * in1 + 1, dtype=tf.int32)[:, in1]\n",
      "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Index out of range using input dim 1; input has only 1 dims [Op:StridedSlice] name: strided_slice/\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 23:59:36.544717: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at gather_nd_op.cc:48 : INVALID_ARGUMENT: indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd\n",
      "2024-03-27 23:59:36.546524: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at gather_nd_op.cc:48 : INVALID_ARGUMENT: indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd\n",
      "2024-03-27 23:59:36.547367: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at gather_nd_op.cc:48 : INVALID_ARGUMENT: indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd\n",
      "2024-03-27 23:59:36.548175: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at gather_nd_op.cc:48 : INVALID_ARGUMENT: indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd\n",
      "2024-03-27 23:59:36.549818: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at gather_nd_op.cc:48 : INVALID_ARGUMENT: indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd\n",
      "2024-03-27 23:59:36.550747: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at gather_nd_op.cc:48 : INVALID_ARGUMENT: indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd\n",
      "2024-03-27 23:59:36.551565: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at gather_nd_op.cc:48 : INVALID_ARGUMENT: indices[5] = [5, 0] does not index into param shape [3,6], node name: GatherNd\n",
      "2024-03-27 23:59:36.616884: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: Index out of range using input dim 1; input has only 1 dims\n",
      "2024-03-27 23:59:36.617584: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: Index out of range using input dim 1; input has only 1 dims\n",
      "2024-03-27 23:59:36.618225: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: Index out of range using input dim 1; input has only 1 dims\n",
      "2024-03-27 23:59:36.619031: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: Index out of range using input dim 1; input has only 1 dims\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1447"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EVALUATED_TASKS_FILE = CURRENT_DIRECTORY / \"evaluated_tfcoder.json\"\n",
    "\n",
    "EVALUATED_TASKS_FILE.write_text(json.dumps(\n",
    "    {\n",
    "        task.name: task.num_correct_completions()\n",
    "        for task in TASKS.values()\n",
    "    }\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
