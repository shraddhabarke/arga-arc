{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/ubuntu/arga-arc/tf_coder\n",
      "Root directory: /home/ubuntu/arga-arc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "CURRENT_DIRECTORY = Path(os.getcwd())\n",
    "ROOT_DIRECTORY = (CURRENT_DIRECTORY / \"..\").absolute().resolve()\n",
    "\n",
    "print(f\"Current directory: {CURRENT_DIRECTORY}\")\n",
    "print(f\"Root directory: {ROOT_DIRECTORY}\")\n",
    "\n",
    "sys.path.append(str(ROOT_DIRECTORY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['OPENAI_SECRET_KEY', 'OPENAI_ORGANIZATION', 'TOGETHER_SECRET_KEY', 'TOGETHER_BASE_URL', 'OCTO_SECRET_KEY'])\n"
     ]
    }
   ],
   "source": [
    "import typing as t\n",
    "import json\n",
    "from pprint import pprint\n",
    "from dataclasses import dataclass\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from config import CONFIG\n",
    "from openai import OpenAI\n",
    "import re\n",
    "from collections import Counter\n",
    "import random\n",
    "import ast\n",
    "import traceback\n",
    "from tf_coder.utils import Example, extract_code, normalize_code, TFOPERATORS, SPARSETF_OPERATORS, ConstantCounts, Task, TaskJSONWithOutput\n",
    "\n",
    "pprint(CONFIG.__dict__.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10350\n"
     ]
    }
   ],
   "source": [
    "COMPLETIONS_FILE = CONFIG.ROOT_DIR / \"tf_coder/tfcoder_output.deepseek-ai__deepseek-coder-33b-instruct.json\"\n",
    "\n",
    "with open(COMPLETIONS_FILE, \"r\") as f:\n",
    "    COMPLETIONS_JSON = json.load(f)\n",
    "\n",
    "COMPLETIONS = sum([output[\"completions\"] for output in COMPLETIONS_JSON], [])\n",
    "print(len(COMPLETIONS)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 00:19:00.030311: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "dataset_json: t.List[TaskJSONWithOutput] = json.loads(COMPLETIONS_FILE.read_text())\n",
    "tasks = [Task.from_json_with_output(task_json) for task_json in dataset_json]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLES = [\n",
    "    \"\\ndef transform(in1):\\n    indices = tf.expand_dims(in1, -1)\\n    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n    return tf.concat([range_, indices], axis=1))\\n\\nLead by example, here are examples of the coding assistant's role:\\n\\n[TASK DESCRIPTION]:\\nExecute a MatMul of two tensors.\\n\\n[INPUTS]:\\n[[1,2,3],[4,5,6]] and [[1,2],[3,4],[5,6]]\\n\\n[OUTPUTS]:\\n[[22,28],[49,64]]\\n\\n[PROGRAM]:\\ndef transform(in1, in2):\\n    return tf.matmul(in1, in2)\\n\\n\\n[TASK DESCRIPTION]:\\nCompute the sum of a tensor.\\n\\n[INPUTS]:\\n[[1,2,3],[4,5,6]]\\n\\n[OUTPUTS]:\\n21\\n\\n[PROGRAM]:\\ndef transform(in1):\\n    return tf.reduce_sum(in1)\\n\\n\\n[TASK DESCRIPTION]:\\nFind the maximum value in a\",\n",
    "    'return tf.stack([tf.math.bincount(in1), in1], axis=1)',\n",
    " 'return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])',\n",
    " 'return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])',\n",
    " 'return tf.reshape(in1, [4, 3, 2])',\n",
    " 'tf.reshape(in1, shape=(4, 3, 2))'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalize code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def transform(in1):\\n    indices = tf.expand_dims(in1, -1)\\n    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n    return tf.concat([range_, indices], axis=1))',\n",
       " 'return tf.stack([tf.math.bincount(in1), in1], axis=1)',\n",
       " 'return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])',\n",
       " 'return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])',\n",
       " 'return tf.reshape(in1, [4, 3, 2])',\n",
       " 'tf.reshape(in1, shape=(4, 3, 2))']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXTRACTED_CODE = [\n",
    "    extract_code(example) for example in EXAMPLES\n",
    "]\n",
    "EXTRACTED_CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: unmatched ')' (<unknown>, line 4)\n",
      "def transform(in1):\n",
      "    indices = tf.expand_dims(in1, -1)\n",
      "    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\n",
      "    return tf.concat([range_, indices], axis=1))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for code in EXTRACTED_CODE:\n",
    "    try:\n",
    "        ast.parse(code)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(code)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def transform(in1):\\n    indices = tf.expand_dims(in1, -1)\\n    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n    return tf.concat([range_, indices], axis=1))',\n",
       " 'def transform(in1):\\n    return tf.stack([tf.math.bincount(in1), in1], axis=1)',\n",
       " 'def transform(in1):\\n    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])',\n",
       " 'def transform(in1):\\n    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])',\n",
       " 'def transform(in1):\\n    return tf.reshape(in1, [4, 3, 2])',\n",
       " 'def transform(in1):\\n    return tf.reshape(in1, shape=(4, 3, 2))']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NORMALIZED_CODE = [\n",
    "    normalize_code(code, 'def transform(in1):') for code in EXTRACTED_CODE if code is not None\n",
    "]\n",
    "NORMALIZED_CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: unmatched ')' (<unknown>, line 4)\n",
      "def transform(in1):\n",
      "    indices = tf.expand_dims(in1, -1)\n",
      "    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\n",
      "    return tf.concat([range_, indices], axis=1))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for code in NORMALIZED_CODE:\n",
    "    try:\n",
    "        ast.parse(code)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(code)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokenInfo(type=63 (ENCODING), string='utf-8', start=(0, 0), end=(0, 0), line='')\n",
      "TokenInfo(type=1 (NAME), string='def', start=(1, 0), end=(1, 3), line='def transform(in1):\\n')\n",
      "TokenInfo(type=1 (NAME), string='transform', start=(1, 4), end=(1, 13), line='def transform(in1):\\n')\n",
      "TokenInfo(type=54 (OP), string='(', start=(1, 13), end=(1, 14), line='def transform(in1):\\n')\n",
      "TokenInfo(type=1 (NAME), string='in1', start=(1, 14), end=(1, 17), line='def transform(in1):\\n')\n",
      "TokenInfo(type=54 (OP), string=')', start=(1, 17), end=(1, 18), line='def transform(in1):\\n')\n",
      "TokenInfo(type=54 (OP), string=':', start=(1, 18), end=(1, 19), line='def transform(in1):\\n')\n",
      "TokenInfo(type=4 (NEWLINE), string='\\n', start=(1, 19), end=(1, 20), line='def transform(in1):\\n')\n",
      "TokenInfo(type=5 (INDENT), string='    ', start=(2, 0), end=(2, 4), line='    indices = tf.expand_dims(in1, -1)\\n')\n",
      "TokenInfo(type=1 (NAME), string='indices', start=(2, 4), end=(2, 11), line='    indices = tf.expand_dims(in1, -1)\\n')\n",
      "TokenInfo(type=54 (OP), string='=', start=(2, 12), end=(2, 13), line='    indices = tf.expand_dims(in1, -1)\\n')\n",
      "TokenInfo(type=1 (NAME), string='tf', start=(2, 14), end=(2, 16), line='    indices = tf.expand_dims(in1, -1)\\n')\n",
      "TokenInfo(type=54 (OP), string='.', start=(2, 16), end=(2, 17), line='    indices = tf.expand_dims(in1, -1)\\n')\n",
      "TokenInfo(type=1 (NAME), string='expand_dims', start=(2, 17), end=(2, 28), line='    indices = tf.expand_dims(in1, -1)\\n')\n",
      "TokenInfo(type=54 (OP), string='(', start=(2, 28), end=(2, 29), line='    indices = tf.expand_dims(in1, -1)\\n')\n",
      "TokenInfo(type=1 (NAME), string='in1', start=(2, 29), end=(2, 32), line='    indices = tf.expand_dims(in1, -1)\\n')\n",
      "TokenInfo(type=54 (OP), string=',', start=(2, 32), end=(2, 33), line='    indices = tf.expand_dims(in1, -1)\\n')\n",
      "TokenInfo(type=54 (OP), string='-', start=(2, 34), end=(2, 35), line='    indices = tf.expand_dims(in1, -1)\\n')\n",
      "TokenInfo(type=2 (NUMBER), string='1', start=(2, 35), end=(2, 36), line='    indices = tf.expand_dims(in1, -1)\\n')\n",
      "TokenInfo(type=54 (OP), string=')', start=(2, 36), end=(2, 37), line='    indices = tf.expand_dims(in1, -1)\\n')\n",
      "TokenInfo(type=4 (NEWLINE), string='\\n', start=(2, 37), end=(2, 38), line='    indices = tf.expand_dims(in1, -1)\\n')\n",
      "TokenInfo(type=1 (NAME), string='range_', start=(3, 4), end=(3, 10), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=54 (OP), string='=', start=(3, 11), end=(3, 12), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=1 (NAME), string='tf', start=(3, 13), end=(3, 15), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=54 (OP), string='.', start=(3, 15), end=(3, 16), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=1 (NAME), string='expand_dims', start=(3, 16), end=(3, 27), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=54 (OP), string='(', start=(3, 27), end=(3, 28), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=1 (NAME), string='tf', start=(3, 28), end=(3, 30), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=54 (OP), string='.', start=(3, 30), end=(3, 31), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=1 (NAME), string='range', start=(3, 31), end=(3, 36), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=54 (OP), string='(', start=(3, 36), end=(3, 37), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=1 (NAME), string='tf', start=(3, 37), end=(3, 39), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=54 (OP), string='.', start=(3, 39), end=(3, 40), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=1 (NAME), string='shape', start=(3, 40), end=(3, 45), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=54 (OP), string='(', start=(3, 45), end=(3, 46), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=1 (NAME), string='indices', start=(3, 46), end=(3, 53), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=54 (OP), string=')', start=(3, 53), end=(3, 54), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=54 (OP), string='[', start=(3, 54), end=(3, 55), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=2 (NUMBER), string='0', start=(3, 55), end=(3, 56), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=54 (OP), string=']', start=(3, 56), end=(3, 57), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=54 (OP), string=')', start=(3, 57), end=(3, 58), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=54 (OP), string=',', start=(3, 58), end=(3, 59), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=54 (OP), string='-', start=(3, 60), end=(3, 61), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=2 (NUMBER), string='1', start=(3, 61), end=(3, 62), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=54 (OP), string=')', start=(3, 62), end=(3, 63), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=4 (NEWLINE), string='\\n', start=(3, 63), end=(3, 64), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n')\n",
      "TokenInfo(type=1 (NAME), string='return', start=(4, 4), end=(4, 10), line='    return tf.concat([range_, indices], axis=1))')\n",
      "TokenInfo(type=1 (NAME), string='tf', start=(4, 11), end=(4, 13), line='    return tf.concat([range_, indices], axis=1))')\n",
      "TokenInfo(type=54 (OP), string='.', start=(4, 13), end=(4, 14), line='    return tf.concat([range_, indices], axis=1))')\n",
      "TokenInfo(type=1 (NAME), string='concat', start=(4, 14), end=(4, 20), line='    return tf.concat([range_, indices], axis=1))')\n",
      "TokenInfo(type=54 (OP), string='(', start=(4, 20), end=(4, 21), line='    return tf.concat([range_, indices], axis=1))')\n",
      "TokenInfo(type=54 (OP), string='[', start=(4, 21), end=(4, 22), line='    return tf.concat([range_, indices], axis=1))')\n",
      "TokenInfo(type=1 (NAME), string='range_', start=(4, 22), end=(4, 28), line='    return tf.concat([range_, indices], axis=1))')\n",
      "TokenInfo(type=54 (OP), string=',', start=(4, 28), end=(4, 29), line='    return tf.concat([range_, indices], axis=1))')\n",
      "TokenInfo(type=1 (NAME), string='indices', start=(4, 30), end=(4, 37), line='    return tf.concat([range_, indices], axis=1))')\n",
      "TokenInfo(type=54 (OP), string=']', start=(4, 37), end=(4, 38), line='    return tf.concat([range_, indices], axis=1))')\n",
      "TokenInfo(type=54 (OP), string=',', start=(4, 38), end=(4, 39), line='    return tf.concat([range_, indices], axis=1))')\n",
      "TokenInfo(type=1 (NAME), string='axis', start=(4, 40), end=(4, 44), line='    return tf.concat([range_, indices], axis=1))')\n",
      "TokenInfo(type=54 (OP), string='=', start=(4, 44), end=(4, 45), line='    return tf.concat([range_, indices], axis=1))')\n",
      "TokenInfo(type=2 (NUMBER), string='1', start=(4, 45), end=(4, 46), line='    return tf.concat([range_, indices], axis=1))')\n",
      "TokenInfo(type=54 (OP), string=')', start=(4, 46), end=(4, 47), line='    return tf.concat([range_, indices], axis=1))')\n",
      "TokenInfo(type=54 (OP), string=')', start=(4, 47), end=(4, 48), line='    return tf.concat([range_, indices], axis=1))')\n",
      "Error: ('EOF in multi-line statement', (5, 0))\n",
      "def transform(in1):\n",
      "    indices = tf.expand_dims(in1, -1)\n",
      "    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\n",
      "    return tf.concat([range_, indices], axis=1))\n",
      "\n",
      "TokenInfo(type=63 (ENCODING), string='utf-8', start=(0, 0), end=(0, 0), line='')\n",
      "TokenInfo(type=1 (NAME), string='def', start=(1, 0), end=(1, 3), line='def transform(in1):\\n')\n",
      "TokenInfo(type=1 (NAME), string='transform', start=(1, 4), end=(1, 13), line='def transform(in1):\\n')\n",
      "TokenInfo(type=54 (OP), string='(', start=(1, 13), end=(1, 14), line='def transform(in1):\\n')\n",
      "TokenInfo(type=1 (NAME), string='in1', start=(1, 14), end=(1, 17), line='def transform(in1):\\n')\n",
      "TokenInfo(type=54 (OP), string=')', start=(1, 17), end=(1, 18), line='def transform(in1):\\n')\n",
      "TokenInfo(type=54 (OP), string=':', start=(1, 18), end=(1, 19), line='def transform(in1):\\n')\n",
      "TokenInfo(type=4 (NEWLINE), string='\\n', start=(1, 19), end=(1, 20), line='def transform(in1):\\n')\n",
      "TokenInfo(type=5 (INDENT), string='    ', start=(2, 0), end=(2, 4), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=1 (NAME), string='return', start=(2, 4), end=(2, 10), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=1 (NAME), string='tf', start=(2, 11), end=(2, 13), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=54 (OP), string='.', start=(2, 13), end=(2, 14), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=1 (NAME), string='stack', start=(2, 14), end=(2, 19), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=54 (OP), string='(', start=(2, 19), end=(2, 20), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=54 (OP), string='[', start=(2, 20), end=(2, 21), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=1 (NAME), string='tf', start=(2, 21), end=(2, 23), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=54 (OP), string='.', start=(2, 23), end=(2, 24), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=1 (NAME), string='math', start=(2, 24), end=(2, 28), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=54 (OP), string='.', start=(2, 28), end=(2, 29), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=1 (NAME), string='bincount', start=(2, 29), end=(2, 37), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=54 (OP), string='(', start=(2, 37), end=(2, 38), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=1 (NAME), string='in1', start=(2, 38), end=(2, 41), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=54 (OP), string=')', start=(2, 41), end=(2, 42), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=54 (OP), string=',', start=(2, 42), end=(2, 43), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=1 (NAME), string='in1', start=(2, 44), end=(2, 47), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=54 (OP), string=']', start=(2, 47), end=(2, 48), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=54 (OP), string=',', start=(2, 48), end=(2, 49), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=1 (NAME), string='axis', start=(2, 50), end=(2, 54), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=54 (OP), string='=', start=(2, 54), end=(2, 55), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=2 (NUMBER), string='1', start=(2, 55), end=(2, 56), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=54 (OP), string=')', start=(2, 56), end=(2, 57), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)')\n",
      "TokenInfo(type=4 (NEWLINE), string='', start=(2, 57), end=(2, 58), line='')\n",
      "TokenInfo(type=6 (DEDENT), string='', start=(3, 0), end=(3, 0), line='')\n",
      "TokenInfo(type=0 (ENDMARKER), string='', start=(3, 0), end=(3, 0), line='')\n",
      "TokenInfo(type=63 (ENCODING), string='utf-8', start=(0, 0), end=(0, 0), line='')\n",
      "TokenInfo(type=1 (NAME), string='def', start=(1, 0), end=(1, 3), line='def transform(in1):\\n')\n",
      "TokenInfo(type=1 (NAME), string='transform', start=(1, 4), end=(1, 13), line='def transform(in1):\\n')\n",
      "TokenInfo(type=54 (OP), string='(', start=(1, 13), end=(1, 14), line='def transform(in1):\\n')\n",
      "TokenInfo(type=1 (NAME), string='in1', start=(1, 14), end=(1, 17), line='def transform(in1):\\n')\n",
      "TokenInfo(type=54 (OP), string=')', start=(1, 17), end=(1, 18), line='def transform(in1):\\n')\n",
      "TokenInfo(type=54 (OP), string=':', start=(1, 18), end=(1, 19), line='def transform(in1):\\n')\n",
      "TokenInfo(type=4 (NEWLINE), string='\\n', start=(1, 19), end=(1, 20), line='def transform(in1):\\n')\n",
      "TokenInfo(type=5 (INDENT), string='    ', start=(2, 0), end=(2, 4), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=1 (NAME), string='return', start=(2, 4), end=(2, 10), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=1 (NAME), string='tf', start=(2, 11), end=(2, 13), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string='.', start=(2, 13), end=(2, 14), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=1 (NAME), string='sparse', start=(2, 14), end=(2, 20), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string='.', start=(2, 20), end=(2, 21), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=1 (NAME), string='slice', start=(2, 21), end=(2, 26), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string='(', start=(2, 26), end=(2, 27), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=1 (NAME), string='in1', start=(2, 27), end=(2, 30), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string=',', start=(2, 30), end=(2, 31), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=1 (NAME), string='start', start=(2, 32), end=(2, 37), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string='=', start=(2, 37), end=(2, 38), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string='[', start=(2, 38), end=(2, 39), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=2 (NUMBER), string='0', start=(2, 39), end=(2, 40), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string=',', start=(2, 40), end=(2, 41), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=2 (NUMBER), string='0', start=(2, 41), end=(2, 42), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string=',', start=(2, 42), end=(2, 43), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=2 (NUMBER), string='0', start=(2, 43), end=(2, 44), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string=']', start=(2, 44), end=(2, 45), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string=',', start=(2, 45), end=(2, 46), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=1 (NAME), string='size', start=(2, 47), end=(2, 51), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string='=', start=(2, 51), end=(2, 52), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string='[', start=(2, 52), end=(2, 53), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=2 (NUMBER), string='1', start=(2, 53), end=(2, 54), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string=',', start=(2, 54), end=(2, 55), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string='-', start=(2, 55), end=(2, 56), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=2 (NUMBER), string='1', start=(2, 56), end=(2, 57), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string=',', start=(2, 57), end=(2, 58), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string='-', start=(2, 58), end=(2, 59), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=2 (NUMBER), string='1', start=(2, 59), end=(2, 60), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string=']', start=(2, 60), end=(2, 61), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string=')', start=(2, 61), end=(2, 62), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])')\n",
      "TokenInfo(type=4 (NEWLINE), string='', start=(2, 62), end=(2, 63), line='')\n",
      "TokenInfo(type=6 (DEDENT), string='', start=(3, 0), end=(3, 0), line='')\n",
      "TokenInfo(type=0 (ENDMARKER), string='', start=(3, 0), end=(3, 0), line='')\n",
      "TokenInfo(type=63 (ENCODING), string='utf-8', start=(0, 0), end=(0, 0), line='')\n",
      "TokenInfo(type=1 (NAME), string='def', start=(1, 0), end=(1, 3), line='def transform(in1):\\n')\n",
      "TokenInfo(type=1 (NAME), string='transform', start=(1, 4), end=(1, 13), line='def transform(in1):\\n')\n",
      "TokenInfo(type=54 (OP), string='(', start=(1, 13), end=(1, 14), line='def transform(in1):\\n')\n",
      "TokenInfo(type=1 (NAME), string='in1', start=(1, 14), end=(1, 17), line='def transform(in1):\\n')\n",
      "TokenInfo(type=54 (OP), string=')', start=(1, 17), end=(1, 18), line='def transform(in1):\\n')\n",
      "TokenInfo(type=54 (OP), string=':', start=(1, 18), end=(1, 19), line='def transform(in1):\\n')\n",
      "TokenInfo(type=4 (NEWLINE), string='\\n', start=(1, 19), end=(1, 20), line='def transform(in1):\\n')\n",
      "TokenInfo(type=5 (INDENT), string='    ', start=(2, 0), end=(2, 4), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=1 (NAME), string='return', start=(2, 4), end=(2, 10), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=1 (NAME), string='tf', start=(2, 11), end=(2, 13), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string='.', start=(2, 13), end=(2, 14), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=1 (NAME), string='sparse', start=(2, 14), end=(2, 20), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string='.', start=(2, 20), end=(2, 21), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=1 (NAME), string='slice', start=(2, 21), end=(2, 26), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string='(', start=(2, 26), end=(2, 27), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=1 (NAME), string='in1', start=(2, 27), end=(2, 30), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string=',', start=(2, 30), end=(2, 31), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=1 (NAME), string='start', start=(2, 32), end=(2, 37), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string='=', start=(2, 37), end=(2, 38), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string='[', start=(2, 38), end=(2, 39), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=2 (NUMBER), string='3', start=(2, 39), end=(2, 40), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string=',', start=(2, 40), end=(2, 41), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=2 (NUMBER), string='800', start=(2, 41), end=(2, 44), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string=',', start=(2, 44), end=(2, 45), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=2 (NUMBER), string='2', start=(2, 45), end=(2, 46), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string=']', start=(2, 46), end=(2, 47), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string=',', start=(2, 47), end=(2, 48), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=1 (NAME), string='size', start=(2, 49), end=(2, 53), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string='=', start=(2, 53), end=(2, 54), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string='[', start=(2, 54), end=(2, 55), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=2 (NUMBER), string='1', start=(2, 55), end=(2, 56), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string=',', start=(2, 56), end=(2, 57), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string='-', start=(2, 57), end=(2, 58), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=2 (NUMBER), string='1', start=(2, 58), end=(2, 59), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string=',', start=(2, 59), end=(2, 60), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string='-', start=(2, 60), end=(2, 61), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=2 (NUMBER), string='1', start=(2, 61), end=(2, 62), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string=']', start=(2, 62), end=(2, 63), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=54 (OP), string=')', start=(2, 63), end=(2, 64), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])')\n",
      "TokenInfo(type=4 (NEWLINE), string='', start=(2, 64), end=(2, 65), line='')\n",
      "TokenInfo(type=6 (DEDENT), string='', start=(3, 0), end=(3, 0), line='')\n",
      "TokenInfo(type=0 (ENDMARKER), string='', start=(3, 0), end=(3, 0), line='')\n",
      "TokenInfo(type=63 (ENCODING), string='utf-8', start=(0, 0), end=(0, 0), line='')\n",
      "TokenInfo(type=1 (NAME), string='def', start=(1, 0), end=(1, 3), line='def transform(in1):\\n')\n",
      "TokenInfo(type=1 (NAME), string='transform', start=(1, 4), end=(1, 13), line='def transform(in1):\\n')\n",
      "TokenInfo(type=54 (OP), string='(', start=(1, 13), end=(1, 14), line='def transform(in1):\\n')\n",
      "TokenInfo(type=1 (NAME), string='in1', start=(1, 14), end=(1, 17), line='def transform(in1):\\n')\n",
      "TokenInfo(type=54 (OP), string=')', start=(1, 17), end=(1, 18), line='def transform(in1):\\n')\n",
      "TokenInfo(type=54 (OP), string=':', start=(1, 18), end=(1, 19), line='def transform(in1):\\n')\n",
      "TokenInfo(type=4 (NEWLINE), string='\\n', start=(1, 19), end=(1, 20), line='def transform(in1):\\n')\n",
      "TokenInfo(type=5 (INDENT), string='    ', start=(2, 0), end=(2, 4), line='    return tf.reshape(in1, [4, 3, 2])')\n",
      "TokenInfo(type=1 (NAME), string='return', start=(2, 4), end=(2, 10), line='    return tf.reshape(in1, [4, 3, 2])')\n",
      "TokenInfo(type=1 (NAME), string='tf', start=(2, 11), end=(2, 13), line='    return tf.reshape(in1, [4, 3, 2])')\n",
      "TokenInfo(type=54 (OP), string='.', start=(2, 13), end=(2, 14), line='    return tf.reshape(in1, [4, 3, 2])')\n",
      "TokenInfo(type=1 (NAME), string='reshape', start=(2, 14), end=(2, 21), line='    return tf.reshape(in1, [4, 3, 2])')\n",
      "TokenInfo(type=54 (OP), string='(', start=(2, 21), end=(2, 22), line='    return tf.reshape(in1, [4, 3, 2])')\n",
      "TokenInfo(type=1 (NAME), string='in1', start=(2, 22), end=(2, 25), line='    return tf.reshape(in1, [4, 3, 2])')\n",
      "TokenInfo(type=54 (OP), string=',', start=(2, 25), end=(2, 26), line='    return tf.reshape(in1, [4, 3, 2])')\n",
      "TokenInfo(type=54 (OP), string='[', start=(2, 27), end=(2, 28), line='    return tf.reshape(in1, [4, 3, 2])')\n",
      "TokenInfo(type=2 (NUMBER), string='4', start=(2, 28), end=(2, 29), line='    return tf.reshape(in1, [4, 3, 2])')\n",
      "TokenInfo(type=54 (OP), string=',', start=(2, 29), end=(2, 30), line='    return tf.reshape(in1, [4, 3, 2])')\n",
      "TokenInfo(type=2 (NUMBER), string='3', start=(2, 31), end=(2, 32), line='    return tf.reshape(in1, [4, 3, 2])')\n",
      "TokenInfo(type=54 (OP), string=',', start=(2, 32), end=(2, 33), line='    return tf.reshape(in1, [4, 3, 2])')\n",
      "TokenInfo(type=2 (NUMBER), string='2', start=(2, 34), end=(2, 35), line='    return tf.reshape(in1, [4, 3, 2])')\n",
      "TokenInfo(type=54 (OP), string=']', start=(2, 35), end=(2, 36), line='    return tf.reshape(in1, [4, 3, 2])')\n",
      "TokenInfo(type=54 (OP), string=')', start=(2, 36), end=(2, 37), line='    return tf.reshape(in1, [4, 3, 2])')\n",
      "TokenInfo(type=4 (NEWLINE), string='', start=(2, 37), end=(2, 38), line='')\n",
      "TokenInfo(type=6 (DEDENT), string='', start=(3, 0), end=(3, 0), line='')\n",
      "TokenInfo(type=0 (ENDMARKER), string='', start=(3, 0), end=(3, 0), line='')\n",
      "TokenInfo(type=63 (ENCODING), string='utf-8', start=(0, 0), end=(0, 0), line='')\n",
      "TokenInfo(type=1 (NAME), string='def', start=(1, 0), end=(1, 3), line='def transform(in1):\\n')\n",
      "TokenInfo(type=1 (NAME), string='transform', start=(1, 4), end=(1, 13), line='def transform(in1):\\n')\n",
      "TokenInfo(type=54 (OP), string='(', start=(1, 13), end=(1, 14), line='def transform(in1):\\n')\n",
      "TokenInfo(type=1 (NAME), string='in1', start=(1, 14), end=(1, 17), line='def transform(in1):\\n')\n",
      "TokenInfo(type=54 (OP), string=')', start=(1, 17), end=(1, 18), line='def transform(in1):\\n')\n",
      "TokenInfo(type=54 (OP), string=':', start=(1, 18), end=(1, 19), line='def transform(in1):\\n')\n",
      "TokenInfo(type=4 (NEWLINE), string='\\n', start=(1, 19), end=(1, 20), line='def transform(in1):\\n')\n",
      "TokenInfo(type=5 (INDENT), string='    ', start=(2, 0), end=(2, 4), line='    return tf.reshape(in1, shape=(4, 3, 2))')\n",
      "TokenInfo(type=1 (NAME), string='return', start=(2, 4), end=(2, 10), line='    return tf.reshape(in1, shape=(4, 3, 2))')\n",
      "TokenInfo(type=1 (NAME), string='tf', start=(2, 11), end=(2, 13), line='    return tf.reshape(in1, shape=(4, 3, 2))')\n",
      "TokenInfo(type=54 (OP), string='.', start=(2, 13), end=(2, 14), line='    return tf.reshape(in1, shape=(4, 3, 2))')\n",
      "TokenInfo(type=1 (NAME), string='reshape', start=(2, 14), end=(2, 21), line='    return tf.reshape(in1, shape=(4, 3, 2))')\n",
      "TokenInfo(type=54 (OP), string='(', start=(2, 21), end=(2, 22), line='    return tf.reshape(in1, shape=(4, 3, 2))')\n",
      "TokenInfo(type=1 (NAME), string='in1', start=(2, 22), end=(2, 25), line='    return tf.reshape(in1, shape=(4, 3, 2))')\n",
      "TokenInfo(type=54 (OP), string=',', start=(2, 25), end=(2, 26), line='    return tf.reshape(in1, shape=(4, 3, 2))')\n",
      "TokenInfo(type=1 (NAME), string='shape', start=(2, 27), end=(2, 32), line='    return tf.reshape(in1, shape=(4, 3, 2))')\n",
      "TokenInfo(type=54 (OP), string='=', start=(2, 32), end=(2, 33), line='    return tf.reshape(in1, shape=(4, 3, 2))')\n",
      "TokenInfo(type=54 (OP), string='(', start=(2, 33), end=(2, 34), line='    return tf.reshape(in1, shape=(4, 3, 2))')\n",
      "TokenInfo(type=2 (NUMBER), string='4', start=(2, 34), end=(2, 35), line='    return tf.reshape(in1, shape=(4, 3, 2))')\n",
      "TokenInfo(type=54 (OP), string=',', start=(2, 35), end=(2, 36), line='    return tf.reshape(in1, shape=(4, 3, 2))')\n",
      "TokenInfo(type=2 (NUMBER), string='3', start=(2, 37), end=(2, 38), line='    return tf.reshape(in1, shape=(4, 3, 2))')\n",
      "TokenInfo(type=54 (OP), string=',', start=(2, 38), end=(2, 39), line='    return tf.reshape(in1, shape=(4, 3, 2))')\n",
      "TokenInfo(type=2 (NUMBER), string='2', start=(2, 40), end=(2, 41), line='    return tf.reshape(in1, shape=(4, 3, 2))')\n",
      "TokenInfo(type=54 (OP), string=')', start=(2, 41), end=(2, 42), line='    return tf.reshape(in1, shape=(4, 3, 2))')\n",
      "TokenInfo(type=54 (OP), string=')', start=(2, 42), end=(2, 43), line='    return tf.reshape(in1, shape=(4, 3, 2))')\n",
      "TokenInfo(type=4 (NEWLINE), string='', start=(2, 43), end=(2, 44), line='')\n",
      "TokenInfo(type=6 (DEDENT), string='', start=(3, 0), end=(3, 0), line='')\n",
      "TokenInfo(type=0 (ENDMARKER), string='', start=(3, 0), end=(3, 0), line='')\n"
     ]
    }
   ],
   "source": [
    "import tokenize\n",
    "import io\n",
    "\n",
    "for code in NORMALIZED_CODE:\n",
    "    try:\n",
    "        for token in tokenize.tokenize(io.BytesIO(code.encode('utf-8')).readline):\n",
    "            print(token)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(code)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lex(code: str) -> t.List[tokenize.TokenInfo]:\n",
    "    ans = []\n",
    "    try:\n",
    "        for token in tokenize.tokenize(io.BytesIO(code.encode('utf-8')).readline):\n",
    "            ans.append(token)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TokenInfo(type=63 (ENCODING), string='utf-8', start=(0, 0), end=(0, 0), line=''),\n",
      " TokenInfo(type=1 (NAME), string='def', start=(1, 0), end=(1, 3), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=1 (NAME), string='transform', start=(1, 4), end=(1, 13), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=54 (OP), string='(', start=(1, 13), end=(1, 14), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=1 (NAME), string='in1', start=(1, 14), end=(1, 17), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=54 (OP), string=')', start=(1, 17), end=(1, 18), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=54 (OP), string=':', start=(1, 18), end=(1, 19), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=4 (NEWLINE), string='\\n', start=(1, 19), end=(1, 20), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=5 (INDENT), string='    ', start=(2, 0), end=(2, 4), line='    indices = tf.expand_dims(in1, -1)\\n'),\n",
      " TokenInfo(type=1 (NAME), string='indices', start=(2, 4), end=(2, 11), line='    indices = tf.expand_dims(in1, -1)\\n'),\n",
      " TokenInfo(type=54 (OP), string='=', start=(2, 12), end=(2, 13), line='    indices = tf.expand_dims(in1, -1)\\n'),\n",
      " TokenInfo(type=1 (NAME), string='tf', start=(2, 14), end=(2, 16), line='    indices = tf.expand_dims(in1, -1)\\n'),\n",
      " TokenInfo(type=54 (OP), string='.', start=(2, 16), end=(2, 17), line='    indices = tf.expand_dims(in1, -1)\\n'),\n",
      " TokenInfo(type=1 (NAME), string='expand_dims', start=(2, 17), end=(2, 28), line='    indices = tf.expand_dims(in1, -1)\\n'),\n",
      " TokenInfo(type=54 (OP), string='(', start=(2, 28), end=(2, 29), line='    indices = tf.expand_dims(in1, -1)\\n'),\n",
      " TokenInfo(type=1 (NAME), string='in1', start=(2, 29), end=(2, 32), line='    indices = tf.expand_dims(in1, -1)\\n'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(2, 32), end=(2, 33), line='    indices = tf.expand_dims(in1, -1)\\n'),\n",
      " TokenInfo(type=54 (OP), string='-', start=(2, 34), end=(2, 35), line='    indices = tf.expand_dims(in1, -1)\\n'),\n",
      " TokenInfo(type=2 (NUMBER), string='1', start=(2, 35), end=(2, 36), line='    indices = tf.expand_dims(in1, -1)\\n'),\n",
      " TokenInfo(type=54 (OP), string=')', start=(2, 36), end=(2, 37), line='    indices = tf.expand_dims(in1, -1)\\n'),\n",
      " TokenInfo(type=4 (NEWLINE), string='\\n', start=(2, 37), end=(2, 38), line='    indices = tf.expand_dims(in1, -1)\\n'),\n",
      " TokenInfo(type=1 (NAME), string='range_', start=(3, 4), end=(3, 10), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=54 (OP), string='=', start=(3, 11), end=(3, 12), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=1 (NAME), string='tf', start=(3, 13), end=(3, 15), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=54 (OP), string='.', start=(3, 15), end=(3, 16), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=1 (NAME), string='expand_dims', start=(3, 16), end=(3, 27), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=54 (OP), string='(', start=(3, 27), end=(3, 28), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=1 (NAME), string='tf', start=(3, 28), end=(3, 30), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=54 (OP), string='.', start=(3, 30), end=(3, 31), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=1 (NAME), string='range', start=(3, 31), end=(3, 36), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=54 (OP), string='(', start=(3, 36), end=(3, 37), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=1 (NAME), string='tf', start=(3, 37), end=(3, 39), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=54 (OP), string='.', start=(3, 39), end=(3, 40), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=1 (NAME), string='shape', start=(3, 40), end=(3, 45), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=54 (OP), string='(', start=(3, 45), end=(3, 46), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=1 (NAME), string='indices', start=(3, 46), end=(3, 53), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=54 (OP), string=')', start=(3, 53), end=(3, 54), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=54 (OP), string='[', start=(3, 54), end=(3, 55), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=2 (NUMBER), string='0', start=(3, 55), end=(3, 56), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=54 (OP), string=']', start=(3, 56), end=(3, 57), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=54 (OP), string=')', start=(3, 57), end=(3, 58), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(3, 58), end=(3, 59), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=54 (OP), string='-', start=(3, 60), end=(3, 61), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=2 (NUMBER), string='1', start=(3, 61), end=(3, 62), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=54 (OP), string=')', start=(3, 62), end=(3, 63), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=4 (NEWLINE), string='\\n', start=(3, 63), end=(3, 64), line='    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\\n'),\n",
      " TokenInfo(type=1 (NAME), string='return', start=(4, 4), end=(4, 10), line='    return tf.concat([range_, indices], axis=1))'),\n",
      " TokenInfo(type=1 (NAME), string='tf', start=(4, 11), end=(4, 13), line='    return tf.concat([range_, indices], axis=1))'),\n",
      " TokenInfo(type=54 (OP), string='.', start=(4, 13), end=(4, 14), line='    return tf.concat([range_, indices], axis=1))'),\n",
      " TokenInfo(type=1 (NAME), string='concat', start=(4, 14), end=(4, 20), line='    return tf.concat([range_, indices], axis=1))'),\n",
      " TokenInfo(type=54 (OP), string='(', start=(4, 20), end=(4, 21), line='    return tf.concat([range_, indices], axis=1))'),\n",
      " TokenInfo(type=54 (OP), string='[', start=(4, 21), end=(4, 22), line='    return tf.concat([range_, indices], axis=1))'),\n",
      " TokenInfo(type=1 (NAME), string='range_', start=(4, 22), end=(4, 28), line='    return tf.concat([range_, indices], axis=1))'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(4, 28), end=(4, 29), line='    return tf.concat([range_, indices], axis=1))'),\n",
      " TokenInfo(type=1 (NAME), string='indices', start=(4, 30), end=(4, 37), line='    return tf.concat([range_, indices], axis=1))'),\n",
      " TokenInfo(type=54 (OP), string=']', start=(4, 37), end=(4, 38), line='    return tf.concat([range_, indices], axis=1))'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(4, 38), end=(4, 39), line='    return tf.concat([range_, indices], axis=1))'),\n",
      " TokenInfo(type=1 (NAME), string='axis', start=(4, 40), end=(4, 44), line='    return tf.concat([range_, indices], axis=1))'),\n",
      " TokenInfo(type=54 (OP), string='=', start=(4, 44), end=(4, 45), line='    return tf.concat([range_, indices], axis=1))'),\n",
      " TokenInfo(type=2 (NUMBER), string='1', start=(4, 45), end=(4, 46), line='    return tf.concat([range_, indices], axis=1))'),\n",
      " TokenInfo(type=54 (OP), string=')', start=(4, 46), end=(4, 47), line='    return tf.concat([range_, indices], axis=1))'),\n",
      " TokenInfo(type=54 (OP), string=')', start=(4, 47), end=(4, 48), line='    return tf.concat([range_, indices], axis=1))')]\n",
      "\n",
      "[TokenInfo(type=63 (ENCODING), string='utf-8', start=(0, 0), end=(0, 0), line=''),\n",
      " TokenInfo(type=1 (NAME), string='def', start=(1, 0), end=(1, 3), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=1 (NAME), string='transform', start=(1, 4), end=(1, 13), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=54 (OP), string='(', start=(1, 13), end=(1, 14), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=1 (NAME), string='in1', start=(1, 14), end=(1, 17), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=54 (OP), string=')', start=(1, 17), end=(1, 18), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=54 (OP), string=':', start=(1, 18), end=(1, 19), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=4 (NEWLINE), string='\\n', start=(1, 19), end=(1, 20), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=5 (INDENT), string='    ', start=(2, 0), end=(2, 4), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=1 (NAME), string='return', start=(2, 4), end=(2, 10), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=1 (NAME), string='tf', start=(2, 11), end=(2, 13), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=54 (OP), string='.', start=(2, 13), end=(2, 14), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=1 (NAME), string='stack', start=(2, 14), end=(2, 19), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=54 (OP), string='(', start=(2, 19), end=(2, 20), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=54 (OP), string='[', start=(2, 20), end=(2, 21), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=1 (NAME), string='tf', start=(2, 21), end=(2, 23), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=54 (OP), string='.', start=(2, 23), end=(2, 24), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=1 (NAME), string='math', start=(2, 24), end=(2, 28), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=54 (OP), string='.', start=(2, 28), end=(2, 29), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=1 (NAME), string='bincount', start=(2, 29), end=(2, 37), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=54 (OP), string='(', start=(2, 37), end=(2, 38), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=1 (NAME), string='in1', start=(2, 38), end=(2, 41), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=54 (OP), string=')', start=(2, 41), end=(2, 42), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(2, 42), end=(2, 43), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=1 (NAME), string='in1', start=(2, 44), end=(2, 47), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=54 (OP), string=']', start=(2, 47), end=(2, 48), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(2, 48), end=(2, 49), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=1 (NAME), string='axis', start=(2, 50), end=(2, 54), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=54 (OP), string='=', start=(2, 54), end=(2, 55), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=2 (NUMBER), string='1', start=(2, 55), end=(2, 56), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=54 (OP), string=')', start=(2, 56), end=(2, 57), line='    return tf.stack([tf.math.bincount(in1), in1], axis=1)'),\n",
      " TokenInfo(type=4 (NEWLINE), string='', start=(2, 57), end=(2, 58), line=''),\n",
      " TokenInfo(type=6 (DEDENT), string='', start=(3, 0), end=(3, 0), line=''),\n",
      " TokenInfo(type=0 (ENDMARKER), string='', start=(3, 0), end=(3, 0), line='')]\n",
      "\n",
      "[TokenInfo(type=63 (ENCODING), string='utf-8', start=(0, 0), end=(0, 0), line=''),\n",
      " TokenInfo(type=1 (NAME), string='def', start=(1, 0), end=(1, 3), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=1 (NAME), string='transform', start=(1, 4), end=(1, 13), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=54 (OP), string='(', start=(1, 13), end=(1, 14), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=1 (NAME), string='in1', start=(1, 14), end=(1, 17), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=54 (OP), string=')', start=(1, 17), end=(1, 18), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=54 (OP), string=':', start=(1, 18), end=(1, 19), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=4 (NEWLINE), string='\\n', start=(1, 19), end=(1, 20), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=5 (INDENT), string='    ', start=(2, 0), end=(2, 4), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=1 (NAME), string='return', start=(2, 4), end=(2, 10), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=1 (NAME), string='tf', start=(2, 11), end=(2, 13), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string='.', start=(2, 13), end=(2, 14), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=1 (NAME), string='sparse', start=(2, 14), end=(2, 20), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string='.', start=(2, 20), end=(2, 21), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=1 (NAME), string='slice', start=(2, 21), end=(2, 26), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string='(', start=(2, 26), end=(2, 27), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=1 (NAME), string='in1', start=(2, 27), end=(2, 30), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(2, 30), end=(2, 31), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=1 (NAME), string='start', start=(2, 32), end=(2, 37), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string='=', start=(2, 37), end=(2, 38), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string='[', start=(2, 38), end=(2, 39), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=2 (NUMBER), string='0', start=(2, 39), end=(2, 40), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(2, 40), end=(2, 41), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=2 (NUMBER), string='0', start=(2, 41), end=(2, 42), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(2, 42), end=(2, 43), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=2 (NUMBER), string='0', start=(2, 43), end=(2, 44), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string=']', start=(2, 44), end=(2, 45), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(2, 45), end=(2, 46), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=1 (NAME), string='size', start=(2, 47), end=(2, 51), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string='=', start=(2, 51), end=(2, 52), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string='[', start=(2, 52), end=(2, 53), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=2 (NUMBER), string='1', start=(2, 53), end=(2, 54), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(2, 54), end=(2, 55), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string='-', start=(2, 55), end=(2, 56), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=2 (NUMBER), string='1', start=(2, 56), end=(2, 57), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(2, 57), end=(2, 58), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string='-', start=(2, 58), end=(2, 59), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=2 (NUMBER), string='1', start=(2, 59), end=(2, 60), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string=']', start=(2, 60), end=(2, 61), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string=')', start=(2, 61), end=(2, 62), line='    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])'),\n",
      " TokenInfo(type=4 (NEWLINE), string='', start=(2, 62), end=(2, 63), line=''),\n",
      " TokenInfo(type=6 (DEDENT), string='', start=(3, 0), end=(3, 0), line=''),\n",
      " TokenInfo(type=0 (ENDMARKER), string='', start=(3, 0), end=(3, 0), line='')]\n",
      "\n",
      "[TokenInfo(type=63 (ENCODING), string='utf-8', start=(0, 0), end=(0, 0), line=''),\n",
      " TokenInfo(type=1 (NAME), string='def', start=(1, 0), end=(1, 3), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=1 (NAME), string='transform', start=(1, 4), end=(1, 13), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=54 (OP), string='(', start=(1, 13), end=(1, 14), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=1 (NAME), string='in1', start=(1, 14), end=(1, 17), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=54 (OP), string=')', start=(1, 17), end=(1, 18), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=54 (OP), string=':', start=(1, 18), end=(1, 19), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=4 (NEWLINE), string='\\n', start=(1, 19), end=(1, 20), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=5 (INDENT), string='    ', start=(2, 0), end=(2, 4), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=1 (NAME), string='return', start=(2, 4), end=(2, 10), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=1 (NAME), string='tf', start=(2, 11), end=(2, 13), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string='.', start=(2, 13), end=(2, 14), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=1 (NAME), string='sparse', start=(2, 14), end=(2, 20), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string='.', start=(2, 20), end=(2, 21), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=1 (NAME), string='slice', start=(2, 21), end=(2, 26), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string='(', start=(2, 26), end=(2, 27), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=1 (NAME), string='in1', start=(2, 27), end=(2, 30), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(2, 30), end=(2, 31), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=1 (NAME), string='start', start=(2, 32), end=(2, 37), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string='=', start=(2, 37), end=(2, 38), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string='[', start=(2, 38), end=(2, 39), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=2 (NUMBER), string='3', start=(2, 39), end=(2, 40), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(2, 40), end=(2, 41), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=2 (NUMBER), string='800', start=(2, 41), end=(2, 44), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(2, 44), end=(2, 45), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=2 (NUMBER), string='2', start=(2, 45), end=(2, 46), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string=']', start=(2, 46), end=(2, 47), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(2, 47), end=(2, 48), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=1 (NAME), string='size', start=(2, 49), end=(2, 53), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string='=', start=(2, 53), end=(2, 54), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string='[', start=(2, 54), end=(2, 55), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=2 (NUMBER), string='1', start=(2, 55), end=(2, 56), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(2, 56), end=(2, 57), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string='-', start=(2, 57), end=(2, 58), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=2 (NUMBER), string='1', start=(2, 58), end=(2, 59), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(2, 59), end=(2, 60), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string='-', start=(2, 60), end=(2, 61), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=2 (NUMBER), string='1', start=(2, 61), end=(2, 62), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string=']', start=(2, 62), end=(2, 63), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=54 (OP), string=')', start=(2, 63), end=(2, 64), line='    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])'),\n",
      " TokenInfo(type=4 (NEWLINE), string='', start=(2, 64), end=(2, 65), line=''),\n",
      " TokenInfo(type=6 (DEDENT), string='', start=(3, 0), end=(3, 0), line=''),\n",
      " TokenInfo(type=0 (ENDMARKER), string='', start=(3, 0), end=(3, 0), line='')]\n",
      "\n",
      "[TokenInfo(type=63 (ENCODING), string='utf-8', start=(0, 0), end=(0, 0), line=''),\n",
      " TokenInfo(type=1 (NAME), string='def', start=(1, 0), end=(1, 3), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=1 (NAME), string='transform', start=(1, 4), end=(1, 13), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=54 (OP), string='(', start=(1, 13), end=(1, 14), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=1 (NAME), string='in1', start=(1, 14), end=(1, 17), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=54 (OP), string=')', start=(1, 17), end=(1, 18), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=54 (OP), string=':', start=(1, 18), end=(1, 19), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=4 (NEWLINE), string='\\n', start=(1, 19), end=(1, 20), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=5 (INDENT), string='    ', start=(2, 0), end=(2, 4), line='    return tf.reshape(in1, [4, 3, 2])'),\n",
      " TokenInfo(type=1 (NAME), string='return', start=(2, 4), end=(2, 10), line='    return tf.reshape(in1, [4, 3, 2])'),\n",
      " TokenInfo(type=1 (NAME), string='tf', start=(2, 11), end=(2, 13), line='    return tf.reshape(in1, [4, 3, 2])'),\n",
      " TokenInfo(type=54 (OP), string='.', start=(2, 13), end=(2, 14), line='    return tf.reshape(in1, [4, 3, 2])'),\n",
      " TokenInfo(type=1 (NAME), string='reshape', start=(2, 14), end=(2, 21), line='    return tf.reshape(in1, [4, 3, 2])'),\n",
      " TokenInfo(type=54 (OP), string='(', start=(2, 21), end=(2, 22), line='    return tf.reshape(in1, [4, 3, 2])'),\n",
      " TokenInfo(type=1 (NAME), string='in1', start=(2, 22), end=(2, 25), line='    return tf.reshape(in1, [4, 3, 2])'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(2, 25), end=(2, 26), line='    return tf.reshape(in1, [4, 3, 2])'),\n",
      " TokenInfo(type=54 (OP), string='[', start=(2, 27), end=(2, 28), line='    return tf.reshape(in1, [4, 3, 2])'),\n",
      " TokenInfo(type=2 (NUMBER), string='4', start=(2, 28), end=(2, 29), line='    return tf.reshape(in1, [4, 3, 2])'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(2, 29), end=(2, 30), line='    return tf.reshape(in1, [4, 3, 2])'),\n",
      " TokenInfo(type=2 (NUMBER), string='3', start=(2, 31), end=(2, 32), line='    return tf.reshape(in1, [4, 3, 2])'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(2, 32), end=(2, 33), line='    return tf.reshape(in1, [4, 3, 2])'),\n",
      " TokenInfo(type=2 (NUMBER), string='2', start=(2, 34), end=(2, 35), line='    return tf.reshape(in1, [4, 3, 2])'),\n",
      " TokenInfo(type=54 (OP), string=']', start=(2, 35), end=(2, 36), line='    return tf.reshape(in1, [4, 3, 2])'),\n",
      " TokenInfo(type=54 (OP), string=')', start=(2, 36), end=(2, 37), line='    return tf.reshape(in1, [4, 3, 2])'),\n",
      " TokenInfo(type=4 (NEWLINE), string='', start=(2, 37), end=(2, 38), line=''),\n",
      " TokenInfo(type=6 (DEDENT), string='', start=(3, 0), end=(3, 0), line=''),\n",
      " TokenInfo(type=0 (ENDMARKER), string='', start=(3, 0), end=(3, 0), line='')]\n",
      "\n",
      "[TokenInfo(type=63 (ENCODING), string='utf-8', start=(0, 0), end=(0, 0), line=''),\n",
      " TokenInfo(type=1 (NAME), string='def', start=(1, 0), end=(1, 3), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=1 (NAME), string='transform', start=(1, 4), end=(1, 13), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=54 (OP), string='(', start=(1, 13), end=(1, 14), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=1 (NAME), string='in1', start=(1, 14), end=(1, 17), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=54 (OP), string=')', start=(1, 17), end=(1, 18), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=54 (OP), string=':', start=(1, 18), end=(1, 19), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=4 (NEWLINE), string='\\n', start=(1, 19), end=(1, 20), line='def transform(in1):\\n'),\n",
      " TokenInfo(type=5 (INDENT), string='    ', start=(2, 0), end=(2, 4), line='    return tf.reshape(in1, shape=(4, 3, 2))'),\n",
      " TokenInfo(type=1 (NAME), string='return', start=(2, 4), end=(2, 10), line='    return tf.reshape(in1, shape=(4, 3, 2))'),\n",
      " TokenInfo(type=1 (NAME), string='tf', start=(2, 11), end=(2, 13), line='    return tf.reshape(in1, shape=(4, 3, 2))'),\n",
      " TokenInfo(type=54 (OP), string='.', start=(2, 13), end=(2, 14), line='    return tf.reshape(in1, shape=(4, 3, 2))'),\n",
      " TokenInfo(type=1 (NAME), string='reshape', start=(2, 14), end=(2, 21), line='    return tf.reshape(in1, shape=(4, 3, 2))'),\n",
      " TokenInfo(type=54 (OP), string='(', start=(2, 21), end=(2, 22), line='    return tf.reshape(in1, shape=(4, 3, 2))'),\n",
      " TokenInfo(type=1 (NAME), string='in1', start=(2, 22), end=(2, 25), line='    return tf.reshape(in1, shape=(4, 3, 2))'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(2, 25), end=(2, 26), line='    return tf.reshape(in1, shape=(4, 3, 2))'),\n",
      " TokenInfo(type=1 (NAME), string='shape', start=(2, 27), end=(2, 32), line='    return tf.reshape(in1, shape=(4, 3, 2))'),\n",
      " TokenInfo(type=54 (OP), string='=', start=(2, 32), end=(2, 33), line='    return tf.reshape(in1, shape=(4, 3, 2))'),\n",
      " TokenInfo(type=54 (OP), string='(', start=(2, 33), end=(2, 34), line='    return tf.reshape(in1, shape=(4, 3, 2))'),\n",
      " TokenInfo(type=2 (NUMBER), string='4', start=(2, 34), end=(2, 35), line='    return tf.reshape(in1, shape=(4, 3, 2))'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(2, 35), end=(2, 36), line='    return tf.reshape(in1, shape=(4, 3, 2))'),\n",
      " TokenInfo(type=2 (NUMBER), string='3', start=(2, 37), end=(2, 38), line='    return tf.reshape(in1, shape=(4, 3, 2))'),\n",
      " TokenInfo(type=54 (OP), string=',', start=(2, 38), end=(2, 39), line='    return tf.reshape(in1, shape=(4, 3, 2))'),\n",
      " TokenInfo(type=2 (NUMBER), string='2', start=(2, 40), end=(2, 41), line='    return tf.reshape(in1, shape=(4, 3, 2))'),\n",
      " TokenInfo(type=54 (OP), string=')', start=(2, 41), end=(2, 42), line='    return tf.reshape(in1, shape=(4, 3, 2))'),\n",
      " TokenInfo(type=54 (OP), string=')', start=(2, 42), end=(2, 43), line='    return tf.reshape(in1, shape=(4, 3, 2))'),\n",
      " TokenInfo(type=4 (NEWLINE), string='', start=(2, 43), end=(2, 44), line=''),\n",
      " TokenInfo(type=6 (DEDENT), string='', start=(3, 0), end=(3, 0), line=''),\n",
      " TokenInfo(type=0 (ENDMARKER), string='', start=(3, 0), end=(3, 0), line='')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LEXED = [\n",
    "    lex(code) for code in NORMALIZED_CODE\n",
    "]\n",
    "\n",
    "for lexed in LEXED:\n",
    "    pprint(lexed)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_OPERATORS = TFOPERATORS + SPARSETF_OPERATORS\n",
    "def count_operators(tokens: t.List[tokenize.TokenInfo]) -> t.Dict[str, int]:\n",
    "    seen_tf = False\n",
    "    seen_sparse = False\n",
    "\n",
    "    ans = {}\n",
    "\n",
    "    for token in tokens:\n",
    "        if token.string == '.':\n",
    "            continue\n",
    "        \n",
    "        if token.string == 'tf':\n",
    "            seen_tf = True\n",
    "            continue\n",
    "\n",
    "        if seen_tf:\n",
    "            if seen_sparse:\n",
    "                if any(f\"tf.sparse.{token.string}(\" in operator for operator in ALL_OPERATORS):\n",
    "                    ans[f\"tf.sparse.{token.string}\"] = ans.get(f\"tf.sparse.{token.string}\", 0) + 1\n",
    "                seen_sparse = False\n",
    "                seen_tf = False\n",
    "            elif token.string == 'sparse':\n",
    "                seen_sparse = True\n",
    "            else:\n",
    "                if any(f\"tf.{token.string}(\" in operator for operator in ALL_OPERATORS):\n",
    "                    ans[f\"tf.{token.string}\"] = ans.get(f\"tf.{token.string}\", 0) + 1\n",
    "                seen_tf = False \n",
    "    \n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def transform(in1):\n",
      "    indices = tf.expand_dims(in1, -1)\n",
      "    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\n",
      "    return tf.concat([range_, indices], axis=1))\n",
      "\n",
      "{'tf.concat': 1, 'tf.expand_dims': 2, 'tf.range': 1, 'tf.shape': 1}\n",
      "\n",
      "def transform(in1):\n",
      "    return tf.stack([tf.math.bincount(in1), in1], axis=1)\n",
      "\n",
      "{'tf.stack': 1}\n",
      "\n",
      "def transform(in1):\n",
      "    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\n",
      "\n",
      "{'tf.sparse.slice': 1}\n",
      "\n",
      "def transform(in1):\n",
      "    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])\n",
      "\n",
      "{'tf.sparse.slice': 1}\n",
      "\n",
      "def transform(in1):\n",
      "    return tf.reshape(in1, [4, 3, 2])\n",
      "\n",
      "{'tf.reshape': 1}\n",
      "\n",
      "def transform(in1):\n",
      "    return tf.reshape(in1, shape=(4, 3, 2))\n",
      "\n",
      "{'tf.reshape': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for example,lexed in zip(NORMALIZED_CODE,LEXED):\n",
    "    print(example)\n",
    "    print()\n",
    "    pprint(count_operators(lexed))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example(inputs=[array([0, 0, 0, 1, 3, 3])], output=array([[0, 0],\n",
       "       [0, 1],\n",
       "       [0, 2],\n",
       "       [1, 0],\n",
       "       [3, 0],\n",
       "       [3, 1]]), input_names=None, json={'inputs': '[[0, 0, 0, 1, 3, 3],]', 'outputs': '[[0, 0], [0, 1], [0, 2], [1, 0], [3, 0], [3, 1]]'})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks[0].examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_constant_counts(\n",
    "    counts1: ConstantCounts, counts2: ConstantCounts\n",
    ") -> ConstantCounts:\n",
    "    return {\n",
    "        key: counts1.get(key, 0) + counts2.get(key, 0)\n",
    "        for key in set(counts1.keys()) | set(counts2.keys())\n",
    "    }\n",
    "\n",
    "\n",
    "def is_common(value: t.Any) -> bool:\n",
    "    return (type(value) == int or type(value) == bool) and value in [\n",
    "        0,\n",
    "        1,\n",
    "        -1,\n",
    "        True,\n",
    "        False,\n",
    "    ]\n",
    "\n",
    "\n",
    "def is_axis(value: t.Any, max_input_rank) -> bool:\n",
    "    return type(value) == int and value in range(2, max_input_rank + 1)\n",
    "\n",
    "\n",
    "def is_shape(value: t.Any, dimension_lengths) -> bool:\n",
    "    return type(value) == int and value in dimension_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_constants_lexed(tokens: t.List[tokenize.TokenInfo]) -> t.List[int]:\n",
    "    ans = []\n",
    "    seen_minus = False\n",
    "    for token in tokens:\n",
    "        if token.type == tokenize.OP:\n",
    "            if token.string == \"-\":\n",
    "                seen_minus = True\n",
    "                continue\n",
    "        elif token.type == tokenize.NUMBER:\n",
    "            try:\n",
    "                value = -int(token.string) if seen_minus else int(token.string)\n",
    "            except:\n",
    "                continue\n",
    "            ans.append(value)\n",
    "        \n",
    "        seen_minus = False\n",
    "    return list(set(ans))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def transform(in1):\n",
      "    indices = tf.expand_dims(in1, -1)\n",
      "    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\n",
      "    return tf.concat([range_, indices], axis=1))\n",
      "\n",
      "[0, 1, -1]\n",
      "\n",
      "def transform(in1):\n",
      "    return tf.stack([tf.math.bincount(in1), in1], axis=1)\n",
      "\n",
      "[1]\n",
      "\n",
      "def transform(in1):\n",
      "    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\n",
      "\n",
      "[0, 1, -1]\n",
      "\n",
      "def transform(in1):\n",
      "    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])\n",
      "\n",
      "[800, 1, 2, 3, -1]\n",
      "\n",
      "def transform(in1):\n",
      "    return tf.reshape(in1, [4, 3, 2])\n",
      "\n",
      "[2, 3, 4]\n",
      "\n",
      "def transform(in1):\n",
      "    return tf.reshape(in1, shape=(4, 3, 2))\n",
      "\n",
      "[2, 3, 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for example,lexed in zip(NORMALIZED_CODE,LEXED):\n",
    "    print(example)\n",
    "    print()\n",
    "    pprint(get_constants_lexed(lexed))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_constants(tokens: t.List[tokenize.TokenInfo], example: Example) -> ConstantCounts:\n",
    "    counts = {\n",
    "        \"common\": 0,\n",
    "        \"axis\": 0,\n",
    "        \"shape\": 0,\n",
    "        \"provided\": 0,\n",
    "        \"tf_int32\": 0,\n",
    "        \"tf_float32\": 0,\n",
    "        \"tf_int64\": 0,\n",
    "        \"tf_bool\": 0,\n",
    "        \"input_var\": 0,\n",
    "        \"shape_tuple\": 0,\n",
    "    }\n",
    "    # example.max_input_rank,\n",
    "    #     example.dimension_lengths,\n",
    "    #     example.output_shape,\n",
    "    seen_minus = False\n",
    "    seen_tf = False\n",
    "    for token in tokens:\n",
    "        if token.type == tokenize.OP:\n",
    "            if token.string == \"-\":\n",
    "                seen_minus = True\n",
    "                continue\n",
    "        elif token.type == tokenize.NUMBER:\n",
    "            try:\n",
    "                value = -int(token.string) if seen_minus else int(token.string)\n",
    "            except:\n",
    "                continue\n",
    "            if is_common(value):\n",
    "                counts[\"common\"] += 1\n",
    "            elif is_axis(value, example.max_input_rank):\n",
    "                counts[\"axis\"] += 1\n",
    "            elif is_shape(value, example.dimension_lengths):\n",
    "                counts[\"shape\"] += 1\n",
    "            else:\n",
    "                counts[\"provided\"] += 1\n",
    "        elif token.type == tokenize.NAME:\n",
    "            if token.string == \"tf\":\n",
    "                seen_tf = True\n",
    "                continue\n",
    "            elif seen_tf:\n",
    "                if token.string == \"int32\":\n",
    "                    counts[\"tf_int32\"] += 1\n",
    "                elif token.string == \"float32\":\n",
    "                    counts[\"tf_float32\"] += 1\n",
    "                elif token.string == \"int64\":\n",
    "                    counts[\"tf_int64\"] += 1\n",
    "                elif token.string == \"bool\":\n",
    "                    counts[\"tf_bool\"] += 1\n",
    "        elif token.type == tokenize.DOT:\n",
    "            continue\n",
    "\n",
    "        # TODO: shape tuple (not sure if it's worth implementing at the lexer level)\n",
    "        seen_minus = False\n",
    "        seen_tf = False\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_EXAMPLES = [\n",
    "    tasks[0].examples,\n",
    "    tasks[2].examples,\n",
    "    tasks[2].examples,\n",
    "    tasks[3].examples,\n",
    "    tasks[3].examples\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def transform(in1):\n",
      "    indices = tf.expand_dims(in1, -1)\n",
      "    range_ = tf.expand_dims(tf.range(tf.shape(indices)[0]), -1)\n",
      "    return tf.concat([range_, indices], axis=1))\n",
      "\n",
      "{'axis': 0,\n",
      " 'common': 4,\n",
      " 'input_var': 0,\n",
      " 'provided': 0,\n",
      " 'shape': 0,\n",
      " 'shape_tuple': 0,\n",
      " 'tf_bool': 0,\n",
      " 'tf_float32': 0,\n",
      " 'tf_int32': 0,\n",
      " 'tf_int64': 0}\n",
      "\n",
      "def transform(in1):\n",
      "    return tf.stack([tf.math.bincount(in1), in1], axis=1)\n",
      "\n",
      "{'axis': 0,\n",
      " 'common': 1,\n",
      " 'input_var': 0,\n",
      " 'provided': 0,\n",
      " 'shape': 0,\n",
      " 'shape_tuple': 0,\n",
      " 'tf_bool': 0,\n",
      " 'tf_float32': 0,\n",
      " 'tf_int32': 0,\n",
      " 'tf_int64': 0}\n",
      "\n",
      "def transform(in1):\n",
      "    return tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\n",
      "\n",
      "{'axis': 0,\n",
      " 'common': 6,\n",
      " 'input_var': 0,\n",
      " 'provided': 0,\n",
      " 'shape': 0,\n",
      " 'shape_tuple': 0,\n",
      " 'tf_bool': 0,\n",
      " 'tf_float32': 0,\n",
      " 'tf_int32': 0,\n",
      " 'tf_int64': 0}\n",
      "\n",
      "def transform(in1):\n",
      "    return tf.sparse.slice(in1, start=[3,800,2], size=[1,-1,-1])\n",
      "\n",
      "{'axis': 1,\n",
      " 'common': 3,\n",
      " 'input_var': 0,\n",
      " 'provided': 2,\n",
      " 'shape': 0,\n",
      " 'shape_tuple': 0,\n",
      " 'tf_bool': 0,\n",
      " 'tf_float32': 0,\n",
      " 'tf_int32': 0,\n",
      " 'tf_int64': 0}\n",
      "\n",
      "def transform(in1):\n",
      "    return tf.reshape(in1, [4, 3, 2])\n",
      "\n",
      "{'axis': 1,\n",
      " 'common': 0,\n",
      " 'input_var': 0,\n",
      " 'provided': 1,\n",
      " 'shape': 1,\n",
      " 'shape_tuple': 0,\n",
      " 'tf_bool': 0,\n",
      " 'tf_float32': 0,\n",
      " 'tf_int32': 0,\n",
      " 'tf_int64': 0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for code,lexed, example in zip(NORMALIZED_CODE,LEXED, TEST_EXAMPLES):\n",
    "    print(code)\n",
    "    print()\n",
    "    pprint(count_constants(lexed, example))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
