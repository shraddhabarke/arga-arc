{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/ubuntu/arga-arc/tf_coder\n",
      "Root directory: /home/ubuntu/arga-arc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "CURRENT_DIRECTORY = Path(os.getcwd())\n",
    "ROOT_DIRECTORY = (CURRENT_DIRECTORY / \"..\").absolute().resolve()\n",
    "\n",
    "print(f\"Current directory: {CURRENT_DIRECTORY}\")\n",
    "print(f\"Root directory: {ROOT_DIRECTORY}\")\n",
    "\n",
    "sys.path.append(str(ROOT_DIRECTORY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['OPENAI_SECRET_KEY', 'OPENAI_ORGANIZATION'])\n"
     ]
    }
   ],
   "source": [
    "import typing as t\n",
    "import json\n",
    "from pprint import pprint\n",
    "from dataclasses import dataclass\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from config import CONFIG\n",
    "from openai import OpenAI\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "pprint(CONFIG.__dict__.keys())\n",
    "\n",
    "OPENAI = OpenAI(api_key=CONFIG.OPENAI_SECRET_KEY, organization=CONFIG.OPENAI_ORGANIZATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parsing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 72 tasks from /home/ubuntu/arga-arc/tf_coder/tfcoder_dataset.json\n",
      "dict_keys(['google_01', 'google_02', 'google_03', 'google_04', 'google_05', 'google_06', 'google_07', 'google_08', 'google_09', 'google_10', 'google_11', 'google_12', 'google_13', 'google_14', 'google_15', 'google_16', 'google_17', 'google_18', 'google_19', 'google_20', 'google_21', 'google_22', 'stackoverflow_01', 'stackoverflow_02', 'stackoverflow_03', 'stackoverflow_04', 'stackoverflow_05', 'stackoverflow_06', 'stackoverflow_07', 'stackoverflow_08', 'stackoverflow_09', 'stackoverflow_10', 'stackoverflow_11', 'stackoverflow_12', 'stackoverflow_13', 'stackoverflow_14', 'stackoverflow_15', 'stackoverflow_16', 'stackoverflow_17', 'stackoverflow_18', 'stackoverflow_19', 'stackoverflow_20', 'stackoverflow_21', 'stackoverflow_22', 'stackoverflow_23', 'stackoverflow_24', 'stackoverflow_25', 'stackoverflow_26', 'stackoverflow_27', 'stackoverflow_28', 'stackoverflow_29', 'stackoverflow_30', 'stackoverflow_31', 'stackoverflow_32', 'stackoverflow_33', 'stackoverflow_34', 'stackoverflow_35', 'stackoverflow_36', 'stackoverflow_37', 'stackoverflow_38', 'stackoverflow_39', 'stackoverflow_40', 'stackoverflow_41', 'stackoverflow_42', 'stackoverflow_43', 'stackoverflow_44', 'stackoverflow_45', 'stackoverflow_46', 'stackoverflow_47', 'stackoverflow_48', 'stackoverflow_49', 'stackoverflow_50'])\n"
     ]
    }
   ],
   "source": [
    "class OutputJSON(t.TypedDict):\n",
    "    task_id: str\n",
    "    completions: t.List[str]\n",
    "    coverage_percentage: float\n",
    "    description: str\n",
    "    tf_operators: t.Dict[str, int]\n",
    "    total_covered: int\n",
    "    total_in_target: int\n",
    "\n",
    "class ExamplesJSON(t.TypedDict):\n",
    "    inputs: str\n",
    "    outputs: str\n",
    "\n",
    "class TaskJSON(t.TypedDict):\n",
    "    constants: str\n",
    "    description: str\n",
    "    name: str\n",
    "    source: str\n",
    "    target_program: str\n",
    "    examples: ExamplesJSON\n",
    "\n",
    "DATASET_FILE = CURRENT_DIRECTORY / \"tfcoder_dataset.json\"\n",
    "DATASET: t.List[TaskJSON] = json.loads(DATASET_FILE.read_text())\n",
    "\n",
    "print(f\"Loaded {len(DATASET)} tasks from {DATASET_FILE}\")\n",
    "\n",
    "TASK_JSONS = {task[\"name\"] : task for task in DATASET}\n",
    "pprint(TASK_JSONS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'completions': ['tf.sparse.slice(input_1, start=[0,0,0], size=[1,-1,-1])',\n",
      "                 'tf.sparse.slice(input_1, [0,0,0], [1,-1,-1])',\n",
      "                 'tf.sparse.slice(input_1, tf.constant([0, 0, 0], '\n",
      "                 'dtype=tf.int64), tf.constant([1, -1, -1], dtype=tf.int64))',\n",
      "                 'tf.sparse.slice(input_1, [0,0,0], [1,-1,-1])',\n",
      "                 'tf.sparse.slice(input_1, [0, 0, 0], [1, -1, -1])',\n",
      "                 'tf.sparse.slice(input_1, [0, 0, 0], [1, -1, -1])',\n",
      "                 'tf.sparse.slice(input_1, [0, 0, 0], [1, -1, -1])',\n",
      "                 'tf.sparse.slice(input_1, [0, 0, 0], [1, -1, -1])',\n",
      "                 'tf.sparse.slice(input_1, [0, 0, 0], [1, -1, -1])',\n",
      "                 'tf.sparse.slice(input_1, [0, 0, 0], [1, -1, -1])'],\n",
      " 'constants': '[]',\n",
      " 'description': 'Slice the first dimension of a SparseTensor',\n",
      " 'examples': {'inputs': 'tf.SparseTensor(indices=[[0, 0, 0], [0, 1, 1], [1, 1, '\n",
      "                        '1], [1, 1, 2]], values=[1., 1., 1., 1.], '\n",
      "                        'dense_shape=[2, 2, 800])',\n",
      "              'outputs': 'tf.SparseTensor(indices=[[0, 0, 0], [0, 1, 1]], '\n",
      "                         'values=[1., 1.], dense_shape=[1, 2, 800])'},\n",
      " 'name': 'google_03',\n",
      " 'parsed_examples': Example(inputs=[SparseTensor(indices=tf.Tensor(\n",
      "[[0 0 0]\n",
      " [0 1 1]\n",
      " [1 1 1]\n",
      " [1 1 2]], shape=(4, 3), dtype=int64), values=tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32), dense_shape=tf.Tensor([  2   2 800], shape=(3,), dtype=int64))],\n",
      "                            output=SparseTensor(indices=tf.Tensor(\n",
      "[[0 0 0]\n",
      " [0 1 1]], shape=(2, 3), dtype=int64), values=tf.Tensor([1. 1.], shape=(2,), dtype=float32), dense_shape=tf.Tensor([  1   2 800], shape=(3,), dtype=int64))),\n",
      " 'source': 'Real task encountered by Googler, 11/01/2018',\n",
      " 'target_program': 'tf.divide(in1, tf.expand_dims(tf.reduce_sum(in1, axis=1), '\n",
      "                   '1))'}\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Example:\n",
    "    inputs: t.List[np.ndarray]\n",
    "    output: t.Union[np.ndarray, tf.SparseTensor]\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, examples: ExamplesJSON):\n",
    "        try:\n",
    "            evaluated_inputs = eval(examples[\"inputs\"])\n",
    "            if isinstance(evaluated_inputs, list):\n",
    "                inputs = [np.array(i) for i in evaluated_inputs]\n",
    "            else:\n",
    "                inputs = [evaluated_inputs]\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating inputs: {e}\")\n",
    "            print(f\"Inputs: {examples['inputs']}\")\n",
    "            raise e\n",
    "\n",
    "        try:\n",
    "            evaluated_outputs = eval(examples[\"outputs\"])\n",
    "            if isinstance(evaluated_outputs, list):\n",
    "                outputs = np.array(evaluated_outputs)\n",
    "            elif isinstance(evaluated_outputs, tf.SparseTensor):\n",
    "                outputs = evaluated_outputs\n",
    "            elif isinstance(evaluated_outputs, tf.Tensor):\n",
    "                outputs = evaluated_outputs.numpy()\n",
    "            else:\n",
    "                outputs = evaluated_outputs\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating outputs: {e}\")\n",
    "            print(f\"Outputs: {examples['outputs']}\")\n",
    "            raise e\n",
    "\n",
    "        return cls(inputs, outputs)\n",
    "    \n",
    "    def toJSON(self):\n",
    "        return {\n",
    "            \"inputs\": [i.tolist() for i in self.inputs],\n",
    "            \"output\": self.output.tolist()\n",
    "        }\n",
    "\n",
    "for name, task in TASK_JSONS.items():\n",
    "    task[\"parsed_examples\"] = Example.from_json(task[\"examples\"])\n",
    "\n",
    "pprint(TASK_JSONS[\"google_03\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFOPERATORS = \"\\nTensorFlow functions to use:\\n---------------------\\ntf.abs(x)\\ntf.add(x, y)\\ntf.add_n(inputs)\\ntf.argmax(input, axis)\\ntf.argmin(input, axis)\\n\"+\\\n",
    "\"tf.argsort(values, axis, stable=True)\\ntf.argsort(values, axis, direction='DESCENDING', stable=True)\\ntf.boolean_mask(tensor, mask)\\ntf.broadcast_to(input, shape)\\n\"+\\\n",
    "\"tf.cast(x, dtype)\\ntf.clip_by_value(t, clip_value_min, clip_value_max)\\ntf.concat(values, axis)\\ntf.constant(value)\\ntf.constant(value, dtype)\\ntf.divide(x, y)\\n\"+\\\n",
    "\"tf.equal(x, y)\\ntf.exp(x)\\ntf.expand_dims(input, axis)\\ntf.eye(num_rows)\\ntf.eye(num_rows, num_columns)\\ntf.eye(num_rows, dtype)\\ntf.fill(dims, value)\"+\\\n",
    "\"tf.gather(params, indices)\\ntf.gather(params, indices, axis, batch_dims)\\ntf.gather_nd(params, indices)\\ntf.gather_nd(params, indices, batch_dims)\\ntf.greater(x, y)\\n\"+\\\n",
    "\"tf.greater_equal(x, y)\\ntf.math.bincount(arr)\\ntf.math.ceil(x)\\ntf.math.count_nonzero(input)\\ntf.math.count_nonzero(input, axis)\\ntf.math.cumsum(x, axis)\\n\"+\\\n",
    "\"tf.math.cumsum(x, axis, exclusive=True)\\ntf.math.divide_no_nan(x, y)\\ntf.math.floor(x)\\ntf.math.log(x)\\ntf.math.logical_and(x, y)\\ntf.math.logical_not(x)\"+\\\n",
    "\"tf.math.logical_or(x, y)\\ntf.math.logical_xor(x, y)\\ntf.math.negative(x)\\ntf.math.reciprocal(x)\\ntf.math.reciprocal_no_nan(x)\\ntf.math.segment_max(data, segment_ids)\\n\"+\\\n",
    "\"tf.math.segment_mean(data, segment_ids)\\ntf.math.segment_min(data, segment_ids)\\ntf.math.segment_prod(data, segment_ids)\\ntf.math.segment_sum(data, segment_ids)\\n\"+\\\n",
    "\"tf.math.squared_difference(x, y)\\ntf.math.top_k(input, k)\\ntf.math.unsorted_segment_max(data, segment_ids, num_segments)\\ntf.math.unsorted_segment_mean(data, segment_ids, num_segments)\\n\"+\\\n",
    "\"tf.math.unsorted_segment_min(data, segment_ids, num_segments)\\ntf.math.unsorted_segment_prod(data, segment_ids, num_segments)\\ntf.math.unsorted_segment_sum(data, segment_ids, num_segments)\\n\"+\\\n",
    "\"tf.matmul(a, b)\\ntf.maximum(x, y)\\ntf.minimum(x, y)\\ntf.multiply(x, y)\\ntf.not_equal(x, y)\\ntf.one_hot(indices, depth)\\ntf.ones(shape)\\ntf.ones_like(input)\\n\"+\\\n",
    "\"tf.pad(tensor, paddings, mode='CONSTANT')\\ntf.pad(tensor, paddings, mode='CONSTANT', constant_values)\\ntf.pad(tensor, paddings, mode='REFLECT')\\n\"+\\\n",
    "\"tf.pad(tensor, paddings, mode='SYMMETRIC')\\ntf.range(start)\\ntf.range(start, limit, delta)\\ntf.reduce_any(input_tensor, axis)\\ntf.reduce_all(input_tensor, axis)\\n\"+\\\n",
    "\"tf.reduce_max(input_tensor)\\ntf.reduce_max(input_tensor, axis)\\ntf.reduce_mean(input_tensor)\\n\"+\\\n",
    "\"tf.reduce_mean(input_tensor, axis)\\ntf.reduce_min(input_tensor)\\ntf.reduce_min(input_tensor, axis)\\n\"+\\\n",
    "\"tf.reduce_prod(input_tensor, axis)\\ntf.reduce_sum(input_tensor)\\ntf.reduce_sum(input_tensor, axis)\\n\"+\\\n",
    "\"tf.repeat(input, repeats)\\ntf.repeat(input, repeats, axis)\\ntf.reshape(tensor, shape)\\n\"+\\\n",
    "\"tf.reverse(tensor, axis)\\ntf.roll(input, shift, axis)\\ntf.round(x)\\ntf.scatter_nd(indices, updates, shape)\\n\"+\\\n",
    "\"tf.searchsorted(sorted_sequence, values, side='left')\\ntf.searchsorted(sorted_sequence, values, side='right')\\n\"+\\\n",
    "\"tf.sequence_mask(lengths)\\ntf.sequence_mask(lengths, maxlen)\\ntf.shape(input)\\ntf.sign(x)\\n\"+\\\n",
    "\"tf.sort(values, axis)\\ntf.sort(values, axis, direction='DESCENDING')\\ntf.sqrt(x)\\n\"+\\\n",
    "\"tf.square(x)\\ntf.squeeze(input)\\ntf.squeeze(input, axis)\\ntf.stack(values, axis)\\ntf.subtract(x, y)\\n\"+\\\n",
    "\"tf.tensor_scatter_nd_update(tensor, indices, updates)\\ntf.tensordot(a, b, axes)\\ntf.tile(input, multiples)\\n\"+\\\n",
    "\"tf.transpose(a)\\ntf.transpose(a, perm)\\ntf.unique_with_counts(x)\\ntf.unstack(value, axis)\\n\"+\\\n",
    "\"tf.where(condition)\\ntf.where(condition, x, y)\\ntf.zeros(shape)\\ntf.zeros_like(input)\"+\\\n",
    "\"\\n\\nSparseTensor functions:\\n-----------------------\\ntf.SparseTensor(indices, values, dense_shape)\\ntf.sparse.add(a, b)\\n\"+\\\n",
    "\"tf.sparse.concat(axis, sp_inputs)\\ntf.sparse.expand_dims(sp_input, axis)\\ntf.sparse.from_dense(tensor)\\ntf.sparse.maximum(sp_a, sp_b)\\n\"+\\\n",
    "\"tf.sparse.minimum(sp_a, sp_b)\\ntf.sparse.reduce_max(sp_input, axis, output_is_sparse)\\ntf.sparse.reduce_sum(sp_input, axis, output_is_sparse)\\n\"+\\\n",
    "\"tf.sparse.reset_shape(sp_input)\\ntf.sparse.reshape(sp_input, shape)\\ntf.sparse.retain(sp_input, to_retain)\\ntf.sparse.slice(sp_input, start, size)\\n\"+\\\n",
    "\"tf.sparse.split(sp_input, num_split, axis)\\ntf.sparse.to_dense(sp_input)\\ntf.sparse.to_dense(sp_input, default_value)\\n\"+\\\n",
    "\"tf.sparse.to_indicator(sp_input, vocab_size)\\ntf.sparse.transpose(sp_input)\\ntf.sparse.transpose(sp_input, perm)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a coding assistant. Be precise and terse.\n",
    "You will be provided a list of tensorflow operators, a task description, and some input/output examples.\n",
    "Your task is to generate the body of a python function that will transform the input to the output.\n",
    "Only use the operators provided in the list.\n",
    "\"\"\"\n",
    "\n",
    "def make_user_message(task):\n",
    "    parsed_examples: Example = task['parsed_examples']\n",
    "    examples_str = \"Inputs:\\n\"\n",
    "    for inp in parsed_examples.inputs:\n",
    "        examples_str += f\"{inp}\\n\"\n",
    "    examples_str += \"Output:\\n\"\n",
    "    examples_str += f\"{parsed_examples.output}\\n\"\n",
    "\n",
    "    formals_str = [f\"in{i+1}\" for i in range(len(parsed_examples.inputs))]\n",
    "\n",
    "    return f\"\"\"[TENSORFLOW OPERATORS]\n",
    "{TFOPERATORS}\n",
    "\n",
    "[TASK DESCRIPTION]\n",
    "{task['description']}\n",
    "\n",
    "[EXAMPLES]\n",
    "{examples_str}\n",
    "\n",
    "[PROGRAM]\n",
    "def transform({\",\".join(formals_str)}):\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(system_message: str, user_message: str, n_completions: int) -> t.List[str]:\n",
    "    response = OPENAI.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_message},\n",
    "        ],\n",
    "        n=n_completions,\n",
    "        temperature=1.0,\n",
    "    )\n",
    "    return [choice.message.content for choice in response.choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[TENSORFLOW OPERATORS]\\n'\n",
      " '\\n'\n",
      " 'TensorFlow functions to use:\\n'\n",
      " '---------------------\\n'\n",
      " 'tf.abs(x)\\n'\n",
      " 'tf.add(x, y)\\n'\n",
      " 'tf.add_n(inputs)\\n'\n",
      " 'tf.argmax(input, axis)\\n'\n",
      " 'tf.argmin(input, axis)\\n'\n",
      " 'tf.argsort(values, axis, stable=True)\\n'\n",
      " \"tf.argsort(values, axis, direction='DESCENDING', stable=True)\\n\"\n",
      " 'tf.boolean_mask(tensor, mask)\\n'\n",
      " 'tf.broadcast_to(input, shape)\\n'\n",
      " 'tf.cast(x, dtype)\\n'\n",
      " 'tf.clip_by_value(t, clip_value_min, clip_value_max)\\n'\n",
      " 'tf.concat(values, axis)\\n'\n",
      " 'tf.constant(value)\\n'\n",
      " 'tf.constant(value, dtype)\\n'\n",
      " 'tf.divide(x, y)\\n'\n",
      " 'tf.equal(x, y)\\n'\n",
      " 'tf.exp(x)\\n'\n",
      " 'tf.expand_dims(input, axis)\\n'\n",
      " 'tf.eye(num_rows)\\n'\n",
      " 'tf.eye(num_rows, num_columns)\\n'\n",
      " 'tf.eye(num_rows, dtype)\\n'\n",
      " 'tf.fill(dims, value)tf.gather(params, indices)\\n'\n",
      " 'tf.gather(params, indices, axis, batch_dims)\\n'\n",
      " 'tf.gather_nd(params, indices)\\n'\n",
      " 'tf.gather_nd(params, indices, batch_dims)\\n'\n",
      " 'tf.greater(x, y)\\n'\n",
      " 'tf.greater_equal(x, y)\\n'\n",
      " 'tf.math.bincount(arr)\\n'\n",
      " 'tf.math.ceil(x)\\n'\n",
      " 'tf.math.count_nonzero(input)\\n'\n",
      " 'tf.math.count_nonzero(input, axis)\\n'\n",
      " 'tf.math.cumsum(x, axis)\\n'\n",
      " 'tf.math.cumsum(x, axis, exclusive=True)\\n'\n",
      " 'tf.math.divide_no_nan(x, y)\\n'\n",
      " 'tf.math.floor(x)\\n'\n",
      " 'tf.math.log(x)\\n'\n",
      " 'tf.math.logical_and(x, y)\\n'\n",
      " 'tf.math.logical_not(x)tf.math.logical_or(x, y)\\n'\n",
      " 'tf.math.logical_xor(x, y)\\n'\n",
      " 'tf.math.negative(x)\\n'\n",
      " 'tf.math.reciprocal(x)\\n'\n",
      " 'tf.math.reciprocal_no_nan(x)\\n'\n",
      " 'tf.math.segment_max(data, segment_ids)\\n'\n",
      " 'tf.math.segment_mean(data, segment_ids)\\n'\n",
      " 'tf.math.segment_min(data, segment_ids)\\n'\n",
      " 'tf.math.segment_prod(data, segment_ids)\\n'\n",
      " 'tf.math.segment_sum(data, segment_ids)\\n'\n",
      " 'tf.math.squared_difference(x, y)\\n'\n",
      " 'tf.math.top_k(input, k)\\n'\n",
      " 'tf.math.unsorted_segment_max(data, segment_ids, num_segments)\\n'\n",
      " 'tf.math.unsorted_segment_mean(data, segment_ids, num_segments)\\n'\n",
      " 'tf.math.unsorted_segment_min(data, segment_ids, num_segments)\\n'\n",
      " 'tf.math.unsorted_segment_prod(data, segment_ids, num_segments)\\n'\n",
      " 'tf.math.unsorted_segment_sum(data, segment_ids, num_segments)\\n'\n",
      " 'tf.matmul(a, b)\\n'\n",
      " 'tf.maximum(x, y)\\n'\n",
      " 'tf.minimum(x, y)\\n'\n",
      " 'tf.multiply(x, y)\\n'\n",
      " 'tf.not_equal(x, y)\\n'\n",
      " 'tf.one_hot(indices, depth)\\n'\n",
      " 'tf.ones(shape)\\n'\n",
      " 'tf.ones_like(input)\\n'\n",
      " \"tf.pad(tensor, paddings, mode='CONSTANT')\\n\"\n",
      " \"tf.pad(tensor, paddings, mode='CONSTANT', constant_values)\\n\"\n",
      " \"tf.pad(tensor, paddings, mode='REFLECT')\\n\"\n",
      " \"tf.pad(tensor, paddings, mode='SYMMETRIC')\\n\"\n",
      " 'tf.range(start)\\n'\n",
      " 'tf.range(start, limit, delta)\\n'\n",
      " 'tf.reduce_any(input_tensor, axis)\\n'\n",
      " 'tf.reduce_all(input_tensor, axis)\\n'\n",
      " 'tf.reduce_max(input_tensor)\\n'\n",
      " 'tf.reduce_max(input_tensor, axis)\\n'\n",
      " 'tf.reduce_mean(input_tensor)\\n'\n",
      " 'tf.reduce_mean(input_tensor, axis)\\n'\n",
      " 'tf.reduce_min(input_tensor)\\n'\n",
      " 'tf.reduce_min(input_tensor, axis)\\n'\n",
      " 'tf.reduce_prod(input_tensor, axis)\\n'\n",
      " 'tf.reduce_sum(input_tensor)\\n'\n",
      " 'tf.reduce_sum(input_tensor, axis)\\n'\n",
      " 'tf.repeat(input, repeats)\\n'\n",
      " 'tf.repeat(input, repeats, axis)\\n'\n",
      " 'tf.reshape(tensor, shape)\\n'\n",
      " 'tf.reverse(tensor, axis)\\n'\n",
      " 'tf.roll(input, shift, axis)\\n'\n",
      " 'tf.round(x)\\n'\n",
      " 'tf.scatter_nd(indices, updates, shape)\\n'\n",
      " \"tf.searchsorted(sorted_sequence, values, side='left')\\n\"\n",
      " \"tf.searchsorted(sorted_sequence, values, side='right')\\n\"\n",
      " 'tf.sequence_mask(lengths)\\n'\n",
      " 'tf.sequence_mask(lengths, maxlen)\\n'\n",
      " 'tf.shape(input)\\n'\n",
      " 'tf.sign(x)\\n'\n",
      " 'tf.sort(values, axis)\\n'\n",
      " \"tf.sort(values, axis, direction='DESCENDING')\\n\"\n",
      " 'tf.sqrt(x)\\n'\n",
      " 'tf.square(x)\\n'\n",
      " 'tf.squeeze(input)\\n'\n",
      " 'tf.squeeze(input, axis)\\n'\n",
      " 'tf.stack(values, axis)\\n'\n",
      " 'tf.subtract(x, y)\\n'\n",
      " 'tf.tensor_scatter_nd_update(tensor, indices, updates)\\n'\n",
      " 'tf.tensordot(a, b, axes)\\n'\n",
      " 'tf.tile(input, multiples)\\n'\n",
      " 'tf.transpose(a)\\n'\n",
      " 'tf.transpose(a, perm)\\n'\n",
      " 'tf.unique_with_counts(x)\\n'\n",
      " 'tf.unstack(value, axis)\\n'\n",
      " 'tf.where(condition)\\n'\n",
      " 'tf.where(condition, x, y)\\n'\n",
      " 'tf.zeros(shape)\\n'\n",
      " 'tf.zeros_like(input)\\n'\n",
      " '\\n'\n",
      " 'SparseTensor functions:\\n'\n",
      " '-----------------------\\n'\n",
      " 'tf.SparseTensor(indices, values, dense_shape)\\n'\n",
      " 'tf.sparse.add(a, b)\\n'\n",
      " 'tf.sparse.concat(axis, sp_inputs)\\n'\n",
      " 'tf.sparse.expand_dims(sp_input, axis)\\n'\n",
      " 'tf.sparse.from_dense(tensor)\\n'\n",
      " 'tf.sparse.maximum(sp_a, sp_b)\\n'\n",
      " 'tf.sparse.minimum(sp_a, sp_b)\\n'\n",
      " 'tf.sparse.reduce_max(sp_input, axis, output_is_sparse)\\n'\n",
      " 'tf.sparse.reduce_sum(sp_input, axis, output_is_sparse)\\n'\n",
      " 'tf.sparse.reset_shape(sp_input)\\n'\n",
      " 'tf.sparse.reshape(sp_input, shape)\\n'\n",
      " 'tf.sparse.retain(sp_input, to_retain)\\n'\n",
      " 'tf.sparse.slice(sp_input, start, size)\\n'\n",
      " 'tf.sparse.split(sp_input, num_split, axis)\\n'\n",
      " 'tf.sparse.to_dense(sp_input)\\n'\n",
      " 'tf.sparse.to_dense(sp_input, default_value)\\n'\n",
      " 'tf.sparse.to_indicator(sp_input, vocab_size)\\n'\n",
      " 'tf.sparse.transpose(sp_input)\\n'\n",
      " 'tf.sparse.transpose(sp_input, perm)\\n'\n",
      " '\\n'\n",
      " '[TASK DESCRIPTION]\\n'\n",
      " 'Slice the first dimension of a SparseTensor\\n'\n",
      " '\\n'\n",
      " '[EXAMPLES]\\n'\n",
      " 'Inputs:\\n'\n",
      " 'SparseTensor(indices=tf.Tensor(\\n'\n",
      " '[[0 0 0]\\n'\n",
      " ' [0 1 1]\\n'\n",
      " ' [1 1 1]\\n'\n",
      " ' [1 1 2]], shape=(4, 3), dtype=int64), values=tf.Tensor([1. 1. 1. 1.], '\n",
      " 'shape=(4,), dtype=float32), dense_shape=tf.Tensor([  2   2 800], shape=(3,), '\n",
      " 'dtype=int64))\\n'\n",
      " 'Output:\\n'\n",
      " 'SparseTensor(indices=tf.Tensor(\\n'\n",
      " '[[0 0 0]\\n'\n",
      " ' [0 1 1]], shape=(2, 3), dtype=int64), values=tf.Tensor([1. 1.], shape=(2,), '\n",
      " 'dtype=float32), dense_shape=tf.Tensor([  1   2 800], shape=(3,), '\n",
      " 'dtype=int64))\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '[PROGRAM]\\n'\n",
      " 'def transform(in1):\\n'\n",
      " '    ')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['return tf.sparse.slice(sp_input= in1, start= [0, 0, 0], size= [1, -1, -1])',\n",
       " 'indices = tf.boolean_mask(in1.indices, in1.indices[:, 0] == 0)\\n    values = tf.gather_nd(in1.values, tf.where(in1.indices[:, 0] == 0))\\n    dense_shape = tf.concat([[1], in1.dense_shape[1:]], 0)\\n    return tf.SparseTensor(indices, values, dense_shape)',\n",
       " '# The task requires to slice the first dimension of a SparseTensor. We can use the `tf.sparse.slice` function for this operation.\\n# Start is a 1-D tensor represents the start of the slice and for this case it will be [0, 0, 0] because we want to start from the beginning.\\n# Size is a 1-D tensor represents the size of the slice. we only want to take first element along the first dimension and all elements along the remaining dimensions, so it will be [1, -1, -1].\\n# tf.sparse.slice(input, start, size) function extracts a slice from a SparseTensor.\\n\\nreturn tf.sparse.slice(in1, start=[0, 0, 0], size=[1, -1, -1])',\n",
       " '# Function to slice the first dimension of SparseTensor\\ndef transform(SparseTensor):\\n\\n    # create a boolean mask where the first dimension is 0\\n    mask = tf.equal(SparseTensor.indices[:,0], 0)\\n\\n    # use the boolean mask to get the sliced SparseTensor\\n    sliced_SparseTensor = tf.sparse.retain(SparseTensor, mask)\\n\\n    # reset the shape of the sliced SparseTensor\\n    sliced_SparseTensor = tf.sparse.reset_shape(sliced_SparseTensor)\\n\\n    return sliced_SparseTensor\\n',\n",
       " 'indices = tf.boolean_mask(in1.indices, in1.indices[:, 0] < 1)\\n    values = tf.gather(in1.values, tf.where(in1.indices[:, 0] < 1)[:, 0])\\n    dense_shape = in1.dense_shape\\n    dense_shape = tf.concat([[1], dense_shape[1:]], 0)\\n    return tf.SparseTensor(indices, values, dense_shape)']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_TASK = TASK_JSONS[\"google_03\"]\n",
    "\n",
    "pprint(make_user_message(TEST_TASK))\n",
    "\n",
    "prompt(SYSTEM_PROMPT, make_user_message(TEST_TASK), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_name, task in TASK_JSONS.items():\n",
    "    del task[\"completions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompting for task: google_01, description: Convert index tensor into pairs for SparseTensor indexing\n",
      "['pairs = tf.stack([tf.math.bincount(in1), tf.range(tf.shape(in1)[0])], '\n",
      " 'axis=1)\\n'\n",
      " '     idx = tf.where(tf.not_equal(pairs[:, 0], 0))\\n'\n",
      " '     pairs = tf.gather(pairs, idx)\\n'\n",
      " '     return pairs[:, 0]',\n",
      " 'return tf.stack([tf.math.floor_div(in1, 4), tf.math.floormod(in1, 4)], '\n",
      " 'axis=-1)',\n",
      " 'indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'uniques, idx = tf.unique_with_counts(in1)\\n'\n",
      " 'return tf.stack([in1, tf.gather(tf.math.bincount(idx), idx)], axis=-1)',\n",
      " 'return tf.stack([tf.math.bincount(in1), tf.gather(tf.range(tf.size(in1)), '\n",
      " 'tf.argsort(in1))], axis=1)',\n",
      " '# We want to convert simple indices to pairs \\n'\n",
      " '# First, We count the frequency of occurrence of each element in the input '\n",
      " 'tensor\\n'\n",
      " '# Then We create a sequence for each unique element in the input tensor up '\n",
      " 'to its count\\n'\n",
      " '# Finally, we gather all these sequences into our final output tensor.\\n'\n",
      " '\\n'\n",
      " 'def transform(in1):\\n'\n",
      " '    count = tf.math.bincount(in1)  # count occurrences of each index\\n'\n",
      " '    unique, _ = tf.unique_with_counts(in1)  # get unique indices\\n'\n",
      " '    result = tf.concat([tf.stack([tf.tile([u], [c]), tf.range(c)], axis=1)\\n'\n",
      " '                        for u, c in zip(unique.numpy(), '\n",
      " 'count.numpy()[unique.numpy()])], axis=0)\\n'\n",
      " '    return result',\n",
      " 'return tf.stack([in1, tf.math.bincount(in1)], axis=1)',\n",
      " 'return tf.stack([in1, tf.math.bincount(in1)], axis=1)',\n",
      " 'return tf.stack([tf.math.floor_divide(in1, tf.reduce_max(in1) + 1), '\n",
      " 'tf.math.floormod(in1,  tf.reduce_max(in1) + 1)], axis=1)',\n",
      " 'range_tensor = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'return tf.stack([in1, range_tensor], axis=1)',\n",
      " 'indices = tf.range(tf.size(in1), dtype=in1.dtype)\\n'\n",
      " 'result = tf.stack([in1, indices], axis=1)\\n'\n",
      " 'return result']\n",
      "\n",
      "Prompting for task: google_02, description: Divide each row by the sum of that row\n",
      "['row_sums = tf.reduce_sum(in1, axis=1, keepdims=True)\\n'\n",
      " 'return tf.divide(in1, row_sums)',\n",
      " 'row_sums = tf.reduce_sum(in1, axis=1, keepdims=True)\\n'\n",
      " 'return tf.divide(in1, row_sums)',\n",
      " 'row_sums = tf.reduce_sum(in1, axis=1)\\n'\n",
      " 'row_sums_reshaped = tf.reshape(row_sums, [-1, 1])\\n'\n",
      " 'output = tf.divide(in1, row_sums_reshaped)\\n'\n",
      " 'return output',\n",
      " 'return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))',\n",
      " 'return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))',\n",
      " 'row_sum = tf.reduce_sum(in1, axis=1, keepdims=True)\\n'\n",
      " 'output = tf.divide(in1, row_sum)\\n'\n",
      " 'return output',\n",
      " 'return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))',\n",
      " 'row_sum = tf.reduce_sum(in1, axis=1, keepdims=True)\\n'\n",
      " 'return tf.divide(in1, row_sum)',\n",
      " 'row_sums = tf.reduce_sum(in1, axis=1)\\n'\n",
      " 'row_sums_exp = tf.expand_dims(row_sums, axis=1)\\n'\n",
      " 'result = tf.divide(in1, row_sums_exp)\\n'\n",
      " 'return result',\n",
      " 'return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))']\n",
      "\n",
      "Prompting for task: google_03, description: Slice the first dimension of a SparseTensor\n",
      "['# In this TensorFlow task, we need to slice the first dimension of a '\n",
      " \"SparseTensor. For this, we can use the 'tf.sparse.slice' function.\\n\"\n",
      " \"# The required 'start' and 'size' parameters will respectively be an array \"\n",
      " \"of zeros (same length as SparseTensor dimensions) and an array having '1' \"\n",
      " \"for the first element and '-1' for the rest.\\n\"\n",
      " '\\n'\n",
      " 'import tensorflow as tf\\n'\n",
      " '\\n'\n",
      " 'def transform(sparse_tensor):\\n'\n",
      " '    dims = len(sparse_tensor.dense_shape.numpy())\\n'\n",
      " '    start = [0] * dims\\n'\n",
      " '    size = [-1] * dims\\n'\n",
      " '    size[0] = 1\\n'\n",
      " '    return tf.sparse.slice(sparse_tensor, start, size)',\n",
      " 'indices = in1.indices\\n'\n",
      " '    values = in1.values\\n'\n",
      " '    dense_shape = in1.dense_shape\\n'\n",
      " '\\n'\n",
      " '    mask = tf.less(indices[:, 0], 1)\\n'\n",
      " '    new_indices = tf.boolean_mask(indices, mask)\\n'\n",
      " '    new_values = tf.boolean_mask(values, mask)\\n'\n",
      " '\\n'\n",
      " '    new_dense_shape = tf.concat([[1], dense_shape[1:]], 0)\\n'\n",
      " '\\n'\n",
      " '    return tf.SparseTensor(indices=new_indices, values=new_values, '\n",
      " 'dense_shape=new_dense_shape)',\n",
      " 'condition = tf.less(in1.indices[:, 0], 1)\\n'\n",
      " 'indices = tf.boolean_mask(in1.indices, condition)\\n'\n",
      " 'values = tf.boolean_mask(in1.values, condition)\\n'\n",
      " 'dense_shape = tf.concat([[1], in1.dense_shape[1:]], axis=0)\\n'\n",
      " 'return tf.SparseTensor(indices, values, dense_shape)',\n",
      " '# we want to slice the first dimension \\n'\n",
      " \"# first let's find the indices where the first column of `indices` is zero, \"\n",
      " 'which denotes the first dimension\\n'\n",
      " 'mask = tf.equal(in1.indices[:,0], 0)\\n'\n",
      " '# now we select those indices using `boolean_mask`\\n'\n",
      " 'indices = tf.boolean_mask(in1.indices, mask)\\n'\n",
      " '# we also select the corresponding values\\n'\n",
      " 'values = tf.boolean_mask(in1.values, mask)\\n'\n",
      " '# we need to adjust the dense_shape by setting the first element to 1 '\n",
      " 'because we sliced the first dimension\\n'\n",
      " 'dense_shape = tf.concat([[1], in1.dense_shape[1:]], 0)\\n'\n",
      " '# finally we return the new SparseTensor\\n'\n",
      " 'return tf.SparseTensor(indices, values, dense_shape)',\n",
      " 'indices = tf.where(in1.indices[:, 0] < 1)\\n'\n",
      " 'new_indices = tf.gather(in1.indices, indices)[:,0]\\n'\n",
      " 'new_values = tf.gather(in1.values, indices)[:,0]\\n'\n",
      " 'new_shape = tf.concat([[1], in1.dense_shape[1:]], axis=0)\\n'\n",
      " 'return tf.SparseTensor(new_indices, new_values, new_shape)',\n",
      " '# first, we convert the sparse tensor to dense tensor \\n'\n",
      " '# then we slice the first dimension \\n'\n",
      " 'slice_tensor=tf.slice(tf.sparse.to_dense(in1),[0,0,0],[-1,-1,-1])\\n'\n",
      " '# Now we find the indices where the tensor is not zero\\n'\n",
      " 'indices = tf.where(slice_tensor != 0)\\n'\n",
      " '# Now we gather the values from tensor for these indices\\n'\n",
      " 'values = tf.gather_nd(slice_tensor, indices)\\n'\n",
      " '# Now we create a new sparse tensor with these indices and values \\n'\n",
      " '# but we need to adjust the first dimension of the dense shape\\n'\n",
      " 'shape = [1]\\n'\n",
      " 'shape.extend(in1.dense_shape.numpy()[1:].tolist())\\n'\n",
      " 'return tf.SparseTensor(indices=indices, values=values, dense_shape=shape)',\n",
      " '# Use tf.sparse.slice to make a slice along the first dimension\\n'\n",
      " '    return tf.sparse.slice(in1, [0, 0, 0], [1, -1, -1])',\n",
      " 'return tf.sparse.slice(in1, [0, 0, 0], [1, -1, -1])',\n",
      " '# Create a mask that returns True for entries in the SparseTensor where the '\n",
      " 'first index is 0\\n'\n",
      " 'mask = tf.equal(in1.indices[:, 0], 0)\\n'\n",
      " '\\n'\n",
      " '# Use the mask to retain the entries where the first index is 0\\n'\n",
      " 'result = tf.sparse.retain(in1, mask)\\n'\n",
      " '\\n'\n",
      " '# Reset the dense_shape of the result to reflect the sliced dimension\\n'\n",
      " 'result = tf.sparse.reset_shape(result, [1] + '\n",
      " 'in1.dense_shape.numpy().tolist()[1:])\\n'\n",
      " '\\n'\n",
      " 'return result',\n",
      " 'out = tf.sparse.slice(in1, start=[0, 0, 0], size=[1, -1, -1])\\nreturn out']\n",
      "\n",
      "Prompting for task: google_04, description: Reshape a flat array into a rank 3 tensor\n",
      "['return tf.reshape(in1, [4, 3, 2])',\n",
      " 'return tf.reshape(in1, [4, 3, 2])',\n",
      " 'return tf.reshape(in1, [4, 3, 2])',\n",
      " 'return tf.reshape(in1, [4, 3, 2])',\n",
      " 'return tf.reshape(in1, [4, 3, 2])',\n",
      " 'return tf.reshape(in1, [4, 3, 2])',\n",
      " 'return tf.reshape(in1, [4, 3, 2])',\n",
      " 'return tf.reshape(in1, [4, 3, 2])',\n",
      " 'return tf.reshape(in1, [4, 3, 2])',\n",
      " 'return tf.reshape(in1, [4, 3, 2])']\n",
      "\n",
      "Prompting for task: google_05, description: Repeat each input entry 6 times\n",
      "['return tf.repeat(in1, repeats=6, axis=1)',\n",
      " 'return tf.repeat(in1, repeats=6, axis=0)',\n",
      " 'return tf.repeat(tf.expand_dims(in1, axis=1), repeats=6, axis=1)',\n",
      " 'return tf.repeat(in1, repeats=6, axis=0)',\n",
      " 'return tf.repeat(in1, 6, axis=0)',\n",
      " 'return tf.repeat(in1, [6], axis=0)',\n",
      " 'return tf.repeat(in1, repeats=6, axis=0)',\n",
      " 'return tf.repeat(tf.expand_dims(in1, axis=1), repeats=6, axis=1)',\n",
      " 'return tf.repeat(tf.expand_dims(in1, axis=1), repeats=6, axis=1)',\n",
      " 'return tf.repeat(in1, repeats=6, axis=0)']\n",
      "\n",
      "Prompting for task: google_06, description: Take the max from each group of elements\n",
      "['return tf.math.segment_max(in2, in1)',\n",
      " 'return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + '\n",
      " '1).numpy()',\n",
      " 'unique_elements, id_map = tf.unique(in1)\\n'\n",
      " 'groups_max = tf.math.segment_max(in2, id_map)\\n'\n",
      " 'return groups_max',\n",
      " 'return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1)+1)',\n",
      " 'return tf.math.segment_max(in2, in1)',\n",
      " 'return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + '\n",
      " '1).numpy().tolist()',\n",
      " 'return tf.math.segment_max(in2, in1)',\n",
      " 'return tf.math.segment_max(in2, in1).numpy().tolist()',\n",
      " 'return tf.math.unsorted_segment_max(in2, in1, '\n",
      " 'tf.reduce_max(in1)+1).numpy().tolist()',\n",
      " 'segments = tf.constant(in1)\\n'\n",
      " 'data = tf.constant(in2)\\n'\n",
      " 'max_of_segments = tf.math.segment_max(data, segments)\\n'\n",
      " 'return max_of_segments.numpy().tolist()']\n",
      "\n",
      "Prompting for task: google_07, description: Take the argmax of each group of elements\n",
      "['unique, indices, counts = tf.unique_with_counts(in1)\\n'\n",
      " 'max_values = [tf.reduce_max(tf.boolean_mask(in2, tf.equal(in1, u))) for u in '\n",
      " 'unique.numpy()]\\n'\n",
      " 'return max_values',\n",
      " 'group_ids = tf.unique_with_counts(in1).y\\n'\n",
      " 'counts = tf.unique_with_counts(in1).count\\n'\n",
      " '\\n'\n",
      " 'start_index = tf.cumsum(counts, exclusive=True)\\n'\n",
      " 'end_index = tf.cumsum(counts, exclusive=False)\\n'\n",
      " '\\n'\n",
      " 'range_vals = tf.reshape(tf.range(start_index, end_index), (-1, 1))\\n'\n",
      " 'argmax_indices = tf.argmax(tf.gather(in2, range_vals), axis=1)\\n'\n",
      " '\\n'\n",
      " 'return tf.gather(in2, argmax_indices)',\n",
      " 'return tf.math.segment_max(in2, in1).numpy().tolist()',\n",
      " 'segments = tf.cast(in1, tf.int32)\\n'\n",
      " 'values = tf.cast(in2, tf.int32)\\n'\n",
      " 'result = tf.math.segment_max(values, segments)\\n'\n",
      " 'return result',\n",
      " 'return tf.math.segment_max(in2, in1)',\n",
      " 'segment_ids = tf.constant(in1)\\n'\n",
      " 'data = tf.constant(in2)\\n'\n",
      " 'return tf.math.segment_max(data, segment_ids)',\n",
      " 'segment_ids = tf.cast(in1, tf.int32)\\n'\n",
      " 'data = tf.cast(in2, tf.int32)\\n'\n",
      " 'argmax_indices = tf.math.segment_max(data, segment_ids)\\n'\n",
      " 'return argmax_indices',\n",
      " 'segment_ids = tf.constant(in1)\\n'\n",
      " 'data = tf.constant(in2)\\n'\n",
      " 'out = tf.argmax(tf.math.unsorted_segment_max(data, segment_ids, '\n",
      " 'tf.reduce_max(segment_ids)+1))\\n'\n",
      " 'return tf.cast(out, tf.int32).numpy().tolist()',\n",
      " 'return tf.math.segment_max(in2, in1).numpy().tolist()',\n",
      " 'import tensorflow as tf\\n'\n",
      " '\\n'\n",
      " 'def transform(in1,in2):\\n'\n",
      " '    unique_values, indices, counts = tf.unique_with_counts(in1)\\n'\n",
      " '    segments = tf.cumsum(counts)[:-1]\\n'\n",
      " '    segment_max = tf.math.unsorted_segment_max(in2, indices, '\n",
      " 'tf.reduce_max(indices) + 1)\\n'\n",
      " '    return tf.gather(indices, tf.math.argmax(segment_max))']\n",
      "\n",
      "Prompting for task: google_08, description: create a mask for sequences of the given lengths\n",
      "['return tf.sequence_mask(in1, tf.reduce_max(in1))',\n",
      " 'return tf.sequence_mask(in1, maxlen=tf.reduce_max(in1))',\n",
      " 'return tf.sequence_mask(in1).numpy().astype(int)',\n",
      " 'return tf.sequence_mask(in1, maxlen=tf.reduce_max(in1)).numpy()',\n",
      " 'return tf.sequence_mask(in1, tf.reduce_max(in1))',\n",
      " 'return tf.sequence_mask(in1).numpy()',\n",
      " 'return tf.sequence_mask(in1, tf.reduce_max(in1))',\n",
      " 'return tf.sequence_mask(in1, tf.reduce_max(in1))',\n",
      " 'return tf.sequence_mask(in1, tf.reduce_max(in1))',\n",
      " 'return tf.sequence_mask(in1, tf.reduce_max(in1)).numpy().astype(int)']\n",
      "\n",
      "Prompting for task: google_09, description: sort the segments\n",
      "['# Sorting the segments in in2 according to their corresponding segment IDs '\n",
      " 'in in1.\\n'\n",
      " '# This is done by using the tf.math.unsorted_segment_max and tf.argsort '\n",
      " 'functions to get the sorting order of the segments,\\n'\n",
      " '# and then using tf.gather to reorder the segments.\\n'\n",
      " '\\n'\n",
      " 'def transform(in1,in2):\\n'\n",
      " '    sorted_segments = tf.math.unsorted_segment_max(in2, in1, '\n",
      " 'tf.reduce_max(in1) + 1)\\n'\n",
      " '    sorted_order = tf.argsort(sorted_segments)\\n'\n",
      " '    reorder = tf.gather(in1, sorted_order)\\n'\n",
      " '    result = tf.gather(in2, reorder)\\n'\n",
      " '    return result',\n",
      " '# sort the input segment wise, we first gather the elements of each segment '\n",
      " 'and then sorts them. \\n'\n",
      " '# We then concatenate the sorted segments again to form the final answer.\\n'\n",
      " '\\n'\n",
      " 'segment_ids = tf.constant(in1)\\n'\n",
      " 'to_segment = tf.constant(in2)\\n'\n",
      " '\\n'\n",
      " '# Get the unique segment identifiers and sort them.\\n'\n",
      " 'unique_segment_ids, _ = tf.unique(segment_ids) \\n'\n",
      " 'sorted_segment_ids = tf.sort(unique_segment_ids)\\n'\n",
      " '\\n'\n",
      " '# For each segment identifier...\\n'\n",
      " 'segments = [tf.boolean_mask(to_segment, tf.equal(segment_ids, segment_id)) '\n",
      " 'for segment_id in sorted_segment_ids]\\n'\n",
      " '\\n'\n",
      " '# Sort the elements of each segment.\\n'\n",
      " 'sorted_segments = [tf.sort(segment) for segment in segments]\\n'\n",
      " '\\n'\n",
      " '# Concatenate the sorted segments to obtain the final sorted tensor.\\n'\n",
      " 'sorted_tensor = tf.concat(sorted_segments, axis=0)\\n'\n",
      " '\\n'\n",
      " 'return sorted_tensor.numpy().tolist()',\n",
      " '# Create a sparse tensor with in1 as segments and in2 as values, then use '\n",
      " 'sparse_to_dense to sort\\n'\n",
      " '    return tf.sparse.to_dense(tf.SparseTensor(tf.expand_dims(in1, axis=-1), '\n",
      " 'in2, tf.shape(in2))).numpy().tolist()',\n",
      " '# create a function that takes two inputs, sorts the second input based on '\n",
      " 'the first input\\n'\n",
      " 'def transform(in1, in2):\\n'\n",
      " '    sorted_indices = tf.argsort(in1, axis=-1, stable=True)\\n'\n",
      " '    sorted_segments = tf.gather(in2, sorted_indices)\\n'\n",
      " '    return sorted_segments',\n",
      " '# The aim is to sort the elements within each segment in ascending order.\\n'\n",
      " '# We first determine the number of segments using the `reduce_max` '\n",
      " 'function.\\n'\n",
      " \"# The `unsorted_segment_sort` function isn't directly available, but can be \"\n",
      " 'achieved by obtaining sorted indices using `argsort`\\n'\n",
      " '# in each segment, then gathering elements from the input tensor based on '\n",
      " 'these indices.\\n'\n",
      " '\\n'\n",
      " 'import tensorflow as tf\\n'\n",
      " '\\n'\n",
      " 'def transform(ids, values):\\n'\n",
      " '    num_segments = tf.reduce_max(ids) + 1\\n'\n",
      " '    sorted_indices_in_segment = tf.argsort(tf.concat([\\n'\n",
      " '            tf.boolean_mask(values, tf.equal(ids, i)) for i in '\n",
      " 'tf.range(num_segments)], \\n'\n",
      " '        axis=0))\\n'\n",
      " '    return tf.gather(values, sorted_indices_in_segment)',\n",
      " 'indices = tf.argsort(in1, axis=-1, stable=True)\\n'\n",
      " 'return tf.gather(in2, indices)',\n",
      " '# First, we will map the indices and its corresponding values using '\n",
      " 'tf.stack\\n'\n",
      " '# Then, we will use tf.argsort to sort our values in ascending order\\n'\n",
      " '# At the end, we will gather our data according to our sorted indices\\n'\n",
      " '\\n'\n",
      " '    mapping = tf.stack([in1, in2], axis=1)\\n'\n",
      " '    sorted_indices = tf.argsort(mapping[:, 1])\\n'\n",
      " '    sorted_segments = tf.gather(mapping[:, 0], sorted_indices)\\n'\n",
      " '    return sorted_segments',\n",
      " 'segments = tf.constant(in1)\\n'\n",
      " 'values = tf.constant(in2)\\n'\n",
      " 'num_segments = tf.reduce_max(segments) + 1\\n'\n",
      " 'output = tf.math.unsorted_segment_sum(values, segments, num_segments)\\n'\n",
      " 'sorted_segments = tf.argsort(output)\\n'\n",
      " 'sorted_values = tf.gather(output, sorted_segments)\\n'\n",
      " 'return sorted_values.numpy().tolist()',\n",
      " '# First we zip the given input lists\\n'\n",
      " '# Then we sort them\\n'\n",
      " '# After sorting, we unzip them\\n'\n",
      " '# Finally we return the sorted values\\n'\n",
      " '\\n'\n",
      " 'z = tf.stack([tf.constant(in1), tf.constant(in2)], axis=-1)\\n'\n",
      " 'sorted_z = tf.sort(z, axis=0)\\n'\n",
      " 'res = tf.unstack(sorted_z, axis=-1)\\n'\n",
      " 'return res[1].numpy()',\n",
      " 'data = tf.constant(in2)\\n'\n",
      " 'segment_ids = tf.constant(in1)\\n'\n",
      " 'num_segments = tf.reduce_max(in1) + 1\\n'\n",
      " 'segment_min = tf.math.unsorted_segment_min(data, segment_ids, num_segments)\\n'\n",
      " 'segment_max = tf.math.unsorted_segment_max(data, segment_ids, num_segments)\\n'\n",
      " 'min_locs = tf.where(tf.equal(data, tf.broadcast_to(segment_min, '\n",
      " 'tf.shape(in1))))\\n'\n",
      " 'max_locs = tf.where(tf.equal(data, tf.broadcast_to(segment_max, '\n",
      " 'tf.shape(in1))))\\n'\n",
      " 'temp = tf.tensor_scatter_nd_update(data, min_locs, segment_max)\\n'\n",
      " 'result = tf.tensor_scatter_nd_update(temp, max_locs, segment_min)\\n'\n",
      " 'return result.numpy()']\n",
      "\n",
      "Prompting for task: google_10, description: gather the marked elements\n",
      "['return tf.boolean_mask(in1, tf.cast(in2, tf.bool))',\n",
      " 'return tf.boolean_mask(in1, in2).numpy().tolist()',\n",
      " 'return tf.boolean_mask(in1, tf.cast(in2, bool)).numpy()',\n",
      " 'return tf.boolean_mask(in1, in2)',\n",
      " 'return tf.boolean_mask(in1, in2)',\n",
      " 'return tf.boolean_mask(in1, in2).numpy()',\n",
      " 'return tf.boolean_mask(in1, in2)',\n",
      " 'return tf.boolean_mask(in1, tf.cast(in2, tf.bool))',\n",
      " 'return tf.boolean_mask(in1, tf.equal(in2, 1))',\n",
      " 'return tf.boolean_mask(in1, tf.cast(in2, tf.bool)).numpy()']\n",
      "\n",
      "Prompting for task: google_11, description: count the number of elements greater than 0 in each row\n",
      "['return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)',\n",
      " 'return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)',\n",
      " 'return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)',\n",
      " 'return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)',\n",
      " 'return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)',\n",
      " 'return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)',\n",
      " 'return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)',\n",
      " 'return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)',\n",
      " 'return tf.reduce_sum(tf.cast(tf.greater(in1, 0), dtype=tf.int32), axis=1)',\n",
      " 'return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)']\n",
      "\n",
      "Prompting for task: google_12, description: identify elements between 0 and 1\n",
      "['return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), '\n",
      " 'tf.int32)',\n",
      " 'return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), '\n",
      " 'dtype=tf.int32)',\n",
      " 'return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), '\n",
      " 'tf.int32)',\n",
      " 'return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), '\n",
      " 'dtype=tf.int32)',\n",
      " 'return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), '\n",
      " 'tf.int32)',\n",
      " 'return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), '\n",
      " 'tf.int32)',\n",
      " 'return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), '\n",
      " 'dtype=tf.int32)',\n",
      " 'return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), int)',\n",
      " 'return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), '\n",
      " 'tf.int32)',\n",
      " 'return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), '\n",
      " 'dtype=tf.int32)']\n",
      "\n",
      "Prompting for task: google_13, description: Concatenate batches of sequences\n",
      "['return tf.concat([in1, in2], axis=1)',\n",
      " 'return tf.concat([in1,in2], axis=1)',\n",
      " 'return tf.concat([in1, in2], axis=1)',\n",
      " 'return tf.concat([in1, in2], axis=1)',\n",
      " 'return tf.concat([in1, in2], axis=1)',\n",
      " 'return tf.concat([in1, in2], axis=1)',\n",
      " 'return tf.concat([in1, in2], axis=1)',\n",
      " 'return tf.concat([in1, in2], axis=1)',\n",
      " 'return tf.concat([in1, in2], axis=1)',\n",
      " 'return tf.concat([in1, in2], axis=-1)']\n",
      "\n",
      "Prompting for task: google_14, description: circular buffer\n",
      "['return tf.roll(in1, shift=1, axis=1)',\n",
      " 'return tf.roll(in1, shift=1, axis=1)',\n",
      " 'return tf.roll(in1, shift = 1, axis = 1)',\n",
      " 'return tf.roll(in1, shift=1, axis=1)',\n",
      " 'return tf.roll(in1, shift=1, axis=1)',\n",
      " 'return tf.roll(in1, shift=1, axis=1)',\n",
      " 'return tf.roll(in1, shift=1, axis=1)',\n",
      " '# We are essentially shifting the input array to the right by one position '\n",
      " 'and filling the first position by 0\\n'\n",
      " '# We can achieve this by using tf.roll for shifting and '\n",
      " 'tf.tensor_scatter_nd_update for setting the first position to 0\\n'\n",
      " '\\n'\n",
      " 'def transform(in1):\\n'\n",
      " '    shifted = tf.roll(in1, shift=1, axis=1)\\n'\n",
      " '    indices = tf.constant([[i, 0] for i in range(tf.shape(in1)[0])])\\n'\n",
      " '    result = tf.tensor_scatter_nd_update(shifted, indices, '\n",
      " 'tf.zeros(tf.shape(in1)[0]))\\n'\n",
      " '    return result',\n",
      " 'return tf.roll(in1, shift=1, axis=1)',\n",
      " 'return tf.pad(in1, [[0, 0], [1, 1]])']\n",
      "\n",
      "Prompting for task: google_15, description: pad a zero column\n",
      "['import tensorflow as tf\\n'\n",
      " '\\n'\n",
      " 'def transform(in1):\\n'\n",
      " '    zero_column = tf.zeros([tf.shape(in1)[0], 1], dtype=in1.dtype)\\n'\n",
      " '    return tf.concat([in1, zero_column], axis=1)',\n",
      " 'return tf.concat([in1, tf.zeros_like(in1[:, :1])], axis=1)',\n",
      " 'return tf.pad(in1, [[0, 0], [0, 1]])',\n",
      " 'return tf.concat([in1, tf.zeros([tf.shape(in1)[0], 1], dtype=in1.dtype)], '\n",
      " 'axis=1)',\n",
      " 'padded_tensor = tf.pad(in1, paddings=[[0, 0], [0, 1]])\\n'\n",
      " '     return padded_tensor',\n",
      " 'return tf.pad(in1, tf.constant([[0, 0], [0, 1]]))',\n",
      " 'return tf.pad(in1, [[0,0],[0,1]])',\n",
      " 'return tf.pad(in1, [[0, 0], [0, 1]])',\n",
      " 'return tf.pad(in1, [[0, 0], [0, 1]])',\n",
      " 'return tf.pad(in1, [[0, 0], [0, 1]])']\n",
      "\n",
      "Prompting for task: google_16, description: replicate elements a given number of times\n",
      "['return tf.repeat(in1, in2).numpy()',\n",
      " 'return tf.repeat(in1, in2).numpy()',\n",
      " 'return tf.repeat(in1, in2).numpy().tolist()',\n",
      " 'return tf.reshape(tf.repeat(in1, in2), [-1])',\n",
      " 'return tf.repeat(in1, in2).numpy().tolist()',\n",
      " 'return tf.repeat(in1, in2)',\n",
      " 'return tf.repeat(in1, in2).numpy()',\n",
      " 'return tf.repeat(in1, in2).numpy()',\n",
      " 'return tf.repeat(in1, in2).numpy()',\n",
      " 'return tf.repeat(in1, in2).numpy()']\n",
      "\n",
      "Prompting for task: google_17, description: use bool tensor as condition\n",
      "['return tf.where(in1, in2, tf.multiply(in2, -10))',\n",
      " 'return tf.where(in1, in2, tf.multiply(in2, -10))',\n",
      " 'return tf.where(in1, in2, in2 * -10)',\n",
      " 'return tf.where(in1, in2, tf.multiply(in2, -10))',\n",
      " 'return tf.where(in1, in2, tf.multiply(in2, -10))',\n",
      " 'return tf.where(in1, in2, tf.multiply(in2, -10))',\n",
      " 'return tf.where(in1, in2, in2* -10)',\n",
      " 'return tf.where(in1,in2,tf.multiply(in2, -10))',\n",
      " 'return tf.where(in1, in2, tf.multiply(in2, -10))',\n",
      " 'return tf.where(in1, in2, tf.multiply(in2, -10))']\n",
      "\n",
      "Prompting for task: google_18, description: (\\'sum of elements in the first tensor but partitioned by the second tensor\\')\n",
      "['return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1).numpy()',\n",
      " 'return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)',\n",
      " 'return tf.math.unsorted_segment_sum(in1, in2, '\n",
      " 'tf.reduce_max(in2)+1).numpy().tolist()',\n",
      " 'return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + 1)',\n",
      " 'out = tf.math.segment_sum(in1, in2)\\nreturn out',\n",
      " 'return tf.math.unsorted_segment_sum(in1, in2, '\n",
      " 'tf.reduce_max(in2)+1).numpy()[in2]',\n",
      " 'return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)',\n",
      " 'return tf.math.unsorted_segment_sum(in1,in2,tf.reduce_max(in2)+1)',\n",
      " 'return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)',\n",
      " 'return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + 1)']\n",
      "\n",
      "Prompting for task: google_19, description: scatter a 2-D tensor with indices\n",
      "['return tf.tensor_scatter_nd_update(in1, tf.stack([tf.range(in1.shape[0]), '\n",
      " 'in2], axis=1), tf.gather_nd(in1, tf.stack([tf.range(in1.shape[0]), in2], '\n",
      " 'axis=1)))',\n",
      " 'return tf.gather(in1, in2, axis=1)',\n",
      " 'return tf.gather(in1, in2, axis=1, batch_dims=1)',\n",
      " 'out = tf.gather(in1, in2, axis=1)\\nreturn out',\n",
      " 'return tf.gather(in1, in2, axis=1, batch_dims=1)',\n",
      " 'return tf.gather(in1, in2, batch_dims=1)',\n",
      " 'return tf.gather(in1, in2, axis=-1)',\n",
      " 'return tf.gather(in1, in2, batch_dims=1)',\n",
      " 'return tf.gather(in1, in2, axis=1)',\n",
      " 'shape = tf.shape(in1)\\n'\n",
      " 'flat_in2 = tf.reshape(in2, [-1])\\n'\n",
      " 'flat_in1 = tf.reshape(in1, [-1])\\n'\n",
      " 'flat_out = tf.gather(flat_in1, flat_in2)\\n'\n",
      " 'return tf.reshape(flat_out, shape)']\n",
      "\n",
      "Prompting for task: google_20, description: sort a tensor and return sorted index in original order\n",
      "['return tf.argsort(tf.argsort(in1)).numpy()',\n",
      " 'return tf.argsort(tf.argsort(in1)).numpy().tolist()',\n",
      " 'sorted_idxs = tf.argsort(in1)\\nreturn tf.argsort(sorted_idxs)',\n",
      " 'sorted_indices = tf.argsort(in1)\\n'\n",
      " 'original_order_indices = tf.argsort(sorted_indices)\\n'\n",
      " 'return original_order_indices',\n",
      " 'return tf.argsort(tf.argsort(in1))',\n",
      " 'return tf.argsort(tf.argsort(in1)).numpy()',\n",
      " 'sorted_indices = tf.argsort(in1)\\nreturn tf.argsort(sorted_indices)',\n",
      " 'sorted_indices = tf.argsort(in1)\\nreturn tf.argsort(sorted_indices)',\n",
      " 'sorted_index = tf.argsort(in1)\\n'\n",
      " 'inverse_permutation = tf.argsort(sorted_index)\\n'\n",
      " 'return inverse_permutation',\n",
      " 'return tf.argsort(tf.argsort(in1)).numpy()']\n",
      "\n",
      "Prompting for task: google_21, description: update a tensor at the given indices\n",
      "[\"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\",\n",
      " \"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\",\n",
      " \"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\",\n",
      " \"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\",\n",
      " \"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\",\n",
      " \"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\",\n",
      " \"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\",\n",
      " \"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\",\n",
      " \"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\",\n",
      " \"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\"]\n",
      "\n",
      "Prompting for task: google_22, description: pair with row index\n",
      "['# get the indices of the input matrix as pairs\\n'\n",
      " '    indices = tf.where(tf.ones_like(in1))\\n'\n",
      " '\\n'\n",
      " '    # get the input matrix and flatten it to 1-D\\n'\n",
      " '    flattened_in1 = tf.reshape(in1, [-1])\\n'\n",
      " '\\n'\n",
      " '    # gather elements from flattened_in1 using the second column of the '\n",
      " 'indices\\n'\n",
      " '    gathered = tf.gather(flattened_in1, indices[:, 1])\\n'\n",
      " '\\n'\n",
      " '    # stack the indices and gathered data along the second dimension\\n'\n",
      " '    result = tf.stack([indices, gathered], axis=-1)\\n'\n",
      " '\\n'\n",
      " '    # reshape the result back to 2-D matrix\\n'\n",
      " '    result = tf.reshape(result, [-1, 2])\\n'\n",
      " '\\n'\n",
      " '    # return the transformed matrix\\n'\n",
      " '    return result',\n",
      " 'indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " '     indices = tf.expand_dims(indices, axis=-1)\\n'\n",
      " '     repeated_indices = tf.repeat(indices, tf.shape(in1)[1], axis=1)\\n'\n",
      " '     flattened_indices = tf.reshape(repeated_indices, [-1, 1])\\n'\n",
      " '     flattened_in1 = tf.reshape(in1, [-1, 1])\\n'\n",
      " '     result = tf.concat([flattened_indices, flattened_in1], axis=1)\\n'\n",
      " '     return result',\n",
      " 'indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'indices = tf.reshape(indices, [-1, 1])\\n'\n",
      " 'indices = tf.tile(indices, [1, tf.shape(in1)[1]])\\n'\n",
      " 'indices = tf.reshape(indices, [-1, 1])\\n'\n",
      " 'in1 = tf.reshape(in1, [-1, 1])\\n'\n",
      " 'out1 = tf.concat([indices, in1], axis=-1)\\n'\n",
      " 'return out1',\n",
      " 'indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'indices = tf.reshape(indices, [-1, 1])\\n'\n",
      " 'indices = tf.tile(indices, [1, tf.shape(in1)[1]])\\n'\n",
      " 'indices = tf.reshape(indices, [-1, 1])\\n'\n",
      " 'in1 = tf.reshape(in1, [-1, 1])\\n'\n",
      " 'return tf.concat([indices, in1], axis=1)',\n",
      " 'import tensorflow as tf\\n'\n",
      " '\\n'\n",
      " 'def transform(in1):\\n'\n",
      " '    row_indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " '    repeated_row_indices = tf.repeat(row_indices, tf.shape(in1)[1])\\n'\n",
      " '    flat_in1 = tf.reshape(in1, [-1])\\n'\n",
      " '    return tf.stack([repeated_row_indices, flat_in1], axis=1)',\n",
      " 'indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'indices = tf.reshape(indices, [-1,1])\\n'\n",
      " 'indices = tf.broadcast_to(indices, tf.shape(in1))\\n'\n",
      " 'out = tf.stack([indices, in1], axis=-1)\\n'\n",
      " 'out = tf.reshape(out, [-1,2])\\n'\n",
      " 'return out',\n",
      " 'indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " '     indices = tf.reshape(indices, (-1, 1))\\n'\n",
      " '     extended_indices = tf.tile(indices, [1, tf.shape(in1)[1]])\\n'\n",
      " '     reshaped_in1 = tf.reshape(in1, (-1, 1))\\n'\n",
      " '\\n'\n",
      " '     return tf.concat([tf.reshape(extended_indices, (-1, 1)), reshaped_in1], '\n",
      " 'axis=1)',\n",
      " 'indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'indices = tf.expand_dims(indices, axis=-1)\\n'\n",
      " 'final = tf.broadcast_to(indices, tf.shape(in1))\\n'\n",
      " 'return tf.stack([final, in1], axis=-1)',\n",
      " '# For every element in the input, create a pair of [row index, element '\n",
      " 'value]. This can be done by using tf.range to generate row indices, '\n",
      " 'tf.repeat to repeat each index n times, tf.reshape to match the shape of the '\n",
      " 'input, and finally using tf.concat to pair each index with the corresponding '\n",
      " 'element.\\n'\n",
      " '\\n'\n",
      " 'return tf.concat([tf.reshape(tf.repeat(tf.range(tf.shape(in1)[0]), '\n",
      " 'tf.shape(in1)[1]), in1.shape), in1], axis=1)',\n",
      " 'import tensorflow as tf\\n'\n",
      " '\\n'\n",
      " 'def transform(in1):\\n'\n",
      " '    row_indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " '    expanded_row_indices = tf.expand_dims(row_indices, axis=-1)\\n'\n",
      " '    tiled_row_indices = tf.tile(expanded_row_indices, [1, '\n",
      " 'tf.shape(in1)[1]])\\n'\n",
      " '    reshaped_row_indices = tf.reshape(tiled_row_indices, [-1, 1])\\n'\n",
      " '\\n'\n",
      " '    in1_reshaped = tf.reshape(in1, [-1, 1])\\n'\n",
      " '\\n'\n",
      " '    return tf.concat([reshaped_row_indices, in1_reshaped], axis=1)']\n",
      "\n",
      "Prompting for task: stackoverflow_01, description: reshape by separating and duplicating columns\n",
      "['return tf.reshape(tf.repeat(in1, 2, axis=1), [2, in1.shape[0], 2])',\n",
      " 'reshaped = tf.expand_dims(in1, axis=0)\\n'\n",
      " 'transposed = tf.transpose(reshaped, perm=[2, 1, 0])\\n'\n",
      " 'duplicated = tf.tile(transposed, multiples=[1, 1, 2])\\n'\n",
      " 'return duplicated',\n",
      " 'in1 = tf.constant(in1)\\n'\n",
      " 'in1_sep = tf.unstack(in1, axis=1)\\n'\n",
      " 'in1_dup = [tf.expand_dims(tf.tile(tf.reshape(el, (-1, 1)), [1, 2]), axis=0) '\n",
      " 'for el in in1_sep]\\n'\n",
      " 'return tf.concat(in1_dup, axis=0)',\n",
      " 'in1 = tf.expand_dims(in1, -1)\\n'\n",
      " 'in1 = tf.tile(in1, [1, 1, 2])\\n'\n",
      " 'in1 = tf.transpose(in1, [2, 0, 1])\\n'\n",
      " 'return in1',\n",
      " 'in1 = tf.expand_dims(in1, axis=0)\\n'\n",
      " 'in1 = tf.tile(in1, [2,1,2])\\n'\n",
      " 'out = tf.unstack(in1, axis=2)\\n'\n",
      " 'return out',\n",
      " 'return tf.reshape(tf.tile(in1, [1, 2]), [tf.shape(in1)[1], tf.shape(in1)[0], '\n",
      " '2])',\n",
      " 'return tf.reshape(tf.tile(in1, [2, 1]), [2, tf.shape(in1)[0], 2])',\n",
      " 'return tf.reshape(tf.tile(in1, [1, 2]), [2, tf.shape(in1)[0], -1])',\n",
      " 'return tf.reshape(tf.tile(in1, [1, 2]), [2, tf.shape(in1)[0], 2])',\n",
      " 'reshaped = tf.reshape(in1, [in1.shape[1], in1.shape[0], 1])\\n'\n",
      " 'return tf.tile(reshaped, [1, 1, 2])']\n",
      "\n",
      "Prompting for task: stackoverflow_02, description: clip values that are greater than 1\n",
      "['return tf.clip_by_value(in1, -1 * tf.float32.max, 1)',\n",
      " 'return tf.clip_by_value(in1, -np.inf, 1)',\n",
      " 'return tf.clip_by_value(in1, -np.inf, 1)',\n",
      " 'return tf.clip_by_value(in1, -tf.float32.max, 1)',\n",
      " 'return tf.clip_by_value(in1, -tf.float32.max, 1)',\n",
      " 'return tf.clip_by_value(in1, -np.inf, 1)',\n",
      " 'return tf.clip_by_value(in1, -np.inf, 1)',\n",
      " 'return tf.clip_by_value(in1, -np.inf, 1)',\n",
      " 'return tf.clip_by_value(in1, -np.inf, 1)',\n",
      " 'return tf.clip_by_value(in1, -np.inf, 1)']\n",
      "\n",
      "Prompting for task: stackoverflow_03, description: replace certain columns with columns from the other tensor\n",
      "['indices = tf.constant([3, 4])\\n'\n",
      " 'return tf.tensor_scatter_nd_update(in1, tf.expand_dims(indices, axis=-1), '\n",
      " 'tf.transpose(tf.gather(in2, indices, axis=1)))',\n",
      " 'in1 = tf.constant(in1)\\n'\n",
      " 'in2 = tf.constant(in2)\\n'\n",
      " '\\n'\n",
      " 'indices = tf.constant([[0, 3], [0, 4], [1, 3], [1, 4]])\\n'\n",
      " 'updates = tf.gather_nd(in2, indices)\\n'\n",
      " '\\n'\n",
      " 'out = tf.tensor_scatter_nd_update(in1, indices, updates)\\n'\n",
      " '\\n'\n",
      " 'return out',\n",
      " 'indices = tf.constant([3,4]) # columns to replace\\n'\n",
      " '     in1 = tf.gather(in1, indices, axis=1)\\n'\n",
      " '     in2 = tf.gather(in2, indices, axis=1)\\n'\n",
      " '\\n'\n",
      " '     # Concatenate the tensors along the second axis (columns)\\n'\n",
      " '     return tf.concat([in1, in2], axis=1)',\n",
      " 'return tf.tensor_scatter_nd_update(in1, [[0,3], [0,4],[1,3], [1,4]], '\n",
      " '[in2[0,3], in2[0,4], in2[1,3], in2[1,4]])',\n",
      " 'return tf.tensor_scatter_nd_update(in1, [[0,3],[0,4],[1,3],[1,4]], '\n",
      " 'tf.gather_nd(in2, [[0,3],[0,4],[1,3],[1,4]]))',\n",
      " 'in1 = tf.constant(in1)\\n'\n",
      " 'in2 = tf.constant(in2)\\n'\n",
      " 'cols_to_replace = [3,4]\\n'\n",
      " 'return tf.tensor_scatter_nd_update(in1,\\n'\n",
      " '                                  '\n",
      " 'tf.expand_dims(tf.constant(cols_to_replace),1),\\n'\n",
      " '                                  tf.gather(in2,cols_to_replace, axis=1))',\n",
      " 'in1 = tf.constant(in1)\\n'\n",
      " '     in2 = tf.constant(in2)\\n'\n",
      " '\\n'\n",
      " '     swapped_tensor = tf.tensor_scatter_nd_update(in1, '\n",
      " '[[0,3],[0,4],[1,3],[1,4]], [in2[0][3], in2[0][4], in2[1][3], in2[1][4]])\\n'\n",
      " '     return tf.reshape(swapped_tensor, [1, tf.shape(swapped_tensor)[0], '\n",
      " 'tf.shape(swapped_tensor)[1]])',\n",
      " 'in1 = tf.constant(in1)\\n'\n",
      " '     in2 = tf.constant(in2)\\n'\n",
      " '     in1 = tf.tensor_scatter_nd_update(in1, [[0,3], [0,4], [1,3], [1,4]], '\n",
      " '[in2[0,3], in2[0,4], in2[1,3], in2[1,4]])\\n'\n",
      " '     return tf.expand_dims(in1, 0)',\n",
      " 'indices = tf.constant([3, 4])\\n'\n",
      " '     return tf.tensor_scatter_nd_update(in1, '\n",
      " 'tf.stack([tf.range(tf.shape(in1)[0]), indices], axis=-1), tf.gather(in2, '\n",
      " 'indices, axis=-1))',\n",
      " 'in1 = tf.constant(in1)\\n'\n",
      " 'in2 = tf.constant(in2)\\n'\n",
      " 'indices = tf.constant([3, 4])  # columns to replace\\n'\n",
      " 'in1_gathered = tf.gather(in1, indices, axis=1)\\n'\n",
      " 'in2_gathered = tf.gather(in2, indices, axis=1)\\n'\n",
      " 'res = tf.tensor_scatter_nd_update(in1, tf.expand_dims(indices, 1), '\n",
      " 'in2_gathered)\\n'\n",
      " 'return tf.expand_dims(res, 0)']\n",
      "\n",
      "Prompting for task: stackoverflow_04, description: index into the tensor\n",
      "['return tf.stack([tf.gather(in1, 0, axis=1), tf.gather(in1, 1, axis=1)], '\n",
      " 'axis=0)',\n",
      " 'return tf.gather(in1, tf.argsort(in1, axis=-1, stable=True), axis=1)',\n",
      " 'return tf.gather(in1, tf.constant([0, 1]), axis=1)',\n",
      " 'return tf.transpose(tf.broadcast_to(in1, [2,3,2]))',\n",
      " 'return tf.transpose(tf.expand_dims(in1, axis=0), perm=[2, 1, 0])',\n",
      " 'return tf.transpose(tf.expand_dims(in1, -1), perm=[2, 0, 1])',\n",
      " 'return tf.broadcast_to(in1, [2, *tf.shape(in1)])',\n",
      " 'return tf.gather(in1, [[0, 0], [1, 1]], axis=1)',\n",
      " 'return tf.gather(tf.transpose(in1), [0, 1], axis=0)',\n",
      " 'return tf.transpose(tf.stack([in1, in1]), perm=[1, 2, 0])']\n",
      "\n",
      "Prompting for task: stackoverflow_05, description: tensor multiplication like np.tensordot\n",
      "['return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=[[1], [0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=[[1], [1]])',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=[[1], [0]])']\n",
      "\n",
      "Prompting for task: stackoverflow_06, description: binary tensor from vector indicating if elements are equal\n",
      "['return tf.cast(tf.equal(tf.expand_dims(in1, 0), tf.expand_dims(in1, 1)), '\n",
      " 'tf.int32)',\n",
      " 'return tf.cast(tf.equal(tf.expand_dims(in1, 0), tf.expand_dims(in1, 1)), '\n",
      " 'tf.float32)',\n",
      " 'return tf.cast(tf.equal(tf.reshape(in1, [-1, 1]), in1), tf.float32)',\n",
      " 'return tf.cast(tf.equal(tf.expand_dims(in1, 0), tf.expand_dims(in1, 1)), '\n",
      " 'tf.float32)',\n",
      " 'import tensorflow as tf\\n'\n",
      " '\\n'\n",
      " 'def transform(in1):\\n'\n",
      " '    return tf.cast(tf.equal(tf.expand_dims(in1, axis=0), tf.expand_dims(in1, '\n",
      " 'axis=1)), tf.float32)',\n",
      " 'return tf.cast(tf.equal(tf.expand_dims(in1, 0), tf.expand_dims(in1, 1)), '\n",
      " 'tf.float32)',\n",
      " 'return tf.cast(tf.equal(tf.reshape(in1, [-1, 1]), tf.reshape(in1, [1, -1])), '\n",
      " 'dtype=float)',\n",
      " 'return tf.cast(tf.equal(in1[:, tf.newaxis], in1), tf.float32)',\n",
      " 'return tf.cast(tf.equal(tf.expand_dims(in1, 1), tf.expand_dims(in1, 0)), '\n",
      " 'tf.float32)',\n",
      " 'return tf.cast(tf.equal(tf.expand_dims(in1, 0), tf.expand_dims(in1, 1)), '\n",
      " 'dtype=tf.float32)']\n",
      "\n",
      "Prompting for task: stackoverflow_07, description: swap the first two dimensions of the tensor\n",
      "['return tf.transpose(in1, perm=[1, 0, 2])',\n",
      " 'return tf.transpose(in1, perm=[1, 0, 2])',\n",
      " 'return tf.transpose(in1, perm=[1, 0, 2])',\n",
      " 'return tf.transpose(in1, perm=[1, 0, 2])',\n",
      " 'return tf.transpose(in1, perm=[1, 0, 2])',\n",
      " 'return tf.transpose(a=in1, perm=[1, 0, 2])',\n",
      " 'return tf.transpose(in1, perm=[1, 0, 2])',\n",
      " 'return tf.transpose(in1, perm=[1, 0, 2])',\n",
      " 'return tf.transpose(in1, perm=[1, 0, 2])',\n",
      " 'return tf.transpose(in1, perm=[1, 0, 2])']\n",
      "\n",
      "Prompting for task: stackoverflow_08, description: (\\'select the values in the second tensor where the first tensor is greater than 1\\')\n",
      "['return tf.boolean_mask(in2, tf.greater(in1, 1)).numpy()',\n",
      " 'return tf.boolean_mask(in2, tf.greater(in1, 1))',\n",
      " 'mask = tf.greater(in1, 1)\\n     return tf.boolean_mask(in2, mask)',\n",
      " 'return tf.boolean_mask(in2, tf.greater(in1, tf.constant(1)))',\n",
      " 'mask = tf.greater(in1, 1)\\n     return tf.boolean_mask(in2, mask)',\n",
      " 'mask = tf.greater(in1, 1)\\nreturn tf.boolean_mask(in2, mask)',\n",
      " 'return tf.boolean_mask(in2, tf.greater(in1, 1))',\n",
      " 'mask = tf.greater(in1, 1)\\n     return tf.boolean_mask(in2, mask)',\n",
      " 'mask = tf.greater(in1, 1)\\nout = tf.boolean_mask(in2, mask)\\nreturn out',\n",
      " 'mask = tf.greater(in1, 1)\\n     return tf.boolean_mask(in2, mask)']\n",
      "\n",
      "Prompting for task: stackoverflow_09, description: group items by value and get the group indices\n",
      "['_, indices = tf.unique_with_counts(in1)\\nreturn tf.gather(indices, in1)',\n",
      " '_, idx = tf.unique_with_counts(in1)\\nreturn idx.numpy()',\n",
      " '_, idx = tf.unique_with_counts(in1)\\nout = tf.gather(idx, in1)\\nreturn out',\n",
      " '_, idx = tf.unique_with_counts(in1)\\nreturn tf.gather(idx, in1)',\n",
      " 'uniques, idx = tf.unique_with_counts(in1)\\n'\n",
      " 'idx_parts = tf.math.bincount(idx)\\n'\n",
      " 'start = tf.roll(tf.math.cumsum(idx_parts), shift=1, axis=0)\\n'\n",
      " 'start = tf.concat([[0], start[:-1]], axis=0)\\n'\n",
      " 'group_idx = tf.zeros_like(in1)\\n'\n",
      " 'for i in range(tf.reduce_max(idx)):\\n'\n",
      " '    mask = tf.equal(idx, i)\\n'\n",
      " '    group_idx = tf.where(mask, i, group_idx)\\n'\n",
      " 'return group_idx',\n",
      " 'unique_values, unique_indices = tf.unique(in1)\\n'\n",
      " 'return tf.gather(unique_indices, in1)',\n",
      " '_, idx = tf.unique_with_counts(in1)\\nreturn idx.numpy()',\n",
      " '_, indices = tf.unique(in1)\\nreturn tf.cast(indices, tf.int32)',\n",
      " '_, unique_indices = tf.unique_with_counts(in1)\\n'\n",
      " 'return tf.gather(unique_indices.indices, in1)',\n",
      " '_, idx = tf.unique(in1)\\nreturn tf.cast(idx, tf.int32).numpy()']\n",
      "\n",
      "Prompting for task: stackoverflow_10, description: perform matrix multiplication\n",
      "['return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in1,in2)',\n",
      " 'return tf.matmul(in1, in2)']\n",
      "\n",
      "Prompting for task: stackoverflow_11, description: count the number of occurences of each distinct number\n",
      "['counts = tf.math.bincount(in1)\\n'\n",
      " 'indices = tf.where(counts > 0)\\n'\n",
      " 'return tf.gather(indices, 0)',\n",
      " '_, _, count = tf.unique_with_counts(in1)\\nreturn count',\n",
      " '_, _, count = tf.unique_with_counts(in1)\\nreturn count',\n",
      " 'return tf.math.bincount(in1)',\n",
      " 'out1 = tf.math.bincount(in1)\\nreturn out1',\n",
      " 'return tf.math.bincount(in1).numpy().tolist()',\n",
      " 'return tf.math.bincount(in1).numpy().tolist()',\n",
      " 'return tf.math.bincount(in1)',\n",
      " 'result = tf.math.bincount(in1)\\nreturn result',\n",
      " \"# We can use TensorFlow's bincount function to count occurences of each \"\n",
      " 'number\\n'\n",
      " 'import tensorflow as tf\\n'\n",
      " '\\n'\n",
      " 'def transform(in1):\\n'\n",
      " '    return tf.math.bincount(in1).numpy()']\n",
      "\n",
      "Prompting for task: stackoverflow_12, description: remove a column from the tensor\n",
      "['return tf.gather(in1, [0, 2], axis=1)',\n",
      " 'return tf.gather(in1, [0, 2], axis=1)',\n",
      " 'return tf.gather(in1, [0, 2], axis=1)',\n",
      " 'return tf.gather(in1, [0,2], axis=1)',\n",
      " 'return tf.gather(in1, [0, 2], axis=1)',\n",
      " 'return tf.gather(in1, [0, 2], axis=1)',\n",
      " 'return tf.gather(in1, [0, 2], axis=1)',\n",
      " 'return tf.gather(in1, [0, 2], axis=1)',\n",
      " 'return tf.gather(in1, [0,2], axis=1)',\n",
      " 'return tf.gather(in1, [0, 2], axis=1)']\n",
      "\n",
      "Prompting for task: stackoverflow_13, description: multiply vectors by tensor\n",
      "['return tf.matmul(in2, tf.transpose(in1))',\n",
      " 'return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in1,in2)',\n",
      " 'return tf.matmul(in2, tf.expand_dims(in1, -1)).numpy().squeeze(-1)',\n",
      " 'return tf.matmul(in2, tf.expand_dims(in1, 2)).numpy().squeeze(2)',\n",
      " 'return tf.matmul(in2, tf.transpose(in1))',\n",
      " 'return tf.matmul(in2, tf.expand_dims(in1, 2))[:,:,0]',\n",
      " 'return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in2, tf.expand_dims(in1, 2))[:,:,0]',\n",
      " 'return tf.matmul(in1,in2)']\n",
      "\n",
      "Prompting for task: stackoverflow_14, description: choose True if any value in a row is True, False otherwise\n",
      "['return tf.reduce_any(in1, axis=2)',\n",
      " 'return tf.reduce_any(in1, axis=2)',\n",
      " 'return tf.reduce_any(in1, axis=2)',\n",
      " 'return tf.reduce_any(in1, axis=2)',\n",
      " 'return tf.reduce_any(in1, axis=-1)',\n",
      " 'return tf.reduce_any(in1, axis=-1)',\n",
      " 'return tf.reduce_any(in1, axis=2)',\n",
      " 'return tf.reduce_any(in1, axis=-1)',\n",
      " 'return tf.reduce_any(in1, axis=2)',\n",
      " 'return tf.reduce_any(in1, axis=2)']\n",
      "\n",
      "Prompting for task: stackoverflow_15, description: set all instances of 1 to 0\n",
      "['return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)']\n",
      "\n",
      "Prompting for task: stackoverflow_16, description: multiply tensors across the first axis\n",
      "['return tf.multiply(in1, tf.reshape(in2, [-1, 1]))',\n",
      " 'return tf.multiply(in1, tf.reshape(in2, [-1, 1]))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2,1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, 1))',\n",
      " 'return tf.multiply(in1, tf.reshape(in2, [-1, 1]))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, 1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, 1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, axis=-1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, axis=1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, 1))']\n",
      "\n",
      "Prompting for task: stackoverflow_17, description: duplicate each element of a tensor\n",
      "['return tf.reshape(tf.tile(in1, [2]), (-1, 2))',\n",
      " 'return tf.repeat(tf.expand_dims(in1, axis=1), 2, axis=1)',\n",
      " 'return tf.reshape(tf.repeat(in1, 2), (-1, 2))',\n",
      " 'return tf.repeat(in1, 2, axis=-1)',\n",
      " 'return tf.repeat(in1, repeats=2, axis=-1).numpy().reshape(len(in1),2)',\n",
      " 'return tf.reshape(tf.tile(in1, [2]), [-1, 2])',\n",
      " 'return tf.reshape(tf.tile(in1, [2]), [-1, 2])',\n",
      " 'return tf.repeat(in1, repeats=[2], axis=1)',\n",
      " 'return tf.reshape(tf.tile(in1, [2]), [-1, 2])',\n",
      " 'return tf.repeat(in1, repeats=2, axis=-1)']\n",
      "\n",
      "Prompting for task: stackoverflow_18, description: multiply 3D tensor and 2D tensor and add another tensor\n",
      "['mult_2d_3d = tf.tensordot(in1, in2, axes=[[2], [0]])\\n'\n",
      " 'return tf.add(mult_2d_3d, in3)',\n",
      " 'result = tf.add(tf.matmul(in1, in2), in3)\\nreturn result',\n",
      " 'multiplied = tf.tensordot(in1, in2, axes=1)\\n'\n",
      " 'result = tf.add(multiplied, in3)\\n'\n",
      " 'return result',\n",
      " '# We first extend 2D tensor into 3D to match the first tensor\\n'\n",
      " '# Then we multiply the tensors and add another tensor to it.\\n'\n",
      " '# We need to ensure that the shape of each tensor match to each others.\\n'\n",
      " '# As for tf.tensordot, when axes is an integer, it treats the last axes '\n",
      " 'dimensions as vectors and does\\n'\n",
      " '# the inner product with them.\\n'\n",
      " 'result = tf.add(tf.tensordot(in1, in2, axes=[[2], [0]]), in3)\\n'\n",
      " 'return result',\n",
      " '# cast the third input as tensor\\n'\n",
      " '    in3 = tf.constant(in3)\\n'\n",
      " '    # calculate the product of the first and second input\\n'\n",
      " '    product = tf.tensordot(in1, in2, axes=[[2],[0]])\\n'\n",
      " '    # add the third input to the product \\n'\n",
      " '    result = tf.add(product, in3)\\n'\n",
      " '\\n'\n",
      " '    return result',\n",
      " 'product = tf.tensordot(in1, in2, axes=1)\\n'\n",
      " 'result = tf.add(product, in3)\\n'\n",
      " 'return result',\n",
      " 'result = tf.add(tf.matmul(in1, in2), in3)\\nreturn result',\n",
      " 'product = tf.matmul(in1, in2)\\nreturn tf.add(product, in3)',\n",
      " '# multiply the 3D tensor and 2D tensor\\n'\n",
      " '    mul = tf.matmul(in1, in2)\\n'\n",
      " '\\n'\n",
      " '    # add another tensor\\n'\n",
      " '    result = tf.add(mul, in3)\\n'\n",
      " '    \\n'\n",
      " '    return result',\n",
      " 'temp = tf.tensordot(in1, in2, axes=1)\\n'\n",
      " 'result = tf.add(temp, in3)\\n'\n",
      " 'return result']\n",
      "\n",
      "Prompting for task: stackoverflow_19, description: (\\'sort a tensor considering the first column, breaking ties using the second column\\')\n",
      "['return tf.sort(in1, axis=0)',\n",
      " 'return tf.gather(in1, tf.argsort(in1, axis=0, stable=True))',\n",
      " 'return tf.sort(in1, axis=0)',\n",
      " 'return tf.sort(in1, axis=0)',\n",
      " 'return tf.sort(in1, axis=0)',\n",
      " 'return tf.sort(in1, axis=0)',\n",
      " 'return tf.gather(in1, tf.argsort(in1, axis=0, stable=True))',\n",
      " 'return tf.sort(in1, axis=0)',\n",
      " 'return tf.gather(in1, tf.argsort(in1[:, :2], axis=0, stable=True))',\n",
      " 'return tf.sort(in1, axis=0)']\n",
      "\n",
      "Prompting for task: stackoverflow_20, description: compute argmax in each tensor and set it to 1\n",
      "['import tensorflow as tf\\n'\n",
      " '    \\n'\n",
      " '    # Find indices of maximum values\\n'\n",
      " '    arg_max_indices = tf.argmax(in1, axis=1)\\n'\n",
      " '\\n'\n",
      " '    # Convert indices to one hot\\n'\n",
      " '    one_hot_max = tf.one_hot(arg_max_indices, depth=in1.shape[1])\\n'\n",
      " '    \\n'\n",
      " '    return one_hot_max',\n",
      " 'index = tf.argmax(in1, axis=-1)\\n'\n",
      " 'one_hot = tf.one_hot(index, in1.shape[-1])\\n'\n",
      " 'return one_hot',\n",
      " 'import tensorflow as tf\\n'\n",
      " '\\n'\n",
      " 'def transform(in1):\\n'\n",
      " '    argmax_indx = tf.argmax(in1, axis=1)\\n'\n",
      " '    one_hot_indx = tf.one_hot(argmax_indx, depth=in1.shape[1])\\n'\n",
      " '    return one_hot_indx.numpy()',\n",
      " '# First we compute the argmax in each tensor along the last axis\\n'\n",
      " '    idx_max = tf.argmax(in1, axis=-1)\\n'\n",
      " '    # We create a matrix of zeros with the same shape as the input\\n'\n",
      " '    mat_zero = tf.zeros_like(in1, dtype=tf.int32)\\n'\n",
      " '    # Then we create a matrix of ones with a shape that fits the argmax '\n",
      " 'matrix\\n'\n",
      " '    mat_one = tf.ones_like(idx_max, dtype=tf.int32)\\n'\n",
      " '    # As Tensorflow only allows to modify a tensor by an entire axis we need '\n",
      " 'to expand the dimensions\\n'\n",
      " '    idx_max = tf.expand_dims(idx_max, 1)\\n'\n",
      " '    mat_one = tf.expand_dims(mat_one, 1)\\n'\n",
      " '    # We then use tensor_scatter_nd_update to set the position of the '\n",
      " 'maximum value to 1\\n'\n",
      " '    result = tf.tensor_scatter_nd_update(mat_zero, idx_max, mat_one)\\n'\n",
      " '    return result',\n",
      " 'import tensorflow as tf\\n'\n",
      " '\\n'\n",
      " 'def transform(in1):\\n'\n",
      " '    in1 = tf.constant(in1)\\n'\n",
      " '    argmax = tf.argmax(in1, axis=1)\\n'\n",
      " '    mask = tf.one_hot(argmax, depth=in1.shape[1])\\n'\n",
      " '    return mask.numpy()',\n",
      " 'idx = tf.argmax(in1, axis=1)\\n'\n",
      " 'out = tf.one_hot(idx, depth=in1.shape[1])\\n'\n",
      " 'return tf.cast(out, dtype=tf.int32)',\n",
      " 'max_indices = tf.argmax(in1, axis=1)\\n'\n",
      " 'rows = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'indices = tf.stack([rows, max_indices], axis=1)\\n'\n",
      " 'updates = tf.ones(shape=(tf.shape(in1)[0],), dtype=tf.int32)\\n'\n",
      " 'shape = tf.shape(in1)\\n'\n",
      " 'result = tf.scatter_nd(indices, updates, shape)\\n'\n",
      " 'return result',\n",
      " 'argmax = tf.argmax(in1, axis=1)\\n'\n",
      " 'indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'indices = tf.stack([indices, argmax], axis=1)\\n'\n",
      " 'ones = tf.ones(tf.shape(indices)[0], dtype=tf.float32)\\n'\n",
      " 'updates = tf.scatter_nd(indices, ones, tf.shape(in1))\\n'\n",
      " 'return updates',\n",
      " '#First we get the indices of the max values\\n'\n",
      " '    max_indices = tf.argmax(in1, axis=1)\\n'\n",
      " '\\n'\n",
      " '    #Generate a range to match the first dimension of the input array\\n'\n",
      " '    range_values = tf.range(tf.shape(in1)[0])\\n'\n",
      " '\\n'\n",
      " '    #Stack the range and max indices together to get the coordinates\\n'\n",
      " '    indices = tf.stack([range_values, max_indices], axis=1)\\n'\n",
      " '\\n'\n",
      " '    #Create a ones array of the same size as the number of max_indices to '\n",
      " 'use as updates\\n'\n",
      " '    updates = tf.ones_like(max_indices, dtype=tf.float32)\\n'\n",
      " '    \\n'\n",
      " \"    #Use scatter_nd to create a new tensor with 1's at the argmax locations \"\n",
      " 'and zeros elsewhere\\n'\n",
      " '    return tf.tensor_scatter_nd_update(tf.zeros_like(in1), indices, updates)',\n",
      " 'argmax_values = tf.argmax(in1, axis=1)\\n'\n",
      " 'one_hot = tf.one_hot(argmax_values, depth=in1.shape[1])\\n'\n",
      " 'return one_hot.numpy().astype(int)']\n",
      "\n",
      "Prompting for task: stackoverflow_21, description: gather elements in a tensor along axis 1\n",
      "['return tf.gather(in2, in1, axis=1, batch_dims=1)',\n",
      " 'return tf.gather(in2, in1, axis=1)',\n",
      " 'return tf.gather(in2, in1, axis=1)',\n",
      " 'return tf.gather(in2, in1, axis=1)',\n",
      " 'return tf.gather(in2, in1, axis=1)',\n",
      " 'return tf.gather(in2, in1, axis=1)',\n",
      " 'return tf.gather(in2,in1,axis=1)',\n",
      " 'return tf.gather(in2, in1, axis=1, batch_dims=1)',\n",
      " 'return tf.gather(in2, in1, axis=1)',\n",
      " 'return tf.gather(in2, in1, axis=1)']\n",
      "\n",
      "Prompting for task: stackoverflow_22, description: multiply a vector with a matrix without reshaping the vector\n",
      "['return tf.reduce_sum(tf.multiply(in1, in2), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, in2), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, in2), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, in2), 0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, in2), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, in2), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, in2), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, in2), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, in2), axis = 0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, in2), axis=0)']\n",
      "\n",
      "Prompting for task: stackoverflow_23, description: place 1 at the indices in the input tensor\n",
      "['return tf.one_hot(in1, tf.reduce_max(in1)+1, axis=-1)',\n",
      " 'return tf.one_hot(in1, tf.reduce_max(in1) + 1, axis=-1)',\n",
      " 'return tf.reduce_sum(tf.one_hot(in1, depth=tf.reduce_max(in1) + 1), axis=1)',\n",
      " 'return tf.one_hot(in1, tf.reduce_max(in1) + 1)',\n",
      " 'return tf.one_hot(in1, tf.reduce_max(in1)+1)',\n",
      " 'return tf.scatter_nd(tf.expand_dims(in1, -1), tf.ones_like(in1), '\n",
      " 'tf.constant([in1.shape[0], tf.reduce_max(in1)+1]))',\n",
      " 'return tf.reduce_sum(tf.one_hot(in1, tf.reduce_max(in1) + 1), axis=1)',\n",
      " 'return tf.one_hot(in1, tf.reduce_max(in1) + 1)',\n",
      " 'return tf.one_hot(in1, depth=tf.reduce_max(in1)+1)',\n",
      " 'return tf.one_hot(in1, tf.reduce_max(in1)+1)']\n",
      "\n",
      "Prompting for task: stackoverflow_24, description: (\\'like tf.divide(), but when dividing by 0, return the numerator\\')\n",
      "['return tf.math.divide_no_nan(in1,in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)']\n",
      "\n",
      "Prompting for task: stackoverflow_25, description: copy the tensor tf.eye(3), 4 times\n",
      "['return tf.tile(tf.eye(in1), [in2, 1])',\n",
      " 'return tf.tile(tf.eye(in1), [in2, 1])',\n",
      " 'return tf.tile(tf.eye(in1), [in2, 1])',\n",
      " 'eye_tensor = tf.eye(in1)\\n     return tf.tile(eye_tensor, [in2,1])',\n",
      " 'return tf.tile(tf.eye(in1), [in2, 1])',\n",
      " 'return tf.tile(tf.eye(in1), [in2, 1])',\n",
      " 'return tf.tile(tf.eye(in1), [in2, 1])',\n",
      " 'return tf.tile(tf.eye(in1), [in2, 1])',\n",
      " 'return tf.tile(tf.eye(in1), [in2, 1])',\n",
      " 'return tf.tile(tf.eye(in1), [in2, 1])']\n",
      "\n",
      "Prompting for task: stackoverflow_26, description: reduction operation for multiple dimensions simultaneously\n",
      "['return tf.reduce_sum(in1, axis=[0, 1]).numpy().tolist()',\n",
      " 'return tf.reduce_max(tf.reduce_sum(in1, axis=2), axis=1)',\n",
      " 'return tf.reduce_sum(in1, axis=[0, 1]).numpy().tolist()',\n",
      " 'return tf.reduce_min(in1, axis=[0, 1]).numpy().tolist()',\n",
      " 'return tf.reduce_sum(in1, axis=[0,1]).numpy().tolist()',\n",
      " 'return tf.reduce_sum(in1, axis=[0,1]).numpy().tolist()',\n",
      " 'return tf.reduce_sum(in1, axis=[0, 2]).numpy().tolist()',\n",
      " 'return tf.reduce_sum(in1, axis=[0, 1]).numpy().tolist()',\n",
      " 'return tf.reduce_sum(in1, axis=[0,1])',\n",
      " 'return tf.reduce_sum(in1, axis=[0, 1]).numpy().tolist()']\n",
      "\n",
      "Prompting for task: stackoverflow_27, description: boolean tensor with 1 at the indices in the input tensor\n",
      "['return tf.cast(tf.reduce_any(tf.one_hot(in1, in2), axis=0), dtype=tf.int32)',\n",
      " 'return tf.cast(tf.reduce_sum(tf.one_hot(in1, in2), axis=0), dtype=tf.int32)',\n",
      " 'return tf.cast(tf.scatter_nd(tf.reshape(in1, [-1, 1]), tf.ones_like(in1), '\n",
      " '[in2]), tf.int32)',\n",
      " 'return tf.cast(tf.reduce_any(tf.equal(tf.range(in2), tf.expand_dims(in1, '\n",
      " '1)), axis=0), tf.int32)',\n",
      " 'return tf.sparse.to_dense(tf.SparseTensor(in1[:,None], '\n",
      " 'tf.ones(tf.shape(in1),dtype=tf.int32), [in2]))',\n",
      " 'return tf.cast(tf.sequence_mask(in1,in2), dtype=tf.int32)',\n",
      " 'return tf.cast(tf.reduce_sum(tf.one_hot(in1, in2), axis=0), tf.int32)',\n",
      " 'return tf.cast(tf.scatter_nd(tf.expand_dims(in1, axis=1), tf.ones_like(in1, '\n",
      " 'dtype=tf.int32), [in2]), tf.int32)',\n",
      " 'return tf.cast(tf.reduce_sum(tf.one_hot(in1, in2), axis=0), '\n",
      " 'tf.int32).numpy().tolist()',\n",
      " 'return tf.cast(tf.reduce_max(tf.one_hot(in1, in2), axis=0), tf.int32)']\n",
      "\n",
      "Prompting for task: stackoverflow_28, description: extract columns from a 3D tensor given column indices\n",
      "['indices = tf.stack([tf.range(tf.shape(in1)[0]), in2], axis=1)\\n'\n",
      " '     return tf.gather_nd(in1, indices)',\n",
      " 'return tf.gather(in1, tf.constant(in2), axis=2, batch_dims=1)',\n",
      " 'return tf.gather(in1, in2, axis=2, batch_dims=1)',\n",
      " 'return tf.gather(in1, in2, axis=2, batch_dims=1)',\n",
      " 'return tf.gather(in1, in2, axis=2, batch_dims=1)',\n",
      " 'return tf.gather(in1, in2, axis=2, batch_dims=1)',\n",
      " 'return tf.gather(in1, in2, axis=2, batch_dims=1)',\n",
      " 'return tf.gather(in1, in2, axis=2, batch_dims=1)',\n",
      " 'return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in1)[0]), in2], '\n",
      " 'axis=1))',\n",
      " 'return tf.gather(in1, in2, axis=2, batch_dims=1)']\n",
      "\n",
      "Prompting for task: stackoverflow_29, description: place continuous values into buckets given bucket boundaries\n",
      "['return tf.searchsorted(sorted_sequence=in1, values=in2, '\n",
      " \"side='right').numpy().tolist()\",\n",
      " 'return tf.searchsorted(tf.constant(in1), tf.constant(in2)).numpy().tolist()',\n",
      " \"return tf.searchsorted(in1, in2, side='right')\",\n",
      " \"return tf.searchsorted(tf.constant(in1), in2, side='left').numpy().tolist()\",\n",
      " \"return tf.searchsorted(in1, in2, side='left').numpy().tolist()\",\n",
      " 'return tf.searchsorted(tf.constant(in1), tf.constant(in2)).numpy().tolist()',\n",
      " 'return tf.searchsorted(tf.constant(in1), tf.constant(in2)).numpy().tolist()',\n",
      " 'return tf.searchsorted(tf.constant(in1), tf.constant(in2)).numpy().tolist()',\n",
      " 'return tf.searchsorted(tf.constant(in1, dtype=tf.float32), tf.constant(in2, '\n",
      " 'dtype=tf.float32))',\n",
      " \"return tf.searchsorted(in1, in2, side='right').numpy().tolist()\"]\n",
      "\n",
      "Prompting for task: stackoverflow_30, description: compute Euclidean distance between two tensors\n",
      "['return tf.sqrt(tf.reduce_sum(tf.square(in1-in2), axis=1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis -1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))']\n",
      "\n",
      "Prompting for task: stackoverflow_31, description: squared error between two tensors, one being a sparse tensor\n",
      "['dense1 = tf.sparse.to_dense(in1[0])\\n'\n",
      " '     square_diff = tf.math.squared_difference(dense1, in1[1])\\n'\n",
      " '     return tf.reduce_sum(square_diff)',\n",
      " 'sparse_tensor_input = tf.sparse.to_dense(in1[0])\\n'\n",
      " 'dense_tensor_input = tf.convert_to_tensor(in1[1])\\n'\n",
      " '\\n'\n",
      " 'error = tf.square(sparse_tensor_input - dense_tensor_input)\\n'\n",
      " 'sum_error = tf.reduce_sum(error)\\n'\n",
      " '\\n'\n",
      " 'return sum_error.numpy()',\n",
      " '# Convert the sparse tensor to a dense tensor\\n'\n",
      " '    dense_tensor = tf.sparse.to_dense(in1[0])\\n'\n",
      " '    # Calculate the squared difference between the dense tensors\\n'\n",
      " '    squared_diff = tf.math.squared_difference(dense_tensor, in1[1])\\n'\n",
      " '    # Reduce sum to obtain scalar output\\n'\n",
      " '    return tf.reduce_sum(squared_diff).numpy()',\n",
      " 'dense1 = tf.sparse.to_dense(in1[0])\\n'\n",
      " '    squared_diff = tf.math.squared_difference(dense1, in1[1])\\n'\n",
      " '    return tf.reduce_sum(squared_diff).numpy()',\n",
      " '# Cast the input sparse tensor to a dense tensor.\\n'\n",
      " '     dense1 = tf.sparse.to_dense(in1[0])\\n'\n",
      " '     # Compute the squared difference between the dense tensor and the input '\n",
      " 'tensor.\\n'\n",
      " '     diff = tf.math.squared_difference(dense1, in1[1])\\n'\n",
      " '     # Sum all the elements in the difference tensor.\\n'\n",
      " '     output = tf.reduce_sum(diff)\\n'\n",
      " '     return output',\n",
      " 'sparse_tensor, dense_tensor = in1\\n'\n",
      " 'dense_tensor = tf.convert_to_tensor(dense_tensor, dtype=tf.float32)\\n'\n",
      " 'sparse_tensor = tf.sparse.to_dense(sparse_tensor)\\n'\n",
      " 'squared_diff = tf.math.squared_difference(sparse_tensor, dense_tensor)\\n'\n",
      " 'output = tf.reduce_sum(squared_diff)\\n'\n",
      " 'return output.numpy()',\n",
      " 'dense_tensor = tf.sparse.to_dense(in1[0])\\n'\n",
      " '    squared_error = tf.math.squared_difference(dense_tensor, in1[1])\\n'\n",
      " '    return tf.reduce_sum(squared_error)',\n",
      " 'sp_1, in2 = in1\\n'\n",
      " 'dense_1 = tf.sparse.to_dense(sp_1)\\n'\n",
      " 'error = tf.math.squared_difference(dense_1, in2)\\n'\n",
      " 'return tf.reduce_sum(error)',\n",
      " '# First convert the sparse tensor to a dense tensor\\r\\n'\n",
      " 'dense_tensor = tf.sparse.to_dense(in1[0])\\r\\n'\n",
      " '\\r\\n'\n",
      " '# Now calculate the squared difference between the dense versions of the two '\n",
      " 'tensors\\r\\n'\n",
      " 'diff = tf.math.squared_difference(dense_tensor, in1[1])\\r\\n'\n",
      " '\\r\\n'\n",
      " '# Finally, sum all the elements of the resulting tensor to get the final '\n",
      " 'output\\r\\n'\n",
      " 'output = tf.reduce_sum(diff)\\r\\n'\n",
      " '\\r\\n'\n",
      " 'return output.numpy().item()',\n",
      " 'dense_in1 = tf.sparse.to_dense(in1[0])\\n'\n",
      " '    squared_diff = tf.math.squared_difference(dense_in1, in1[1])\\n'\n",
      " '    return tf.reduce_sum(squared_diff)']\n",
      "\n",
      "Prompting for task: stackoverflow_32, description: weighted sum across rows, where the column index is the weight\n",
      "['return tf.reduce_sum(tf.multiply(in1, tf.range(tf.shape(in1)[1])), axis=1)',\n",
      " 'weights = tf.range(tf.shape(in1)[1])\\n'\n",
      " 'weights = tf.cast(weights, dtype=in1.dtype)\\n'\n",
      " '\\n'\n",
      " 'return tf.reduce_sum(in1 * weights, axis=1)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, tf.range(tf.shape(in1)[1])), axis=1)',\n",
      " 'weights = tf.range(tf.shape(in1)[1])\\n'\n",
      " 'weights = tf.cast(weights, tf.float32)\\n'\n",
      " 'result = tf.reduce_sum(in1 * weights, axis=1)\\n'\n",
      " 'return result',\n",
      " 'weights = tf.range(tf.shape(in1)[1], dtype=tf.float32)\\n'\n",
      " 'weighted_in1 = tf.multiply(in1, weights)\\n'\n",
      " 'result = tf.reduce_sum(weighted_in1, axis=1)\\n'\n",
      " 'return result',\n",
      " 'weights = tf.range(tf.shape(in1)[1])\\n'\n",
      " 'weights = tf.cast(weights, dtype=in1.dtype)\\n'\n",
      " 'weighted_in1 = tf.multiply(in1, weights)\\n'\n",
      " 'out = tf.reduce_sum(weighted_in1, axis=1)\\n'\n",
      " 'return out',\n",
      " 'import tensorflow as tf\\n'\n",
      " '\\n'\n",
      " 'def transform(in1):\\n'\n",
      " '    weights = tf.range(start=0, limit=tf.shape(in1)[1], dtype=tf.float32)\\n'\n",
      " '    return tf.reduce_sum(in1 * weights, axis=1)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, tf.range(tf.shape(in1)[1])), axis=1)',\n",
      " 'return tf.reduce_sum(in1 * tf.range(tf.shape(in1)[1]), axis=1)',\n",
      " 'weights = tf.range(start=0, limit=tf.shape(in1)[1])\\n'\n",
      " 'weighted_matrix = tf.multiply(in1, tf.cast(weights, tf.float32))\\n'\n",
      " 'weighted_sum = tf.reduce_sum(weighted_matrix, axis=1)\\n'\n",
      " 'return weighted_sum']\n",
      "\n",
      "Prompting for task: stackoverflow_33, description: find the minimum distance between two sets of points\n",
      "['distances = []\\n'\n",
      " '    for point_1 in in1:\\n'\n",
      " '        min_distance = '\n",
      " 'tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in2, point_1)), '\n",
      " 'axis=1)))\\n'\n",
      " '        distances.append(min_distance)\\n'\n",
      " '    return tf.cast(distances, tf.float32)',\n",
      " 'distances = '\n",
      " 'tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, '\n",
      " '1), tf.expand_dims(in2, 0))), 2)), 1)\\n'\n",
      " '     return distances',\n",
      " 'distances = '\n",
      " 'tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, '\n",
      " 'axis=1), in2)), axis=2)), axis=1)\\n'\n",
      " '     return distances',\n",
      " 'distances = '\n",
      " 'tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1,1),tf.expand_dims(in2,0))),2)),1)\\n'\n",
      " '     return distances',\n",
      " 'distances = '\n",
      " 'tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, '\n",
      " 'axis=1), in2)), axis=2)), axis=1)\\n'\n",
      " 'return distances',\n",
      " 'diffs = tf.subtract(tf.expand_dims(in1, 1), tf.expand_dims(in2, 0))\\n'\n",
      " 'squared_diffs = tf.square(diffs)\\n'\n",
      " 'distances = tf.sqrt(tf.reduce_sum(squared_diffs, axis=2))\\n'\n",
      " 'minimum_distance = tf.reduce_min(distances, axis=1)\\n'\n",
      " 'return minimum_distance',\n",
      " 'distances = '\n",
      " 'tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.expand_dims(in1, axis=1) - '\n",
      " 'tf.expand_dims(in2, axis=0)), axis=2)), axis=1)\\n'\n",
      " 'return distances',\n",
      " 'distances = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1[:, '\n",
      " 'tf.newaxis], in2)), axis=-1)), axis=-1)\\n'\n",
      " 'return distances',\n",
      " 'distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, '\n",
      " 'axis=1), tf.expand_dims(in2, axis=0))), axis=2))\\n'\n",
      " 'min_distance = tf.reduce_min(distances, axis=1)\\n'\n",
      " 'return min_distance',\n",
      " 'differences = tf.subtract(tf.expand_dims(in1, 1), tf.expand_dims(in2, 0))\\n'\n",
      " '     distances = tf.sqrt(tf.reduce_sum(tf.square(differences), axis=-1))\\n'\n",
      " '     min_distances = tf.reduce_min(distances, axis=-1)\\n'\n",
      " '     return min_distances']\n",
      "\n",
      "Prompting for task: stackoverflow_34, description: compute a weighted sum of tensors\n",
      "['return tf.reduce_sum(tf.multiply(in1,tf.expand_dims(tf.cast(in2, '\n",
      " 'dtype=tf.int32), 1)), 0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, (-1,1,1))), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(in2, axis=-1)), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(in1, -1)), axis=0)',\n",
      " '# First, we convert the weights list to a tensor\\n'\n",
      " '    weights = tf.convert_to_tensor(in2, dtype=tf.int32)\\n'\n",
      " '\\n'\n",
      " '    # Then, we expand the dimension of our weights tensor to match the '\n",
      " 'dimensions of the input tensor\\n'\n",
      " '    expanded_weights = tf.expand_dims(weights, axis=-1)\\n'\n",
      " '\\n'\n",
      " '    # Next, we multiply our input tensor by our weights tensor\\n'\n",
      " '    weighted_inputs = tf.multiply(in1, expanded_weights)\\n'\n",
      " '\\n'\n",
      " '    # Lastly, we sum our weighted inputs along the first dimension\\n'\n",
      " '    return tf.reduce_sum(weighted_inputs, axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(tf.cast(in2, '\n",
      " 'tf.float32), -1)), axis=0)',\n",
      " 'in1 = tf.constant(in1, dtype=tf.float32)\\n'\n",
      " '     in2 = tf.constant(in2, dtype=tf.float32)\\n'\n",
      " '     in2 = tf.expand_dims(in2, axis=1)\\n'\n",
      " '     in2 = tf.expand_dims(in2, axis=2)\\n'\n",
      " '     weighted_tensors = tf.multiply(in1, in2)\\n'\n",
      " '     return tf.reduce_sum(weighted_tensors, axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, [-1, 1, 1])), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(tf.expand_dims(in2, 1), '\n",
      " '1)), axis=0)',\n",
      " 'weights = tf.expand_dims(tf.constant(in2, dtype=tf.int32), -1)\\n'\n",
      " 'weighted_tensors = tf.multiply(in1, weights)\\n'\n",
      " 'return tf.reduce_sum(weighted_tensors, axis=0)']\n",
      "\n",
      "Prompting for task: stackoverflow_35, description: linear interpolation between two tensors\n",
      "['return tf.add(tf.multiply(in1, tf.reshape(1 - in3, [len(in3), 1, 1])), '\n",
      " 'tf.multiply(in2, tf.reshape(in3, [len(in3), 1, 1])))',\n",
      " 'return tf.add(tf.multiply(in1, tf.reshape(1.0-in3, [in3.shape[0],1,1])), '\n",
      " 'tf.multiply(in2, tf.reshape(in3, [in3.shape[0],1,1])))',\n",
      " 'in1 = tf.constant(in1, dtype=tf.float32)\\n'\n",
      " 'in2 = tf.constant(in2, dtype=tf.float32)\\n'\n",
      " 'in3 = tf.expand_dims(tf.expand_dims(tf.constant(in3, dtype=tf.float32), '\n",
      " '-1),-1)\\n'\n",
      " '\\n'\n",
      " 'return tf.add(tf.multiply(in1, 1.0 - in3), tf.multiply(in2, in3))',\n",
      " 'return tf.add(tf.multiply(in1, tf.reshape(1 - in3, [len(in3), 1, 1])), '\n",
      " 'tf.multiply(in2, tf.reshape(in3, [len(in3), 1, 1])))',\n",
      " 'return in1 * (1 - tf.expand_dims(in3, -1)) + in2 * tf.expand_dims(in3, -1)',\n",
      " 'return tf.add(tf.multiply(in1, tf.subtract(tf.constant(1.0), in3)), '\n",
      " 'tf.multiply(in2, in3))',\n",
      " 'return tf.add(tf.multiply(in1, tf.reshape(1.0 - in3, [-1, 1, 1])), '\n",
      " 'tf.multiply(in2, tf.reshape(in3, [-1, 1, 1])))',\n",
      " 'return tf.add(tf.multiply(in1, tf.expand_dims(tf.expand_dims(1 - in3, -1), '\n",
      " '-1)), tf.multiply(in2, tf.expand_dims(tf.expand_dims(in3, -1), -1)))',\n",
      " 'return tf.add(tf.multiply(in1, tf.reshape(1 - in3, shape=[-1, 1, 1])), '\n",
      " 'tf.multiply(in2, tf.reshape(in3, shape=[-1, 1, 1])))',\n",
      " 'return tf.add(tf.multiply(in1, tf.reshape(1.0 - in3, (-1, 1, 1))), '\n",
      " 'tf.multiply(in2, tf.reshape(in3, (-1, 1, 1))))']\n",
      "\n",
      "Prompting for task: stackoverflow_36, description: divide each element by the column index\n",
      "['# First we need to reshape the input into 2D array where each column '\n",
      " 'represents an index from\\n'\n",
      " '# the original 1D array\\n'\n",
      " '# Then we divide each element by the column index + 1 (to avoid division by '\n",
      " 'zero)\\n'\n",
      " '# Finally, we reshape the result back to 1D\\n'\n",
      " '\\n'\n",
      " 'import tensorflow as tf\\n'\n",
      " '\\n'\n",
      " 'def transform(in1):\\n'\n",
      " '    tensor = tf.constant(in1, dtype=tf.float32)\\n'\n",
      " '    tensor = tf.reshape(tensor, shape=(-1, 1))\\n'\n",
      " '    indices = tf.range(start=1, limit=tf.shape(tensor)[0] + 1, '\n",
      " 'dtype=tf.float32)\\n'\n",
      " '    indices = tf.reshape(indices, shape=(-1, 1))\\n'\n",
      " '    result = tf.divide(tensor, indices)\\n'\n",
      " '    return tf.reshape(result, shape=(-1,)).numpy()',\n",
      " '# First transform the 1D tensor in1 into a 2D tensor.\\n'\n",
      " '    in1_2d = tf.expand_dims(in1, axis=-1)\\n'\n",
      " '    # Get the shape of the 2D tensor.\\n'\n",
      " '    shape = tf.shape(in1_2d)\\n'\n",
      " '    # Create a tensor where values are their column indices.\\n'\n",
      " '    column_indices = tf.expand_dims(tf.range(shape[1]), axis=0)\\n'\n",
      " '    # Broadcast the column_indices tensor to the shape of in1_2d.\\n'\n",
      " '    column_indices_broad = tf.broadcast_to(column_indices, shape)\\n'\n",
      " '    # Convert the column indices to float to avoid integer division.\\n'\n",
      " '    indices_float = tf.cast(column_indices_broad, tf.float32)\\n'\n",
      " '    # Now divide in1_2d by the float column indices. Add 1 to avoid division '\n",
      " 'by zero.\\n'\n",
      " '    return tf.divide(in1_2d, indices_float + 1)',\n",
      " 'return tf.divide(in1, tf.range(1, tf.shape(in1)[0] + 1))',\n",
      " 'import tensorflow as tf\\n'\n",
      " '\\n'\n",
      " 'def transform(in1):\\n'\n",
      " '    in1 = tf.constant(in1, dtype=tf.float32)\\n'\n",
      " '    column_indices = tf.range(1, tf.shape(in1)[0] + 1, dtype=tf.float32)\\n'\n",
      " '    return tf.divide(in1, column_indices)',\n",
      " 'in1 = tf.cast(in1, tf.float32)\\nreturn tf.divide(in1,[1,2,3,4,5,6,7,8])',\n",
      " 'return tf.divide(in1, tf.range(1, tf.shape(in1)[0] + 1, dtype=in1.dtype))',\n",
      " '# first we will reshape the 1D input array into 2D array \\n'\n",
      " '# because we are told to divide by the colum index\\n'\n",
      " '# So the input could be like [[1, 0, 1, 1, 0, 1, 0, 1]]\\n'\n",
      " \"# Now we can consider '1's index in each column as the column index\\n\"\n",
      " '# so reshaping is like framing the problem into a way we can understand\\n'\n",
      " 'in1 = tf.reshape(in1, (1, -1))\\n'\n",
      " '\\n'\n",
      " '# get the length of the array which will also be the number of columns\\n'\n",
      " 'length = tf.shape(in1)[1]\\n'\n",
      " '\\n'\n",
      " '# generate a sequence from 1 to n, where n is the length\\n'\n",
      " 'indices = tf.range(1, length + 1, 1)\\n'\n",
      " '\\n'\n",
      " '# cast the indices to float as the input is of float type\\n'\n",
      " 'indices = tf.cast(indices, tf.float32)\\n'\n",
      " '\\n'\n",
      " '# divide the input array (2D) with the indices\\n'\n",
      " 'output = tf.math.divide_no_nan(in1, indices)\\n'\n",
      " '\\n'\n",
      " '# the result is a 2D array with a single row, reshape it to 1D\\n'\n",
      " 'output = tf.reshape(output, (-1,))\\n'\n",
      " '\\n'\n",
      " 'return output',\n",
      " 'import tensorflow as tf\\n'\n",
      " '\\n'\n",
      " 'def transform(in1):\\n'\n",
      " '    indices = tf.range(1, tf.size(in1) + 1, dtype=in1.dtype)\\n'\n",
      " '    return tf.divide(in1, indices)',\n",
      " 'import tensorflow as tf\\n'\n",
      " '\\n'\n",
      " 'def transform(in1):\\n'\n",
      " '    in1_shape = tf.shape(in1)\\n'\n",
      " '    col_indices = tf.range(in1_shape[-1], dtype=in1.dtype)\\n'\n",
      " '    col_indices = tf.add(col_indices, 1)\\n'\n",
      " '    col_indices = tf.cast(col_indices, tf.float32)\\n'\n",
      " '    in1 = tf.cast(in1, tf.float32)\\n'\n",
      " '    return tf.divide(in1, col_indices)',\n",
      " 'return tf.divide(in1, tf.range(1, tf.size(in1)+1, dtype=tf.float32))']\n",
      "\n",
      "Prompting for task: stackoverflow_37, description: dot product a vector with last dimension of a tensor\n",
      "['return tf.tensordot(in1, in2, axes=[[-1], [0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=[[-1], [0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=[[-1], [0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=[[-1], [0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=[[-1], [0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=[[len(in1.shape)-1], [0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=[[-1], [0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=[[-1], [0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=[[-1],[0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=[[-1],[0]])']\n",
      "\n",
      "Prompting for task: stackoverflow_38, description: compute the product of marked elements\n",
      "['return tf.reduce_prod(tf.boolean_mask(in1, in2), 1)',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, dtype=tf.bool)), '\n",
      " 'axis=1)',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1, tf.equal(in2, 1)), axis=1)',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=-1)']\n",
      "\n",
      "Prompting for task: stackoverflow_39, description: (\\'set to 0 the elements with absolute value less than 1, and square the other elements\\')\n",
      "['abs_in1 = tf.abs(in1)\\n'\n",
      " 'mask = tf.greater(abs_in1, 1)\\n'\n",
      " 'masked_in1 = tf.boolean_mask(in1, mask)\\n'\n",
      " 'masked_in1_squared = tf.square(masked_in1)\\n'\n",
      " 'tf.tensor_scatter_nd_update(in1, tf.where(mask), masked_in1_squared)',\n",
      " '# First we will calculate the absolute of all elements in the input tensor\\n'\n",
      " '    abs_in1 = tf.abs(in1)\\n'\n",
      " '\\n'\n",
      " '    # Then we will make a mask of elements that are less than 1\\n'\n",
      " '    mask = tf.less(abs_in1, 1)\\n'\n",
      " '\\n'\n",
      " '    # We will make a tensor of the same shape as the input tensor but filled '\n",
      " 'with zeros\\n'\n",
      " '    zeros = tf.zeros_like(in1)\\n'\n",
      " '\\n'\n",
      " '    # We will replace the elements that are less than 1 with zeroes\\n'\n",
      " '    temp = tf.where(mask, zeros, in1)\\n'\n",
      " '\\n'\n",
      " '    # Lastly we will square the remaining (non-zero) elements of the tensor\\n'\n",
      " '    result = tf.square(temp)\\n'\n",
      " '\\n'\n",
      " '    return result',\n",
      " 'return tf.where(tf.abs(in1) < 1, 0, tf.square(in1))',\n",
      " '# Using tf.where, tf.abs and tf.square for conditional replacement and '\n",
      " 'squaring\\n'\n",
      " '# We have the condition as less than 1, so we catch them and set those '\n",
      " 'positions as 0\\n'\n",
      " '# For other positions we perform the square operation\\n'\n",
      " '\\n'\n",
      " 'mask = tf.less(tf.abs(in1), 1)\\n'\n",
      " 'return tf.where(mask, tf.zeros_like(in1), tf.square(in1))',\n",
      " 'in1_abs = tf.abs(in1)\\n'\n",
      " 'mask = tf.greater(in1_abs, 1)\\n'\n",
      " 'res = tf.where(mask, tf.square(in1), 0)\\n'\n",
      " 'return res',\n",
      " '# Check the absolute value of all elements in the tensor\\n'\n",
      " '    abs_in1 = tf.abs(in1)\\n'\n",
      " '\\n'\n",
      " '    # Create a mask for elements with absolute value less than 1\\n'\n",
      " '    mask = tf.less(abs_in1, 1)\\n'\n",
      " '\\n'\n",
      " '    # Replace the elements less than 1 by 0\\n'\n",
      " '    in1_zeroed = tf.where(mask, 0, in1)\\n'\n",
      " '\\n'\n",
      " '    # Square the elements\\n'\n",
      " '    result = tf.square(in1_zeroed)\\n'\n",
      " '\\n'\n",
      " '    return result',\n",
      " '# Import required tensorflow module\\n'\n",
      " '    import tensorflow as tf\\n'\n",
      " '\\n'\n",
      " '    # Convert given input into tensor\\n'\n",
      " '    in_tensor = tf.constant(in1)\\n'\n",
      " '\\n'\n",
      " '    # Find the absolute value of each element in the tensor\\n'\n",
      " '    abs_vals = tf.abs(in_tensor)\\n'\n",
      " '\\n'\n",
      " '    # Create a mask where values less than 1 result in True\\n'\n",
      " '    mask = tf.less(abs_vals, 1)\\n'\n",
      " '\\n'\n",
      " '    # Set the values in the tensor that are less than 1 to 0\\n'\n",
      " '    in_tensor = tf.where(mask, 0., in_tensor)\\n'\n",
      " '\\n'\n",
      " '    # Square the remaining elements in the tensor\\n'\n",
      " '    output = tf.square(in_tensor)\\n'\n",
      " '\\n'\n",
      " '    # Convert the tensor into numpy array and return\\n'\n",
      " '    return output.numpy()',\n",
      " 'abs_in1 = tf.abs(in1)\\n'\n",
      " 'mask = tf.greater(abs_in1, tf.constant(1.0))\\n'\n",
      " 'filtered_in1 = tf.where(mask, tf.square(in1), tf.zeros_like(in1))\\n'\n",
      " 'return filtered_in1',\n",
      " '# create a mask for elements with absolute value less than 1\\n'\n",
      " '    mask = tf.math.less(tf.abs(in1), 1)\\n'\n",
      " '    # set to 0 the elements with absolute value less than 1\\n'\n",
      " '    in1 = tf.where(mask, tf.zeros_like(in1), in1)\\n'\n",
      " '    # square the other elements\\n'\n",
      " '    return tf.square(in1)',\n",
      " 'return tf.where(tf.abs(in1) < 1, 0, tf.square(in1))']\n",
      "\n",
      "Prompting for task: stackoverflow_40, description: use the output of tf.nn.top_k to make a sparse tensor\n",
      "['values, indices = tf.math.top_k(in1)\\n'\n",
      " 'sparse_tensor = tf.SparseTensor(tf.cast(indices, dtype=tf.int64), '\n",
      " 'tf.cast(values, dtype=tf.float32), dense_shape=tf.shape(in1))\\n'\n",
      " 'return tf.sparse.to_dense(sparse_tensor)',\n",
      " 'values, indices = tf.math.top_k(in1, tf.shape(in1)[0])\\n'\n",
      " 'return tf.SparseTensor(tf.cast(in2, dtype=tf.int64), values, '\n",
      " 'tf.constant([3,5], tf.int64))',\n",
      " 'values, indices = tf.nn.top_k(in1, len(in1))\\n'\n",
      " 'return tf.sparse.to_dense(tf.SparseTensor(in2, values, '\n",
      " 'tf.constant([len(in1), len(in1)])))',\n",
      " 'values, indices = tf.math.top_k(in1, k=in1.shape[0])\\n'\n",
      " 'sparse_tensor = tf.sparse.SparseTensor(in2, values, '\n",
      " 'dense_shape=[tf.reduce_max(in2[:, 0])+1, tf.reduce_max(in2[:, 1])+1])\\n'\n",
      " 'return tf.sparse.to_dense(sparse_tensor)',\n",
      " 'values, indices = tf.math.top_k(in1, k=tf.shape(in1)[0])\\n'\n",
      " 'sparse_tensor = tf.SparseTensor(indices=tf.expand_dims(indices, 1), '\n",
      " 'values=values, dense_shape=[tf.reduce_max(indices)+1])\\n'\n",
      " 'dense_tensor = tf.sparse.to_dense(sparse_tensor)\\n'\n",
      " 'return dense_tensor',\n",
      " \"values, indices = tf.nn.top_k(in1, k=tf.size(in1)) # Find the largest 'k' \"\n",
      " 'values in the input\\n'\n",
      " 'sparse_tensor = tf.SparseTensor(indices=tf.expand_dims(indices, 1), '\n",
      " 'values=values, dense_shape=[tf.size(in1)])\\n'\n",
      " 'dense_tensor = tf.sparse.to_dense(sparse_tensor, default_value=0) # Converts '\n",
      " 'sparse representations to dense.\\n'\n",
      " 'dense_tensor = tf.reshape(dense_tensor, in2) # Reshape dense tensor to the '\n",
      " \"shape of 'in2'\\n\"\n",
      " 'return dense_tensor',\n",
      " 'values, indices = tf.nn.top_k(in1, k=in1.shape[0])\\n'\n",
      " 'sparse_tensor = tf.SparseTensor(in2, values, [3,5])\\n'\n",
      " 'return tf.sparse.to_dense(sparse_tensor)',\n",
      " 'values, indices = tf.nn.top_k(in1, k=len(in1))\\n'\n",
      " 'sparse_tensor = tf.SparseTensor(indices=tf.expand_dims(indices, 1), '\n",
      " 'values=values, dense_shape=[len(in1)])\\n'\n",
      " 'return tf.sparse.to_dense(sparse_tensor, validate_indices=False)',\n",
      " 'values, indices = tf.math.top_k(in1, k=len(in1))\\n'\n",
      " 'return tf.SparseTensor(indices=tf.expand_dims(in2, 1), values=values, '\n",
      " 'dense_shape=[len(in1), tf.reduce_max(in2)+1]).to_dense()',\n",
      " 'top_k_values, top_k_indices = tf.math.top_k(in1, k=tf.shape(in1)[0])\\n'\n",
      " 'return tf.SparseTensor(indices=in2, values=top_k_values, '\n",
      " 'dense_shape=tf.shape(in1)).to_dense()']\n",
      "\n",
      "Prompting for task: stackoverflow_41, description: copy all elements except at the given index\n",
      "['indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'filtered_indices = tf.boolean_mask(indices, indices != in2)\\n'\n",
      " 'return tf.gather(in1, filtered_indices)',\n",
      " 'indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'mask = tf.not_equal(indices, in2)\\n'\n",
      " 'return tf.boolean_mask(in1, mask)',\n",
      " 'indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'mask = tf.not_equal(indices, in2)\\n'\n",
      " 'return tf.boolean_mask(in1, mask)',\n",
      " 'indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'mask = tf.not_equal(indices, in2)\\n'\n",
      " 'result = tf.boolean_mask(in1, mask)\\n'\n",
      " 'return result',\n",
      " 'indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'indices_to_keep = tf.not_equal(indices, in2)\\n'\n",
      " 'return tf.boolean_mask(in1, indices_to_keep)',\n",
      " 'idx_mask = tf.one_hot(in2, tf.shape(in1)[0])\\n'\n",
      " 'return tf.boolean_mask(in1, tf.logical_not(idx_mask))',\n",
      " 'return tf.concat([in1[:in2], in1[in2+1:]], 0)',\n",
      " 'indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'mask = tf.not_equal(indices, in2)\\n'\n",
      " 'return tf.boolean_mask(in1, mask)',\n",
      " 'indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'mask = tf.not_equal(indices, in2)\\n'\n",
      " 'return tf.boolean_mask(in1, mask)',\n",
      " 'indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'mask = tf.not_equal(indices, in2)\\n'\n",
      " 'return tf.boolean_mask(in1, mask)']\n",
      "\n",
      "Prompting for task: stackoverflow_42, description: create a binary vector where the max element is 1\n",
      "['max_val = tf.reduce_max(in1)\\nreturn tf.cast(tf.equal(in1, max_val), int)',\n",
      " 'return tf.one_hot(tf.argmax(in1), tf.size(in1))',\n",
      " 'max_elem = tf.reduce_max(in1)\\n'\n",
      " 'max_mask = tf.equal(in1, max_elem)\\n'\n",
      " 'return tf.cast(max_mask, tf.int32)',\n",
      " 'max_value = tf.reduce_max(in1)\\n'\n",
      " 'binary_vector = tf.where(tf.equal(in1, max_value), 1, 0)\\n'\n",
      " 'return binary_vector',\n",
      " 'return tf.where(tf.equal(in1, tf.reduce_max(in1)), 1, 0)',\n",
      " 'max_value = tf.reduce_max(in1)\\n'\n",
      " 'return tf.cast(tf.equal(in1, max_value), tf.int32)',\n",
      " 'max_element = tf.reduce_max(in1)\\n'\n",
      " 'binary_vector = tf.where(tf.equal(in1, max_element), 1, 0)\\n'\n",
      " 'return binary_vector',\n",
      " 'max_value = tf.reduce_max(in1)\\n'\n",
      " 'one_hot_map = tf.equal(in1, max_value)\\n'\n",
      " 'one_hot_map = tf.cast(one_hot_map, tf.int32)\\n'\n",
      " 'return one_hot_map',\n",
      " 'max_value = tf.reduce_max(in1)\\n'\n",
      " 'return tf.cast(tf.equal(in1, max_value), tf.int32)',\n",
      " 'max_element = tf.reduce_max(in1)\\n'\n",
      " 'binary_vector = tf.where(tf.equal(in1, max_element), 1, 0)\\n'\n",
      " 'return binary_vector']\n",
      "\n",
      "Prompting for task: stackoverflow_43, description: extract elements of a tensor given row indices\n",
      "['return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.size(in2))], axis=1))',\n",
      " 'return tf.gather(in1, in2, axis=1)',\n",
      " 'return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], '\n",
      " 'axis=1))',\n",
      " 'return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], '\n",
      " 'axis=1))',\n",
      " 'return tf.gather_nd(in1, tf.transpose([in2, tf.range(tf.shape(in2)[0])]))',\n",
      " 'return tf.gather_nd(in1, tf.stack((tf.range(in2.shape[0]), in2), -1))',\n",
      " 'return tf.gather(in1, in2)',\n",
      " 'return tf.gather(in1, in2, axis=1)',\n",
      " 'return tf.gather(in1,in2)',\n",
      " 'return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], '\n",
      " 'axis=-1))']\n",
      "\n",
      "Prompting for task: stackoverflow_44, description: sum across columns for pairs of consecutive rows\n",
      "['reshaped = tf.reshape(in1, (-1, 2, tf.shape(in1)[-1]))\\n'\n",
      " '    out = tf.reduce_sum(reshaped, axis=1)\\n'\n",
      " '    return out',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, [-1, 2, in1.shape[1]]), axis=1)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, [-1, 2, tf.shape(in1)[-1]]), axis=1)']\n",
      "\n",
      "Prompting for task: stackoverflow_45, description: reverse the order in the marked rows\n",
      "['return tf.where(tf.broadcast_to(tf.reshape(in2, [len(in2),1]), '\n",
      " 'tf.shape(in1)), tf.reverse(in1,[1]), in1)',\n",
      " 'out = [tf.reverse(in1[i], axis=[-1]) if in2[i] else in1[i] for i in '\n",
      " 'range(len(in1))]\\n'\n",
      " 'return tf.stack(out, axis=0)',\n",
      " 'return tf.where(tf.tile(tf.expand_dims(in2, axis=-1), [1, '\n",
      " 'tf.shape(in1)[1]]), tf.reverse(in1, axis=-1), in1)',\n",
      " 'return tf.where(tf.reshape(in2, (len(in2), 1)), tf.reverse(in1, [-1]), in1)',\n",
      " 'output = tf.where(tf.reshape(in2, [-1, 1]), tf.reverse(in1, axis=[-1]), '\n",
      " 'in1)\\n'\n",
      " 'return output',\n",
      " 'return tf.where(tf.broadcast_to(tf.reshape(in2, [-1, 1]), tf.shape(in1)), \\n'\n",
      " '                tf.reverse(in1, [-1]), \\n'\n",
      " '                in1)',\n",
      " 'return tf.where(tf.expand_dims(in2, axis=-1), tf.reverse(in1, axis=[-1]), '\n",
      " 'in1)',\n",
      " 'return tf.where(tf.broadcast_to(tf.reshape(in2,[-1,1]), tf.shape(in1)), '\n",
      " 'tf.reverse(in1,[-1]), in1)',\n",
      " 'out = tf.Tensor(in1.shape)  # initialize output tensor with the same shape '\n",
      " 'as `in1`\\n'\n",
      " 'for i, row in enumerate(in1):\\n'\n",
      " '    if in2[i] == 1:   # if the row is marked for reversal\\n'\n",
      " '        out[i] = tf.reverse(row, axis=-1)  # reverse the row\\n'\n",
      " '    else:\\n'\n",
      " '        out[i] = row  # keep the original row\\n'\n",
      " 'return out',\n",
      " 'return tf.where(tf.expand_dims(in2, -1), tf.reverse(in1, [-1]), in1)']\n",
      "\n",
      "Prompting for task: stackoverflow_46, description: convert segment lengths to segment ids\n",
      "['return tf.repeat(tf.range(tf.shape(in1)[0]), in1)',\n",
      " 'return tf.repeat(tf.range(tf.shape(in1)[0]), in1)',\n",
      " 'return tf.concat([tf.fill([in1[i]], i) for i in range(tf.size(in1))], 0)',\n",
      " 'return tf.repeat(tf.range(tf.shape(in1)[0]), in1)',\n",
      " 'return tf.repeat(tf.range(tf.size(in1)), in1)',\n",
      " 'return tf.repeat(tf.range(tf.size(in1)), in1)',\n",
      " 'return tf.repeat(tf.range(tf.size(in1)), in1)',\n",
      " 'return tf.repeat(tf.range(tf.shape(in1)[0]), in1)',\n",
      " 'return tf.repeat(tf.range(tf.shape(in1)[0]), in1)',\n",
      " 'return tf.repeat(tf.range(tf.shape(in1)[0]), in1)']\n",
      "\n",
      "Prompting for task: stackoverflow_47, description: put given values into a sequence mask\n",
      "['idx = tf.boolean_mask(tf.range(tf.size(in1)), tf.reshape(in2, [-1]))\\n'\n",
      " '     result = tf.scatter_nd(tf.where(in2), idx, tf.shape(in2))\\n'\n",
      " '     return result',\n",
      " 'mask_indexes = tf.boolean_mask(tf.range(tf.size(in2)), tf.reshape(in2, '\n",
      " '[-1]))\\n'\n",
      " 'mask_values = tf.gather(in1, mask_indexes)\\n'\n",
      " 'mask_shape = tf.shape(in2, out_type=mask_indexes.dtype)\\n'\n",
      " 'return tf.scatter_nd(tf.where(in2), mask_values, mask_shape)',\n",
      " 'return tf.where(in2, tf.reshape(in1, tf.shape(in2)), tf.zeros_like(in2))',\n",
      " 'indices = tf.where(in2)\\n'\n",
      " '     return tf.tensor_scatter_nd_update(tf.zeros_like(in2, dtype=in1.dtype), '\n",
      " 'indices, tf.gather(in1, tf.range(tf.shape(indices)[0])))',\n",
      " 'in1 = tf.boolean_mask(in1, tf.reshape(in2, [-1]))\\n'\n",
      " '     out = tf.scatter_nd(tf.where(in2), in1, tf.shape(in2))\\n'\n",
      " '     return out.numpy()',\n",
      " 'output = tf.where(in2, tf.reshape(in1, tf.shape(in2)), tf.zeros_like(in2, '\n",
      " 'dtype=in1.dtype))\\n'\n",
      " 'return output',\n",
      " 'mask_lengths = tf.reduce_sum(tf.cast(in2, tf.int32), axis=-1)\\n'\n",
      " 'masked_values = tf.RaggedTensor.from_row_lengths(in1, mask_lengths)\\n'\n",
      " 'return tf.cast(masked_values.to_tensor(), in1.dtype)',\n",
      " 'out = tf.where(in2, tf.reshape(in1, tf.shape(in2)), 0)\\nreturn out',\n",
      " 'return tf.where(in2, tf.reshape(in1[:tf.reduce_sum(tf.cast(in2, tf.int32))], '\n",
      " 'tf.shape(in2)), 0)',\n",
      " '# first create a zeros_like tensor from the sequence mask\\n'\n",
      " '    tensor = tf.zeros_like(in2, dtype=in1.dtype)\\n'\n",
      " '    \\n'\n",
      " '    # get the indices where the mask is True\\n'\n",
      " '    indices = tf.where(condition=in2)\\n'\n",
      " '    \\n'\n",
      " '    # gather the values from the original tensor based on the indices\\n'\n",
      " '    values = tf.gather(params=in1, indices=tf.reshape(tensor=indices[:, 1], '\n",
      " 'shape=[-1]))\\n'\n",
      " '\\n'\n",
      " '    # update the zeros tensor with the gathered values at the correct '\n",
      " 'indices\\n'\n",
      " '    result = tf.tensor_scatter_nd_update(tensor=tensor, indices=indices, '\n",
      " 'updates=values)\\n'\n",
      " '    \\n'\n",
      " '    return result']\n",
      "\n",
      "Prompting for task: stackoverflow_48, description: find the indices of all elements\n",
      "['return tf.argsort(tf.searchsorted(tf.sort(in1), in2)).numpy().tolist()',\n",
      " 'return tf.where(tf.equal(tf.expand_dims(in1, 1), in2))[:, 1]',\n",
      " 'return [tf.where(tf.equal(in1, x))[0].numpy()[0] for x in in2]',\n",
      " 'return tf.where(tf.equal(tf.expand_dims(in1, 1), in2))[1]',\n",
      " 'return tf.where(tf.equal(tf.expand_dims(in1, axis=-1), in2)).numpy()[:,1]',\n",
      " 'return tf.argsort(tf.searchsorted(in1, in2)).numpy().tolist()',\n",
      " 'return tf.argsort(tf.gather(in1, tf.argsort(in2))).numpy().tolist()',\n",
      " 'return [tf.where(tf.equal(in1, x)).numpy()[0][0] for x in in2]',\n",
      " 'return tf.argsort(tf.argsort(in2)).numpy().tolist()',\n",
      " 'return tf.where(tf.equal(tf.expand_dims(in1, 1), '\n",
      " 'in2)).numpy().flatten().tolist()']\n",
      "\n",
      "Prompting for task: stackoverflow_49, description: multiply tensors by scalars in a batched way\n",
      "['in2 = tf.reshape(in2, [-1, 1, 1, 1])\\n     return tf.multiply(in1, in2)',\n",
      " 'return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))',\n",
      " 'return tf.multiply(tf.expand_dims(in2, axis=[1,2,3]), in1)',\n",
      " 'return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))',\n",
      " 'return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))',\n",
      " 'return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))',\n",
      " 'return tf.multiply(tf.expand_dims(in2, -1), in1)',\n",
      " 'return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))',\n",
      " 'return tf.multiply(tf.expand_dims(in2, axis=-1), in1)',\n",
      " 'return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))']\n",
      "\n",
      "Prompting for task: stackoverflow_50, description: create a binary matrix where a specified column is set to one\n",
      "['return tf.concat([tf.zeros([in1, in1], dtype=tf.int32), '\n",
      " 'tf.reshape(tf.ones([in1], dtype=tf.int32), [in1, 1]), tf.zeros([in1, in1], '\n",
      " 'dtype=tf.int32)], axis=1)',\n",
      " 'return tf.pad(tf.expand_dims(tf.eye(in1, dtype=tf.int32), 2), '\n",
      " '[[0,0],[0,1],[0,0]])[:, 3, :]',\n",
      " 'return tf.one_hot(in1, depth=6, axis=1)',\n",
      " 'return tf.concat([tf.zeros([in1, in1], dtype=tf.int32),\\n'\n",
      " '                  tf.ones([in1, 1], dtype=tf.int32),\\n'\n",
      " '                  tf.zeros([in1, in1], dtype=tf.int32)],\\n'\n",
      " '                 axis=1)',\n",
      " '# In TensorFlow, the tf.ones and tf.zeros function is used to initialize a '\n",
      " 'matrix to ones or zeros respectively. \\n'\n",
      " '# The tf.scatter_nd function is used to create a tensor given the desired '\n",
      " 'indices and updates.\\n'\n",
      " '# To create a binary matrix where a specified column is set to one, we can '\n",
      " 'initialize a zero matrix and set the specified column to one.\\n'\n",
      " '# The function tf.eye creates an identity matrix of given size. If '\n",
      " 'num_columns is not provided, it will default to num_rows.\\n'\n",
      " '\\n'\n",
      " 'def transform(column_no, size=5):\\n'\n",
      " '    # Create a matrix full of zeros\\n'\n",
      " '    matrix = tf.zeros([size, size], dtype=tf.int32)\\n'\n",
      " '    \\n'\n",
      " '    # Create a range to use as indices\\n'\n",
      " '    indices = tf.range(size)\\n'\n",
      " '    \\n'\n",
      " '    # Prepare indices by concatenating with column_no\\n'\n",
      " '    indices = tf.stack([indices, tf.fill([size], column_no)], axis=1)\\n'\n",
      " '    \\n'\n",
      " '    # Use scatter_nd to fill corresponding column with ones\\n'\n",
      " '    transformed_matrix = tf.tensor_scatter_nd_update(matrix, indices, '\n",
      " 'tf.ones([size], dtype=tf.int32))\\n'\n",
      " '    \\n'\n",
      " '    return transformed_matrix',\n",
      " \"# First let's create a 2D tensor where all elements are zero with dimension \"\n",
      " '(in1, in1)\\n'\n",
      " '    matrix_zeros = tf.zeros([in1, in1], tf.int32)\\n'\n",
      " '\\n'\n",
      " \"    # Now let's create a tensor with only one column set to one\\n\"\n",
      " '    column_ones = tf.one_hot(in1//2, in1, dtype=tf.int32)\\n'\n",
      " '\\n'\n",
      " '    # Replace the column in the zero matrix with the column of ones\\n'\n",
      " '    result = tf.tensor_scatter_nd_update(matrix_zeros, [[i, in1//2] for i in '\n",
      " 'range(in1)], column_ones)\\n'\n",
      " '    \\n'\n",
      " '    return result',\n",
      " 'matrix = tf.zeros([5, 6])\\n'\n",
      " 'index = 3\\n'\n",
      " 'column = tf.one_hot(index, 6)\\n'\n",
      " 'return tf.broadcast_to(column, [5, 6])',\n",
      " '# The length of the matrix and the index of the column to set to 1 is not '\n",
      " 'clear from the task description.\\n'\n",
      " \"# I'm assuming that the matrix is of shape 5x5 and the column at index 3 \"\n",
      " 'should be set to 1. If these assumptions are incorrect, please provide '\n",
      " 'further information.\\n'\n",
      " '\\n'\n",
      " 'matrix = tf.zeros((5, 5))  # create a matrix of zeros\\n'\n",
      " 'column = tf.ones((5, 1))  # create a column of ones\\n'\n",
      " 'matrix = tf.tensor_scatter_nd_update(matrix, [[i, 3] for i in range(5)], '\n",
      " 'column)  # update the specified column with ones\\n'\n",
      " '   return matrix.numpy().astype(int)  # return the matrix as a numpy array '\n",
      " 'of integers',\n",
      " 'cols = tf.fill([5, 5], 0)\\n'\n",
      " 'ones_column = tf.fill([5], 1)\\n'\n",
      " 'final_matrix = tf.tensor_scatter_nd_update(cols, [[i, in1] for i in '\n",
      " 'range(5)], ones_column)\\n'\n",
      " 'return final_matrix.numpy()',\n",
      " 'import tensorflow as tf\\n'\n",
      " '\\n'\n",
      " 'def transform(in1):\\n'\n",
      " '    matrix = tf.zeros([5, 6], dtype=tf.int32)\\n'\n",
      " '    updated_matrix = tf.tensor_scatter_nd_update(matrix, [[i, in1] for i in '\n",
      " 'range(5)], tf.ones(5, dtype=tf.int32))\\n'\n",
      " '    return updated_matrix.numpy()']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_COMPLETIONS = 10\n",
    "i = 0\n",
    "for task_name, task in TASK_JSONS.items():\n",
    "    if \"completions\" in task:\n",
    "        continue \n",
    "    print(f\"Prompting for task: {task['name']}, description: {task['description']}\")\n",
    "    completions = prompt(SYSTEM_PROMPT, make_user_message(task), NUM_COMPLETIONS)\n",
    "    task[\"completions\"] = completions\n",
    "    pprint(completions)\n",
    "    print()\n",
    "    # i += 1\n",
    "    # if i > 10:\n",
    "    #     break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS_WITH_COMPLETIONS_FILE = CURRENT_DIRECTORY / \"tfcoder_dataset_with_completions.json\"\n",
    "for name, task in TASK_JSONS.items():\n",
    "    if \"parsed_examples\" in task:\n",
    "        del task[\"parsed_examples\"]\n",
    "TASKS_WITH_COMPLETIONS_FILE.write_text(json.dumps(DATASET, indent=4))\n",
    "for name, task in TASK_JSONS.items():\n",
    "    task[\"parsed_examples\"] = Example.from_json(task[\"examples\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract tf operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tf_operators(code_snippet):\n",
    "    pattern = r\"tf\\.[a-zA-Z_][a-zA-Z0-9_]*(?:\\.[a-zA-Z_][a-zA-Z0-9_]*)*\"\n",
    "    return set(re.findall(pattern, code_snippet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tf_operator_coverage_and_count(target_operators, completion_operators):\n",
    "    \"\"\"Extend to include all completion operators and mark those used in the target program.\"\"\"\n",
    "    completion_operators_count = Counter(completion_operators)\n",
    "    tf_operators_dict = {op: completion_operators_count[op] for op in completion_operators_count}\n",
    "\n",
    "    # Calculate coverage based on target program operators found in completions\n",
    "    covered_operators = set(target_operators).intersection(completion_operators)\n",
    "    coverage_percentage = len(covered_operators) / len(target_operators) * 100 if target_operators else 0\n",
    "\n",
    "    return {\n",
    "        \"tf_operators\": tf_operators_dict,\n",
    "        \"coverage_percentage\": coverage_percentage,\n",
    "        \"total_in_target\": len(target_operators),\n",
    "        \"total_covered\": len(covered_operators)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, task in TASK_JSONS.items():\n",
    "    completions = task[\"completions\"]\n",
    "    completion_tf_operators = [op for completion in completions for op in extract_tf_operators(completion)]\n",
    "    target_program = task[\"target_program\"]\n",
    "    target_tf_operators = extract_tf_operators(target_program)\n",
    "    tf_operator_info = calculate_tf_operator_coverage_and_count(target_tf_operators, completion_tf_operators)\n",
    "\n",
    "    task[\"response\"] = {\n",
    "        \"task_id\": task.get(\"name\", \"unknown\"),\n",
    "        \"completions\": completions,\n",
    "        \"target-program\": task[\"target_program\"],\n",
    "        \"description\": task[\"description\"],\n",
    "        **tf_operator_info  # Includes adjusted tf_operators dictionary\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS_WITH_COMPLETIONS_FILE = CURRENT_DIRECTORY / \"tfcoder_dataset_with_completions.json\"\n",
    "for name, task in TASK_JSONS.items():\n",
    "    if \"parsed_examples\" in task:\n",
    "        del task[\"parsed_examples\"]\n",
    "TASKS_WITH_COMPLETIONS_FILE.write_text(json.dumps(DATASET, indent=4))\n",
    "for name, task in TASK_JSONS.items():\n",
    "    task[\"parsed_examples\"] = Example.from_json(task[\"examples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVERAGE_PERCENTAGES = [task[\"response\"][\"coverage_percentage\"] for task in TASK_JSONS.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.30555555555556"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average coverage percentage\n",
    "sum(COVERAGE_PERCENTAGES) / len(COVERAGE_PERCENTAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# median coverage percentage\n",
    "sorted_coverage_percentages = sorted(COVERAGE_PERCENTAGES)\n",
    "median_index = len(sorted_coverage_percentages) // 2\n",
    "sorted_coverage_percentages[median_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.95833333333334"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLD_OUTPUT_FILE = CURRENT_DIRECTORY / \"output_tfcoder.old.json\"\n",
    "OLD_OUTPUT_JSON = json.loads(OLD_OUTPUT_FILE.read_text())\n",
    "\n",
    "OLD_COVERAGE_PERCENTAGES = [task[\"coverage_percentage\"] for task in OLD_OUTPUT_JSON]\n",
    "sum(OLD_COVERAGE_PERCENTAGES) / len(OLD_COVERAGE_PERCENTAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# median coverage percentage\n",
    "sorted_old_coverage_percentages = sorted(OLD_COVERAGE_PERCENTAGES)\n",
    "median_index = len(sorted_old_coverage_percentages) // 2\n",
    "sorted_old_coverage_percentages[median_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
