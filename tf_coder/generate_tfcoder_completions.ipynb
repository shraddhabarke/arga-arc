{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/ubuntu/arga-arc/tf_coder\n",
      "Root directory: /home/ubuntu/arga-arc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "CURRENT_DIRECTORY = Path(os.getcwd())\n",
    "ROOT_DIRECTORY = (CURRENT_DIRECTORY / \"..\").absolute().resolve()\n",
    "\n",
    "print(f\"Current directory: {CURRENT_DIRECTORY}\")\n",
    "print(f\"Root directory: {ROOT_DIRECTORY}\")\n",
    "\n",
    "sys.path.append(str(ROOT_DIRECTORY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 17:08:11.691103: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-20 17:08:11.709713: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-20 17:08:11.815765: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-20 17:08:11.815827: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-20 17:08:11.832511: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-20 17:08:11.883073: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-20 17:08:11.886141: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-20 17:08:12.811787: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['OPENAI_SECRET_KEY', 'OPENAI_ORGANIZATION'])\n"
     ]
    }
   ],
   "source": [
    "import typing as t\n",
    "import json\n",
    "from pprint import pprint\n",
    "from dataclasses import dataclass\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from config import CONFIG\n",
    "from openai import OpenAI\n",
    "import re\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "pprint(CONFIG.__dict__.keys())\n",
    "\n",
    "OPENAI = OpenAI(api_key=CONFIG.OPENAI_SECRET_KEY, organization=CONFIG.OPENAI_ORGANIZATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parsing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 72 tasks from /home/ubuntu/arga-arc/tf_coder/tfcoder_dataset.json\n"
     ]
    }
   ],
   "source": [
    "class OutputJSON(t.TypedDict):\n",
    "    task_id: str\n",
    "    completions: t.List[str]\n",
    "    coverage_percentage: float\n",
    "    description: str\n",
    "    tf_operators: t.Dict[str, int]\n",
    "    total_covered: int\n",
    "    total_in_target: int\n",
    "\n",
    "class ExamplesJSON(t.TypedDict):\n",
    "    inputs: str\n",
    "    outputs: str\n",
    "\n",
    "class TaskJSON(t.TypedDict):\n",
    "    constants: str\n",
    "    description: str\n",
    "    name: str\n",
    "    source: str\n",
    "    target_program: str\n",
    "    examples: ExamplesJSON\n",
    "\n",
    "DATASET_FILE = CURRENT_DIRECTORY / \"tfcoder_dataset.json\"\n",
    "DATASET: t.List[TaskJSON] = json.loads(DATASET_FILE.read_text())\n",
    "\n",
    "print(f\"Loaded {len(DATASET)} tasks from {DATASET_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'constants': '[]',\n",
      "  'description': 'Divide each row by the sum of that row',\n",
      "  'examples': {'inputs': '[[[0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 1.0, 0.0], [1.0, '\n",
      "                         '1.0, 1.0, 1.0]],]',\n",
      "               'outputs': '[[0.0, 1.0, 0.0, 0.0],    [0.0, 0.5, 0.5, 0.0],    '\n",
      "                          '[0.25, 0.25, 0.25, 0.25]]'},\n",
      "  'name': 'google_02',\n",
      "  'source': 'Real task encountered by Googler, 11/01/2018',\n",
      "  'target_program': 'tf.divide(in1, tf.expand_dims(tf.reduce_sum(in1, axis=1), '\n",
      "                    '1))'},\n",
      " {'constants': '[]',\n",
      "  'description': 'gather the marked elements',\n",
      "  'examples': {'inputs': '[[10, 20, 0, 40, 0, 30],[1, 1, 0, 1, 0, 1],]',\n",
      "               'outputs': '[10, 20, 40, 30]'},\n",
      "  'name': 'google_10',\n",
      "  'source': None,\n",
      "  'target_program': 'tf.boolean_mask(in1, tf.cast(in2, tf.bool))'},\n",
      " {'constants': '[]',\n",
      "  'description': 'swap the first two dimensions of the tensor',\n",
      "  'examples': {'inputs': '[[[[8, 4, 6], [2, 12, 3]], [[11, 12, 5], [9, 12, '\n",
      "                         '12]], [[9, 2, 13], [7, 0, 7]], [[2, 10, 5], [7, 1, '\n",
      "                         '2]]],]',\n",
      "               'outputs': '[[[8, 4, 6], [11, 12, 5], [9, 2, 13], [2, 10, '\n",
      "                          '5]],    [[2, 12, 3], [9, 12, 12], [7, 0, 7], [7, 1, '\n",
      "                          '2]]]'},\n",
      "  'name': 'stackoverflow_07',\n",
      "  'source': 'https://stackoverflow.com/questions/38212205/swap-tensor-axes-in-tensorflow',\n",
      "  'target_program': 'tf.cast(tf.unstack(in1, axis=1), tf.int32)'}]\n"
     ]
    }
   ],
   "source": [
    "IN_CONTEXT_TASK_JSONS = random.sample(DATASET, 3)\n",
    "pprint(IN_CONTEXT_TASK_JSONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    }
   ],
   "source": [
    "TASK_JSONS = {\n",
    "    task[\"name\"]: task for task in DATASET if task not in IN_CONTEXT_TASK_JSONS\n",
    "}\n",
    "pprint(len(TASK_JSONS.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'constants': '[]',\n",
      " 'description': 'Slice the first dimension of a SparseTensor',\n",
      " 'examples': {'inputs': 'tf.SparseTensor(indices=[[0, 0, 0], [0, 1, 1], [1, 1, '\n",
      "                        '1], [1, 1, 2]], values=[1., 1., 1., 1.], '\n",
      "                        'dense_shape=[2, 2, 800])',\n",
      "              'outputs': 'tf.SparseTensor(indices=[[0, 0, 0], [0, 1, 1]], '\n",
      "                         'values=[1., 1.], dense_shape=[1, 2, 800])'},\n",
      " 'name': 'google_03',\n",
      " 'parsed_examples': Example(inputs=[SparseTensor(indices=tf.Tensor(\n",
      "[[0 0 0]\n",
      " [0 1 1]\n",
      " [1 1 1]\n",
      " [1 1 2]], shape=(4, 3), dtype=int64), values=tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32), dense_shape=tf.Tensor([  2   2 800], shape=(3,), dtype=int64))],\n",
      "                            output=SparseTensor(indices=tf.Tensor(\n",
      "[[0 0 0]\n",
      " [0 1 1]], shape=(2, 3), dtype=int64), values=tf.Tensor([1. 1.], shape=(2,), dtype=float32), dense_shape=tf.Tensor([  1   2 800], shape=(3,), dtype=int64))),\n",
      " 'source': 'Real task encountered by Googler, 11/01/2018',\n",
      " 'target_program': 'tf.divide(in1, tf.expand_dims(tf.reduce_sum(in1, axis=1), '\n",
      "                   '1))'}\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Example:\n",
    "    inputs: t.List[np.ndarray]\n",
    "    output: t.Union[np.ndarray, tf.SparseTensor]\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, examples: ExamplesJSON):\n",
    "        try:\n",
    "            evaluated_inputs = eval(examples[\"inputs\"])\n",
    "            if isinstance(evaluated_inputs, list):\n",
    "                inputs = [np.array(i) for i in evaluated_inputs]\n",
    "            else:\n",
    "                inputs = [evaluated_inputs]\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating inputs: {e}\")\n",
    "            print(f\"Inputs: {examples['inputs']}\")\n",
    "            raise e\n",
    "\n",
    "        try:\n",
    "            evaluated_outputs = eval(examples[\"outputs\"])\n",
    "            if isinstance(evaluated_outputs, list):\n",
    "                outputs = np.array(evaluated_outputs)\n",
    "            elif isinstance(evaluated_outputs, tf.SparseTensor):\n",
    "                outputs = evaluated_outputs\n",
    "            elif isinstance(evaluated_outputs, tf.Tensor):\n",
    "                outputs = evaluated_outputs.numpy()\n",
    "            else:\n",
    "                outputs = evaluated_outputs\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating outputs: {e}\")\n",
    "            print(f\"Outputs: {examples['outputs']}\")\n",
    "            raise e\n",
    "\n",
    "        return cls(inputs, outputs)\n",
    "    \n",
    "    def toJSON(self):\n",
    "        return {\n",
    "            \"inputs\": [i.tolist() for i in self.inputs],\n",
    "            \"output\": self.output.tolist()\n",
    "        }\n",
    "\n",
    "for name, task in TASK_JSONS.items():\n",
    "    task[\"parsed_examples\"] = Example.from_json(task[\"examples\"])\n",
    "\n",
    "pprint(TASK_JSONS[\"google_03\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFOPERATORS_STR = \"tf.abs(x)\\ntf.add(x, y)\\ntf.add_n(inputs)\\ntf.argmax(input, axis)\\ntf.argmin(input, axis)\\n\"+\\\n",
    "\"tf.argsort(values, axis, stable=True)\\ntf.argsort(values, axis, direction='DESCENDING', stable=True)\\ntf.boolean_mask(tensor, mask)\\ntf.broadcast_to(input, shape)\\n\"+\\\n",
    "\"tf.cast(x, dtype)\\ntf.clip_by_value(t, clip_value_min, clip_value_max)\\ntf.concat(values, axis)\\ntf.constant(value)\\ntf.constant(value, dtype)\\ntf.divide(x, y)\\n\"+\\\n",
    "\"tf.equal(x, y)\\ntf.exp(x)\\ntf.expand_dims(input, axis)\\ntf.eye(num_rows)\\ntf.eye(num_rows, num_columns)\\ntf.eye(num_rows, dtype)\\ntf.fill(dims, value)\"+\\\n",
    "\"tf.gather(params, indices)\\ntf.gather(params, indices, axis, batch_dims)\\ntf.gather_nd(params, indices)\\ntf.gather_nd(params, indices, batch_dims)\\ntf.greater(x, y)\\n\"+\\\n",
    "\"tf.greater_equal(x, y)\\ntf.math.bincount(arr)\\ntf.math.ceil(x)\\ntf.math.count_nonzero(input)\\ntf.math.count_nonzero(input, axis)\\ntf.math.cumsum(x, axis)\\n\"+\\\n",
    "\"tf.math.cumsum(x, axis, exclusive=True)\\ntf.math.divide_no_nan(x, y)\\ntf.math.floor(x)\\ntf.math.log(x)\\ntf.math.logical_and(x, y)\\ntf.math.logical_not(x)\"+\\\n",
    "\"tf.math.logical_or(x, y)\\ntf.math.logical_xor(x, y)\\ntf.math.negative(x)\\ntf.math.reciprocal(x)\\ntf.math.reciprocal_no_nan(x)\\ntf.math.segment_max(data, segment_ids)\\n\"+\\\n",
    "\"tf.math.segment_mean(data, segment_ids)\\ntf.math.segment_min(data, segment_ids)\\ntf.math.segment_prod(data, segment_ids)\\ntf.math.segment_sum(data, segment_ids)\\n\"+\\\n",
    "\"tf.math.squared_difference(x, y)\\ntf.math.top_k(input, k)\\ntf.math.unsorted_segment_max(data, segment_ids, num_segments)\\ntf.math.unsorted_segment_mean(data, segment_ids, num_segments)\\n\"+\\\n",
    "\"tf.math.unsorted_segment_min(data, segment_ids, num_segments)\\ntf.math.unsorted_segment_prod(data, segment_ids, num_segments)\\ntf.math.unsorted_segment_sum(data, segment_ids, num_segments)\\n\"+\\\n",
    "\"tf.matmul(a, b)\\ntf.maximum(x, y)\\ntf.minimum(x, y)\\ntf.multiply(x, y)\\ntf.not_equal(x, y)\\ntf.one_hot(indices, depth)\\ntf.ones(shape)\\ntf.ones_like(input)\\n\"+\\\n",
    "\"tf.pad(tensor, paddings, mode='CONSTANT')\\ntf.pad(tensor, paddings, mode='CONSTANT', constant_values)\\ntf.pad(tensor, paddings, mode='REFLECT')\\n\"+\\\n",
    "\"tf.pad(tensor, paddings, mode='SYMMETRIC')\\ntf.range(start)\\ntf.range(start, limit, delta)\\ntf.reduce_any(input_tensor, axis)\\ntf.reduce_all(input_tensor, axis)\\n\"+\\\n",
    "\"tf.reduce_max(input_tensor)\\ntf.reduce_max(input_tensor, axis)\\ntf.reduce_mean(input_tensor)\\n\"+\\\n",
    "\"tf.reduce_mean(input_tensor, axis)\\ntf.reduce_min(input_tensor)\\ntf.reduce_min(input_tensor, axis)\\n\"+\\\n",
    "\"tf.reduce_prod(input_tensor, axis)\\ntf.reduce_sum(input_tensor)\\ntf.reduce_sum(input_tensor, axis)\\n\"+\\\n",
    "\"tf.repeat(input, repeats)\\ntf.repeat(input, repeats, axis)\\ntf.reshape(tensor, shape)\\n\"+\\\n",
    "\"tf.reverse(tensor, axis)\\ntf.roll(input, shift, axis)\\ntf.round(x)\\ntf.scatter_nd(indices, updates, shape)\\n\"+\\\n",
    "\"tf.searchsorted(sorted_sequence, values, side='left')\\ntf.searchsorted(sorted_sequence, values, side='right')\\n\"+\\\n",
    "\"tf.sequence_mask(lengths)\\ntf.sequence_mask(lengths, maxlen)\\ntf.shape(input)\\ntf.sign(x)\\n\"+\\\n",
    "\"tf.sort(values, axis)\\ntf.sort(values, axis, direction='DESCENDING')\\ntf.sqrt(x)\\n\"+\\\n",
    "\"tf.square(x)\\ntf.squeeze(input)\\ntf.squeeze(input, axis)\\ntf.stack(values, axis)\\ntf.subtract(x, y)\\n\"+\\\n",
    "\"tf.tensor_scatter_nd_update(tensor, indices, updates)\\ntf.tensordot(a, b, axes)\\ntf.tile(input, multiples)\\n\"+\\\n",
    "\"tf.transpose(a)\\ntf.transpose(a, perm)\\ntf.unique_with_counts(x)\\ntf.unstack(value, axis)\\n\"+\\\n",
    "\"tf.where(condition)\\ntf.where(condition, x, y)\\ntf.zeros(shape)\\ntf.zeros_like(input)\"\n",
    "SPARSETF_OPERATORS_STR = \"tf.SparseTensor(indices, values, dense_shape)\\ntf.sparse.add(a, b)\\n\"+\\\n",
    "\"tf.sparse.concat(axis, sp_inputs)\\ntf.sparse.expand_dims(sp_input, axis)\\ntf.sparse.from_dense(tensor)\\ntf.sparse.maximum(sp_a, sp_b)\\n\"+\\\n",
    "\"tf.sparse.minimum(sp_a, sp_b)\\ntf.sparse.reduce_max(sp_input, axis, output_is_sparse)\\ntf.sparse.reduce_sum(sp_input, axis, output_is_sparse)\\n\"+\\\n",
    "\"tf.sparse.reset_shape(sp_input)\\ntf.sparse.reshape(sp_input, shape)\\ntf.sparse.retain(sp_input, to_retain)\\ntf.sparse.slice(sp_input, start, size)\\n\"+\\\n",
    "\"tf.sparse.split(sp_input, num_split, axis)\\ntf.sparse.to_dense(sp_input)\\ntf.sparse.to_dense(sp_input, default_value)\\n\"+\\\n",
    "\"tf.sparse.to_indicator(sp_input, vocab_size)\\ntf.sparse.transpose(sp_input)\\ntf.sparse.transpose(sp_input, perm)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Operators: 111, ['tf.abs(x)', 'tf.add(x, y)', 'tf.add_n(inputs)', 'tf.argmax(input, axis)', 'tf.argmin(input, axis)']\n",
      "SparseTF Operators: 19, ['tf.SparseTensor(indices, values, dense_shape)', 'tf.sparse.add(a, b)', 'tf.sparse.concat(axis, sp_inputs)', 'tf.sparse.expand_dims(sp_input, axis)', 'tf.sparse.from_dense(tensor)']\n"
     ]
    }
   ],
   "source": [
    "TFOPERATORS = [op.strip() for op in TFOPERATORS_STR.split(\"\\n\") if op.strip() != \"\"]\n",
    "\n",
    "SPARSETF_OPERATORS = [op.strip() for op in SPARSETF_OPERATORS_STR.split(\"\\n\") if op.strip() != \"\"]\n",
    "\n",
    "print(f\"TF Operators: {len(TFOPERATORS)}, {TFOPERATORS[:5]}\")\n",
    "print(f\"SparseTF Operators: {len(SPARSETF_OPERATORS)}, {SPARSETF_OPERATORS[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFOPERATORS_WEIGHT_ORDER = ['tf.cast(x, dtype)', 'tf.expand_dims(input, axis)', 'tf.constant(value)', 'tf.squeeze(input, axis)', 'tf.constant(value, dtype)', 'tf.equal(x, y)', 'tf.gather(params, indices)', 'tf.greater(x, y)', 'tf.matmul(a, b)', 'tf.maximum(x, y)', 'tf.multiply(x, y)', 'tf.reduce_max(input_tensor)', 'tf.reduce_max(input_tensor, axis)', 'tf.reduce_sum(input_tensor)', 'tf.reduce_sum(input_tensor, axis)', 'tf.tensordot(a, b, axes)', 'tf.transpose(a)', 'tf.where(condition)', 'tf.where(condition, x, y)', 'tf.add(x, y)', 'tf.boolean_mask(tensor, mask)', 'tf.divide(x, y)', 'tf.gather_nd(params, indices)', 'tf.one_hot(indices, depth)', 'tf.range(start)', 'tf.reshape(tensor, shape)', 'tf.square(x)', 'tf.subtract(x, y)', 'tf.tile(input, multiples)', 'tf.argmax(input, axis)', 'tf.greater_equal(x, y)', 'tf.minimum(x, y)', 'tf.sequence_mask(lengths)', 'tf.zeros_like(input)', 'tf.concat(values, axis)', 'tf.gather_nd(params, indices, batch_dims)', 'tf.ones_like(input)', 'tf.shape(input)', 'tf.stack(values, axis)', 'tf.squeeze(input)', 'tf.abs(x)', 'tf.argsort(values, axis, stable=True)', 'tf.eye(num_rows)', 'tf.fill(dims, value)', 'tf.gather(params, indices, axis, batch_dims)', 'tf.math.bincount(arr)', 'tf.math.segment_max(data, segment_ids)', 'tf.math.segment_sum(data, segment_ids)', 'tf.math.unsorted_segment_max(data, segment_ids, num_segments)', 'tf.math.unsorted_segment_sum(data, segment_ids, num_segments)', \"tf.pad(tensor, paddings, mode='CONSTANT')\", 'tf.reduce_any(input_tensor, axis)', 'tf.reduce_mean(input_tensor)', 'tf.reduce_mean(input_tensor, axis)', 'tf.reduce_min(input_tensor)', 'tf.reduce_min(input_tensor, axis)', 'tf.unstack(value, axis)', 'tf.zeros(shape)', 'tf.add_n(inputs)', 'tf.broadcast_to(input, shape)', 'tf.clip_by_value(t, clip_value_min, clip_value_max)', 'tf.math.ceil(x)', 'tf.math.cumsum(x, axis)', 'tf.math.floor(x)', 'tf.math.logical_and(x, y)', 'tf.math.logical_or(x, y)', 'tf.not_equal(x, y)', 'tf.ones(shape)', 'tf.reduce_all(input_tensor, axis)', 'tf.sequence_mask(lengths, maxlen)', 'tf.tensor_scatter_nd_update(tensor, indices, updates)', 'tf.transpose(a, perm)', 'tf.argmin(input, axis)', \"tf.argsort(values, axis, direction='DESCENDING', stable=True)\", 'tf.eye(num_rows, dtype)', 'tf.math.cumsum(x, axis, exclusive=True)', 'tf.math.logical_not(x)', 'tf.math.negative(x)', 'tf.math.segment_min(data, segment_ids)', 'tf.math.top_k(input, k)', 'tf.math.unsorted_segment_min(data, segment_ids, num_segments)', 'tf.reverse(tensor, axis)', 'tf.roll(input, shift, axis)', 'tf.sign(x)', 'tf.unique_with_counts(x)', 'tf.exp(x)', 'tf.math.divide_no_nan(x, y)', 'tf.math.log(x)', 'tf.math.reciprocal(x)', 'tf.math.squared_difference(x, y)', \"tf.pad(tensor, paddings, mode='CONSTANT', constant_values)\", 'tf.reduce_prod(input_tensor, axis)', 'tf.repeat(input, repeats, axis)', 'tf.round(x)', 'tf.scatter_nd(indices, updates, shape)', 'tf.sort(values, axis)', 'tf.math.count_nonzero(input)', 'tf.math.count_nonzero(input, axis)', 'tf.math.segment_mean(data, segment_ids)', 'tf.math.unsorted_segment_mean(data, segment_ids, num_segments)', 'tf.range(start, limit, delta)', 'tf.repeat(input, repeats)', \"tf.searchsorted(sorted_sequence, values, side='left')\", \"tf.searchsorted(sorted_sequence, values, side='right')\", 'tf.sqrt(x)', 'tf.eye(num_rows, num_columns)', 'tf.math.logical_xor(x, y)', 'tf.math.reciprocal_no_nan(x)', 'tf.math.segment_prod(data, segment_ids)', 'tf.math.unsorted_segment_prod(data, segment_ids, num_segments)', \"tf.pad(tensor, paddings, mode='REFLECT')\", \"tf.pad(tensor, paddings, mode='SYMMETRIC')\", \"tf.sort(values, axis, direction='DESCENDING')\"]\n",
    "\n",
    "SPARSETF_OPERATORS_WEIGHT_ORDER = ['tf.SparseTensor(indices, values, dense_shape)', 'tf.sparse.from_dense(tensor)', 'tf.sparse.to_dense(sp_input)', 'tf.sparse.expand_dims(sp_input, axis)', 'tf.sparse.reduce_max(sp_input, axis, output_is_sparse)', 'tf.sparse.reduce_sum(sp_input, axis, output_is_sparse)', 'tf.sparse.add(a, b)', 'tf.sparse.maximum(sp_a, sp_b)', 'tf.sparse.slice(sp_input, start, size)', 'tf.sparse.split(sp_input, num_split, axis)', 'tf.sparse.retain(sp_input, to_retain)', 'tf.sparse.to_dense(sp_input, default_value)', 'tf.sparse.transpose(sp_input)', 'tf.sparse.concat(axis, sp_inputs)', 'tf.sparse.minimum(sp_a, sp_b)', 'tf.sparse.reset_shape(sp_input)', 'tf.sparse.reshape(sp_input, shape)', 'tf.sparse.to_indicator(sp_input, vocab_size)', 'tf.sparse.transpose(sp_input, perm)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_operators_section(shuffle = True, include_sparse = True, order_by_weight = False) -> str:\n",
    "    operators = TFOPERATORS_WEIGHT_ORDER if order_by_weight else TFOPERATORS\n",
    "    sparse_operators = SPARSETF_OPERATORS_WEIGHT_ORDER if order_by_weight else SPARSETF_OPERATORS\n",
    "    shuffled_tf = operators.copy()\n",
    "    shuffled_sparse = sparse_operators.copy()\n",
    "    if shuffle:\n",
    "        random.shuffle(shuffled_tf)\n",
    "        random.shuffle(shuffled_sparse)\n",
    "    \n",
    "    tf_str = \"\\n\".join(shuffled_tf)\n",
    "    sparse_str = \"\\n\".join(shuffled_sparse)\n",
    "\n",
    "    ans = f\"[TENSORFLOW OPERATORS]\\n{tf_str}\\n\"\n",
    "    if include_sparse:\n",
    "        ans += f\"\\n[SPARSE TENSORFLOW OPERATORS]\\n{sparse_str}\"\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TASK DESCRIPTION]\n",
      "create a binary matrix where a specified column is set to one\n",
      "\n",
      "[INPUTS]\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [1. 1. 1. 1.]]\n",
      "\n",
      "[OUTPUTS]\n",
      "[[0.   1.   0.   0.  ]\n",
      " [0.   0.5  0.5  0.  ]\n",
      " [0.25 0.25 0.25 0.25]]\n",
      "\n",
      "[PROGRAM]\n",
      "def transform(in1):\n",
      "    return tf.divide(in1, tf.expand_dims(tf.reduce_sum(in1, axis=1), 1))\n",
      "\n",
      "\n",
      "[TASK DESCRIPTION]\n",
      "create a binary matrix where a specified column is set to one\n",
      "\n",
      "[INPUTS]\n",
      "[10 20  0 40  0 30]\n",
      "[1 1 0 1 0 1]\n",
      "\n",
      "[OUTPUTS]\n",
      "[10 20 40 30]\n",
      "\n",
      "[PROGRAM]\n",
      "def transform(in1, in2):\n",
      "    return tf.boolean_mask(in1, tf.cast(in2, tf.bool))\n",
      "\n",
      "\n",
      "[TASK DESCRIPTION]\n",
      "create a binary matrix where a specified column is set to one\n",
      "\n",
      "[INPUTS]\n",
      "[[[ 8  4  6]\n",
      "  [ 2 12  3]]\n",
      "\n",
      " [[11 12  5]\n",
      "  [ 9 12 12]]\n",
      "\n",
      " [[ 9  2 13]\n",
      "  [ 7  0  7]]\n",
      "\n",
      " [[ 2 10  5]\n",
      "  [ 7  1  2]]]\n",
      "\n",
      "[OUTPUTS]\n",
      "[[[ 8  4  6]\n",
      "  [11 12  5]\n",
      "  [ 9  2 13]\n",
      "  [ 2 10  5]]\n",
      "\n",
      " [[ 2 12  3]\n",
      "  [ 9 12 12]\n",
      "  [ 7  0  7]\n",
      "  [ 7  1  2]]]\n",
      "\n",
      "[PROGRAM]\n",
      "def transform(in1):\n",
      "    return tf.cast(tf.unstack(in1, axis=1), tf.int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def make_in_context_example(task_json: TaskJSON, include_program = True) -> str:\n",
    "    parsed_examples = Example.from_json(task_json[\"examples\"])\n",
    "    inputs_str = \"\"\n",
    "    for inp in parsed_examples.inputs:\n",
    "        inputs_str += f\"{inp}\\n\"\n",
    "    outputs_str = f\"{parsed_examples.output}\\n\"\n",
    "\n",
    "    formals_str = [f\"in{i+1}\" for i in range(len(parsed_examples.inputs))]\n",
    "\n",
    "    ans = f\"\"\"[TASK DESCRIPTION]\n",
    "{task['description']}\n",
    "\n",
    "[INPUTS]\n",
    "{inputs_str}\n",
    "[OUTPUTS]\n",
    "{outputs_str}\n",
    "\"\"\"\n",
    "    ans += f\"\"\"[PROGRAM]\n",
    "def transform({\", \".join(formals_str)}):\n",
    "    \"\"\"\n",
    "    if include_program:\n",
    "        ans += f\"return {task_json['target_program']}\\n\"\n",
    "    \n",
    "    return ans\n",
    "\n",
    "IN_CONTEXT_SECTION = \"\\n\\n\".join([make_in_context_example(task_json) for task_json in IN_CONTEXT_TASK_JSONS])\n",
    "\n",
    "print(IN_CONTEXT_SECTION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a coding assistant. Be precise and terse.\n",
    "You will be provided a list of tensorflow operators, a task description, and some input/output examples.\n",
    "Your task is to generate the body of a python function that will transform the input to the output.\n",
    "Only use the operators provided in the list.\n",
    "\"\"\"\n",
    "\n",
    "def make_user_message(task, shuffle_operators = True, order_by_weight = False):\n",
    "    parsed_examples: Example = task['parsed_examples']\n",
    "    include_sparse = any(isinstance(i, tf.SparseTensor) for i in parsed_examples.inputs) or isinstance(parsed_examples.output, tf.SparseTensor)\n",
    "\n",
    "    return f\"\"\"{make_operators_section(shuffle_operators, include_sparse, order_by_weight)}\n",
    "\n",
    "{IN_CONTEXT_SECTION}\n",
    "\n",
    "{make_in_context_example(task, include_program=False)}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(system_message: str, user_message: str, n_completions: int) -> t.List[str]:\n",
    "    response = OPENAI.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_message},\n",
    "        ],\n",
    "        n=n_completions,\n",
    "        temperature=1.0,\n",
    "    )\n",
    "    return [choice.message.content for choice in response.choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TENSORFLOW OPERATORS]\n",
      "tf.cast(x, dtype)\n",
      "tf.expand_dims(input, axis)\n",
      "tf.constant(value)\n",
      "tf.squeeze(input, axis)\n",
      "tf.constant(value, dtype)\n",
      "tf.equal(x, y)\n",
      "tf.gather(params, indices)\n",
      "tf.greater(x, y)\n",
      "tf.matmul(a, b)\n",
      "tf.maximum(x, y)\n",
      "tf.multiply(x, y)\n",
      "tf.reduce_max(input_tensor)\n",
      "tf.reduce_max(input_tensor, axis)\n",
      "tf.reduce_sum(input_tensor)\n",
      "tf.reduce_sum(input_tensor, axis)\n",
      "tf.tensordot(a, b, axes)\n",
      "tf.transpose(a)\n",
      "tf.where(condition)\n",
      "tf.where(condition, x, y)\n",
      "tf.add(x, y)\n",
      "tf.boolean_mask(tensor, mask)\n",
      "tf.divide(x, y)\n",
      "tf.gather_nd(params, indices)\n",
      "tf.one_hot(indices, depth)\n",
      "tf.range(start)\n",
      "tf.reshape(tensor, shape)\n",
      "tf.square(x)\n",
      "tf.subtract(x, y)\n",
      "tf.tile(input, multiples)\n",
      "tf.argmax(input, axis)\n",
      "tf.greater_equal(x, y)\n",
      "tf.minimum(x, y)\n",
      "tf.sequence_mask(lengths)\n",
      "tf.zeros_like(input)\n",
      "tf.concat(values, axis)\n",
      "tf.gather_nd(params, indices, batch_dims)\n",
      "tf.ones_like(input)\n",
      "tf.shape(input)\n",
      "tf.stack(values, axis)\n",
      "tf.squeeze(input)\n",
      "tf.abs(x)\n",
      "tf.argsort(values, axis, stable=True)\n",
      "tf.eye(num_rows)\n",
      "tf.fill(dims, value)\n",
      "tf.gather(params, indices, axis, batch_dims)\n",
      "tf.math.bincount(arr)\n",
      "tf.math.segment_max(data, segment_ids)\n",
      "tf.math.segment_sum(data, segment_ids)\n",
      "tf.math.unsorted_segment_max(data, segment_ids, num_segments)\n",
      "tf.math.unsorted_segment_sum(data, segment_ids, num_segments)\n",
      "tf.pad(tensor, paddings, mode='CONSTANT')\n",
      "tf.reduce_any(input_tensor, axis)\n",
      "tf.reduce_mean(input_tensor)\n",
      "tf.reduce_mean(input_tensor, axis)\n",
      "tf.reduce_min(input_tensor)\n",
      "tf.reduce_min(input_tensor, axis)\n",
      "tf.unstack(value, axis)\n",
      "tf.zeros(shape)\n",
      "tf.add_n(inputs)\n",
      "tf.broadcast_to(input, shape)\n",
      "tf.clip_by_value(t, clip_value_min, clip_value_max)\n",
      "tf.math.ceil(x)\n",
      "tf.math.cumsum(x, axis)\n",
      "tf.math.floor(x)\n",
      "tf.math.logical_and(x, y)\n",
      "tf.math.logical_or(x, y)\n",
      "tf.not_equal(x, y)\n",
      "tf.ones(shape)\n",
      "tf.reduce_all(input_tensor, axis)\n",
      "tf.sequence_mask(lengths, maxlen)\n",
      "tf.tensor_scatter_nd_update(tensor, indices, updates)\n",
      "tf.transpose(a, perm)\n",
      "tf.argmin(input, axis)\n",
      "tf.argsort(values, axis, direction='DESCENDING', stable=True)\n",
      "tf.eye(num_rows, dtype)\n",
      "tf.math.cumsum(x, axis, exclusive=True)\n",
      "tf.math.logical_not(x)\n",
      "tf.math.negative(x)\n",
      "tf.math.segment_min(data, segment_ids)\n",
      "tf.math.top_k(input, k)\n",
      "tf.math.unsorted_segment_min(data, segment_ids, num_segments)\n",
      "tf.reverse(tensor, axis)\n",
      "tf.roll(input, shift, axis)\n",
      "tf.sign(x)\n",
      "tf.unique_with_counts(x)\n",
      "tf.exp(x)\n",
      "tf.math.divide_no_nan(x, y)\n",
      "tf.math.log(x)\n",
      "tf.math.reciprocal(x)\n",
      "tf.math.squared_difference(x, y)\n",
      "tf.pad(tensor, paddings, mode='CONSTANT', constant_values)\n",
      "tf.reduce_prod(input_tensor, axis)\n",
      "tf.repeat(input, repeats, axis)\n",
      "tf.round(x)\n",
      "tf.scatter_nd(indices, updates, shape)\n",
      "tf.sort(values, axis)\n",
      "tf.math.count_nonzero(input)\n",
      "tf.math.count_nonzero(input, axis)\n",
      "tf.math.segment_mean(data, segment_ids)\n",
      "tf.math.unsorted_segment_mean(data, segment_ids, num_segments)\n",
      "tf.range(start, limit, delta)\n",
      "tf.repeat(input, repeats)\n",
      "tf.searchsorted(sorted_sequence, values, side='left')\n",
      "tf.searchsorted(sorted_sequence, values, side='right')\n",
      "tf.sqrt(x)\n",
      "tf.eye(num_rows, num_columns)\n",
      "tf.math.logical_xor(x, y)\n",
      "tf.math.reciprocal_no_nan(x)\n",
      "tf.math.segment_prod(data, segment_ids)\n",
      "tf.math.unsorted_segment_prod(data, segment_ids, num_segments)\n",
      "tf.pad(tensor, paddings, mode='REFLECT')\n",
      "tf.pad(tensor, paddings, mode='SYMMETRIC')\n",
      "tf.sort(values, axis, direction='DESCENDING')\n",
      "\n",
      "[SPARSE TENSORFLOW OPERATORS]\n",
      "tf.SparseTensor(indices, values, dense_shape)\n",
      "tf.sparse.from_dense(tensor)\n",
      "tf.sparse.to_dense(sp_input)\n",
      "tf.sparse.expand_dims(sp_input, axis)\n",
      "tf.sparse.reduce_max(sp_input, axis, output_is_sparse)\n",
      "tf.sparse.reduce_sum(sp_input, axis, output_is_sparse)\n",
      "tf.sparse.add(a, b)\n",
      "tf.sparse.maximum(sp_a, sp_b)\n",
      "tf.sparse.slice(sp_input, start, size)\n",
      "tf.sparse.split(sp_input, num_split, axis)\n",
      "tf.sparse.retain(sp_input, to_retain)\n",
      "tf.sparse.to_dense(sp_input, default_value)\n",
      "tf.sparse.transpose(sp_input)\n",
      "tf.sparse.concat(axis, sp_inputs)\n",
      "tf.sparse.minimum(sp_a, sp_b)\n",
      "tf.sparse.reset_shape(sp_input)\n",
      "tf.sparse.reshape(sp_input, shape)\n",
      "tf.sparse.to_indicator(sp_input, vocab_size)\n",
      "tf.sparse.transpose(sp_input, perm)\n",
      "\n",
      "[TASK DESCRIPTION]\n",
      "create a binary matrix where a specified column is set to one\n",
      "\n",
      "[INPUTS]\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [1. 1. 1. 1.]]\n",
      "\n",
      "[OUTPUTS]\n",
      "[[0.   1.   0.   0.  ]\n",
      " [0.   0.5  0.5  0.  ]\n",
      " [0.25 0.25 0.25 0.25]]\n",
      "\n",
      "[PROGRAM]\n",
      "def transform(in1):\n",
      "    return tf.divide(in1, tf.expand_dims(tf.reduce_sum(in1, axis=1), 1))\n",
      "\n",
      "\n",
      "[TASK DESCRIPTION]\n",
      "create a binary matrix where a specified column is set to one\n",
      "\n",
      "[INPUTS]\n",
      "[10 20  0 40  0 30]\n",
      "[1 1 0 1 0 1]\n",
      "\n",
      "[OUTPUTS]\n",
      "[10 20 40 30]\n",
      "\n",
      "[PROGRAM]\n",
      "def transform(in1, in2):\n",
      "    return tf.boolean_mask(in1, tf.cast(in2, tf.bool))\n",
      "\n",
      "\n",
      "[TASK DESCRIPTION]\n",
      "create a binary matrix where a specified column is set to one\n",
      "\n",
      "[INPUTS]\n",
      "[[[ 8  4  6]\n",
      "  [ 2 12  3]]\n",
      "\n",
      " [[11 12  5]\n",
      "  [ 9 12 12]]\n",
      "\n",
      " [[ 9  2 13]\n",
      "  [ 7  0  7]]\n",
      "\n",
      " [[ 2 10  5]\n",
      "  [ 7  1  2]]]\n",
      "\n",
      "[OUTPUTS]\n",
      "[[[ 8  4  6]\n",
      "  [11 12  5]\n",
      "  [ 9  2 13]\n",
      "  [ 2 10  5]]\n",
      "\n",
      " [[ 2 12  3]\n",
      "  [ 9 12 12]\n",
      "  [ 7  0  7]\n",
      "  [ 7  1  2]]]\n",
      "\n",
      "[PROGRAM]\n",
      "def transform(in1):\n",
      "    return tf.cast(tf.unstack(in1, axis=1), tf.int32)\n",
      "\n",
      "\n",
      "[TASK DESCRIPTION]\n",
      "create a binary matrix where a specified column is set to one\n",
      "\n",
      "[INPUTS]\n",
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 0 0]\n",
      " [0 1 1]\n",
      " [1 1 1]\n",
      " [1 1 2]], shape=(4, 3), dtype=int64), values=tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32), dense_shape=tf.Tensor([  2   2 800], shape=(3,), dtype=int64))\n",
      "\n",
      "[OUTPUTS]\n",
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 0 0]\n",
      " [0 1 1]], shape=(2, 3), dtype=int64), values=tf.Tensor([1. 1.], shape=(2,), dtype=float32), dense_shape=tf.Tensor([  1   2 800], shape=(3,), dtype=int64))\n",
      "\n",
      "[PROGRAM]\n",
      "def transform(in1):\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['return tf.sparse.slice(in1, [0,0,0], [1,-1,-1])',\n",
       " 'return tf.sparse.slice(in1, start=[0, 0, 0], size=[1, 2, 800])',\n",
       " 'return tf.sparse.slice(in1, [0,0,0], [1, -1, -1])',\n",
       " 'return tf.sparse.slice(in1, [0, 0, 0], [1, -1, -1])',\n",
       " 'return tf.sparse.slice(in1, [0,0,0], [1,2,800])']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_TASK = TASK_JSONS[\"google_03\"]\n",
    "\n",
    "print(make_user_message(TEST_TASK, False, True))\n",
    "\n",
    "prompt(SYSTEM_PROMPT, make_user_message(TEST_TASK), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_name, task in TASK_JSONS.items():\n",
    "    if \"completions\" in task:\n",
    "        del task[\"completions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompting for task: google_14, description: circular buffer\n",
      "['return tf.roll(in1, shift=1, axis=1)',\n",
      " 'return tf.roll(in1, shift=1, axis=1)',\n",
      " 'return tf.roll(in1, shift=1, axis=1)',\n",
      " 'return tf.roll(in1, shift=1, axis=1)',\n",
      " 'return tf.roll(in1, shift=1, axis=1)',\n",
      " 'return tf.roll(in1, shift=1, axis=1)',\n",
      " 'return tf.roll(in1, shift=1, axis=1)',\n",
      " 'return tf.roll(in1, shift=1, axis=1)',\n",
      " 'return tf.roll(in1, shift=1, axis=1)',\n",
      " 'return tf.roll(in1, shift=-1, axis=-1)']\n",
      "\n",
      "Prompting for task: google_15, description: pad a zero column\n",
      "['return tf.pad(in1, [[0,0],[0,1]])',\n",
      " 'return tf.pad(in1, [[0,0],[0,1]])',\n",
      " 'return tf.pad(in1, [[0, 0], [0, 1]])',\n",
      " 'return tf.pad(in1, [[0,0], [0,1]])',\n",
      " 'return tf.pad(in1, [[0, 0], [0, 1]])',\n",
      " 'return tf.pad(in1, [[0,0], [0,1]])',\n",
      " 'return tf.pad(in1, [[0, 0], [0, 1]])',\n",
      " 'return tf.pad(in1, [[0, 0], [0, 1]])',\n",
      " 'return tf.pad(in1, [[0, 0], [0, 1]])',\n",
      " 'return tf.pad(in1, [[0, 0], [0, 1]])']\n",
      "\n",
      "Prompting for task: google_16, description: replicate elements a given number of times\n",
      "['return tf.repeat(in1, in2)',\n",
      " 'return tf.repeat(in1, in2)',\n",
      " 'return tf.repeat(in1, in2)',\n",
      " 'return tf.repeat(in1, in2)',\n",
      " 'return tf.repeat(in1, in2)',\n",
      " 'return tf.repeat(in1, in2)',\n",
      " 'return tf.repeat(in1, in2)',\n",
      " 'return tf.repeat(in1, in2)',\n",
      " 'return tf.repeat(in1, in2)',\n",
      " 'return tf.repeat(in1, in2)']\n",
      "\n",
      "Prompting for task: google_17, description: use bool tensor as condition\n",
      "['return tf.where(in1, in2, tf.math.negative(tf.multiply(in2, 10)))',\n",
      " 'return tf.where(in1, in2, tf.multiply(in2, -10))',\n",
      " 'return tf.where(in1, in2, tf.multiply(in2, -10))',\n",
      " 'return tf.where(in1, in2, tf.multiply(in2, -10))',\n",
      " 'return tf.where(in1, in2, tf.multiply(in2, tf.constant(-10)))',\n",
      " 'return tf.where(in1, in2, -10*in2)',\n",
      " 'return tf.where(in1, in2, tf.multiply(-10, tf.range(tf.shape(in2)[0]));',\n",
      " 'return tf.where(in1, in2, tf.multiply(in2, -10))',\n",
      " 'return tf.where(in1, in2, tf.multiply(-10, in2))',\n",
      " 'return tf.where(in1, in2, tf.multiply(in2, -10))']\n",
      "\n",
      "Prompting for task: google_18, description: (\\'sum of elements in the first tensor but partitioned by the second tensor\\')\n",
      "['return tf.gather(tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + '\n",
      " '1), in2)',\n",
      " 'return tf.gather(tf.math.unsorted_segment_sum(in1, in2, '\n",
      " 'tf.reduce_max(in2)+1), in2)',\n",
      " 'return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + 1)[in2 - '\n",
      " '1]',\n",
      " 'return tf.gather(tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + '\n",
      " '1), in2)',\n",
      " 'return tf.gather(tf.math.unsorted_segment_sum(in1, in2, '\n",
      " 'tf.reduce_max(in2)+1), in2)',\n",
      " 'return tf.gather(tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + '\n",
      " '1), in2)',\n",
      " 'return tf.gather(tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + '\n",
      " '1), in2)',\n",
      " 'return tf.gather(tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + '\n",
      " '1), in2)',\n",
      " 'return tf.gather(tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + '\n",
      " '1), in2)',\n",
      " 'return tf.gather(tf.math.unsorted_segment_sum(in1, in2, '\n",
      " 'tf.reduce_max(in2)+1), in2)']\n",
      "\n",
      "Prompting for task: google_19, description: scatter a 2-D tensor with indices\n",
      "['return tf.gather(in1, in2, batch_dims=1)',\n",
      " 'return tf.gather(in1, in2, axis=1, batch_dims=1)',\n",
      " 'return tf.gather(in1, in2, axis=1)',\n",
      " 'return tf.gather(in1, in2, axis=1, batch_dims=1)',\n",
      " 'return tf.gather(in1, in2, axis=1)',\n",
      " 'return tf.gather(in1, in2, axis=1, batch_dims=1)',\n",
      " 'return tf.gather(in1, in2, batch_dims=1)',\n",
      " 'return tf.gather(in1, in2, axis=1)',\n",
      " 'return tf.gather(in1, in2, axis=1, batch_dims=1)',\n",
      " 'indices = tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1)\\n'\n",
      " '    return tf.gather_nd(in1, indices)']\n",
      "\n",
      "Prompting for task: google_20, description: sort a tensor and return sorted index in original order\n",
      "['return tf.argsort(tf.argsort(in1))',\n",
      " 'return tf.argsort(tf.argsort(in1))',\n",
      " 'return tf.argsort(tf.argsort(in1))',\n",
      " 'return tf.argsort(tf.argsort(in1))',\n",
      " 'return tf.argsort(tf.argsort(in1)).numpy()',\n",
      " 'return tf.argsort(tf.argsort(in1))',\n",
      " 'return tf.argsort(tf.argsort(in1))',\n",
      " 'return tf.cast(tf.argsort(tf.argsort(in1)), tf.int32)',\n",
      " 'return tf.argsort(tf.argsort(in1))',\n",
      " 'return tf.argsort(tf.argsort(in1))']\n",
      "\n",
      "Prompting for task: google_21, description: update a tensor at the given indices\n",
      "[\"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\",\n",
      " \"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\",\n",
      " \"return tf.tensor_scatter_nd_update(tf.constant(in1['tensor'], \"\n",
      " \"dtype=tf.int32), tf.constant(in1['indices'], dtype=tf.int32), \"\n",
      " \"tf.constant(in1['updates'], dtype=tf.int32))\",\n",
      " 'return tf.tensor_scatter_nd_update(in1[\"tensor\"], in1[\"indices\"], '\n",
      " 'in1[\"updates\"])',\n",
      " \"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\",\n",
      " \"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\",\n",
      " \"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\",\n",
      " \"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\",\n",
      " \"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\",\n",
      " \"return tf.tensor_scatter_nd_update(tf.constant(in1['tensor'], tf.int32), \"\n",
      " \"tf.constant(in1['indices'], tf.int32), tf.constant(in1['updates'], \"\n",
      " 'tf.int32))']\n",
      "\n",
      "Prompting for task: google_22, description: pair with row index\n",
      "['return tf.reshape(tf.transpose(tf.broadcast_to(in1, [2, *tf.shape(in1)]), '\n",
      " '[1, 0, 2]), [-1, 2])',\n",
      " 'ind = tf.reshape(tf.range(tf.shape(in1)[0]), (-1, 1))\\n'\n",
      " ' return tf.reshape(tf.concat([tf.tile(ind, [1, tf.shape(in1)[1]]), in1], '\n",
      " 'axis=2), [-1, 2])',\n",
      " 'return tf.reshape(tf.stack([tf.tile(tf.range(tf.shape(in1)[0])[:, '\n",
      " 'tf.newaxis], [1, 2]), in1], axis=2), [-1, 2])',\n",
      " 'return '\n",
      " 'tf.reshape(tf.transpose(tf.stack([tf.repeat(tf.range(tf.shape(in1)[0]), '\n",
      " 'tf.shape(in1)[1]), tf.reshape(in1, [-1])])), [-1, 2])',\n",
      " 'return '\n",
      " 'tf.reshape(tf.stack([tf.broadcast_to(tf.expand_dims(tf.range(tf.shape(in1)[0]), '\n",
      " '1), tf.shape(in1)), in1], -1), [-1, 2])',\n",
      " 'return tf.reshape(tf.concat([tf.expand_dims(tf.range(tf.shape(in1)[0]), '\n",
      " 'axis=1), in1], axis=2), [-1, 2])',\n",
      " 'indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " '    return tf.reshape(tf.stack([tf.repeat(indices, tf.shape(in1)[1]), '\n",
      " 'tf.reshape(in1, [-1])], axis=1), [-1,2])',\n",
      " 'return '\n",
      " 'tf.reshape(tf.transpose(tf.stack([tf.repeat(tf.range(tf.shape(in1)[0]), '\n",
      " 'tf.shape(in1)[1]), tf.reshape(in1, [-1])])), [-1, 2])',\n",
      " 'return tf.reshape(tf.stack([tf.broadcast_to(tf.range(tf.shape(in1)[0])[:, '\n",
      " 'tf.newaxis], [in1.shape[0], in1.shape[1]]), in1], axis=-1), [-1, 2])',\n",
      " 'return tf.concat([tf.expand_dims(tf.cast(tf.range(tf.shape(in1)[0]), '\n",
      " 'tf.int32), 1), tf.reshape(in1, [-1, 1])], axis=1)']\n",
      "\n",
      "Prompting for task: stackoverflow_01, description: reshape by separating and duplicating columns\n",
      "['return tf.expand_dims(tf.transpose(in1), 2)',\n",
      " 'return tf.expand_dims(tf.transpose(in1), axis=2)',\n",
      " 'return tf.expand_dims(tf.transpose(in1), 2)',\n",
      " 'return tf.expand_dims(tf.transpose(in1), axis=-1)',\n",
      " 'return tf.reshape(tf.tile(in1, [1, 2]), [2, -1, 2])',\n",
      " 'return tf.expand_dims(tf.transpose(in1), 2)',\n",
      " 'return tf.expand_dims(tf.transpose(in1), axis=-1)',\n",
      " 'return tf.expand_dims(tf.transpose(in1),2)',\n",
      " 'return tf.expand_dims(tf.transpose(in1), -1)',\n",
      " 'return tf.expand_dims(tf.transpose(in1), axis=2)']\n",
      "\n",
      "Prompting for task: stackoverflow_02, description: clip values that are greater than 1\n",
      "['return tf.clip_by_value(in1, -tf.constant(1e10), tf.constant(1))',\n",
      " 'return tf.clip_by_value(in1, -tf.constant(np.inf), tf.constant(1.))',\n",
      " \"return tf.clip_by_value(in1, -tf.constant(float('inf')), 1)\",\n",
      " \"return tf.clip_by_value(in1, -tf.constant(float('inf')), tf.constant(1))\",\n",
      " \"return tf.clip_by_value(in1, -tf.constant(float('inf')), 1)\",\n",
      " 'return tf.clip_by_value(in1, -tf.float32.max, 1)',\n",
      " 'return tf.clip_by_value(in1, -tf.constant(np.inf), 1)',\n",
      " 'return tf.clip_by_value(in1, -tf.constant(np.inf), tf.constant(1))',\n",
      " \"return tf.clip_by_value(in1, -tf.constant(float('inf')), 1)\",\n",
      " \"return tf.clip_by_value(in1, -tf.constant(float('inf')), 1)\"]\n",
      "\n",
      "Prompting for task: stackoverflow_03, description: replace certain columns with columns from the other tensor\n",
      "['indices = tf.constant([[0, 3], [0, 4], [1, 3], [1, 4]])\\n'\n",
      " 'updates = tf.gather_nd(in2, indices)\\n'\n",
      " 'return tf.expand_dims(tf.tensor_scatter_nd_update(in1, indices, updates), 0)',\n",
      " 'indices = tf.constant([[0, 1, 2, 0, 0, 2, 3], [0, 1, 2, 1, 1, 2, 3]])\\n'\n",
      " '    return tf.gather(in2, indices, axis=1)',\n",
      " 'return tf.tensor_scatter_nd_update(in1, tf.constant([[0, 3], [0, 4], [1, 3], '\n",
      " '[1, 4]]), tf.gather_nd(in2, tf.constant([[0, 3], [0, 4], [1, 3], [1, 4]])))',\n",
      " 'return tf.tensor_scatter_nd_update(in1, [[0,3], [0,4], [1,3], [1,4]], '\n",
      " 'tf.gather(in2, [3,4,3,4]))',\n",
      " 'indices = tf.constant([[0,3],[0,4],[1,3],[1,4]])\\n'\n",
      " '    updates = tf.gather_nd(in2, indices)\\n'\n",
      " '    return tf.expand_dims(tf.tensor_scatter_nd_update(in1, indices, '\n",
      " 'updates), 0)',\n",
      " 'mask = [True, True, True, False, False, True, True]\\n'\n",
      " 'neg_mask = tf.math.logical_not(mask)\\n'\n",
      " 'in1_masked = tf.boolean_mask(in1, mask, axis=1)\\n'\n",
      " 'in2_masked = tf.boolean_mask(in2, neg_mask, axis=1)\\n'\n",
      " 'return tf.concat([in1_masked, in2_masked], axis=1)',\n",
      " 'indices = tf.constant([[0, 3], [0, 4], [1, 3], [1, 4]])\\n'\n",
      " '    return tf.tensor_scatter_nd_update(in1, indices, tf.gather_nd(in2, '\n",
      " 'indices))',\n",
      " 'return tf.tensor_scatter_nd_update(in1, [[0,3], [0,4], [1,3], [1,4]], '\n",
      " 'tf.gather(in2, [3,4], axis=1))',\n",
      " 'indices = tf.constant([[3,4]])\\n'\n",
      " 'return tf.tensor_scatter_nd_update(in1, indices, tf.gather(in2, indices))',\n",
      " 'indices = tf.constant([[0,3],[0,4],[1,3],[1,4]])\\n'\n",
      " '    return tf.tensor_scatter_nd_update(in1, indices, tf.gather_nd(in2, '\n",
      " 'indices))']\n",
      "\n",
      "Prompting for task: stackoverflow_04, description: index into the tensor\n",
      "['return tf.expand_dims(in1, -1)',\n",
      " 'return tf.expand_dims(in1, 2)',\n",
      " 'return tf.expand_dims(in1, -1)',\n",
      " 'return tf.expand_dims(in1, axis=0)',\n",
      " 'return tf.expand_dims(in1, 0)',\n",
      " 'return tf.expand_dims(in1, 2)',\n",
      " 'return tf.expand_dims(in1, 0)',\n",
      " 'return tf.expand_dims(in1, axis=-1)',\n",
      " 'return tf.expand_dims(in1, axis=2)',\n",
      " 'return tf.expand_dims(in1, axis=-1)']\n",
      "\n",
      "Prompting for task: stackoverflow_05, description: tensor multiplication like np.tensordot\n",
      "['return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=[[1], [0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=[[1],[0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=[[1], [0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=1)']\n",
      "\n",
      "Prompting for task: stackoverflow_06, description: binary tensor from vector indicating if elements are equal\n",
      "['return tf.cast(tf.equal(tf.expand_dims(in1, 0), tf.expand_dims(in1, 1)), '\n",
      " 'tf.float32)',\n",
      " 'return tf.cast(tf.equal(tf.expand_dims(in1, 1), tf.expand_dims(in1, 0)), '\n",
      " 'tf.float32)',\n",
      " 'return tf.cast(tf.equal(tf.expand_dims(in1, 1), in1), tf.float32)',\n",
      " 'return tf.cast(tf.equal(tf.expand_dims(in1, 1), tf.expand_dims(in1, 0)), '\n",
      " 'tf.float32)',\n",
      " 'return tf.cast(tf.equal(tf.expand_dims(in1, 1), tf.expand_dims(in1, 0)), '\n",
      " 'tf.float32)',\n",
      " 'return tf.cast(tf.equal(tf.expand_dims(in1, 1), in1), tf.float32)',\n",
      " 'return tf.cast(tf.equal(tf.expand_dims(in1, 1), in1), tf.float32)',\n",
      " 'return tf.cast(tf.equal(tf.reshape(in1, [-1, 1]), in1), tf.float32)',\n",
      " 'return tf.cast(tf.equal(tf.expand_dims(in1, 1), tf.expand_dims(in1, 0)), '\n",
      " 'tf.float32)',\n",
      " 'return tf.cast(tf.equal(tf.expand_dims(in1, 1), in1), tf.float32)']\n",
      "\n",
      "Prompting for task: stackoverflow_08, description: (\\'select the values in the second tensor where the first tensor is greater than 1\\')\n",
      "['return tf.boolean_mask(in2, tf.greater(in1, 1))',\n",
      " 'return tf.boolean_mask(in2, tf.greater(in1, 1))',\n",
      " 'return tf.boolean_mask(in2, tf.greater(in1, 1))',\n",
      " 'return tf.boolean_mask(in2, tf.greater(in1, 1))',\n",
      " 'return tf.boolean_mask(in2, tf.greater(in1, 1))',\n",
      " 'return tf.boolean_mask(in2, tf.greater(in1, 1))',\n",
      " 'return tf.boolean_mask(in2, tf.greater(in1, 1))',\n",
      " 'return tf.boolean_mask(in2, tf.greater(in1, 1))',\n",
      " 'return tf.boolean_mask(in2, tf.greater(in1, 1))',\n",
      " 'return tf.boolean_mask(in2, tf.greater(in1, 1))']\n",
      "\n",
      "Prompting for task: stackoverflow_09, description: group items by value and get the group indices\n",
      "['_, idx, count = tf.unique_with_counts(in1)\\nreturn tf.gather(idx, in1)',\n",
      " '_, ids = tf.unique(in1)\\nreturn tf.cast(ids, tf.int32)',\n",
      " '_, _, group_idx = tf.unique_with_counts(in1)\\nreturn group_idx',\n",
      " '_, ids = tf.unique(in1)\\nreturn tf.cast(ids, tf.int32)',\n",
      " '_, idx = tf.unique(in1)\\nreturn tf.cast(idx, tf.int32)',\n",
      " '_, _, group_indices = tf.unique_with_counts(in1)\\nreturn group_indices',\n",
      " '_, idx = tf.unique(in1)\\nreturn idx.numpy()',\n",
      " '_, idx = tf.unique_with_counts(in1)\\nreturn idx',\n",
      " '_, idx = tf.unique_with_counts(in1)\\n return tf.gather(idx, in1)',\n",
      " '_, idx = tf.unique(in1)\\nreturn tf.cast(idx, tf.int32)']\n",
      "\n",
      "Prompting for task: stackoverflow_10, description: perform matrix multiplication\n",
      "['return tf.matmul(tf.expand_dims(in1, 0), tf.expand_dims(in2, 0))',\n",
      " 'return tf.matmul(tf.expand_dims(in1,0), tf.expand_dims(in2,0))',\n",
      " 'return tf.matmul(tf.expand_dims(in1, axis=0), tf.expand_dims(in2, axis=0))',\n",
      " 'return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(tf.expand_dims(in1, 0), tf.expand_dims(in2, -1))',\n",
      " 'return tf.matmul(tf.expand_dims(in1,axis =2), '\n",
      " 'tf.reshape(in2,[in1.shape[1],-1,1]))',\n",
      " 'return tf.matmul(tf.expand_dims(in1, 0), tf.expand_dims(in2, 0))',\n",
      " 'return tf.matmul(tf.expand_dims(in1, axis=0), tf.expand_dims(in2, axis=0))',\n",
      " 'return tf.matmul(tf.expand_dims(in1, axis=0), tf.expand_dims(in2, axis=0))',\n",
      " 'return tf.matmul(tf.expand_dims(in1, 0), tf.expand_dims(in2, -1))']\n",
      "\n",
      "Prompting for task: stackoverflow_11, description: count the number of occurences of each distinct number\n",
      "['return tf.math.bincount(in1)',\n",
      " 'return tf.math.bincount(in1)',\n",
      " 'return tf.math.bincount(in1)',\n",
      " 'return tf.math.bincount(in1)',\n",
      " 'return tf.math.bincount(in1)',\n",
      " 'return tf.math.bincount(in1)',\n",
      " 'return tf.math.bincount(in1)',\n",
      " 'return tf.math.bincount(in1)',\n",
      " 'return tf.math.bincount(in1)',\n",
      " 'return tf.math.bincount(in1)']\n",
      "\n",
      "Prompting for task: stackoverflow_12, description: remove a column from the tensor\n",
      "['return tf.gather(in1, [0, 2], axis=1)',\n",
      " 'return tf.gather(in1, [0, 2], axis=1)',\n",
      " 'return tf.gather(in1, [0, 2], axis=1)',\n",
      " 'return tf.gather(in1, [0, 2], axis=1)',\n",
      " 'return tf.boolean_mask(in1, tf.concat([tf.fill([tf.shape(in1)[0], 1], True), '\n",
      " 'tf.fill([tf.shape(in1)[0], 1], False), tf.fill([tf.shape(in1)[0], 1], '\n",
      " 'True)], axis=1))',\n",
      " 'return tf.gather(in1, [0, 2], axis=1)',\n",
      " 'return tf.gather(in1, [0, 2], axis=1)',\n",
      " 'return tf.gather(in1, [0, 2], axis=1)',\n",
      " 'return tf.concat([in1[:, :1], in1[:, 2:]], axis=1)',\n",
      " 'return tf.boolean_mask(in1, tf.not_equal(tf.range(tf.shape(in1)[1]), 1), '\n",
      " 'axis=1)']\n",
      "\n",
      "Prompting for task: stackoverflow_13, description: multiply vectors by tensor\n",
      "['return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in2, tf.transpose(in1))',\n",
      " 'return tf.tensordot(in2, in1, axes=[[2], [1]])',\n",
      " 'return tf.matmul(in1, tf.cast(in2, tf.int32))',\n",
      " 'return tf.matmul(in2, tf.transpose(in1))',\n",
      " 'return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in2, tf.transpose(in1))',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.matmul(in2, tf.cast(tf.transpose(in1), tf.int32))',\n",
      " 'return tf.matmul(in2, tf.transpose(in1))']\n",
      "\n",
      "Prompting for task: stackoverflow_14, description: choose True if any value in a row is True, False otherwise\n",
      "['return tf.reduce_any(in1, axis=2)',\n",
      " 'return tf.reduce_any(in1, axis=2)',\n",
      " 'return tf.reduce_any(in1, axis=2)',\n",
      " 'return tf.reduce_any(in1, axis=2)',\n",
      " 'return tf.reduce_any(in1, axis=2)',\n",
      " 'return tf.cast(tf.reduce_any(in1, axis=2), tf.bool)',\n",
      " 'return tf.reduce_any(in1, axis=2)',\n",
      " 'return tf.cast(tf.reduce_any(in1, axis=2), tf.bool)',\n",
      " 'return tf.reduce_any(in1, axis=-1)',\n",
      " 'return tf.reduce_any(in1, axis=2)']\n",
      "\n",
      "Prompting for task: stackoverflow_15, description: set all instances of 1 to 0\n",
      "['return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), tf.zeros_like(in1), in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)']\n",
      "\n",
      "Prompting for task: stackoverflow_16, description: multiply tensors across the first axis\n",
      "['return tf.multiply(in1, tf.expand_dims(in2, 1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, 1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, 1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, 1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, 1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, 1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, 1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, 1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, 1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, 1))']\n",
      "\n",
      "Prompting for task: stackoverflow_17, description: duplicate each element of a tensor\n",
      "['return tf.expand_dims(in1, 1) * tf.ones((1, 2), dtype=tf.int32)',\n",
      " 'return tf.expand_dims(in1, 1) * tf.ones([1,2], dtype=tf.int32)',\n",
      " 'return tf.expand_dims(in1, axis=1) * tf.ones([1, 2])',\n",
      " 'return tf.expand_dims(in1, axis=-1) * [1, 2]',\n",
      " 'return tf.expand_dims(in1, -1) * tf.ones((1,2), dtype=in1.dtype)',\n",
      " 'return tf.expand_dims(in1, 1) * tf.ones([1, 2], dtype=tf.int32)',\n",
      " 'return tf.expand_dims(in1, 1) * tf.ones([1,2], dtype=in1.dtype)',\n",
      " 'return tf.expand_dims(in1, 1) * tf.ones([1,2], dtype=in1.dtype)',\n",
      " 'return tf.expand_dims(in1, -1) * tf.ones([1, 2], dtype=in1.dtype)',\n",
      " 'return tf.expand_dims(in1, 1) * tf.ones((1, 2), dtype=in1.dtype)']\n",
      "\n",
      "Prompting for task: stackoverflow_18, description: multiply 3D tensor and 2D tensor and add another tensor\n",
      "['return tf.add(tf.matmul(tf.cast(in1, tf.int32), tf.cast(in2, tf.int32)), '\n",
      " 'in3)',\n",
      " 'return tf.add(tf.matmul(in1, in2), in3)',\n",
      " 'return tf.add(tf.matmul(in1, in2), in3)',\n",
      " 'return tf.add(tf.tensordot(in1, in2, axes=([2],[0])), tf.cast(in3, '\n",
      " 'tf.int32))',\n",
      " 'return tf.add(tf.matmul(in1, in2), in3)',\n",
      " 'return tf.add(tf.matmul(in1, in2), in3)',\n",
      " 'return tf.add(tf.matmul(tf.cast(in1, tf.int32), tf.cast(in2, tf.int32)), '\n",
      " 'in3)',\n",
      " 'return tf.add(tf.tensordot(in1, in2, axes=1), in3)',\n",
      " 'return tf.add(tf.tensordot(in1, in2, axes=1), in3)',\n",
      " 'return tf.add(tf.matmul(tf.cast(in1, tf.int32), tf.cast(in2, tf.int32)), '\n",
      " 'tf.cast(in3, tf.int32))']\n",
      "\n",
      "Prompting for task: stackoverflow_19, description: (\\'sort a tensor considering the first column, breaking ties using the second column\\')\n",
      "['return tf.gather(in1, tf.argsort(in1, axis=0))',\n",
      " 'return tf.gather(in1, tf.argsort(in1, axis=0))',\n",
      " 'return tf.gather(in1, tf.argsort(in1, axis = 0, stable=True))',\n",
      " 'return tf.gather(in1, tf.argsort(in1, axis=0))',\n",
      " 'return tf.gather(in1, tf.argsort(in1[:, :2], axis=0))',\n",
      " 'return tf.gather(in1, tf.argsort(in1, axis=0, stable=True))',\n",
      " 'return tf.gather(in1, tf.argsort(in1, axis=0))',\n",
      " 'return tf.gather(in1, tf.argsort(in1[:, :2], axis=0))',\n",
      " 'return tf.cast(tf.gather(in1, tf.argsort(in1, axis=0)), tf.int32)',\n",
      " 'return tf.gather(in1, tf.argsort(in1))']\n",
      "\n",
      "Prompting for task: stackoverflow_20, description: compute argmax in each tensor and set it to 1\n",
      "['return tf.one_hot(tf.argmax(in1, axis=1), depth=tf.shape(in1)[1])',\n",
      " 'return tf.one_hot(tf.argmax(in1, axis=1), depth=in1.shape[1])',\n",
      " 'return tf.one_hot(tf.argmax(in1, axis=1), '\n",
      " 'depth=in1.get_shape().as_list()[1])',\n",
      " 'return tf.one_hot(tf.argmax(in1, axis=1), depth=in1.shape[1])',\n",
      " 'return tf.one_hot(tf.argmax(in1, axis=1), depth=3)',\n",
      " 'return tf.one_hot(tf.argmax(in1, axis=1), depth=in1.get_shape()[1])',\n",
      " 'return tf.one_hot(tf.argmax(in1, axis=1), in1.shape[1])',\n",
      " 'return tf.one_hot(tf.argmax(in1, axis=1), depth=in1.shape[1])',\n",
      " 'return tf.one_hot(tf.argmax(in1, axis=1), depth=in1.shape[1])',\n",
      " 'return tf.one_hot(tf.argmax(in1, axis=1), depth=tf.shape(in1)[1])']\n",
      "\n",
      "Prompting for task: stackoverflow_21, description: gather elements in a tensor along axis 1\n",
      "['return tf.gather(in2, in1, axis=1)',\n",
      " 'return tf.gather_nd(in2, '\n",
      " 'tf.concat([tf.expand_dims(tf.range(tf.shape(in1)[0]),1), in1], axis=1))',\n",
      " 'return tf.gather_nd(in2, tf.concat([tf.range(tf.shape(in1)[0])[:,None], '\n",
      " 'in1], axis=-1))',\n",
      " 'return tf.gather(in2, in1, axis=1)',\n",
      " 'return tf.gather(in2, in1, axis=1)',\n",
      " 'return tf.gather(in2, tf.cast(in1, tf.int32), axis=1)',\n",
      " 'return tf.gather(in2, in1, axis=1)',\n",
      " 'return tf.gather_nd(in2, tf.concat([tf.range(tf.shape(in1)[0])[:, '\n",
      " 'tf.newaxis], in1], axis=1))',\n",
      " 'return tf.gather(in2, in1, axis=1)',\n",
      " 'return tf.gather(in2, in1, axis=1)']\n",
      "\n",
      "Prompting for task: stackoverflow_22, description: multiply a vector with a matrix without reshaping the vector\n",
      "['return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.matmul(tf.cast(in1, tf.float32), in2)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, in2), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(tf.cast(in1, tf.float32), in2), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(tf.expand_dims(in1, 1), in2), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(tf.cast(in1, tf.float32), in2), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(tf.expand_dims(in1, 1), in2), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(tf.cast(in1, dtype=tf.float32), in2), '\n",
      " 'axis=0)',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.reduce_sum(tf.multiply(tf.cast(in1, tf.float32), in2), 0)']\n",
      "\n",
      "Prompting for task: stackoverflow_23, description: place 1 at the indices in the input tensor\n",
      "['return tf.cast(tf.one_hot(in1, 9), tf.int32)',\n",
      " 'return tf.cast(tf.one_hot(in1, tf.reduce_max(in1)+1), tf.int32)',\n",
      " 'return tf.reduce_sum(tf.one_hot(in1, 9), axis=1)',\n",
      " 'return tf.reduce_sum(tf.one_hot(in1, 9), axis=1)',\n",
      " 'return tf.cast(tf.one_hot(in1, depth=9), tf.int32)',\n",
      " 'return tf.reduce_sum(tf.one_hot(in1, depth=9), axis=1)',\n",
      " 'return tf.cast(tf.one_hot(in1, depth=9), tf.int32)',\n",
      " 'return tf.cast(tf.one_hot(in1, depth=9), tf.int32)',\n",
      " 'return tf.reduce_any(tf.one_hot(in1, 9), axis=1, keepdims=False)',\n",
      " 'return tf.reduce_sum(tf.one_hot(in1, 9), axis=1)']\n",
      "\n",
      "Prompting for task: stackoverflow_24, description: (\\'like tf.divide(), but when dividing by 0, return the numerator\\')\n",
      "['return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)']\n",
      "\n",
      "Prompting for task: stackoverflow_25, description: copy the tensor tf.eye(3), 4 times\n",
      "['return tf.tile(tf.eye(in1), [in2, 1])',\n",
      " 'return tf.reshape(tf.tile(tf.eye(in1), [in2, 1]), [-1, in1])',\n",
      " 'return tf.tile(tf.eye(in1), [in2, 1])',\n",
      " 'return tf.tile(tf.eye(in1), [in2, 1])',\n",
      " 'return tf.tile(tf.eye(in1), [in2, 1])',\n",
      " 'return tf.tile(tf.eye(in1), [in2, 1])',\n",
      " 'return tf.tile(tf.eye(in1), [in2, 1])',\n",
      " 'return tf.reshape(tf.tile(tf.eye(in1), [in2, 1]), [-1, in1])',\n",
      " 'return tf.tile(tf.eye(in1), [in2, 1])',\n",
      " 'return tf.tile(tf.eye(in1), [in2, 1])']\n",
      "\n",
      "Prompting for task: stackoverflow_26, description: reduction operation for multiple dimensions simultaneously\n",
      "['return tf.reduce_max(tf.cast(in1, tf.int32), axis=[0,1])',\n",
      " 'return tf.reduce_sum(in1, axis=[0, 1])',\n",
      " 'return tf.reduce_sum(in1, axis=[0, 1])',\n",
      " 'return tf.reduce_sum(in1, axis=[0,1])',\n",
      " 'return tf.reduce_sum(in1, axis=[0, 1])',\n",
      " 'return tf.reduce_max(tf.reduce_sum(in1, axis=1), axis=0)',\n",
      " 'return tf.reduce_sum(in1, axis=[0, 1])',\n",
      " 'return tf.reduce_sum(in1, axis=[0, 1])',\n",
      " 'return tf.reduce_max(tf.reduce_sum(in1, axis=-1), axis=-1)',\n",
      " 'return tf.reduce_sum(tf.abs(in1), axis=[0,1])']\n",
      "\n",
      "Prompting for task: stackoverflow_27, description: boolean tensor with 1 at the indices in the input tensor\n",
      "['return tf.cast(tf.reduce_max(tf.one_hot(in1, in2), axis=0), tf.int32)',\n",
      " 'return tf.cast(tf.math.bincount(in1, minlength=in2), tf.bool)',\n",
      " 'return tf.reduce_sum(tf.one_hot(in1, in2), axis=0)',\n",
      " 'return tf.cast(tf.scatter_nd(tf.expand_dims(in1, 1), tf.ones_like(in1), '\n",
      " '[in2]), tf.int32)',\n",
      " 'return tf.cast(tf.scatter_nd(tf.expand_dims(in1, axis=1), tf.ones_like(in1), '\n",
      " '[in2]), tf.int32)',\n",
      " 'output = tf.scatter_nd(tf.expand_dims(in1, 1), tf.ones_like(in1), [in2])\\n'\n",
      " 'return tf.cast(output, tf.int32)',\n",
      " 'return tf.cast(tf.scatter_nd(tf.expand_dims(in1, axis=-1), '\n",
      " 'tf.ones_like(in1), [in2]), tf.int32)',\n",
      " 'return tf.cast(tf.sequence_mask(in1, in2), int)',\n",
      " 'return tf.cast(tf.scatter_nd(tf.expand_dims(in1, 1), tf.ones_like(in1), '\n",
      " '[in2]), tf.int32)',\n",
      " 'return tf.cast(tf.reduce_sum(tf.one_hot(in1, in2), axis=0), tf.int32)']\n",
      "\n",
      "Prompting for task: stackoverflow_28, description: extract columns from a 3D tensor given column indices\n",
      "['return tf.gather(in1, tf.expand_dims(in2, axis=-1), axis=2, batch_dims=1)',\n",
      " 'return tf.gather(in1, in2, axis=2)',\n",
      " 'return tf.gather(in1, in2, axis=2)',\n",
      " 'return tf.gather(in1, in2, axis=2)',\n",
      " 'return tf.gather(in1, in2, axis=2)',\n",
      " 'return tf.gather(in1, in2, axis=2, batch_dims=1)',\n",
      " 'return tf.gather(in1, in2, axis=2)',\n",
      " 'return tf.gather(in1, tf.expand_dims(in2, -1), axis=2, batch_dims=1)',\n",
      " 'return tf.gather(in1, in2, axis=2, batch_dims=1)',\n",
      " 'return tf.cast(tf.gather(in1, tf.cast(in2, tf.int32), axis=2), tf.int32)']\n",
      "\n",
      "Prompting for task: stackoverflow_29, description: place continuous values into buckets given bucket boundaries\n",
      "['return tf.cast(tf.searchsorted(in1, in2), tf.int32)',\n",
      " \"return tf.searchsorted(in1, in2, side='right')\",\n",
      " \"return tf.searchsorted(in1, in2, side='right')\",\n",
      " \"return tf.searchsorted(in1, in2, side='right')\",\n",
      " 'return tf.cast(tf.searchsorted(tf.sort(in1), in2), tf.int32)',\n",
      " 'return tf.searchsorted(tf.sort(in1), in2)',\n",
      " \"return tf.cast(tf.searchsorted(in1, in2, side='right'), tf.int32)\",\n",
      " \"return tf.searchsorted(in1, in2, 'right')\",\n",
      " \"return tf.searchsorted(tf.sort(in1), in2, side='right')\",\n",
      " 'return tf.searchsorted(in1, in2)']\n",
      "\n",
      "Prompting for task: stackoverflow_30, description: compute Euclidean distance between two tensors\n",
      "['return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.transpose(in2))), '\n",
      " 'axis=1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.transpose(in2))), '\n",
      " 'axis=1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.expand_dims(in2, '\n",
      " '0))), axis=-1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.transpose(in2))), '\n",
      " 'axis=1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.expand_dims(in2, '\n",
      " '1))), axis=2))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.transpose(in2))), '\n",
      " 'axis=1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.expand_dims(in2, '\n",
      " '1))), axis=2))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.expand_dims(in2, '\n",
      " '1))), axis=-1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.expand_dims(in2, '\n",
      " '1))), axis=2))']\n",
      "\n",
      "Prompting for task: stackoverflow_31, description: squared error between two tensors, one being a sparse tensor\n",
      "['return tf.reduce_sum(tf.math.squared_difference(in1.values, '\n",
      " 'tf.gather_nd(in2, in1.indices)))',\n",
      " 'dense1 = tf.sparse.to_dense(in1)\\n'\n",
      " 'return tf.reduce_sum(tf.math.squared_difference(dense1, in1))',\n",
      " 'return tf.reduce_sum(tf.math.squared_difference(in1[0], tf.cast(in1[1], '\n",
      " 'tf.float32)))',\n",
      " 'return tf.reduce_sum(tf.math.squared_difference(in1.values, '\n",
      " 'tf.gather_nd(in2, in1.indices)))',\n",
      " 'return tf.reduce_sum(tf.square(tf.subtract(in1.values, '\n",
      " 'tf.gather_nd(in1.indices))))',\n",
      " 'return tf.reduce_sum(tf.square(tf.subtract(tf.cast(in1[0].values, '\n",
      " 'tf.float32), tf.gather_nd(in1[1], in1[0].indices))))',\n",
      " 'dense_in1 = tf.sparse.to_dense(in1[0], validate_indices=False)\\n'\n",
      " '     return tf.reduce_sum(tf.math.squared_difference(in1[1], dense_in1))',\n",
      " 'return tf.reduce_sum(tf.math.squared_difference(tf.sparse.to_dense(in1[0]), '\n",
      " 'in1[1]))',\n",
      " 'return tf.reduce_sum(tf.math.squared_difference(tf.sparse.to_dense(in1[0]), '\n",
      " 'in1[1]))',\n",
      " 'dense_tensor = tf.sparse.to_dense(in1)\\n'\n",
      " 'return tf.reduce_sum(tf.math.squared_difference(in1, dense_tensor))']\n",
      "\n",
      "Prompting for task: stackoverflow_32, description: weighted sum across rows, where the column index is the weight\n",
      "['return tf.reduce_sum(tf.multiply(in1, tf.range(tf.shape(in1)[1])), axis=1)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, tf.range(tf.cast(tf.shape(in1)[1], '\n",
      " 'tf.float32))), axis=1)',\n",
      " 'return tf.reduce_sum(in1 * tf.cast(tf.range(tf.shape(in1)[1]), tf.float32), '\n",
      " 'axis=1)',\n",
      " 'weights = tf.range(0, tf.shape(in1)[1], 1)\\n'\n",
      " 'in1_weighted = tf.multiply(in1, tf.cast(weights, tf.float32))\\n'\n",
      " 'return tf.reduce_sum(in1_weighted, axis=1)',\n",
      " 'return tf.reduce_sum(in1 * tf.range(tf.shape(in1)[-1], dtype=in1.dtype), '\n",
      " 'axis=1)',\n",
      " 'return tf.reduce_sum(in1 * tf.range(tf.shape(in1)[-1], dtype=in1.dtype), '\n",
      " 'axis=1)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, tf.range(tf.shape(in1)[1])), axis=1)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, tf.range(tf.shape(in1)[1], '\n",
      " 'dtype=tf.float32)), axis=1)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, tf.range(tf.shape(in1)[1])), axis=1)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, tf.range(tf.shape(in1)[1], '\n",
      " 'dtype=in1.dtype)), axis=1)']\n",
      "\n",
      "Prompting for task: stackoverflow_33, description: find the minimum distance between two sets of points\n",
      "['return tf.reduce_min(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, '\n",
      " '1), tf.expand_dims(in2, 0))), 2), 1)',\n",
      " 'return '\n",
      " 'tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, '\n",
      " 'axis=2), tf.expand_dims(in2, axis=1))), axis=-1)), axis=-1)',\n",
      " 'return '\n",
      " 'tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, '\n",
      " '1), in2)), axis=2)), axis=1)',\n",
      " 'distances = '\n",
      " 'tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.expand_dims(in1, axis=1) - '\n",
      " 'tf.expand_dims(in2, axis=0)), axis=2)), axis=1)\\n'\n",
      " '    return distances',\n",
      " 'distances = tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=1), '\n",
      " 'tf.expand_dims(in2, axis=0))), axis=2)\\n'\n",
      " ' return tf.sqrt(tf.reduce_min(distances, axis=1))',\n",
      " 'return tf.reduce_min(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, '\n",
      " '1), in2)), 2), 1)',\n",
      " 'distances = '\n",
      " 'tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, '\n",
      " 'axis=1), in2)), axis=2)), axis=1)\\n'\n",
      " ' return distances',\n",
      " 'expanded_in1 = tf.expand_dims(in1, 1)\\n'\n",
      " '    expanded_in2 = tf.expand_dims(in2, 0)\\n'\n",
      " '    return tf.reduce_min(tf.reduce_sum(tf.square(expanded_in1 - '\n",
      " 'expanded_in2), axis=2), axis=1)',\n",
      " 'distances = tf.reduce_sum(tf.square(tf.expand_dims(in1, axis=1) - '\n",
      " 'tf.expand_dims(in2, axis=0)), axis=2)\\n'\n",
      " ' return tf.reduce_min(distances, axis=1)',\n",
      " 'return tf.reduce_min(tf.reduce_sum(tf.square(tf.expand_dims(in1, axis=1) - '\n",
      " 'tf.expand_dims(in2, axis=0)), axis=2), axis=1)']\n",
      "\n",
      "Prompting for task: stackoverflow_34, description: compute a weighted sum of tensors\n",
      "['return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(tf.expand_dims(in2, 1), '\n",
      " '1)), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(in2, axis=-1)), axis=0)',\n",
      " 'return tf.tensordot(in1, in2, axes=0)',\n",
      " 'return tf.tensordot(in1, in2, axes=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(tf.cast(in2, '\n",
      " 'tf.float32), -1)), axis=0)',\n",
      " 'return tf.tensordot(tf.cast(in1, tf.int32), tf.cast(in2, tf.int32), axes=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, [-1, 1, 1])), axis=0)',\n",
      " 'return tf.tensordot(in1, in2, axes=[0])',\n",
      " 'return tf.tensordot(in1, in2, axes=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(tf.expand_dims(in2, '\n",
      " 'axis=-1), axis=-1)), axis=0)']\n",
      "\n",
      "Prompting for task: stackoverflow_35, description: linear interpolation between two tensors\n",
      "['return tf.add(tf.multiply(in1, tf.expand_dims(tf.expand_dims(1 - in3, 1), '\n",
      " '2)), tf.multiply(in2, tf.expand_dims(tf.expand_dims(in3, 1), 2)))',\n",
      " 'return tf.add(tf.multiply(tf.subtract(in2, in1), '\n",
      " 'tf.expand_dims(tf.expand_dims(in3, 1), 2)), in1)',\n",
      " 'return tf.add(tf.multiply(in1, tf.expand_dims(1 - in3, -1)), '\n",
      " 'tf.multiply(in2, tf.expand_dims(in3, -1)))',\n",
      " 'return tf.add(tf.multiply(in1, tf.reshape(1 - in3, (-1, 1, 1))), '\n",
      " 'tf.multiply(in2, tf.reshape(in3, (-1, 1, 1))))',\n",
      " 'return tf.add(tf.multiply(in1, '\n",
      " 'tf.expand_dims(tf.expand_dims(tf.subtract(tf.constant(1.0), in3), 1), 2)), '\n",
      " 'tf.multiply(in2, tf.expand_dims(tf.expand_dims(in3, 1), 2)))',\n",
      " 'return tf.add(tf.multiply(tf.expand_dims(in3, axis=[1,2]), tf.subtract(in2, '\n",
      " 'in1)), in1)',\n",
      " 'return tf.add(tf.multiply(in1, tf.reshape(1 - in3, [-1, 1, 1])), '\n",
      " 'tf.multiply(in2, tf.reshape(in3, [-1, 1, 1])))',\n",
      " 'return tf.add(tf.multiply(in1, tf.reshape(1. - in3, [in3.shape[0], 1, 1])), '\n",
      " 'tf.multiply(in2, tf.reshape(in3, [in3.shape[0], 1, 1])))',\n",
      " 'return tf.add(tf.multiply(in1, tf.subtract(1.0, '\n",
      " 'tf.expand_dims(tf.expand_dims(in3, 1), 2))), tf.multiply(in2, '\n",
      " 'tf.expand_dims(tf.expand_dims(in3, 1), 2)))',\n",
      " 'return tf.add(tf.multiply(in1, tf.expand_dims(tf.reshape(1. - in3, [-1, 1, '\n",
      " '1]), axis=-1)), tf.multiply(in2, tf.expand_dims(tf.reshape(in3, [-1, 1, 1]), '\n",
      " 'axis=-1)))']\n",
      "\n",
      "Prompting for task: stackoverflow_36, description: divide each element by the column index\n",
      "['return tf.divide(in1, tf.range(1, tf.shape(in1)[0]+1))',\n",
      " 'return tf.divide(in1, tf.range(1, tf.shape(in1)[0] + 1, dtype=tf.float32))',\n",
      " 'return tf.divide(in1, tf.range(1, tf.shape(in1)[0]+1, dtype=tf.float32))',\n",
      " 'return tf.divide(in1, tf.range(1, tf.shape(in1)[0] + 1, dtype=tf.float32))',\n",
      " 'return tf.divide(in1, tf.range(1, tf.shape(in1)[0] + 1, dtype=tf.float32))',\n",
      " 'return tf.divide(in1, tf.range(1, tf.size(in1)+1, dtype=tf.float32))',\n",
      " 'return tf.divide(in1, tf.range(1, tf.add(1, tf.shape(in1)[0]), '\n",
      " 'dtype=tf.float32))',\n",
      " 'return tf.divide(in1, tf.range(1, tf.size(in1) + 1))',\n",
      " 'return tf.divide(in1, tf.range(1, tf.size(in1) + 1))',\n",
      " 'return tf.divide(in1, tf.range(1, tf.size(in1) + 1))']\n",
      "\n",
      "Prompting for task: stackoverflow_37, description: dot product a vector with last dimension of a tensor\n",
      "['return tf.tensordot(in1, in2, axes=[[3], [0]])',\n",
      " 'return tf.tensordot(in1, tf.expand_dims(in2, 0), [[-1], [0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=[[-1], [0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=[[-1],[0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=[[-1], [0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=[[3], [0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=[[-1], [0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=[[-1],[0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=[[-1],[-1]])']\n",
      "\n",
      "Prompting for task: stackoverflow_38, description: compute the product of marked elements\n",
      "['return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)',\n",
      " 'return tf.reduce_prod(tf.reshape(tf.boolean_mask(in1, tf.concat(in2, '\n",
      " 'axis=0)), [tf.shape(in2)[0], -1]), axis=1)',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)']\n",
      "\n",
      "Prompting for task: stackoverflow_39, description: (\\'set to 0 the elements with absolute value less than 1, and square the other elements\\')\n",
      "['return tf.where(tf.greater_equal(tf.abs(in1), 1), tf.square(in1), 0)',\n",
      " 'return tf.where(tf.abs(in1) < 1, 0, tf.square(in1))',\n",
      " 'return tf.where(tf.abs(in1) < 1, 0, tf.square(in1))',\n",
      " 'return tf.where(tf.greater_equal(tf.abs(in1), 1), tf.square(in1), '\n",
      " 'tf.zeros_like(in1))',\n",
      " 'return tf.where(tf.abs(in1) < 1, 0, tf.square(in1))',\n",
      " 'return tf.where(tf.abs(in1) < 1, 0, tf.square(in1))',\n",
      " 'return tf.where(tf.abs(in1) < 1, tf.zeros_like(in1), tf.square(in1))',\n",
      " 'return tf.square(tf.where(tf.greater(tf.abs(in1), 1), in1, 0))',\n",
      " 'return tf.multiply(tf.where(tf.abs(in1) < 1, tf.zeros_like(in1), in1), '\n",
      " 'tf.where(tf.abs(in1) < 1, tf.ones_like(in1), in1))',\n",
      " 'return tf.square(tf.where(tf.abs(in1) < 1, tf.zeros_like(in1), in1))']\n",
      "\n",
      "Prompting for task: stackoverflow_40, description: use the output of tf.nn.top_k to make a sparse tensor\n",
      "['return tf.scatter_nd(in2, in1, [tf.reduce_max(in2[:, 0])+1, '\n",
      " 'tf.reduce_max(in2[:, 1])+1])',\n",
      " 'return tf.scatter_nd(in2, in1, [tf.reduce_max(in2, axis=0)[0]+1, '\n",
      " 'tf.reduce_max(in2, axis=0)[1]+1])',\n",
      " 'return tf.scatter_nd(in2, in1, [tf.reduce_max(in2[:, 0])+1, '\n",
      " 'tf.reduce_max(in2[:, 1])+1])',\n",
      " 'return tf.scatter_nd(in2, in1, tf.constant([3, 5]))',\n",
      " 'return tf.scatter_nd(tf.cast(in2, tf.int32), tf.cast(in1, tf.int32), [3, 5])',\n",
      " 'return tf.scatter_nd(in2, in1, [tf.reduce_max(in2[:, 0]) + 1, '\n",
      " 'tf.reduce_max(in2[:, 1]) + 1])',\n",
      " 'return tf.scatter_nd(in2, in1, [3,5])',\n",
      " 'return tf.scatter_nd(in2, tf.gather(in1, tf.argmin(in2, 1)), '\n",
      " '[tf.reduce_max(in2[:, 0])+1, tf.reduce_max(in2[:, 1])+1])',\n",
      " 'return tf.scatter_nd(in2, tf.math.top_k(in1, k=tf.shape(in1)[0]).values, '\n",
      " '[tf.shape(in1)[0],tf.reduce_max(in2)+1])',\n",
      " 'return tf.scatter_nd(in2, tf.gather(in1, in2[:, 1]), [tf.reduce_max(in2[:, '\n",
      " '0]) + 1, tf.reduce_max(in2[:, 1]) + 1])']\n",
      "\n",
      "Prompting for task: stackoverflow_41, description: copy all elements except at the given index\n",
      "['return tf.concat([in1[:in2], in1[in2+1:]], 0)',\n",
      " 'return tf.boolean_mask(in1, tf.not_equal(tf.range(tf.shape(in1)[0]), in2))',\n",
      " 'return tf.boolean_mask(in1, tf.not_equal(tf.range(tf.shape(in1)[0]), in2))',\n",
      " 'return tf.gather(in1, tf.concat([tf.range(in2), tf.range(in2+1, '\n",
      " 'tf.shape(in1)[0])], 0))',\n",
      " 'return tf.concat([in1[:in2], in1[in2+1:]], 0)',\n",
      " 'indices_to_keep = tf.range(tf.shape(in1)[0]) != in2\\n'\n",
      " 'return tf.boolean_mask(in1, indices_to_keep)',\n",
      " 'return tf.boolean_mask(in1, tf.not_equal(tf.range(tf.shape(in1)[0]), in2))',\n",
      " 'return tf.boolean_mask(in1, tf.not_equal(tf.range(tf.shape(in1)[0]), in2))',\n",
      " 'return tf.concat([in1[:in2], in1[in2+1:]],0)',\n",
      " 'return tf.concat([in1[:in2], in1[in2+1:]], 0)']\n",
      "\n",
      "Prompting for task: stackoverflow_42, description: create a binary vector where the max element is 1\n",
      "['return tf.cast(tf.equal(in1, tf.reduce_max(in1)), tf.int32)',\n",
      " 'max_value = tf.reduce_max(in1)\\n'\n",
      " 'return tf.cast(tf.equal(in1, max_value), tf.int32)',\n",
      " 'return tf.cast(tf.equal(in1, tf.reduce_max(in1)), tf.int32)',\n",
      " 'return tf.cast(tf.equal(in1, tf.reduce_max(in1)), tf.int32)',\n",
      " 'return tf.cast(tf.equal(in1, tf.reduce_max(in1)), tf.int32)',\n",
      " 'return tf.cast(tf.equal(in1, tf.reduce_max(in1)), tf.int32)',\n",
      " 'return tf.cast(tf.equal(in1, tf.reduce_max(in1)), tf.int32)',\n",
      " 'return tf.cast(tf.equal(in1, tf.reduce_max(in1)), tf.int32)',\n",
      " 'return tf.cast(tf.equal(in1, tf.reduce_max(in1)), tf.int32)',\n",
      " 'return tf.where(tf.equal(in1, tf.reduce_max(in1)), 1, 0)']\n",
      "\n",
      "Prompting for task: stackoverflow_43, description: extract elements of a tensor given row indices\n",
      "['return tf.gather_nd(in1, tf.transpose(tf.stack([in2, '\n",
      " 'tf.range(tf.shape(in2)[0])])))',\n",
      " 'return tf.gather_nd(in1, tf.transpose(tf.stack([in2, '\n",
      " 'tf.range(tf.shape(in2)[0])]))).numpy()',\n",
      " 'return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], '\n",
      " 'axis=1))',\n",
      " 'return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in1)[1]), in2], '\n",
      " 'axis=1))',\n",
      " 'return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], '\n",
      " 'axis=1))',\n",
      " 'return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], '\n",
      " 'axis=1))',\n",
      " 'return tf.gather_nd(in1, tf.transpose(tf.stack([in2, '\n",
      " 'tf.range(tf.shape(in2)[0])])))',\n",
      " 'return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], '\n",
      " 'axis=1))',\n",
      " 'return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], '\n",
      " 'axis=1))',\n",
      " 'return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], '\n",
      " 'axis=1))']\n",
      "\n",
      "Prompting for task: stackoverflow_44, description: sum across columns for pairs of consecutive rows\n",
      "['return tf.reshape(tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), '\n",
      " 'axis=1), (-1, in1.shape[1]))',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, [-1, 2, tf.shape(in1)[1]]), axis=1)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, (-1, 2, 3)), axis=1)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, [-1, 2, 3]), axis=1)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)']\n",
      "\n",
      "Prompting for task: stackoverflow_45, description: reverse the order in the marked rows\n",
      "['return tf.where(tf.equal(in2, 1), tf.reverse(in1, axis=[2]), in1)',\n",
      " 'return tf.where(tf.cast(tf.expand_dims(in2, axis=-1), tf.bool), \\n'\n",
      " '                tf.reverse(in1, [-1]), in1)',\n",
      " 'return tf.where(tf.expand_dims(in2, axis=-1), tf.reverse(in1, axis=[1]), '\n",
      " 'in1)',\n",
      " 'return tf.where(tf.expand_dims(in2, -1), tf.reverse(in1, axis=[2]), in1)',\n",
      " 'return tf.where(tf.expand_dims(tf.cast(in2, tf.bool), -1), tf.reverse(in1, '\n",
      " 'axis=[-1]), in1)',\n",
      " 'return tf.where(tf.cast(in2, tf.bool), tf.reverse(in1, [-1]), in1)',\n",
      " 'return tf.where(tf.cast(in2, tf.bool), in1[:, ::-1], in1)',\n",
      " 'return tf.where(tf.reshape(tf.cast(in2, tf.bool),(-1, 1)), tf.reverse(in1, '\n",
      " '[2]), in1)',\n",
      " 'return tf.where(tf.expand_dims(in2, -1), tf.reverse(in1, axis=[2]), in1)',\n",
      " 'return tf.where(tf.equal(in2, 1), in1[:,:,::-1], in1)']\n",
      "\n",
      "Prompting for task: stackoverflow_46, description: convert segment lengths to segment ids\n",
      "['return tf.repeat(tf.range(tf.shape(in1)[0]), in1)',\n",
      " 'return tf.repeat(tf.range(len(in1)), in1)',\n",
      " 'return tf.repeat(tf.range(tf.shape(in1)[0]), in1)',\n",
      " 'return tf.repeat(tf.range(tf.shape(in1)[0]), in1)',\n",
      " 'return tf.repeat(tf.range(len(in1)), in1)',\n",
      " 'return tf.repeat(tf.range(tf.shape(in1)[0]), in1)',\n",
      " 'return tf.repeat(tf.range(tf.shape(in1)[0]), in1)',\n",
      " 'return tf.repeat(tf.range(tf.shape(in1)[0]), in1)',\n",
      " 'return tf.repeat(tf.range(tf.shape(in1)[0]), in1)',\n",
      " 'return tf.repeat(tf.range(tf.shape(in1)[0]), in1)']\n",
      "\n",
      "Prompting for task: stackoverflow_47, description: put given values into a sequence mask\n",
      "['masks = tf.cast(in2, tf.int32)\\n'\n",
      " 'indices = tf.cumsum(masks, axis=1, exclusive=True)\\n'\n",
      " 'return tf.reshape(tf.gather(in1, indices), tf.shape(in2))',\n",
      " 'return tf.reshape(tf.boolean_mask(in1, tf.reshape(in2, [-1])), '\n",
      " 'tf.shape(in2))',\n",
      " 'indices = tf.where(in2)\\n'\n",
      " ' updates = tf.gather(in1, tf.range(tf.reduce_sum(tf.cast(in2, tf.int32))))\\n'\n",
      " ' return tf.scatter_nd(indices, updates, tf.shape(in2))',\n",
      " 'return tf.scatter_nd(tf.where(in2), in1[:tf.math.count_nonzero(in2)], '\n",
      " 'tf.shape(in2))',\n",
      " 'return tf.boolean_mask(in1, tf.cast(tf.reshape(in2, [-1]), tf.bool), axis=0)',\n",
      " 'shape = tf.shape(in2)\\n'\n",
      " 'in1 = tf.reshape(in1[:tf.reduce_sum(shape)], shape)\\n'\n",
      " 'result = tf.where(in2,in1,0)\\n'\n",
      " 'return result',\n",
      " 'mask = tf.cast(in2, tf.int32)\\n'\n",
      " 'idx = tf.reshape(tf.where(mask), [-1])\\n'\n",
      " 'val = tf.gather(in1, idx)\\n'\n",
      " 'padding = tf.fill(tf.shape(in2), 0)\\n'\n",
      " 'out = tf.where(mask, val, padding)\\n'\n",
      " 'return out',\n",
      " 'result = tf.zeros_like(in2, dtype=tf.int32)\\n'\n",
      " 'counter = tf.constant([0])\\n'\n",
      " 'for i in range(in2.shape[0]):\\n'\n",
      " '    for j in range(in2.shape[1]):\\n'\n",
      " '        if in2[i][j]:\\n'\n",
      " '            result[i,j].assign(in1[counter])\\n'\n",
      " '            counter += 1\\n'\n",
      " 'return result',\n",
      " 'return tf.reshape(tf.boolean_mask(in1, tf.cast(tf.reshape(in2, [-1]), '\n",
      " 'tf.bool)), tf.shape(in2))',\n",
      " 'mask = tf.cast(in2, tf.int32)\\n'\n",
      " 'indices = tf.repeat(tf.range(tf.shape(mask)[1]), tf.reduce_sum(mask, '\n",
      " 'axis=0))\\n'\n",
      " 'updates = tf.boolean_mask(in1, tf.reshape(mask, [-1]))\\n'\n",
      " 'shape = tf.shape(mask)\\n'\n",
      " 'return tf.scatter_nd(tf.expand_dims(indices, axis=-1), updates, shape)']\n",
      "\n",
      "Prompting for task: stackoverflow_48, description: find the indices of all elements\n",
      "['return tf.cast(tf.squeeze([tf.where(tf.equal(in1, i)) for i in in2]), '\n",
      " 'tf.int32)',\n",
      " 'return tf.cast(tf.argsort(tf.searchsorted(in1, in2)), tf.int32)',\n",
      " 'return tf.cast(tf.squeeze([tf.where(tf.equal(in1, x)) for x in in2]), '\n",
      " 'tf.int32)',\n",
      " 'return tf.cast(tf.squeeze([tf.where(tf.equal(in1, i)) for i in in2]), '\n",
      " 'tf.int32)',\n",
      " 'return tf.cast(tf.squeeze(tf.where(tf.equal(tf.expand_dims(in1, 1), in2))), '\n",
      " 'tf.int32)',\n",
      " 'return tf.cast(tf.concat([tf.where(tf.equal(in1, n)) for n in in2], axis=0), '\n",
      " 'tf.int32)[:, 0]',\n",
      " 'return tf.cast(tf.gather(tf.argsort(in1), tf.searchsorted(tf.sort(in1), '\n",
      " 'in2)), tf.int32)',\n",
      " 'return tf.cast(tf.map_fn(lambda x: tf.where(tf.equal(in1, x))[0][0], in2), '\n",
      " 'tf.int32)',\n",
      " 'return tf.cast(tf.searchsorted(tf.sort(in1), in2), tf.int32)',\n",
      " 'return tf.cast(tf.where(tf.equal(tf.expand_dims(in1, 1), tf.expand_dims(in2, '\n",
      " '0))), tf.int32)[:,1]']\n",
      "\n",
      "Prompting for task: stackoverflow_49, description: multiply tensors by scalars in a batched way\n",
      "['return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))',\n",
      " 'return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(tf.expand_dims(tf.expand_dims(in2, '\n",
      " '1), 1), 1))',\n",
      " 'return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(tf.expand_dims(in2, 1), 1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(tf.expand_dims(in2, -1), -1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(tf.expand_dims(tf.cast(in2, '\n",
      " 'tf.float32), 1), 2))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(tf.expand_dims(tf.cast(in2, '\n",
      " 'tf.float32), -1), -1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(tf.expand_dims(tf.cast(in2, '\n",
      " 'tf.float32), axis=-1), axis=-1))',\n",
      " 'return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))']\n",
      "\n",
      "Prompting for task: stackoverflow_50, description: create a binary matrix where a specified column is set to one\n",
      "['return tf.pad(tf.reshape(tf.one_hot(in1, 2*in1+1, dtype=tf.int32), (1, -1)), '\n",
      " '[[in1-1, in1-1], [0, 0]])',\n",
      " 'return tf.one_hot(in1, 2*in1, axis=1)',\n",
      " 'return tf.one_hot(in1, depth=in1*2, axis=1)',\n",
      " 'return tf.scatter_nd([[i, in1] for i in range(in1+1)], tf.ones(in1+1, '\n",
      " 'dtype=tf.int32), [in1+1, in1+1])',\n",
      " 'return tf.scatter_nd([[in1]], [1], [6, 6])',\n",
      " 'return tf.one_hot(in1, 2*in1 + 1)[:, 3]',\n",
      " 'return tf.one_hot(in1, in1*2)[:, in1]',\n",
      " 'return tf.one_hot(in1, 2 * in1 + 1)[:, in1]',\n",
      " 'return tf.pad(tf.expand_dims(tf.eye(in1, in1+1)[:, 3],-1), '\n",
      " '[[0,0],[0,0],[0,in1-1]])[:,:,0]',\n",
      " 'return tf.one_hot(in1, 2 * in1 + 1, dtype=tf.int32)[:, in1]']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_COMPLETIONS = 10\n",
    "i = 0\n",
    "for task_name, task in TASK_JSONS.items():\n",
    "    if \"completions\" in task:\n",
    "        continue \n",
    "    print(f\"Prompting for task: {task['name']}, description: {task['description']}\")\n",
    "    completions = prompt(SYSTEM_PROMPT, make_user_message(task, shuffle_operators=False, order_by_weight=True), NUM_COMPLETIONS)\n",
    "    task[\"completions\"] = completions\n",
    "    pprint(completions)\n",
    "    print()\n",
    "    # i += 1\n",
    "    # if i > 10:\n",
    "    #     break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS_WITH_COMPLETIONS_FILE = CURRENT_DIRECTORY / \"tfcoder_dataset_with_completions.json\"\n",
    "for name, task in TASK_JSONS.items():\n",
    "    if \"parsed_examples\" in task:\n",
    "        del task[\"parsed_examples\"]\n",
    "TASKS_WITH_COMPLETIONS_FILE.write_text(json.dumps(DATASET, indent=4))\n",
    "for name, task in TASK_JSONS.items():\n",
    "    task[\"parsed_examples\"] = Example.from_json(task[\"examples\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract tf operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tf_operators(code_snippet):\n",
    "    pattern = r\"tf\\.[a-zA-Z_][a-zA-Z0-9_]*(?:\\.[a-zA-Z_][a-zA-Z0-9_]*)*\"\n",
    "    return set(re.findall(pattern, code_snippet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tf_operator_coverage_and_count(target_operators, completion_operators):\n",
    "    \"\"\"Extend to include all completion operators and mark those used in the target program.\"\"\"\n",
    "    completion_operators_count = Counter(completion_operators)\n",
    "    tf_operators_dict = {op: completion_operators_count[op] for op in completion_operators_count}\n",
    "\n",
    "    # Calculate coverage based on target program operators found in completions\n",
    "    covered_operators = set(target_operators).intersection(completion_operators)\n",
    "    coverage_percentage = len(covered_operators) / len(target_operators) * 100 if target_operators else 0\n",
    "\n",
    "    return {\n",
    "        \"tf_operators\": tf_operators_dict,\n",
    "        \"coverage_percentage\": coverage_percentage,\n",
    "        \"total_in_target\": len(target_operators),\n",
    "        \"total_covered\": len(covered_operators)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, task in TASK_JSONS.items():\n",
    "    if \"completions\" not in task:\n",
    "        continue\n",
    "    completions = task[\"completions\"]\n",
    "    completion_tf_operators = [op for completion in completions for op in extract_tf_operators(completion)]\n",
    "    target_program = task[\"target_program\"]\n",
    "    target_tf_operators = extract_tf_operators(target_program)\n",
    "    tf_operator_info = calculate_tf_operator_coverage_and_count(target_tf_operators, completion_tf_operators)\n",
    "\n",
    "    task[\"response\"] = {\n",
    "        \"task_id\": task.get(\"name\", \"unknown\"),\n",
    "        \"completions\": completions,\n",
    "        \"target-program\": task[\"target_program\"],\n",
    "        \"description\": task[\"description\"],\n",
    "        **tf_operator_info  # Includes adjusted tf_operators dictionary\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS_WITH_COMPLETIONS_FILE = CURRENT_DIRECTORY / \"tfcoder_dataset_with_completions.json\"\n",
    "for name, task in TASK_JSONS.items():\n",
    "    if \"parsed_examples\" in task:\n",
    "        del task[\"parsed_examples\"]\n",
    "TASKS_WITH_COMPLETIONS_FILE.write_text(json.dumps(DATASET, indent=4))\n",
    "for name, task in TASK_JSONS.items():\n",
    "    task[\"parsed_examples\"] = Example.from_json(task[\"examples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVERAGE_PERCENTAGES = [task[\"response\"][\"coverage_percentage\"] for task in list(TASK_JSONS.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.30434782608695"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average coverage percentage\n",
    "sum(COVERAGE_PERCENTAGES) / len(COVERAGE_PERCENTAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# median coverage percentage\n",
    "sorted_coverage_percentages = sorted(COVERAGE_PERCENTAGES)\n",
    "median_index = len(sorted_coverage_percentages) // 2\n",
    "sorted_coverage_percentages[median_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.95833333333334"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLD_OUTPUT_FILE = CURRENT_DIRECTORY / \"output_tfcoder.old.json\"\n",
    "OLD_OUTPUT_JSON = json.loads(OLD_OUTPUT_FILE.read_text())\n",
    "\n",
    "OLD_COVERAGE_PERCENTAGES = [task[\"coverage_percentage\"] for task in OLD_OUTPUT_JSON]\n",
    "sum(OLD_COVERAGE_PERCENTAGES) / len(OLD_COVERAGE_PERCENTAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# median coverage percentage\n",
    "sorted_old_coverage_percentages = sorted(OLD_COVERAGE_PERCENTAGES)\n",
    "median_index = len(sorted_old_coverage_percentages) // 2\n",
    "sorted_old_coverage_percentages[median_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
