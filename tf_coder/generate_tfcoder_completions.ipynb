{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/ubuntu/arga-arc/tf_coder\n",
      "Root directory: /home/ubuntu/arga-arc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "CURRENT_DIRECTORY = Path(os.getcwd())\n",
    "ROOT_DIRECTORY = (CURRENT_DIRECTORY / \"..\").absolute().resolve()\n",
    "\n",
    "print(f\"Current directory: {CURRENT_DIRECTORY}\")\n",
    "print(f\"Root directory: {ROOT_DIRECTORY}\")\n",
    "\n",
    "sys.path.append(str(ROOT_DIRECTORY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['OPENAI_SECRET_KEY', 'OPENAI_ORGANIZATION'])\n"
     ]
    }
   ],
   "source": [
    "import typing as t\n",
    "import json\n",
    "from pprint import pprint\n",
    "from dataclasses import dataclass\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from config import CONFIG\n",
    "from openai import OpenAI\n",
    "import re\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "pprint(CONFIG.__dict__.keys())\n",
    "\n",
    "OPENAI = OpenAI(api_key=CONFIG.OPENAI_SECRET_KEY, organization=CONFIG.OPENAI_ORGANIZATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parsing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 72 tasks from /home/ubuntu/arga-arc/tf_coder/tfcoder_dataset.json\n",
      "dict_keys(['google_01', 'google_02', 'google_03', 'google_04', 'google_05', 'google_06', 'google_07', 'google_08', 'google_09', 'google_10', 'google_11', 'google_12', 'google_13', 'google_14', 'google_15', 'google_16', 'google_17', 'google_18', 'google_19', 'google_20', 'google_21', 'google_22', 'stackoverflow_01', 'stackoverflow_02', 'stackoverflow_03', 'stackoverflow_04', 'stackoverflow_05', 'stackoverflow_06', 'stackoverflow_07', 'stackoverflow_08', 'stackoverflow_09', 'stackoverflow_10', 'stackoverflow_11', 'stackoverflow_12', 'stackoverflow_13', 'stackoverflow_14', 'stackoverflow_15', 'stackoverflow_16', 'stackoverflow_17', 'stackoverflow_18', 'stackoverflow_19', 'stackoverflow_20', 'stackoverflow_21', 'stackoverflow_22', 'stackoverflow_23', 'stackoverflow_24', 'stackoverflow_25', 'stackoverflow_26', 'stackoverflow_27', 'stackoverflow_28', 'stackoverflow_29', 'stackoverflow_30', 'stackoverflow_31', 'stackoverflow_32', 'stackoverflow_33', 'stackoverflow_34', 'stackoverflow_35', 'stackoverflow_36', 'stackoverflow_37', 'stackoverflow_38', 'stackoverflow_39', 'stackoverflow_40', 'stackoverflow_41', 'stackoverflow_42', 'stackoverflow_43', 'stackoverflow_44', 'stackoverflow_45', 'stackoverflow_46', 'stackoverflow_47', 'stackoverflow_48', 'stackoverflow_49', 'stackoverflow_50'])\n"
     ]
    }
   ],
   "source": [
    "class OutputJSON(t.TypedDict):\n",
    "    task_id: str\n",
    "    completions: t.List[str]\n",
    "    coverage_percentage: float\n",
    "    description: str\n",
    "    tf_operators: t.Dict[str, int]\n",
    "    total_covered: int\n",
    "    total_in_target: int\n",
    "\n",
    "class ExamplesJSON(t.TypedDict):\n",
    "    inputs: str\n",
    "    outputs: str\n",
    "\n",
    "class TaskJSON(t.TypedDict):\n",
    "    constants: str\n",
    "    description: str\n",
    "    name: str\n",
    "    source: str\n",
    "    target_program: str\n",
    "    examples: ExamplesJSON\n",
    "\n",
    "DATASET_FILE = CURRENT_DIRECTORY / \"tfcoder_dataset.json\"\n",
    "DATASET: t.List[TaskJSON] = json.loads(DATASET_FILE.read_text())\n",
    "\n",
    "print(f\"Loaded {len(DATASET)} tasks from {DATASET_FILE}\")\n",
    "\n",
    "TASK_JSONS = {task[\"name\"] : task for task in DATASET}\n",
    "pprint(TASK_JSONS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'completions': ['tf.sparse.slice(input_1, start=[0,0,0], size=[1,-1,-1])',\n",
      "                 'tf.sparse.slice(input_1, [0,0,0], [1,-1,-1])',\n",
      "                 'tf.sparse.slice(input_1, tf.constant([0, 0, 0], '\n",
      "                 'dtype=tf.int64), tf.constant([1, -1, -1], dtype=tf.int64))',\n",
      "                 'tf.sparse.slice(input_1, [0,0,0], [1,-1,-1])',\n",
      "                 'tf.sparse.slice(input_1, [0, 0, 0], [1, -1, -1])',\n",
      "                 'tf.sparse.slice(input_1, [0, 0, 0], [1, -1, -1])',\n",
      "                 'tf.sparse.slice(input_1, [0, 0, 0], [1, -1, -1])',\n",
      "                 'tf.sparse.slice(input_1, [0, 0, 0], [1, -1, -1])',\n",
      "                 'tf.sparse.slice(input_1, [0, 0, 0], [1, -1, -1])',\n",
      "                 'tf.sparse.slice(input_1, [0, 0, 0], [1, -1, -1])'],\n",
      " 'constants': '[]',\n",
      " 'description': 'Slice the first dimension of a SparseTensor',\n",
      " 'examples': {'inputs': 'tf.SparseTensor(indices=[[0, 0, 0], [0, 1, 1], [1, 1, '\n",
      "                        '1], [1, 1, 2]], values=[1., 1., 1., 1.], '\n",
      "                        'dense_shape=[2, 2, 800])',\n",
      "              'outputs': 'tf.SparseTensor(indices=[[0, 0, 0], [0, 1, 1]], '\n",
      "                         'values=[1., 1.], dense_shape=[1, 2, 800])'},\n",
      " 'name': 'google_03',\n",
      " 'parsed_examples': Example(inputs=[SparseTensor(indices=tf.Tensor(\n",
      "[[0 0 0]\n",
      " [0 1 1]\n",
      " [1 1 1]\n",
      " [1 1 2]], shape=(4, 3), dtype=int64), values=tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32), dense_shape=tf.Tensor([  2   2 800], shape=(3,), dtype=int64))],\n",
      "                            output=SparseTensor(indices=tf.Tensor(\n",
      "[[0 0 0]\n",
      " [0 1 1]], shape=(2, 3), dtype=int64), values=tf.Tensor([1. 1.], shape=(2,), dtype=float32), dense_shape=tf.Tensor([  1   2 800], shape=(3,), dtype=int64))),\n",
      " 'source': 'Real task encountered by Googler, 11/01/2018',\n",
      " 'target_program': 'tf.divide(in1, tf.expand_dims(tf.reduce_sum(in1, axis=1), '\n",
      "                   '1))'}\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Example:\n",
    "    inputs: t.List[np.ndarray]\n",
    "    output: t.Union[np.ndarray, tf.SparseTensor]\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, examples: ExamplesJSON):\n",
    "        try:\n",
    "            evaluated_inputs = eval(examples[\"inputs\"])\n",
    "            if isinstance(evaluated_inputs, list):\n",
    "                inputs = [np.array(i) for i in evaluated_inputs]\n",
    "            else:\n",
    "                inputs = [evaluated_inputs]\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating inputs: {e}\")\n",
    "            print(f\"Inputs: {examples['inputs']}\")\n",
    "            raise e\n",
    "\n",
    "        try:\n",
    "            evaluated_outputs = eval(examples[\"outputs\"])\n",
    "            if isinstance(evaluated_outputs, list):\n",
    "                outputs = np.array(evaluated_outputs)\n",
    "            elif isinstance(evaluated_outputs, tf.SparseTensor):\n",
    "                outputs = evaluated_outputs\n",
    "            elif isinstance(evaluated_outputs, tf.Tensor):\n",
    "                outputs = evaluated_outputs.numpy()\n",
    "            else:\n",
    "                outputs = evaluated_outputs\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating outputs: {e}\")\n",
    "            print(f\"Outputs: {examples['outputs']}\")\n",
    "            raise e\n",
    "\n",
    "        return cls(inputs, outputs)\n",
    "    \n",
    "    def toJSON(self):\n",
    "        return {\n",
    "            \"inputs\": [i.tolist() for i in self.inputs],\n",
    "            \"output\": self.output.tolist()\n",
    "        }\n",
    "\n",
    "for name, task in TASK_JSONS.items():\n",
    "    task[\"parsed_examples\"] = Example.from_json(task[\"examples\"])\n",
    "\n",
    "pprint(TASK_JSONS[\"google_03\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFOPERATORS_STR = \"tf.abs(x)\\ntf.add(x, y)\\ntf.add_n(inputs)\\ntf.argmax(input, axis)\\ntf.argmin(input, axis)\\n\"+\\\n",
    "\"tf.argsort(values, axis, stable=True)\\ntf.argsort(values, axis, direction='DESCENDING', stable=True)\\ntf.boolean_mask(tensor, mask)\\ntf.broadcast_to(input, shape)\\n\"+\\\n",
    "\"tf.cast(x, dtype)\\ntf.clip_by_value(t, clip_value_min, clip_value_max)\\ntf.concat(values, axis)\\ntf.constant(value)\\ntf.constant(value, dtype)\\ntf.divide(x, y)\\n\"+\\\n",
    "\"tf.equal(x, y)\\ntf.exp(x)\\ntf.expand_dims(input, axis)\\ntf.eye(num_rows)\\ntf.eye(num_rows, num_columns)\\ntf.eye(num_rows, dtype)\\ntf.fill(dims, value)\"+\\\n",
    "\"tf.gather(params, indices)\\ntf.gather(params, indices, axis, batch_dims)\\ntf.gather_nd(params, indices)\\ntf.gather_nd(params, indices, batch_dims)\\ntf.greater(x, y)\\n\"+\\\n",
    "\"tf.greater_equal(x, y)\\ntf.math.bincount(arr)\\ntf.math.ceil(x)\\ntf.math.count_nonzero(input)\\ntf.math.count_nonzero(input, axis)\\ntf.math.cumsum(x, axis)\\n\"+\\\n",
    "\"tf.math.cumsum(x, axis, exclusive=True)\\ntf.math.divide_no_nan(x, y)\\ntf.math.floor(x)\\ntf.math.log(x)\\ntf.math.logical_and(x, y)\\ntf.math.logical_not(x)\"+\\\n",
    "\"tf.math.logical_or(x, y)\\ntf.math.logical_xor(x, y)\\ntf.math.negative(x)\\ntf.math.reciprocal(x)\\ntf.math.reciprocal_no_nan(x)\\ntf.math.segment_max(data, segment_ids)\\n\"+\\\n",
    "\"tf.math.segment_mean(data, segment_ids)\\ntf.math.segment_min(data, segment_ids)\\ntf.math.segment_prod(data, segment_ids)\\ntf.math.segment_sum(data, segment_ids)\\n\"+\\\n",
    "\"tf.math.squared_difference(x, y)\\ntf.math.top_k(input, k)\\ntf.math.unsorted_segment_max(data, segment_ids, num_segments)\\ntf.math.unsorted_segment_mean(data, segment_ids, num_segments)\\n\"+\\\n",
    "\"tf.math.unsorted_segment_min(data, segment_ids, num_segments)\\ntf.math.unsorted_segment_prod(data, segment_ids, num_segments)\\ntf.math.unsorted_segment_sum(data, segment_ids, num_segments)\\n\"+\\\n",
    "\"tf.matmul(a, b)\\ntf.maximum(x, y)\\ntf.minimum(x, y)\\ntf.multiply(x, y)\\ntf.not_equal(x, y)\\ntf.one_hot(indices, depth)\\ntf.ones(shape)\\ntf.ones_like(input)\\n\"+\\\n",
    "\"tf.pad(tensor, paddings, mode='CONSTANT')\\ntf.pad(tensor, paddings, mode='CONSTANT', constant_values)\\ntf.pad(tensor, paddings, mode='REFLECT')\\n\"+\\\n",
    "\"tf.pad(tensor, paddings, mode='SYMMETRIC')\\ntf.range(start)\\ntf.range(start, limit, delta)\\ntf.reduce_any(input_tensor, axis)\\ntf.reduce_all(input_tensor, axis)\\n\"+\\\n",
    "\"tf.reduce_max(input_tensor)\\ntf.reduce_max(input_tensor, axis)\\ntf.reduce_mean(input_tensor)\\n\"+\\\n",
    "\"tf.reduce_mean(input_tensor, axis)\\ntf.reduce_min(input_tensor)\\ntf.reduce_min(input_tensor, axis)\\n\"+\\\n",
    "\"tf.reduce_prod(input_tensor, axis)\\ntf.reduce_sum(input_tensor)\\ntf.reduce_sum(input_tensor, axis)\\n\"+\\\n",
    "\"tf.repeat(input, repeats)\\ntf.repeat(input, repeats, axis)\\ntf.reshape(tensor, shape)\\n\"+\\\n",
    "\"tf.reverse(tensor, axis)\\ntf.roll(input, shift, axis)\\ntf.round(x)\\ntf.scatter_nd(indices, updates, shape)\\n\"+\\\n",
    "\"tf.searchsorted(sorted_sequence, values, side='left')\\ntf.searchsorted(sorted_sequence, values, side='right')\\n\"+\\\n",
    "\"tf.sequence_mask(lengths)\\ntf.sequence_mask(lengths, maxlen)\\ntf.shape(input)\\ntf.sign(x)\\n\"+\\\n",
    "\"tf.sort(values, axis)\\ntf.sort(values, axis, direction='DESCENDING')\\ntf.sqrt(x)\\n\"+\\\n",
    "\"tf.square(x)\\ntf.squeeze(input)\\ntf.squeeze(input, axis)\\ntf.stack(values, axis)\\ntf.subtract(x, y)\\n\"+\\\n",
    "\"tf.tensor_scatter_nd_update(tensor, indices, updates)\\ntf.tensordot(a, b, axes)\\ntf.tile(input, multiples)\\n\"+\\\n",
    "\"tf.transpose(a)\\ntf.transpose(a, perm)\\ntf.unique_with_counts(x)\\ntf.unstack(value, axis)\\n\"+\\\n",
    "\"tf.where(condition)\\ntf.where(condition, x, y)\\ntf.zeros(shape)\\ntf.zeros_like(input)\"\n",
    "SPARSETF_OPERATORS_STR = \"tf.SparseTensor(indices, values, dense_shape)\\ntf.sparse.add(a, b)\\n\"+\\\n",
    "\"tf.sparse.concat(axis, sp_inputs)\\ntf.sparse.expand_dims(sp_input, axis)\\ntf.sparse.from_dense(tensor)\\ntf.sparse.maximum(sp_a, sp_b)\\n\"+\\\n",
    "\"tf.sparse.minimum(sp_a, sp_b)\\ntf.sparse.reduce_max(sp_input, axis, output_is_sparse)\\ntf.sparse.reduce_sum(sp_input, axis, output_is_sparse)\\n\"+\\\n",
    "\"tf.sparse.reset_shape(sp_input)\\ntf.sparse.reshape(sp_input, shape)\\ntf.sparse.retain(sp_input, to_retain)\\ntf.sparse.slice(sp_input, start, size)\\n\"+\\\n",
    "\"tf.sparse.split(sp_input, num_split, axis)\\ntf.sparse.to_dense(sp_input)\\ntf.sparse.to_dense(sp_input, default_value)\\n\"+\\\n",
    "\"tf.sparse.to_indicator(sp_input, vocab_size)\\ntf.sparse.transpose(sp_input)\\ntf.sparse.transpose(sp_input, perm)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Operators: 111, ['tf.abs(x)', 'tf.add(x, y)', 'tf.add_n(inputs)', 'tf.argmax(input, axis)', 'tf.argmin(input, axis)']\n",
      "SparseTF Operators: 19, ['tf.SparseTensor(indices, values, dense_shape)', 'tf.sparse.add(a, b)', 'tf.sparse.concat(axis, sp_inputs)', 'tf.sparse.expand_dims(sp_input, axis)', 'tf.sparse.from_dense(tensor)']\n"
     ]
    }
   ],
   "source": [
    "TFOPERATORS = [op.strip() for op in TFOPERATORS_STR.split(\"\\n\") if op.strip() != \"\"]\n",
    "\n",
    "SPARSETF_OPERATORS = [op.strip() for op in SPARSETF_OPERATORS_STR.split(\"\\n\") if op.strip() != \"\"]\n",
    "\n",
    "print(f\"TF Operators: {len(TFOPERATORS)}, {TFOPERATORS[:5]}\")\n",
    "print(f\"SparseTF Operators: {len(SPARSETF_OPERATORS)}, {SPARSETF_OPERATORS[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_operators_section(shuffle = True, include_sparse = True) -> str:\n",
    "    shuffled_tf = TFOPERATORS.copy()\n",
    "    shuffled_sparse = SPARSETF_OPERATORS.copy()\n",
    "    if shuffle:\n",
    "        random.shuffle(shuffled_tf)\n",
    "        random.shuffle(shuffled_sparse)\n",
    "    \n",
    "    tf_str = \"\\n\".join(shuffled_tf)\n",
    "    sparse_str = \"\\n\".join(shuffled_sparse)\n",
    "\n",
    "    ans = f\"[TENSORFLOW OPERATORS]\\n{tf_str}\\n\"\n",
    "    if include_sparse:\n",
    "        ans += f\"\\n[SPARSE TENSORFLOW OPERATORS]\\n{sparse_str}\"\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a coding assistant. Be precise and terse.\n",
    "You will be provided a list of tensorflow operators, a task description, and some input/output examples.\n",
    "Your task is to generate the body of a python function that will transform the input to the output.\n",
    "Only use the operators provided in the list.\n",
    "\"\"\"\n",
    "\n",
    "def make_user_message(task, shuffle_operators = True):\n",
    "    parsed_examples: Example = task['parsed_examples']\n",
    "    examples_str = \"Inputs:\\n\"\n",
    "    for inp in parsed_examples.inputs:\n",
    "        examples_str += f\"{inp}\\n\"\n",
    "    examples_str += \"Output:\\n\"\n",
    "    examples_str += f\"{parsed_examples.output}\\n\"\n",
    "\n",
    "    formals_str = [f\"in{i+1}\" for i in range(len(parsed_examples.inputs))]\n",
    "\n",
    "    include_sparse = any(isinstance(i, tf.SparseTensor) for i in parsed_examples.inputs) or isinstance(parsed_examples.output, tf.SparseTensor)\n",
    "\n",
    "    return f\"\"\"{make_operators_section(shuffle_operators, include_sparse)}\n",
    "\n",
    "[TASK DESCRIPTION]\n",
    "{task['description']}\n",
    "\n",
    "[EXAMPLES]\n",
    "{examples_str}\n",
    "\n",
    "[PROGRAM]\n",
    "def transform({\",\".join(formals_str)}):\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(system_message: str, user_message: str, n_completions: int) -> t.List[str]:\n",
    "    response = OPENAI.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_message},\n",
    "        ],\n",
    "        n=n_completions,\n",
    "        temperature=1.0,\n",
    "    )\n",
    "    return [choice.message.content for choice in response.choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[TENSORFLOW OPERATORS]\\n'\n",
      " 'tf.math.negative(x)\\n'\n",
      " 'tf.boolean_mask(tensor, mask)\\n'\n",
      " 'tf.maximum(x, y)\\n'\n",
      " 'tf.math.segment_mean(data, segment_ids)\\n'\n",
      " 'tf.not_equal(x, y)\\n'\n",
      " 'tf.math.logical_and(x, y)\\n'\n",
      " 'tf.sequence_mask(lengths)\\n'\n",
      " 'tf.constant(value)\\n'\n",
      " 'tf.gather_nd(params, indices)\\n'\n",
      " 'tf.math.unsorted_segment_mean(data, segment_ids, num_segments)\\n'\n",
      " 'tf.math.cumsum(x, axis, exclusive=True)\\n'\n",
      " 'tf.math.count_nonzero(input, axis)\\n'\n",
      " 'tf.math.count_nonzero(input)\\n'\n",
      " 'tf.math.cumsum(x, axis)\\n'\n",
      " 'tf.cast(x, dtype)\\n'\n",
      " 'tf.reduce_max(input_tensor)\\n'\n",
      " 'tf.reduce_mean(input_tensor, axis)\\n'\n",
      " 'tf.shape(input)\\n'\n",
      " 'tf.square(x)\\n'\n",
      " 'tf.tile(input, multiples)\\n'\n",
      " 'tf.where(condition, x, y)\\n'\n",
      " 'tf.add(x, y)\\n'\n",
      " 'tf.math.floor(x)\\n'\n",
      " 'tf.math.logical_not(x)tf.math.logical_or(x, y)\\n'\n",
      " 'tf.gather(params, indices, axis, batch_dims)\\n'\n",
      " 'tf.math.unsorted_segment_sum(data, segment_ids, num_segments)\\n'\n",
      " 'tf.fill(dims, value)tf.gather(params, indices)\\n'\n",
      " 'tf.reduce_min(input_tensor, axis)\\n'\n",
      " 'tf.sign(x)\\n'\n",
      " 'tf.sqrt(x)\\n'\n",
      " 'tf.greater(x, y)\\n'\n",
      " 'tf.repeat(input, repeats)\\n'\n",
      " 'tf.math.log(x)\\n'\n",
      " 'tf.transpose(a)\\n'\n",
      " 'tf.math.reciprocal(x)\\n'\n",
      " 'tf.tensordot(a, b, axes)\\n'\n",
      " 'tf.math.segment_sum(data, segment_ids)\\n'\n",
      " 'tf.equal(x, y)\\n'\n",
      " 'tf.math.unsorted_segment_prod(data, segment_ids, num_segments)\\n'\n",
      " \"tf.pad(tensor, paddings, mode='CONSTANT')\\n\"\n",
      " 'tf.math.ceil(x)\\n'\n",
      " 'tf.expand_dims(input, axis)\\n'\n",
      " 'tf.constant(value, dtype)\\n'\n",
      " 'tf.multiply(x, y)\\n'\n",
      " 'tf.exp(x)\\n'\n",
      " 'tf.ones_like(input)\\n'\n",
      " 'tf.reduce_mean(input_tensor)\\n'\n",
      " 'tf.one_hot(indices, depth)\\n'\n",
      " 'tf.math.squared_difference(x, y)\\n'\n",
      " 'tf.unique_with_counts(x)\\n'\n",
      " 'tf.add_n(inputs)\\n'\n",
      " \"tf.pad(tensor, paddings, mode='REFLECT')\\n\"\n",
      " \"tf.sort(values, axis, direction='DESCENDING')\\n\"\n",
      " 'tf.matmul(a, b)\\n'\n",
      " 'tf.eye(num_rows)\\n'\n",
      " \"tf.pad(tensor, paddings, mode='SYMMETRIC')\\n\"\n",
      " 'tf.math.segment_max(data, segment_ids)\\n'\n",
      " 'tf.argmax(input, axis)\\n'\n",
      " 'tf.reshape(tensor, shape)\\n'\n",
      " 'tf.reduce_any(input_tensor, axis)\\n'\n",
      " 'tf.math.segment_min(data, segment_ids)\\n'\n",
      " 'tf.subtract(x, y)\\n'\n",
      " 'tf.greater_equal(x, y)\\n'\n",
      " 'tf.transpose(a, perm)\\n'\n",
      " 'tf.math.logical_xor(x, y)\\n'\n",
      " 'tf.tensor_scatter_nd_update(tensor, indices, updates)\\n'\n",
      " 'tf.gather_nd(params, indices, batch_dims)\\n'\n",
      " 'tf.range(start, limit, delta)\\n'\n",
      " 'tf.repeat(input, repeats, axis)\\n'\n",
      " 'tf.divide(x, y)\\n'\n",
      " 'tf.zeros(shape)\\n'\n",
      " 'tf.argsort(values, axis, stable=True)\\n'\n",
      " 'tf.math.reciprocal_no_nan(x)\\n'\n",
      " 'tf.sequence_mask(lengths, maxlen)\\n'\n",
      " 'tf.reduce_min(input_tensor)\\n'\n",
      " 'tf.stack(values, axis)\\n'\n",
      " 'tf.reduce_prod(input_tensor, axis)\\n'\n",
      " 'tf.reverse(tensor, axis)\\n'\n",
      " 'tf.reduce_max(input_tensor, axis)\\n'\n",
      " 'tf.roll(input, shift, axis)\\n'\n",
      " 'tf.math.segment_prod(data, segment_ids)\\n'\n",
      " 'tf.reduce_all(input_tensor, axis)\\n'\n",
      " \"tf.searchsorted(sorted_sequence, values, side='left')\\n\"\n",
      " 'tf.math.unsorted_segment_min(data, segment_ids, num_segments)\\n'\n",
      " 'tf.sort(values, axis)\\n'\n",
      " 'tf.argmin(input, axis)\\n'\n",
      " 'tf.ones(shape)\\n'\n",
      " 'tf.squeeze(input, axis)\\n'\n",
      " 'tf.squeeze(input)\\n'\n",
      " 'tf.concat(values, axis)\\n'\n",
      " 'tf.minimum(x, y)\\n'\n",
      " 'tf.unstack(value, axis)\\n'\n",
      " \"tf.pad(tensor, paddings, mode='CONSTANT', constant_values)\\n\"\n",
      " 'tf.math.unsorted_segment_max(data, segment_ids, num_segments)\\n'\n",
      " 'tf.abs(x)\\n'\n",
      " 'tf.eye(num_rows, num_columns)\\n'\n",
      " \"tf.argsort(values, axis, direction='DESCENDING', stable=True)\\n\"\n",
      " 'tf.math.bincount(arr)\\n'\n",
      " 'tf.eye(num_rows, dtype)\\n'\n",
      " 'tf.zeros_like(input)\\n'\n",
      " 'tf.math.divide_no_nan(x, y)\\n'\n",
      " 'tf.reduce_sum(input_tensor)\\n'\n",
      " 'tf.where(condition)\\n'\n",
      " 'tf.broadcast_to(input, shape)\\n'\n",
      " 'tf.round(x)\\n'\n",
      " 'tf.range(start)\\n'\n",
      " \"tf.searchsorted(sorted_sequence, values, side='right')\\n\"\n",
      " 'tf.scatter_nd(indices, updates, shape)\\n'\n",
      " 'tf.math.top_k(input, k)\\n'\n",
      " 'tf.clip_by_value(t, clip_value_min, clip_value_max)\\n'\n",
      " 'tf.reduce_sum(input_tensor, axis)\\n'\n",
      " '\\n'\n",
      " '[SPARSE TENSORFLOW OPERATORS]\\n'\n",
      " 'tf.sparse.minimum(sp_a, sp_b)\\n'\n",
      " 'tf.sparse.from_dense(tensor)\\n'\n",
      " 'tf.sparse.concat(axis, sp_inputs)\\n'\n",
      " 'tf.sparse.retain(sp_input, to_retain)\\n'\n",
      " 'tf.sparse.to_dense(sp_input)\\n'\n",
      " 'tf.sparse.reset_shape(sp_input)\\n'\n",
      " 'tf.sparse.transpose(sp_input)\\n'\n",
      " 'tf.sparse.reshape(sp_input, shape)\\n'\n",
      " 'tf.SparseTensor(indices, values, dense_shape)\\n'\n",
      " 'tf.sparse.maximum(sp_a, sp_b)\\n'\n",
      " 'tf.sparse.reduce_max(sp_input, axis, output_is_sparse)\\n'\n",
      " 'tf.sparse.reduce_sum(sp_input, axis, output_is_sparse)\\n'\n",
      " 'tf.sparse.split(sp_input, num_split, axis)\\n'\n",
      " 'tf.sparse.slice(sp_input, start, size)\\n'\n",
      " 'tf.sparse.transpose(sp_input, perm)\\n'\n",
      " 'tf.sparse.expand_dims(sp_input, axis)\\n'\n",
      " 'tf.sparse.add(a, b)\\n'\n",
      " 'tf.sparse.to_indicator(sp_input, vocab_size)\\n'\n",
      " 'tf.sparse.to_dense(sp_input, default_value)\\n'\n",
      " '\\n'\n",
      " '[TASK DESCRIPTION]\\n'\n",
      " 'Slice the first dimension of a SparseTensor\\n'\n",
      " '\\n'\n",
      " '[EXAMPLES]\\n'\n",
      " 'Inputs:\\n'\n",
      " 'SparseTensor(indices=tf.Tensor(\\n'\n",
      " '[[0 0 0]\\n'\n",
      " ' [0 1 1]\\n'\n",
      " ' [1 1 1]\\n'\n",
      " ' [1 1 2]], shape=(4, 3), dtype=int64), values=tf.Tensor([1. 1. 1. 1.], '\n",
      " 'shape=(4,), dtype=float32), dense_shape=tf.Tensor([  2   2 800], shape=(3,), '\n",
      " 'dtype=int64))\\n'\n",
      " 'Output:\\n'\n",
      " 'SparseTensor(indices=tf.Tensor(\\n'\n",
      " '[[0 0 0]\\n'\n",
      " ' [0 1 1]], shape=(2, 3), dtype=int64), values=tf.Tensor([1. 1.], shape=(2,), '\n",
      " 'dtype=float32), dense_shape=tf.Tensor([  1   2 800], shape=(3,), '\n",
      " 'dtype=int64))\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '[PROGRAM]\\n'\n",
      " 'def transform(in1):\\n'\n",
      " '    ')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sparse_tensor = in1\\nindices = sparse_tensor.indices.numpy()\\nvalues = sparse_tensor.values.numpy()\\n\\nindices = indices[indices[:, 0] < 1]\\nvalues = values[:len(indices)]\\n\\nreturn tf.SparseTensor(indices=indices, values=values, dense_shape=[1, sparse_tensor.dense_shape[1], sparse_tensor.dense_shape[2]])',\n",
       " 'indices = tf.cast(tf.where(in1.indices[:, 0] < 1), tf.int64)\\n    new_values = tf.squeeze(tf.gather(in1.values, indices), axis=-1)\\n    new_indices = tf.gather(in1.indices, indices)\\n    dense_shape = in1.dense_shape\\n    dense_shape = tf.tensor_scatter_nd_update(dense_shape, [[0]], [tf.reduce_sum(tf.cast(tf.greater_equal(dense_shape[0], 1), tf.int64))])\\n    return tf.SparseTensor(new_indices, new_values, dense_shape)',\n",
       " '# Get the first index where the first dimension changes\\nidx = tf.where(in1.indices[:, 0] > 0)[0, 0]\\n\\n# Slice the indices, values and dense_shape accordingly\\nindices = tf.slice(in1.indices, [0, 0], [idx, -1])\\nvalues = tf.slice(in1.values, [0], [idx])\\ndense_shape = tf.concat([[1], in1.dense_shape[1:]], axis=0)\\nreturn tf.SparseTensor(indices=indices, values=values, dense_shape=dense_shape)',\n",
       " 'indices = tf.where(in1.indices[:,0] == 0)\\nslice_indices = tf.gather(in1.indices, indices)\\nslice_values = tf.gather(in1.values, indices)\\nslice_shape = tf.concat([tf.constant([1]), in1.dense_shape[1:]], 0)\\nreturn tf.SparseTensor(slice_indices, slice_values, slice_shape)',\n",
       " 'return tf.sparse.slice(in1, start=[0, 0, 0], size=[1, -1, -1])']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_TASK = TASK_JSONS[\"google_03\"]\n",
    "\n",
    "pprint(make_user_message(TEST_TASK))\n",
    "\n",
    "prompt(SYSTEM_PROMPT, make_user_message(TEST_TASK), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_name, task in TASK_JSONS.items():\n",
    "    if \"completions\" in task:\n",
    "        del task[\"completions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompting for task: google_12, description: identify elements between 0 and 1\n",
      "['return tf.cast(tf.logical_and(tf.greater(in1, tf.constant(0.)), tf.less(in1, '\n",
      " \"tf.constant(1.))), 'int32')\",\n",
      " 'return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), '\n",
      " 'tf.int32)',\n",
      " 'return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), '\n",
      " 'tf.int32)',\n",
      " 'return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), '\n",
      " 'tf.int32)',\n",
      " 'return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), '\n",
      " 'tf.int32)',\n",
      " 'return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), '\n",
      " 'tf.int32)',\n",
      " 'return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), '\n",
      " 'dtype=tf.int32)',\n",
      " 'return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), '\n",
      " 'tf.int32)',\n",
      " 'return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), '\n",
      " 'tf.int32)',\n",
      " 'return tf.cast(tf.logical_and(tf.greater(in1, tf.zeros_like(in1)), '\n",
      " 'tf.less(in1, tf.ones_like(in1))), dtype=tf.int32)']\n",
      "\n",
      "Prompting for task: google_13, description: Concatenate batches of sequences\n",
      "['return tf.concat([in1, in2], axis=1)',\n",
      " 'return tf.concat([in1, in2], axis=1)',\n",
      " 'return tf.concat([in1, in2], axis=1)',\n",
      " 'return tf.concat([in1, in2], axis=1)',\n",
      " 'return tf.concat([in1,in2], axis=1)',\n",
      " 'return tf.concat([in1, in2], axis=1)',\n",
      " 'return tf.concat([in1, in2], axis=1)',\n",
      " 'return tf.concat([in1, in2], axis=1)',\n",
      " 'return tf.concat([in1, in2], axis=1)',\n",
      " 'return tf.concat([in1, in2], axis=-1)']\n",
      "\n",
      "Prompting for task: google_14, description: circular buffer\n",
      "['return tf.roll(in1, shift=1, axis=1)',\n",
      " 'return tf.roll(in1, shift=1, axis=1)',\n",
      " 'return tf.roll(in1, shift=1, axis=1)',\n",
      " 'return tf.roll(in1, shift=1, axis=1)',\n",
      " 'return tf.pad(in1, [[0, 0], [1, 0]])',\n",
      " 'return tf.pad(in1, tf.constant([[0, 0], [1, 1]]), \"CONSTANT\")',\n",
      " 'return tf.roll(in1, shift=1, axis=1)',\n",
      " '# Shift all elements in each row of in1 to the right by one place, and pad '\n",
      " 'with 0 at the start of each row\\n'\n",
      " 'return tf.roll(in1, shift=1, axis=1)',\n",
      " 'return tf.roll(in1, shift=1, axis=1)',\n",
      " 'return tf.roll(in1, shift=1, axis=1)']\n",
      "\n",
      "Prompting for task: google_15, description: pad a zero column\n",
      "['# pad zeros on the last column\\n'\n",
      " \"return tf.pad(in1, [[0, 0], [0, 1]], mode='CONSTANT', constant_values=0)\",\n",
      " 'padding = tf.constant([[0, 0], [0, 1]])\\n     return tf.pad(in1, padding)',\n",
      " 'paddings = tf.constant([[0, 0], [0, 1]])\\n     return tf.pad(in1, paddings)',\n",
      " \"return tf.pad(in1, [[0,0],[0,1]], mode='CONSTANT')\",\n",
      " 'padding = tf.constant([[0, 0], [0, 1]])\\n'\n",
      " 'return tf.pad(in1, padding, \"CONSTANT\")',\n",
      " 'paddings = tf.constant([[0, 0], [0, 1]])\\n     return tf.pad(in1, paddings)',\n",
      " 'return tf.concat([in1, tf.zeros((tf.shape(in1)[0], 1), dtype=in1.dtype)], '\n",
      " 'axis=1)',\n",
      " \"return tf.pad(in1, [[0, 0], [0, 1]], 'CONSTANT', 0)\",\n",
      " 'return tf.pad(in1, [[0, 0], [0, 1]])',\n",
      " 'return tf.pad(in1, [[0,0],[0,1]])']\n",
      "\n",
      "Prompting for task: google_16, description: replicate elements a given number of times\n",
      "['return tf.repeat(in1, in2)',\n",
      " 'return tf.reshape(tf.repeat(in1, in2), [-1])',\n",
      " 'return tf.repeat(in1, in2)',\n",
      " 'return tf.repeat(in1, in2).numpy().tolist()',\n",
      " 'return tf.reshape(tf.repeat(in1, in2), [-1])',\n",
      " 'return tf.repeat(in1, in2)',\n",
      " 'return tf.reshape(tf.repeat(in1, in2), [-1]).numpy()',\n",
      " 'return tf.repeat(in1, repeats=in2)',\n",
      " 'return tf.reshape(tf.repeat(in1, in2), [-1])',\n",
      " 'return tf.repeat(in1, in2).numpy().tolist()']\n",
      "\n",
      "Prompting for task: google_17, description: use bool tensor as condition\n",
      "['return tf.where(in1, in2, tf.multiply(in2, -10))',\n",
      " 'return tf.where(in1, in2, in2 * -10)',\n",
      " 'return tf.where(in1, in2, tf.multiply(in2, -10))',\n",
      " 'return tf.where(in1, in2, tf.multiply(in2, -10))',\n",
      " 'return tf.where(in1, in2, -10*in2)',\n",
      " 'return tf.where(in1, in2, tf.multiply(in2, -10))',\n",
      " 'return tf.where(in1, in2, in2*tf.constant(-10))',\n",
      " 'return tf.where(in1, in2, in2 * -10)',\n",
      " 'return tf.where(in1, in2, tf.multiply(in2, -10))',\n",
      " 'return tf.where(in1, in2, in2*tf.constant(-10))']\n",
      "\n",
      "Prompting for task: google_18, description: (\\'sum of elements in the first tensor but partitioned by the second tensor\\')\n",
      "['return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)',\n",
      " 'return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + 1)',\n",
      " 'return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)',\n",
      " 'segment_sum = tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)\\n'\n",
      " '     result = tf.gather(segment_sum, in2)\\n'\n",
      " '     return result',\n",
      " 'segments_ids = tf.subtract(in2, tf.constant(1))\\n'\n",
      " 'output = tf.gather(tf.math.unsorted_segment_sum(in1, segments_ids, '\n",
      " 'tf.reduce_max(segments_ids) + 1), segments_ids)\\n'\n",
      " 'return output',\n",
      " 'return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)',\n",
      " 'segments = tf.constant(in2)\\n'\n",
      " 'data = tf.constant(in1)\\n'\n",
      " 'sums = tf.math.unsorted_segment_sum(data, segments, '\n",
      " 'tf.reduce_max(segment_ids)+1)\\n'\n",
      " 'return tf.gather(sums, segments)',\n",
      " 'return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + 1)',\n",
      " 'segmented_sum = tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + '\n",
      " '1)\\n'\n",
      " '     out = tf.gather(segmented_sum, in2)\\n'\n",
      " '     return out',\n",
      " 'return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)']\n",
      "\n",
      "Prompting for task: google_19, description: scatter a 2-D tensor with indices\n",
      "['return tf.gather(in1, in2, batch_dims=1)',\n",
      " 'return tf.gather(in1, in2, axis=1)',\n",
      " 'return tf.gather(in1, in2, axis=1)',\n",
      " 'return tf.gather(in1,in2,axis=1)',\n",
      " 'return tf.gather(in1, in2, axis=1)',\n",
      " 'return tf.transpose(tf.gather(tf.transpose(in1), in2))',\n",
      " 'return tf.gather(in1, in2, axis=1)',\n",
      " 'return tf.map_fn(lambda x: tf.gather(*x), (in1, in2), dtype=tf.int32)',\n",
      " 'return tf.gather(in1, in2, batch_dims=1)',\n",
      " 'return tf.gather(in1, in2, batch_dims=1)']\n",
      "\n",
      "Prompting for task: google_20, description: sort a tensor and return sorted index in original order\n",
      "['return tf.argsort(tf.argsort(in1)).numpy().tolist()',\n",
      " 'return tf.argsort(tf.argsort(in1))',\n",
      " 'return tf.argsort(tf.argsort(in1)).numpy()',\n",
      " 'return tf.argsort(tf.argsort(in1))',\n",
      " 'return tf.argsort(tf.argsort(in1)).numpy().tolist()',\n",
      " 'return tf.argsort(tf.argsort(in1))',\n",
      " 'return tf.argsort(tf.argsort(in1)).numpy()',\n",
      " 'return tf.argsort(tf.argsort(in1)).numpy().tolist()',\n",
      " 'return tf.argsort(tf.argsort(in1)).numpy()',\n",
      " 'sorted_indices = tf.argsort(in1)\\n'\n",
      " 'original_order = tf.argsort(sorted_indices)\\n'\n",
      " 'return original_order']\n",
      "\n",
      "Prompting for task: google_21, description: update a tensor at the given indices\n",
      "[\"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates']).numpy().tolist()\",\n",
      " \"return tf.tensor_scatter_nd_update(tf.constant(in1['tensor']), \"\n",
      " \"tf.constant(in1['indices']), tf.constant(in1['updates']))\",\n",
      " \"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\",\n",
      " \"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\",\n",
      " 'return '\n",
      " \"tf.tensor_scatter_nd_update(in1['tensor'],in1['indices'],in1['updates'])\",\n",
      " \"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\",\n",
      " \"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates']).numpy()\",\n",
      " \"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\",\n",
      " \"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\",\n",
      " \"return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], \"\n",
      " \"in1['updates'])\"]\n",
      "\n",
      "Prompting for task: google_22, description: pair with row index\n",
      "['indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'indices = tf.expand_dims(indices, axis=-1)\\n'\n",
      " 'indices = tf.repeat(indices, tf.shape(in1)[1], axis=-1)\\n'\n",
      " '\\n'\n",
      " 'pair_indices = tf.reshape(indices, (-1, 1))\\n'\n",
      " 'pair_values = tf.reshape(in1, (-1, 1))\\n'\n",
      " '\\n'\n",
      " 'output = tf.concat([pair_indices, pair_values], axis=-1)\\n'\n",
      " 'return output',\n",
      " 'return tf.concat([tf.expand_dims(tf.range(tf.shape(in1)[0]), axis=1), in1], '\n",
      " 'axis=1)',\n",
      " 'indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " '     indices = tf.expand_dims(indices, axis=-1)\\n'\n",
      " '     indices = tf.repeat(indices, repeats=tf.shape(in1)[1], axis=1)\\n'\n",
      " '     in1_flat = tf.reshape(in1, [-1])\\n'\n",
      " '     indices_flat = tf.reshape(indices, [-1])\\n'\n",
      " '     return tf.stack([indices_flat, in1_flat], axis=-1)',\n",
      " 'out = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'out = tf.expand_dims(out, 1)\\n'\n",
      " 'out = tf.tile(out, [1, tf.shape(in1)[1]])\\n'\n",
      " 'out = tf.expand_dims(out, 2)\\n'\n",
      " 'in1 = tf.expand_dims(in1, 2)\\n'\n",
      " 'return tf.reshape(tf.concat([out, in1], axis=2), [-1, 2])',\n",
      " 'return tf.reshape(tf.concat([tf.expand_dims(tf.range(tf.shape(in1)[0]), '\n",
      " 'axis=-1), in1], axis=-1), [-1, 2])',\n",
      " 'index = tf.range(tf.shape(in1)[0])\\n'\n",
      " '     index = tf.expand_dims(index, axis=1)\\n'\n",
      " '     index = tf.tile(index, [1, tf.shape(in1)[1]])\\n'\n",
      " '     return tf.stack([index, in1], axis=-1)',\n",
      " 'rows_indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'rows_indices_rep = tf.repeat(rows_indices, tf.shape(in1)[1])\\n'\n",
      " 'reshaped_indices = tf.reshape(rows_indices_rep, [-1, 1])\\n'\n",
      " 'in1_flattened = tf.reshape(in1, [-1, 1])\\n'\n",
      " 'return tf.concat([reshaped_indices, in1_flattened], axis=1)',\n",
      " 'indices = tf.range(start=0, limit=tf.shape(in1)[0], delta=1)\\n'\n",
      " '    indices = tf.expand_dims(indices, axis=-1)\\n'\n",
      " '    indices = tf.broadcast_to(indices, shape=in1.shape)\\n'\n",
      " '    indices = tf.reshape(indices, shape=(-1, 1))\\n'\n",
      " '    in1 = tf.reshape(in1, shape=(-1, 1))\\n'\n",
      " '    result = tf.concat([indices, in1], axis=1)\\n'\n",
      " '    return result',\n",
      " '# create a range of indices for the rows\\n'\n",
      " '    rows = tf.range(tf.shape(in1)[0])\\n'\n",
      " '\\n'\n",
      " '    # expand the dimensions of the rows\\n'\n",
      " '    expanded_rows = tf.expand_dims(rows , axis = -1)\\n'\n",
      " '   \\n'\n",
      " '    # tile the expanded rows to match the shape of in1\\n'\n",
      " '    tiled_rows = tf.tile(expanded_rows, [1, tf.shape(in1)[1]])\\n'\n",
      " '   \\n'\n",
      " '    # reshape the tiled rows to match the shape of in1\\n'\n",
      " '    reshaped_rows = tf.reshape(tiled_rows, tf.shape(in1))\\n'\n",
      " '   \\n'\n",
      " '    # Concatenate reshaped_rows and in1 along axis 1\\n'\n",
      " '    out1 = tf.concat([reshaped_rows, in1], axis=-1)\\n'\n",
      " '   \\n'\n",
      " '    # reshape out1 to match the shape of the output\\n'\n",
      " '    out2 = tf.reshape(out1, [tf.shape(in1)[0]*2, -1])\\n'\n",
      " '   \\n'\n",
      " '    return out2',\n",
      " 'indices = tf.range(start=0, limit=tf.shape(in1)[0])\\n'\n",
      " '      indices = tf.reshape(indices, [-1, 1])\\n'\n",
      " '      indices = tf.repeat(indices, repeats=2, axis=1) \\n'\n",
      " '      flat_in1 = tf.reshape(in1, [-1, 2])\\n'\n",
      " '      return tf.concat([indices, flat_in1], axis=1)']\n",
      "\n",
      "Prompting for task: stackoverflow_01, description: reshape by separating and duplicating columns\n",
      "['in1 = tf.transpose(in1)\\nreturn tf.expand_dims(in1, -1)',\n",
      " 'return tf.expand_dims(tf.transpose(in1), axis=-1)',\n",
      " 'a = tf.expand_dims(in1, axis=0)\\n'\n",
      " 'b = tf.transpose(a, perm=[2, 1, 0])\\n'\n",
      " 'return tf.tile(b, [1, 1, 2])',\n",
      " 'x = tf.unstack(in1, axis=1)\\n'\n",
      " 'x = [tf.reshape(i, shape=(-1, 1)) for i in x]\\n'\n",
      " 'x = [tf.concat([i, i], axis=1) for i in x]\\n'\n",
      " 'return tf.stack(x)',\n",
      " 'reshaped_input = tf.reshape(in1, [in1.shape[1], in1.shape[0], 1])\\n'\n",
      " 'return tf.tile(reshaped_input, [1, 1, 2])',\n",
      " 'return tf.stack([tf.broadcast_to(tf.expand_dims(in1[:, i], -1), '\n",
      " 'tf.shape(in1)) for i in range(in1.shape[1])], axis=0)',\n",
      " 'a = tf.transpose(in1)\\n'\n",
      " '     b = tf.expand_dims(a, axis=2)\\n'\n",
      " '     c = tf.repeat(b, repeats=[2], axis=2)\\n'\n",
      " '     return c',\n",
      " '# The task requires to reshape the input array by separating each column and '\n",
      " 'replicating them into two.\\n'\n",
      " '\\n'\n",
      " '# Steps:\\n'\n",
      " '# 1. Firstly, transpose the input array to separate the columns\\n'\n",
      " '# 2. Duplicate each row in the transposed array.\\n'\n",
      " '# 3. Finally, reshape the array to match the final desired shape.\\n'\n",
      " '\\n'\n",
      " 'in1 = tf.transpose(in1)  # Transposing the input\\n'\n",
      " '# Expanding dimensions to duplicate rows.\\n'\n",
      " '# Expanding along axis 1 as we want to duplicate rows.\\n'\n",
      " 'in1 = tf.expand_dims(in1, axis=1)\\n'\n",
      " '# Duplicating rows using tf.tile\\n'\n",
      " 'in1 = tf.tile(in1, multiples=[1, 2, 1])\\n'\n",
      " 'return in1  # Returning the reshaped array.',\n",
      " 'return tf.stack([tf.expand_dims(tf.transpose(in1)[i], axis=0) for i in '\n",
      " 'range(tf.shape(in1)[1])])',\n",
      " 'in1_transposed = tf.transpose(in1)\\n'\n",
      " '     reshaped = tf.reshape(in1_transposed, [in1_transposed.shape[0], '\n",
      " 'in1_transposed.shape[1], 1])\\n'\n",
      " '     return tf.tile(reshaped, [1, 1, 2])']\n",
      "\n",
      "Prompting for task: stackoverflow_02, description: clip values that are greater than 1\n",
      "[\"return tf.clip_by_value(in1, -tf.constant(float('inf')), tf.constant(1.0))\",\n",
      " 'return tf.clip_by_value(in1, -tf.float32.max, 1)',\n",
      " \"return tf.clip_by_value(in1, -tf.constant(float('inf')), 1)\",\n",
      " 'return tf.clip_by_value(in1, -tf.float32.max, 1)',\n",
      " \"return tf.clip_by_value(in1, float('-inf'), 1)\",\n",
      " 'return tf.clip_by_value(in1, -np.inf, 1)',\n",
      " 'return tf.clip_by_value(in1, -np.inf, 1)',\n",
      " 'return tf.clip_by_value(in1, -np.inf, 1)',\n",
      " 'return tf.clip_by_value(in1, -np.inf, 1)',\n",
      " 'return tf.clip_by_value(in1, -tf.float32.max, 1)']\n",
      "\n",
      "Prompting for task: stackoverflow_03, description: replace certain columns with columns from the other tensor\n",
      "['in1 = tf.constant(in1)\\n'\n",
      " 'in2 = tf.constant(in2)\\n'\n",
      " '\\n'\n",
      " 'cols_to_replace = [3, 4]\\n'\n",
      " 'replacement = tf.gather(in2, cols_to_replace, axis=1)\\n'\n",
      " '\\n'\n",
      " 'modified = tf.tensor_scatter_nd_update(in1, tf.constant([[0, j] for j in '\n",
      " 'cols_to_replace]), replacement)\\n'\n",
      " '\\n'\n",
      " 'return modified',\n",
      " 'in1 = tf.constant(in1)\\n'\n",
      " 'in2 = tf.constant(in2)\\n'\n",
      " 'indices = tf.constant([[0,3], [0,4], [1,3], [1,4]])\\n'\n",
      " 'updates = tf.gather_nd(in2, indices)\\n'\n",
      " 'return tf.tensor_scatter_nd_update(in1, indices, updates).numpy()',\n",
      " 'in1 = tf.convert_to_tensor(in1)\\n'\n",
      " 'in2 = tf.convert_to_tensor(in2)\\n'\n",
      " 'indices = tf.constant([3, 4])\\n'\n",
      " 'updated_tensor = tf.tensor_scatter_nd_update(in1, tf.reshape(indices, [-1, '\n",
      " '1]), tf.gather(in2, indices, axis=1))\\n'\n",
      " 'return updated_tensor',\n",
      " 'in1 = tf.constant(in1)\\n'\n",
      " 'in2 = tf.constant(in2)\\n'\n",
      " 'indices = tf.constant([[0, 3], [0, 4], [1, 3], [1, 4]])\\n'\n",
      " 'updates = tf.gather_nd(in2, indices)\\n'\n",
      " 'out = tf.tensor_scatter_nd_update(in1, indices, updates)\\n'\n",
      " 'return out',\n",
      " 'in1[:, [3, 4]] = in2[:, [3, 4]]\\nreturn in1',\n",
      " 'in1 = tf.constant(in1, dtype=tf.int32)\\n'\n",
      " 'in2 = tf.constant(in2, dtype=tf.int32)\\n'\n",
      " 'indices = tf.constant([3,4]) # indices of columns to replace\\n'\n",
      " 'in1 = tf.unstack(in1, axis=1)\\n'\n",
      " 'in2 = tf.unstack(in2, axis=1)\\n'\n",
      " 'for i in indices:\\n'\n",
      " '    in1[i] = in2[i]\\n'\n",
      " 'out = tf.stack(in1, axis=1)\\n'\n",
      " 'return out.eval(session=tf.Session())',\n",
      " 'in1_tf = tf.constant(in1)\\n'\n",
      " 'in2_tf = tf.constant(in2)\\n'\n",
      " 'indices_to_replace = [3, 4]\\n'\n",
      " 'for index in indices_to_replace:\\n'\n",
      " '    in1_tf = tf.tensor_scatter_nd_update(in1_tf, [[0, index], [1, index]], '\n",
      " 'in2_tf[:, index])\\n'\n",
      " 'return in1_tf',\n",
      " 'in1 = tf.constant(in1)\\n'\n",
      " 'in2 = tf.constant(in2)\\n'\n",
      " 'in1 = tf.cast(in1, tf.float32)\\n'\n",
      " 'in2 = tf.cast(in2, tf.float32)\\n'\n",
      " 'columns_to_replace = [3,4]\\n'\n",
      " 'replacement_columns = tf.gather(in2, columns_to_replace, axis=1)\\n'\n",
      " 'updated = tf.tensor_scatter_nd_update(in1, tf.constant([[i] for i in '\n",
      " 'columns_to_replace]), replacement_columns)\\n'\n",
      " 'return updated',\n",
      " 'in1 = tf.constant(in1)\\n'\n",
      " 'in2 = tf.constant(in2)\\n'\n",
      " 'indices = tf.constant([[3, 4]])  \\n'\n",
      " 'updates = tf.gather_nd(in2, indices)\\n'\n",
      " 'out = tf.tensor_scatter_nd_update(in1, indices, updates)\\n'\n",
      " 'return out',\n",
      " 'indices = tf.constant([3, 4])\\n'\n",
      " '     out = tf.tensor_scatter_nd_update(in1, tf.expand_dims(indices, '\n",
      " 'axis=-1), tf.gather(in2, indices, axis=1))\\n'\n",
      " '     return out']\n",
      "\n",
      "Prompting for task: stackoverflow_04, description: index into the tensor\n",
      "['return tf.transpose(in1)',\n",
      " 'return tf.gather(in1, [0, 1], axis=1)',\n",
      " 'return tf.transpose(in1)',\n",
      " 'out = tf.stack([tf.gather(in1, i, axis=1) for i in range(tf.shape(in1)[1])], '\n",
      " 'axis=0)\\n'\n",
      " 'return out',\n",
      " 'return tf.transpose(in1)',\n",
      " 'return tf.gather(in1, tf.constant([0, 1]), axis=1)',\n",
      " 'return tf.transpose(tf.broadcast_to(in1, [2, 3, 2]))',\n",
      " 'return tf.transpose(in1)',\n",
      " 'return tf.transpose(tf.broadcast_to(in1, [in1.shape[1]] + list(in1.shape)))',\n",
      " 'return tf.gather(in1, tf.range(tf.shape(in1)[1]), axis=1)']\n",
      "\n",
      "Prompting for task: stackoverflow_05, description: tensor multiplication like np.tensordot\n",
      "['return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1,in2,axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=1)']\n",
      "\n",
      "Prompting for task: stackoverflow_06, description: binary tensor from vector indicating if elements are equal\n",
      "['return tf.cast(tf.equal(tf.expand_dims(in1, 0), tf.expand_dims(in1, 1)), '\n",
      " 'dtype=tf.float32)',\n",
      " 'return tf.cast(tf.equal(tf.expand_dims(in1, 1), tf.expand_dims(in1, 0)), '\n",
      " 'tf.float32)',\n",
      " 'return tf.cast(tf.equal(tf.expand_dims(in1, 1), tf.expand_dims(in1, 0)), '\n",
      " 'tf.float32)',\n",
      " 'matrix = tf.equal(in1[:, None], in1[None, :])\\n'\n",
      " '    return tf.cast(matrix, tf.float32)',\n",
      " 'return tf.cast(tf.equal(in1[:, None], in1), dtype=tf.float32)',\n",
      " 'return tf.cast(tf.equal(tf.reshape(in1, [-1, 1]), in1), tf.float32)',\n",
      " 'in1 = tf.constant(in1, dtype=tf.float32)\\n'\n",
      " 'in1_mat = tf.expand_dims(in1, 1)\\n'\n",
      " 'comp_matrix = tf.equal(in1_mat, tf.transpose(in1_mat))\\n'\n",
      " 'binary_matrix = tf.cast(comp_matrix, tf.float32)\\n'\n",
      " 'return binary_matrix',\n",
      " 'return tf.cast(tf.equal(tf.expand_dims(in1, 1), tf.expand_dims(in1, 0)), '\n",
      " 'tf.float32)',\n",
      " 'in2 = tf.expand_dims(in1, -1)\\n'\n",
      " 'return tf.cast(tf.equal(in2, tf.transpose(in2)), tf.float32)',\n",
      " 'matrix = tf.equal(in1[:, None], in1[None, :])\\n'\n",
      " 'binary_matrix = tf.cast(matrix , tf.int32)\\n'\n",
      " 'return binary_matrix']\n",
      "\n",
      "Prompting for task: stackoverflow_07, description: swap the first two dimensions of the tensor\n",
      "['return tf.transpose(in1, perm=[1, 0, 2])',\n",
      " 'return tf.transpose(in1, perm=[1, 0, 2])',\n",
      " 'return tf.transpose(in1, perm=[1, 0, 2])',\n",
      " 'return tf.transpose(in1, perm=[1, 0, 2])',\n",
      " 'return tf.transpose(in1, perm=[1, 0, 2])',\n",
      " 'return tf.transpose(in1, perm=[1, 0, 2])',\n",
      " 'return tf.transpose(in1, perm=[1, 0, 2])',\n",
      " 'return tf.transpose(in1, perm=[1, 0, 2])',\n",
      " 'return tf.transpose(in1, perm=[1, 0, 2])',\n",
      " 'return tf.transpose(in1, perm=[1, 0, 2])']\n",
      "\n",
      "Prompting for task: stackoverflow_08, description: (\\'select the values in the second tensor where the first tensor is greater than 1\\')\n",
      "['return tf.boolean_mask(in2, tf.greater(in1, 1))',\n",
      " 'mask = tf.greater(in1,1)\\n     return tf.boolean_mask(in2, mask)',\n",
      " 'return tf.boolean_mask(in2, tf.greater(in1, 1))',\n",
      " 'mask = tf.greater(in1, 1)\\nreturn tf.boolean_mask(in2, mask)',\n",
      " 'return tf.boolean_mask(in2, tf.greater(in1,1))',\n",
      " 'mask = tf.greater(in1, 1)\\nout = tf.boolean_mask(in2, mask)\\nreturn out',\n",
      " 'return tf.boolean_mask(in2, tf.greater(in1, 1))',\n",
      " 'condition = tf.greater(in1, 1)\\n     return tf.boolean_mask(in2, condition)',\n",
      " 'mask = tf.greater(in1, 1)\\nreturn tf.boolean_mask(in2, mask)',\n",
      " 'condition = tf.greater(in1, 1)\\n'\n",
      " '     result = tf.boolean_mask(in2, condition)\\n'\n",
      " '     return result']\n",
      "\n",
      "Prompting for task: stackoverflow_09, description: group items by value and get the group indices\n",
      "['_, idx = tf.unique_with_counts(in1)\\nreturn idx',\n",
      " '_, ids = tf.unique_with_counts(in1)\\nreturn tf.gather(ids, in1)',\n",
      " '_, idx = tf.unique_with_counts(in1)\\nreturn tf.gather(idx, tf.argsort(in1))',\n",
      " '_, idx, count = tf.unique_with_counts(in1)\\n'\n",
      " 'output = tf.gather(idx, in1)\\n'\n",
      " 'return output',\n",
      " '_, idx = tf.unique_with_counts(in1)\\nreturn idx',\n",
      " '_, idx = tf.unique_with_counts(in1)\\nreturn tf.gather(idx, tf.argsort(in1))',\n",
      " '_, idx = tf.unique(in1)\\nreturn idx.numpy()',\n",
      " '_, idx = tf.unique(in1)\\nreturn idx',\n",
      " '_, idx = tf.unique_with_counts(in1)\\nreturn idx',\n",
      " '_, idx = tf.unique(in1)\\nreturn idx']\n",
      "\n",
      "Prompting for task: stackoverflow_10, description: perform matrix multiplication\n",
      "['return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in1,in2)',\n",
      " 'return tf.matmul(in1,in2)']\n",
      "\n",
      "Prompting for task: stackoverflow_11, description: count the number of occurences of each distinct number\n",
      "['return tf.math.bincount(in1)',\n",
      " 'return tf.math.bincount(in1)',\n",
      " 'return tf.math.bincount(in1)',\n",
      " 'return tf.math.bincount(in1)',\n",
      " 'return tf.math.bincount(in1)',\n",
      " 'return tf.math.bincount(in1)',\n",
      " 'return tf.math.bincount(tf.cast(in1, dtype=tf.int32)).numpy()',\n",
      " 'return tf.math.bincount(in1)',\n",
      " 'return tf.math.bincount(in1)',\n",
      " 'return tf.math.bincount(in1)']\n",
      "\n",
      "Prompting for task: stackoverflow_12, description: remove a column from the tensor\n",
      "['return tf.gather(in1, [0, 2], axis=1)',\n",
      " 'return tf.gather(in1, [0, 2], axis=1)',\n",
      " 'return tf.gather(in1, [0, 2], axis=1)',\n",
      " 'return tf.gather(in1, [0, 2], axis=1)',\n",
      " 'return tf.gather(in1, [0, 2], axis=1)',\n",
      " 'return tf.gather(in1, indices=[0,2], axis=1)',\n",
      " 'return tf.gather(in1, [0, 2], axis=1)',\n",
      " 'return tf.gather(in1, [0, 2], axis=1)',\n",
      " 'return tf.gather(in1, [0, 2], axis=1)',\n",
      " 'return tf.reshape(tf.gather(in1, [0,2], axis=1), [-1, 2])']\n",
      "\n",
      "Prompting for task: stackoverflow_13, description: multiply vectors by tensor\n",
      "['return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in1, tf.transpose(in2, perm=[0, 2, 1]))',\n",
      " 'return tf.matmul(in2, tf.expand_dims(in1, -1)).numpy().reshape(in2.shape)',\n",
      " 'return tf.matmul(in2, tf.expand_dims(in1, 2))[:,:,0]',\n",
      " 'return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in2, tf.expand_dims(in1, -1))[:,:,0]',\n",
      " 'return tf.matmul(in2, tf.expand_dims(in1, -1))[:, :, 0]',\n",
      " 'return tf.matmul(in2, tf.transpose(in1))',\n",
      " 'return tf.matmul(in1, in2)',\n",
      " 'return tf.matmul(in2, tf.transpose(in1))']\n",
      "\n",
      "Prompting for task: stackoverflow_14, description: choose True if any value in a row is True, False otherwise\n",
      "['return tf.reduce_any(in1, axis=-1)',\n",
      " 'return tf.reduce_any(in1, axis=2)',\n",
      " 'return tf.reduce_any(in1, axis=-1)',\n",
      " 'return tf.reduce_any(in1, axis=-1)',\n",
      " 'return tf.reduce_any(in1, axis=2)',\n",
      " 'return tf.reduce_any(in1, axis=2)',\n",
      " 'return tf.reduce_any(in1, axis=2)',\n",
      " 'return tf.reduce_any(in1, axis=2)',\n",
      " 'return tf.reduce_any(in1, axis=2)',\n",
      " 'return tf.reduce_any(in1, axis=-1)']\n",
      "\n",
      "Prompting for task: stackoverflow_15, description: set all instances of 1 to 0\n",
      "['return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), tf.zeros_like(in1), in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), tf.zeros_like(in1), in1)',\n",
      " 'return tf.where(tf.equal(in1, 1), 0, in1)']\n",
      "\n",
      "Prompting for task: stackoverflow_16, description: multiply tensors across the first axis\n",
      "['return tf.multiply(in1, tf.expand_dims(in2, axis=-1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, 1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, axis=-1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, axis=1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, axis=1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, axis=1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, axis=1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, 1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, axis=1))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, 1))']\n",
      "\n",
      "Prompting for task: stackoverflow_17, description: duplicate each element of a tensor\n",
      "['return tf.repeat(in1, repeats=2, axis=-1)',\n",
      " 'return tf.repeat(in1, repeats=2, axis=-1)',\n",
      " 'return tf.reshape(tf.repeat(in1, 2), [tf.shape(in1)[0], 2])',\n",
      " 'return tf.repeat(in1, repeats=2, axis=-1)',\n",
      " 'return tf.reshape(tf.repeat(in1, repeats = 2), [tf.shape(in1)[0], 2])',\n",
      " 'return tf.reshape(tf.repeat(in1, 2), [in1.shape[0], 2])',\n",
      " 'return tf.repeat(in1, 2, axis=-1)',\n",
      " 'return tf.tile(tf.expand_dims(in1, axis=-1), [1, 2])',\n",
      " 'return tf.tile(tf.expand_dims(in1, axis=1), [1, 2])',\n",
      " 'return tf.repeat(in1[:, tf.newaxis], 2, axis=-1)']\n",
      "\n",
      "Prompting for task: stackoverflow_18, description: multiply 3D tensor and 2D tensor and add another tensor\n",
      "['expanded_tensor = tf.expand_dims(in1, -1)\\n'\n",
      " '    mult = tf.matmul(expanded_tensor, in2)\\n'\n",
      " '    summed = tf.squeeze(mult, axis=-2) + in3\\n'\n",
      " '    return summed',\n",
      " 'intermediate = tf.tensordot(in1, in2, [[2], [0]])\\n'\n",
      " 'return tf.add(intermediate, in3)',\n",
      " 'expanded_in1 = tf.expand_dims(in1, -1)\\n'\n",
      " 'mul_result = tf.matmul(expanded_in1, in2)\\n'\n",
      " 'flat_in3 = tf.expand_dims(in3, 0)\\n'\n",
      " 'result = tf.add(mul_result, flat_in3)\\n'\n",
      " 'return result',\n",
      " 'intermediate = tf.tensordot(in1, in2, axes=1)\\n'\n",
      " 'result = tf.add(intermediate, in3)\\n'\n",
      " 'return result',\n",
      " 'return tf.add(tf.matmul(in1, in2), in3)',\n",
      " 'result = tf.add(tf.tensordot(in1, in2, axes=1), in3)\\nreturn result',\n",
      " 'in1 = tf.expand_dims(in1, -1)\\n'\n",
      " 'result = tf.add(tf.matmul(in1, in2), in3)\\n'\n",
      " 'return result',\n",
      " 'result = tf.add(tf.matmul(in1, in2), in3)\\nreturn result',\n",
      " 'a = tf.tensordot(in1, in2, axes=1)\\n     return tf.add(a, in3)',\n",
      " 'inter = tf.tensordot(in1, in2, axes=1)\\n'\n",
      " 'output = tf.add(inter, in3)\\n'\n",
      " 'return output']\n",
      "\n",
      "Prompting for task: stackoverflow_19, description: (\\'sort a tensor considering the first column, breaking ties using the second column\\')\n",
      "['return tf.sort(in1, axis=0)',\n",
      " 'return tf.sort(in1, axis=0)',\n",
      " 'return tf.sort(in1, axis=0)',\n",
      " 'return tf.argsort(in1, axis=0, stable=True)',\n",
      " 'return tf.sort(in1, axis=0)',\n",
      " 'return tf.argsort(in1, axis=0)',\n",
      " 'return tf.argsort(in1, axis=0, stable=True)',\n",
      " 'return tf.sort(in1, axis=0)',\n",
      " 'return tf.sort(in1, axis=0)',\n",
      " 'return tf.sort(in1, axis=0)']\n",
      "\n",
      "Prompting for task: stackoverflow_20, description: compute argmax in each tensor and set it to 1\n",
      "['# First find the indices of the maximum values in each tensor\\n'\n",
      " '    max_indices = tf.argmax(in1, axis=1)\\n'\n",
      " '    # Use one_hot to set the maximum values to 1.\\n'\n",
      " '    result = tf.one_hot(max_indices, depth=in1.shape[1])\\n'\n",
      " '    return result',\n",
      " '# Find the indices of maximum values along the last axis.\\n'\n",
      " '    max_indices = tf.argmax(in1, axis=-1)\\n'\n",
      " '    # Create a mask whose shape matches the input and set all elements to '\n",
      " 'False initially.\\n'\n",
      " '    mask = tf.zeros_like(in1, dtype=tf.bool)\\n'\n",
      " '    # Convert the indices of maximum values to a 2D shape, where each row '\n",
      " 'correspond to the index\\n'\n",
      " '    # in each tensor of the input.\\n'\n",
      " '    row_indices = tf.range(tf.shape(in1, out_type=max_indices.dtype)[0])[:, '\n",
      " 'None]\\n'\n",
      " '    max_indices = tf.concat([row_indices, max_indices[:, None]], axis=-1)\\n'\n",
      " '    # Set the elements at the indices of maximum values to True.\\n'\n",
      " '    mask = tf.tensor_scatter_nd_update(mask, max_indices, '\n",
      " 'tf.ones_like(max_indices, dtype=tf.bool)[:, :, 0])\\n'\n",
      " '    # Convert the boolean mask to integers.\\n'\n",
      " '    return tf.cast(mask, in1.dtype)',\n",
      " 'max_indices = tf.argmax(in1, axis=1)\\n'\n",
      " 'output = tf.one_hot(max_indices, depth=in1.shape[1])\\n'\n",
      " 'return tf.cast(output, dtype=in1.dtype)',\n",
      " 'argmax = tf.argmax(in1, axis=1)\\n'\n",
      " 'indices = tf.range(tf.shape(in1)[0], dtype=argmax.dtype)\\n'\n",
      " 'indices_argmax = tf.transpose(tf.stack([indices, argmax]))\\n'\n",
      " 'return tf.tensor_scatter_nd_update(tf.zeros_like(in1), indices_argmax, '\n",
      " 'tf.ones(tf.shape(in1)[0]))',\n",
      " '# We first compute argmax across axis 1 (columns)\\n'\n",
      " '    ind = tf.argmax(in1, 1)\\n'\n",
      " '\\n'\n",
      " '    # Calculate number of rows in the input tensor\\n'\n",
      " '    row_num = tf.shape(in1)[0]\\n'\n",
      " '\\n'\n",
      " '    # Create a range tensor from 0 to the number of rows\\n'\n",
      " '    ind_range = tf.range(row_num)\\n'\n",
      " '\\n'\n",
      " '    # Reshape argmax tensor from vector to a tensor\\n'\n",
      " '    ind = tf.expand_dims(ind, -1)\\n'\n",
      " '\\n'\n",
      " '    # Create a tensor of indices by vertically stacking the range and argmax '\n",
      " 'tensors\\n'\n",
      " '    ind_concat = tf.concat([ind_range, ind], 1)\\n'\n",
      " '\\n'\n",
      " '    # Form updates for the scatter operation\\n'\n",
      " '    updates = tf.fill([row_num], 1.)\\n'\n",
      " '\\n'\n",
      " '    # We then set a 1 to each argmax index of the tensor\\n'\n",
      " '    result = tf.tensor_scatter_nd_update(tf.zeros_like(in1), ind_concat, '\n",
      " 'updates)\\n'\n",
      " '\\n'\n",
      " '    # Cast result to int\\n'\n",
      " '    result = tf.cast(result, tf.int32)\\n'\n",
      " '\\n'\n",
      " '    return result',\n",
      " 'indices = tf.argmax(in1, axis=1)\\n'\n",
      " 'output = tf.one_hot(indices, depth=in1.shape[1])\\n'\n",
      " 'return output.numpy().astype(int)',\n",
      " 'argmax = tf.argmax(in1, axis=-1)\\n'\n",
      " 'shape = tf.shape(in1)\\n'\n",
      " 'mask = tf.one_hot(argmax, shape[-1])\\n'\n",
      " 'return tf.cast(mask, tf.int32)',\n",
      " 'argmax_indices = tf.argmax(in1, axis=1)\\n'\n",
      " 'one_hot_matrix = tf.one_hot(argmax_indices, depth=in1.shape[1])\\n'\n",
      " 'return tf.cast(one_hot_matrix, dtype=tf.int32)',\n",
      " '# Get the indices of the maximum element in each row\\n'\n",
      " 'max_indices = tf.argmax(in1, axis=1)\\n'\n",
      " '\\n'\n",
      " '# Create a zero tensor of the same shape as the input\\n'\n",
      " 'out = tf.zeros_like(in1, dtype=tf.int32)\\n'\n",
      " '\\n'\n",
      " '# Get the indices of the elements in the tensor\\n'\n",
      " 'indices = tf.range(tf.shape(in1, out_type=tf.int64)[0])\\n'\n",
      " '\\n'\n",
      " '# Combine the indices with the max_indices\\n'\n",
      " 'combined_indices = tf.transpose([indices, max_indices])\\n'\n",
      " '\\n'\n",
      " '# Update the output tensor with 1s at the positions of the maximum elements\\n'\n",
      " 'out = tf.tensor_scatter_nd_update(out, combined_indices, '\n",
      " 'tf.ones(tf.shape(max_indices, out_type=tf.int32),  dtype=tf.int32))\\n'\n",
      " '\\n'\n",
      " 'return out',\n",
      " '# Compute the argmax of each tensor along the last axis (axis=-1)\\n'\n",
      " '    tensor_argmax_index = tf.argmax(in1, axis=-1)\\n'\n",
      " '\\n'\n",
      " '    # The shape of tensor_argmax_index is (5,) (1-rank tensor)\\n'\n",
      " '    # Convert it to a 2-rank tensor with shape (5,1)\\n'\n",
      " '    # which will be useful for scatter_nd\\n'\n",
      " '    tensor_argmax_index = tf.expand_dims(tensor_argmax_index, axis=-1)\\n'\n",
      " '\\n'\n",
      " '    # Prepare updates, which consist of all ones\\n'\n",
      " '    updates = tf.ones_like(tensor_argmax_index)\\n'\n",
      " '    \\n'\n",
      " \"    # The desired output tensor has the same shape with 'in1'\\n\"\n",
      " '    desired_shape = tf.shape(in1)\\n'\n",
      " '\\n'\n",
      " '    # Use scatter_nd to place the updates at the correct indices\\n'\n",
      " '    result = tf.scatter_nd(tensor_argmax_index, updates, desired_shape)\\n'\n",
      " '\\n'\n",
      " '    return result']\n",
      "\n",
      "Prompting for task: stackoverflow_21, description: gather elements in a tensor along axis 1\n",
      "['return tf.gather(in2, in1, axis=1)',\n",
      " 'return tf.gather(in2, in1, axis=1)',\n",
      " 'return tf.gather(in2, in1, axis=1)',\n",
      " 'return tf.gather(in2, in1, axis=1, batch_dims=1)',\n",
      " 'return tf.gather(in2, in1, axis=1)',\n",
      " 'return tf.gather(in2, in1, axis=1, batch_dims=1)',\n",
      " 'return tf.gather(in2, in1, axis=1, batch_dims=1)',\n",
      " 'return tf.gather(in2, in1, axis=1, batch_dims=1)',\n",
      " 'return tf.gather(in2, in1, axis=1)',\n",
      " 'return tf.gather(in2, in1, axis=1)']\n",
      "\n",
      "Prompting for task: stackoverflow_22, description: multiply a vector with a matrix without reshaping the vector\n",
      "['return tf.reduce_sum(tf.multiply(in1, in2), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, in2), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, in2), 0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, in2), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, in2), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, in2), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, in2), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, in2), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, in2), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, in2), axis=0)']\n",
      "\n",
      "Prompting for task: stackoverflow_23, description: place 1 at the indices in the input tensor\n",
      "['shape = tf.shape(in1)\\n'\n",
      " 'length = shape[0] * shape[1]\\n'\n",
      " 'flat = tf.reshape(in1, [length])\\n'\n",
      " 'out = tf.scatter_nd(tf.expand_dims(flat, 1), tf.ones_like(flat), [length, '\n",
      " 'length])\\n'\n",
      " 'return tf.reshape(out, [shape[0], shape[1], -1])[:, :, 0]',\n",
      " \"depth = tf.reduce_max(in1) + 1  # the maximum index that's going to be \"\n",
      " 'replaced with 1, plus 1 to avoid off-by-one errors\\n'\n",
      " '     return tf.one_hot(in1, depth)',\n",
      " 'depth = tf.reduce_max(in1) + 1\\nreturn tf.one_hot(in1, depth)',\n",
      " 'return tf.scatter_nd(tf.expand_dims(in1, -1), tf.ones_like(in1), '\n",
      " 'tf.constant([in1.shape[0], in1.shape[1], 9]))[:,:,1]',\n",
      " 'depth = tf.reduce_max(in1) + 1\\n     return tf.one_hot(in1, depth)',\n",
      " 'max_val = tf.reduce_max(in1)\\n'\n",
      " 'one_hot_encoded = tf.one_hot(in1, max_val+1)\\n'\n",
      " 'result = tf.reduce_sum(one_hot_encoded, axis=1)\\n'\n",
      " 'return tf.cast(result, tf.int32)',\n",
      " 'return tf.scatter_nd(tf.expand_dims(in1, 1), tf.ones_like(in1), '\n",
      " 'tf.shape(in1))',\n",
      " 'out = tf.one_hot(in1, depth=6)\\nreturn tf.reduce_sum(out, axis=1)',\n",
      " 'depth = tf.reduce_max(in1) + 1\\nreturn tf.one_hot(in1, depth)',\n",
      " 'depth = tf.reduce_max(in1) + 1\\nreturn tf.one_hot(in1, depth)']\n",
      "\n",
      "Prompting for task: stackoverflow_24, description: (\\'like tf.divide(), but when dividing by 0, return the numerator\\')\n",
      "['return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)',\n",
      " 'return tf.math.divide_no_nan(in1, in2)']\n",
      "\n",
      "Prompting for task: stackoverflow_25, description: copy the tensor tf.eye(3), 4 times\n",
      "['return tf.tile(tf.eye(in1), [in2, 1])',\n",
      " 'tensor = tf.eye(in1)\\nreturn tf.tile(tensor,[in2,1])',\n",
      " 'return tf.tile(tf.eye(in1), [in2, 1])',\n",
      " 'return tf.tile(tf.eye(in1), [in2, 1])',\n",
      " 'return tf.tile(tf.eye(in1),(in2,1))',\n",
      " 'return tf.tile(tf.eye(in1), [in2, 1])',\n",
      " 'return tf.tile(tf.eye(in1), multiples=[in2, 1])',\n",
      " 'return tf.tile(tf.eye(in1), [in2, 1])',\n",
      " 'return tf.tile(tf.eye(in1), [in2, 1])',\n",
      " 'return tf.tile(tf.eye(in1), [in2, 1])']\n",
      "\n",
      "Prompting for task: stackoverflow_26, description: reduction operation for multiple dimensions simultaneously\n",
      "['return tf.reduce_sum(in1, axis=[0, 1]).numpy().tolist()',\n",
      " 'return tf.reduce_sum(in1, axis=[0,1]).numpy().tolist()',\n",
      " 'return tf.reduce_sum(in1, axis=[0, 1])',\n",
      " 'return tf.reduce_sum(in1, axis=[0,1])',\n",
      " 'return tf.reduce_sum(in1, axis=[0, 1]).numpy().tolist()',\n",
      " 'return tf.reduce_sum(in1, axis=[0,1])',\n",
      " 'return tf.reduce_sum(in1, axis=[0, 1])',\n",
      " 'return tf.reduce_sum(in1, axis=[0,1,2])',\n",
      " 'return tf.reduce_sum(in1, axis=[0,1])',\n",
      " 'return tf.reduce_sum(in1, axis=[0, 1])']\n",
      "\n",
      "Prompting for task: stackoverflow_27, description: boolean tensor with 1 at the indices in the input tensor\n",
      "['tensor = tf.one_hot(in1, in2)\\n     return tf.reduce_max(tensor, axis=0)',\n",
      " 'output = tf.scatter_nd(tf.expand_dims(in1, axis=1), tf.ones_like(in1), '\n",
      " '[in2])\\n'\n",
      " '     return output',\n",
      " 'return tf.cast(tf.reduce_sum(tf.one_hot(in1, in2), axis=0), tf.int32)',\n",
      " 'output = tf.scatter_nd(tf.expand_dims(in1, 1), tf.ones_like(in1), [in2])\\n'\n",
      " 'return output.numpy()',\n",
      " 'depth = tf.constant(in2)\\n'\n",
      " 'indices = tf.constant(in1)\\n'\n",
      " 'return tf.transpose(tf.one_hot(indices, depth))',\n",
      " 'output = tf.scatter_nd(tf.expand_dims(in1, axis=-1), tf.ones_like(in1), '\n",
      " '[in2])\\n'\n",
      " '     return tf.cast(output, tf.int32)',\n",
      " 'out = tf.one_hot(in1, in2)\\nreturn tf.reduce_sum(out, axis=0)',\n",
      " 'return tf.cast(tf.reduce_any(tf.one_hot(in1, in2), axis=0), tf.int32)',\n",
      " 'out = tf.Tensor(np.zeros(in2), dtype=tf.int32)\\n'\n",
      " '     out = tf.tensor_scatter_nd_update(out, tf.reshape(in1, [in1.shape[0], '\n",
      " '1]), tf.fill([in1.shape[0]], 1))\\n'\n",
      " '     return out',\n",
      " 'return tf.cast(tf.reduce_sum(tf.one_hot(in1, in2), axis=0), tf.int32)']\n",
      "\n",
      "Prompting for task: stackoverflow_28, description: extract columns from a 3D tensor given column indices\n",
      "['return tf.gather(in1, in2, axis=2, batch_dims=1)',\n",
      " 'return tf.gather(in1, in2, axis=2, batch_dims=1)',\n",
      " 'return tf.gather(in1, in2, axis=2, batch_dims=1)',\n",
      " 'return tf.gather(in1,in2,axis=2)',\n",
      " 'return tf.gather(in1, in2, axis=2, batch_dims=1)',\n",
      " 'return tf.gather(in1, tf.expand_dims(in2, axis=-1), batch_dims=1, axis=2)',\n",
      " '# Use tf.gather to select columns by indices\\n'\n",
      " '    result = tf.gather(in1, in2, axis=1, batch_dims=1)\\n'\n",
      " '    return result',\n",
      " 'return tf.gather(in1, in2, axis=2, batch_dims=1)',\n",
      " 'return tf.gather(in1, in2, axis=-1)',\n",
      " 'indices = tf.expand_dims(tf.range(tf.shape(in1)[0]), axis=-1)\\n'\n",
      " 'selected_indices = tf.concat([indices, tf.expand_dims(in2, axis=-1)], '\n",
      " 'axis=-1)\\n'\n",
      " 'return tf.gather_nd(in1, selected_indices)']\n",
      "\n",
      "Prompting for task: stackoverflow_29, description: place continuous values into buckets given bucket boundaries\n",
      "[\"return tf.searchsorted(in1, in2, side='right').numpy().tolist()\",\n",
      " 'return tf.searchsorted(in1,in2).numpy().tolist()',\n",
      " 'return tf.searchsorted(tf.constant(in1), tf.constant(in2)).numpy().tolist()',\n",
      " 'return tf.searchsorted(in1, in2).numpy().tolist()',\n",
      " \"return tf.searchsorted(sorted_sequence=in1, values=in2, side='right')\",\n",
      " 'return tf.searchsorted(tf.constant(in1), tf.constant(in2))',\n",
      " 'return tf.searchsorted(tf.constant(in1), tf.constant(in2)).numpy().tolist()',\n",
      " \"return tf.searchsorted(sorted_sequence=in1, values=in2, side='right')\",\n",
      " \"return tf.searchsorted(in1, in2, side='right')\",\n",
      " \"return tf.searchsorted(in1, in2, side='right')\"]\n",
      "\n",
      "Prompting for task: stackoverflow_30, description: compute Euclidean distance between two tensors\n",
      "['return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.expand_dims(in2, '\n",
      " 'axis=1))), axis=2))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1,in2)), axis=1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.expand_dims(in2, '\n",
      " '1))), axis=-1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1,in2)), axis=1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(in1 - in2), axis=1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1,in2)), axis=1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))',\n",
      " 'return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))']\n",
      "\n",
      "Prompting for task: stackoverflow_31, description: squared error between two tensors, one being a sparse tensor\n",
      "['dense1 = tf.sparse.to_dense(in1[0])\\n'\n",
      " '     error = tf.math.squared_difference(in1[1], dense1)\\n'\n",
      " '     return tf.reduce_sum(error).numpy()',\n",
      " 'dense1 = tf.sparse.to_dense(in1[0])\\n'\n",
      " '     error = tf.math.squared_difference(dense1, in1[1])\\n'\n",
      " '     return tf.reduce_sum(error).numpy()',\n",
      " 'in2 = tf.sparse.to_dense(in1[0], default_value=0)\\n'\n",
      " '     error = tf.math.squared_difference(in2, in1[1])\\n'\n",
      " '     return tf.reduce_sum(error).numpy()',\n",
      " 'dense_tensor = tf.sparse.to_dense(in1[0])\\n'\n",
      " '    error = tf.reduce_sum(tf.math.squared_difference(dense_tensor, in1[1]))\\n'\n",
      " '    return error',\n",
      " 'dense_from_sparse = tf.sparse.to_dense(in1[0])\\n'\n",
      " '     return tf.reduce_sum(tf.math.squared_difference(dense_from_sparse, '\n",
      " 'in1[1]))',\n",
      " 'dense1 = tf.sparse.to_dense(in1[0])\\n'\n",
      " '     return tf.reduce_sum(tf.square(tf.subtract(in1[1], dense1)))',\n",
      " 'dense_tensor = in1[1]\\n'\n",
      " 'sparse_tensor = tf.sparse.to_dense(in1[0])\\n'\n",
      " '\\n'\n",
      " 'squared_difference = tf.math.squared_difference(sparse_tensor, '\n",
      " 'dense_tensor)\\n'\n",
      " '\\n'\n",
      " 'return tf.reduce_sum(squared_difference)',\n",
      " 'sparse_tensor, dense_tensor = in1\\n'\n",
      " 'dense_from_sparse = tf.sparse.to_dense(sparse_tensor)\\n'\n",
      " 'square_error = tf.math.squared_difference(dense_from_sparse, dense_tensor)\\n'\n",
      " 'return tf.reduce_sum(square_error)',\n",
      " 'dense1 = tf.sparse.to_dense(in1[0])\\n'\n",
      " '     return tf.reduce_sum(tf.math.squared_difference(dense1, in1[1]))',\n",
      " 'dense_in1 = tf.sparse.to_dense(in1[0])\\n'\n",
      " '     diff = tf.subtract(dense_in1, in1[1])\\n'\n",
      " '     square = tf.square(diff)\\n'\n",
      " '     return tf.reduce_sum(square)']\n",
      "\n",
      "Prompting for task: stackoverflow_32, description: weighted sum across rows, where the column index is the weight\n",
      "['weights = tf.range(tf.shape(in1)[1])\\n'\n",
      " 'weights = tf.cast(weights, in1.dtype)\\n'\n",
      " 'in1 = in1 * weights\\n'\n",
      " 'return tf.reduce_sum(in1, axis=1)',\n",
      " 'weights = tf.range(tf.shape(in1)[-1])\\n'\n",
      " 'return tf.reduce_sum(tf.multiply(in1, weights), axis=-1)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, tf.range(tf.shape(in1)[1])), axis=1)',\n",
      " 'weights = tf.range(tf.shape(in1)[-1])\\n'\n",
      " 'tiled_weights = tf.broadcast_to(weights, tf.shape(in1))\\n'\n",
      " 'return tf.reduce_sum(tf.multiply(in1, tf.cast(tiled_weights, in1.dtype)), '\n",
      " 'axis=-1)',\n",
      " 'weights = tf.range(tf.shape(in1)[1], dtype=in1.dtype)\\n'\n",
      " 'weighted_sum = tf.reduce_sum(tf.multiply(in1, weights), axis=1)\\n'\n",
      " 'return weighted_sum',\n",
      " 'weights = tf.range(tf.shape(in1)[1])\\n'\n",
      " 'weighted_values = tf.multiply(in1, tf.cast(weights, in1.dtype))\\n'\n",
      " 'out = tf.reduce_sum(weighted_values, axis=1)\\n'\n",
      " 'return out',\n",
      " 'weights = tf.range(tf.shape(in1)[-1])\\n'\n",
      " 'weighted_sum = tf.reduce_sum(in1 * tf.cast(weights, tf.float32), axis=-1)\\n'\n",
      " 'return weighted_sum',\n",
      " 'weights = tf.range(tf.shape(in1)[1], dtype=in1.dtype)\\n'\n",
      " 'expanded_weights = tf.expand_dims(weights, axis=0)\\n'\n",
      " 'broadcasted_weights = tf.broadcast_to(expanded_weights, tf.shape(in1))\\n'\n",
      " 'result = tf.reduce_sum(in1 * broadcasted_weights, axis=1)\\n'\n",
      " 'return result',\n",
      " 'weights = tf.range(start=0, limit=tf.shape(in1)[1], delta=1, '\n",
      " 'dtype=in1.dtype)\\n'\n",
      " 'weighted = tf.multiply(in1, weights)\\n'\n",
      " 'return tf.reduce_sum(weighted, axis=1)',\n",
      " 'weights = tf.range(tf.shape(in1)[-1])\\n'\n",
      " 'weighted_sum = tf.reduce_sum(tf.multiply(in1, weights), axis=-1)\\n'\n",
      " 'return weighted_sum']\n",
      "\n",
      "Prompting for task: stackoverflow_33, description: find the minimum distance between two sets of points\n",
      "['distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, '\n",
      " 'axis=1), tf.expand_dims(in2, axis=0))), axis=-1))\\n'\n",
      " '     return tf.reduce_min(distances, axis=-1)',\n",
      " 'distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, '\n",
      " 'axis=1), tf.expand_dims(in2, axis=0))), axis=2))\\n'\n",
      " '     min_distances = tf.reduce_min(distances, axis=1)\\n'\n",
      " '     return min_distances',\n",
      " 'distances = '\n",
      " 'tf.reduce_min(tf.reduce_sum(tf.square(tf.subtract(in1[:,tf.newaxis], in2)), '\n",
      " '2), 1)\\n'\n",
      " 'return distances',\n",
      " 'distances = '\n",
      " 'tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, '\n",
      " 'axis=1), tf.expand_dims(in2, axis=0))), axis=2)), axis=1)\\n'\n",
      " '     return distances',\n",
      " 'distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, '\n",
      " '2), tf.expand_dims(in2, 0))), 1))\\n'\n",
      " 'min_dists = tf.reduce_min(distances, 1)\\n'\n",
      " 'return min_dists',\n",
      " 'distances = '\n",
      " 'tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, '\n",
      " 'axis=1), tf.expand_dims(in2, axis=0))), axis=-1)), axis=-1)\\n'\n",
      " '     return distances',\n",
      " 'distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, '\n",
      " 'axis=1), tf.expand_dims(in2, axis=0))), axis=-1))\\n'\n",
      " 'min_distances = tf.reduce_min(distances, axis=-1)\\n'\n",
      " 'return min_distances',\n",
      " 'distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, '\n",
      " 'axis=1), tf.expand_dims(in2, axis=0))), axis=2))\\n'\n",
      " '     min_distances = tf.reduce_min(distances, axis=1)\\n'\n",
      " '     return min_distances',\n",
      " 'distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, '\n",
      " '1), tf.expand_dims(in2, 0))), -1))\\n'\n",
      " '     min_distance_idx = tf.argmin(distances, 1)\\n'\n",
      " '     return tf.gather(tf.reshape(distances, [-1]), min_distance_idx)',\n",
      " 'distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, '\n",
      " '1), tf.expand_dims(in2, 0))), 2))\\n'\n",
      " '     return tf.reduce_min(distances, 1)']\n",
      "\n",
      "Prompting for task: stackoverflow_34, description: compute a weighted sum of tensors\n",
      "['weighted_tensors = [tf.multiply(t, w) for t, w in zip(in1, in2)]\\n'\n",
      " '     return tf.reduce_sum(tf.stack(weighted_tensors, axis=0), axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, [-1, 1, 1])), axis=0)',\n",
      " 'weights = tf.expand_dims(tf.cast(in2, dtype=tf.float32), -1)\\n'\n",
      " 'weighted_tensors = tf.multiply(in1, weights)\\n'\n",
      " 'result = tf.reduce_sum(weighted_tensors, axis=0)\\n'\n",
      " 'return result',\n",
      " 'output = tf.tensordot(in1, in2, axes=0)\\n'\n",
      " '     return tf.reduce_sum(output, axis=0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, [-1, 1, 1])), axis=0)',\n",
      " 'return tf.tensordot(in1, in2, axes=0)',\n",
      " 'in1 = tf.cast(in1, tf.float32)\\n'\n",
      " 'in2 = tf.reshape(in2, (-1, 1, 1))\\n'\n",
      " 'return tf.reduce_sum(tf.multiply(in1, in2), axis=0)',\n",
      " 'in1 = tf.constant(in1)\\n'\n",
      " '     in2 = tf.constant(in2)\\n'\n",
      " '     in2 = tf.expand_dims(in2, axis=1)\\n'\n",
      " '     in2 = tf.expand_dims(in2, axis=2)\\n'\n",
      " '     in2 = tf.broadcast_to(in2, tf.shape(in1))\\n'\n",
      " '     out = tf.multiply(in1, in2)\\n'\n",
      " '     out = tf.reduce_sum(out, axis=0)\\n'\n",
      " '     return out.numpy()',\n",
      " 'return tf.reduce_sum(tf.multiply(tf.expand_dims(in2, -1), in1), axis = 0)',\n",
      " 'return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(tf.expand_dims(in2, '\n",
      " '-1), -1)), axis=0)']\n",
      "\n",
      "Prompting for task: stackoverflow_35, description: linear interpolation between two tensors\n",
      "['return tf.add(tf.multiply(in1, tf.reshape(1.0 - in3, [-1, 1, 1])), '\n",
      " 'tf.multiply(in2, tf.reshape(in3, [-1, 1, 1])))',\n",
      " 'return tf.add(tf.multiply(in1, tf.reshape(1.0 - in3, [-1, 1, 1])), '\n",
      " 'tf.multiply(in2, tf.reshape(in3, [-1, 1, 1])))',\n",
      " 'return tf.add(tf.multiply(in1, tf.reshape(1.0 - in3, [3, 1, 1])), '\n",
      " 'tf.multiply(in2, tf.reshape(in3, [3, 1, 1])))',\n",
      " 'return tf.add(tf.multiply(in1, tf.reshape(1.0 - in3, [-1, 1, 1])), '\n",
      " 'tf.multiply(in2, tf.reshape(in3, [-1, 1, 1])))',\n",
      " 'in3 = tf.reshape(in3, (-1,1,1))\\nreturn (1-in3)*in1 + in3*in2',\n",
      " 'return in1 + tf.multiply(in3[:, tf.newaxis, tf.newaxis], (in2 - in1))',\n",
      " 'return tf.add(tf.multiply(in1, tf.subtract(1.0 ,in3)), tf.multiply(in2, '\n",
      " 'in3))',\n",
      " 'in3 = tf.reshape(in3, [-1, 1, 1])\\n     return in1 * (1 - in3) + in2 * in3',\n",
      " 'return tf.add(tf.multiply(in1, tf.broadcast_to(tf.reshape(1 - in3, [3, 1, '\n",
      " '1]), [3, 3, 2])), tf.multiply(in2, tf.broadcast_to(tf.reshape(in3, [3, 1, '\n",
      " '1]), [3, 3, 2])))',\n",
      " 'return tf.add(tf.multiply(in1, tf.reshape(1.0 - in3, [-1, 1, 1])), '\n",
      " 'tf.multiply(in2, tf.reshape(in3, [-1, 1, 1])))']\n",
      "\n",
      "Prompting for task: stackoverflow_36, description: divide each element by the column index\n",
      "['in1 = tf.divide(in1, tf.range(1, tf.shape(in1)[0]+1))\\n     return in1',\n",
      " '# We use the tf.divide function to divide each element by the column index '\n",
      " 'with the help of tf.range and tf.cast functions.\\n'\n",
      " '  \\n'\n",
      " '    in1 = tf.cast(in1, tf.float32)   # Converting the input tensor to '\n",
      " 'float32 for performing division\\n'\n",
      " '    denom = tf.range(1, tf.shape(in1)[0] + 1, dtype=tf.float32) # Creating a '\n",
      " 'tensor with column indices\\n'\n",
      " '    return tf.divide(in1, denom) # Dividing each element of in1 by the '\n",
      " 'corresponding column index. The broadcasting rule applies here.',\n",
      " 'return tf.divide(in1, tf.range(1, tf.size(in1) + 1))',\n",
      " 'shape = tf.shape(in1)\\n'\n",
      " 'column_indices = tf.range(start=1, limit=shape[0]+1, delta=1)\\n'\n",
      " 'column_indices = tf.cast(column_indices, dtype=tf.float32)\\n'\n",
      " 'return tf.divide(in1, column_indices)',\n",
      " 'in1 = tf.constant(in1, dtype=tf.float32)\\n'\n",
      " '     col_indices = tf.range(1, tf.size(in1) + 1, dtype=tf.float32)\\n'\n",
      " '     return tf.divide(in1, col_indices)',\n",
      " 'in1 = tf.cast(in1, dtype=tf.float32)\\n'\n",
      " '     shape = tf.shape(in1)\\n'\n",
      " '     divisor = tf.range(1, tf.cast(shape[-1], tf.float32) + 1)\\n'\n",
      " '     divisor = tf.broadcast_to(divisor, shape)\\n'\n",
      " '     return tf.divide(in1, divisor)',\n",
      " 'import tensorflow as tf\\n'\n",
      " 'def transform(in1):\\n'\n",
      " '    in1 = tf.cast(in1, dtype=tf.float32)\\n'\n",
      " '    col_indices = tf.range(start=1, limit=tf.shape(in1)[0]+1, delta=1, '\n",
      " 'dtype=tf.float32)\\n'\n",
      " '    return tf.divide(in1, col_indices)',\n",
      " 'shape = tf.shape(in1)\\n'\n",
      " 'col_indices = tf.range(1, shape[1] + 1, dtype=in1.dtype)\\n'\n",
      " 'col_indices = tf.broadcast_to(col_indices, shape)\\n'\n",
      " 'return tf.divide(in1, col_indices)',\n",
      " 'return tf.divide(in1, tf.range(1, tf.shape(in1)[0]+1))',\n",
      " '# First, we need to convert the input into a tensorflow tensor\\n'\n",
      " '    tensor = tf.constant(in1, dtype=tf.float32)\\n'\n",
      " '    # Then, we get the shape of the tensor, which gives us the column count\\n'\n",
      " '    col_count = tf.shape(tensor)[0]\\n'\n",
      " '    # We generate a range tensor from 1 to the column count\\n'\n",
      " '    range_tensor = tf.range(1, col_count+1, dtype=tf.float32)\\n'\n",
      " '    # Finally, we divide the input tensor by the range tensor\\n'\n",
      " '    result = tf.divide(tensor, range_tensor)\\n'\n",
      " '    return result']\n",
      "\n",
      "Prompting for task: stackoverflow_37, description: dot product a vector with last dimension of a tensor\n",
      "['return tf.tensordot(in1, in2, axes=[[-1], [0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=[[3],[0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=[[-1], [0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=[[-1],[0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=[-1,0])',\n",
      " 'return tf.tensordot(in1, in2, axes=[[-1], [0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=[[-1],[0]])',\n",
      " 'return tf.tensordot(in1, in2, axes=1)',\n",
      " 'return tf.tensordot(in1, in2, axes=1)']\n",
      "\n",
      "Prompting for task: stackoverflow_38, description: compute the product of marked elements\n",
      "['return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)',\n",
      " 'mask = tf.boolean_mask(in1, in2)\\n'\n",
      " 'res = tf.reduce_prod(mask, axis=1)\\n'\n",
      " 'return res',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1,in2),axis=1)',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, bool)), axis=1)',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1).numpy().tolist()',\n",
      " 'masked_values = tf.boolean_mask(in1, in2)\\n'\n",
      " '     result = tf.math.segment_prod(masked_values, tf.cumsum(in2, axis=1) - '\n",
      " '1)\\n'\n",
      " '     return result',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1,in2), axis=1)',\n",
      " 'return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)']\n",
      "\n",
      "Prompting for task: stackoverflow_39, description: (\\'set to 0 the elements with absolute value less than 1, and square the other elements\\')\n",
      "['# we first create a mask of elements that are less than 1 in absolute value\\n'\n",
      " '    mask = tf.less(tf.abs(in1), 1)\\n'\n",
      " '\\n'\n",
      " '    # we set these elements to 0\\n'\n",
      " '    in1_zeroed = tf.where(mask, tf.zeros_like(in1), in1)\\n'\n",
      " '\\n'\n",
      " '    # we square the remaining elements\\n'\n",
      " '    return tf.square(in1_zeroed)',\n",
      " 'abs_in1 = tf.abs(in1)\\n'\n",
      " 'mask = tf.greater(abs_in1, 1.0)\\n'\n",
      " 'res = tf.where(mask, tf.square(in1), tf.zeros_like(in1))\\n'\n",
      " 'return res',\n",
      " 'return tf.where(tf.abs(in1)<1, 0, tf.square(in1))',\n",
      " 'mask = tf.abs(in1) < 1\\nin1 = tf.where(mask, 0, tf.square(in1))\\nreturn in1',\n",
      " 'abs_input = tf.abs(in1)\\n'\n",
      " 'mask = tf.greater(abs_input, 1)\\n'\n",
      " 'squared_input = tf.square(in1)\\n'\n",
      " 'zeros = tf.zeros_like(in1)\\n'\n",
      " 'return tf.where(mask, squared_input, zeros)',\n",
      " 'in2 = tf.where(tf.abs(in1) < 1., tf.zeros_like(in1), in1)\\n'\n",
      " '     return tf.square(in2)',\n",
      " 'cond = tf.greater(tf.abs(in1), 1.0)\\n'\n",
      " 'out1 = tf.where(cond, tf.square(in1), 0.0)\\n'\n",
      " 'return out1',\n",
      " 'filtered_elements = tf.where(tf.abs(in1) < 1, 0, in1)\\n'\n",
      " 'return tf.square(filtered_elements)',\n",
      " 'abs_in1 = tf.abs(in1)\\n'\n",
      " 'mask = tf.greater(abs_in1, 1.0)\\n'\n",
      " 'out = tf.where(mask, tf.square(in1), tf.zeros_like(in1))\\n'\n",
      " 'return out',\n",
      " 'return tf.where(tf.abs(in1) < 1, 0, tf.square(in1))']\n",
      "\n",
      "Prompting for task: stackoverflow_40, description: use the output of tf.nn.top_k to make a sparse tensor\n",
      "['values, indices = tf.math.top_k(in1, len(in1))\\n'\n",
      " 'return tf.scatter_nd(in2, values, tf.constant([3, 5]))',\n",
      " 'values, indices = tf.math.top_k(in1, k=in1.shape[0])\\n'\n",
      " 'return tf.scatter_nd(tf.expand_dims(indices, 1), values, '\n",
      " 'tf.constant([in1.shape[0]]))',\n",
      " 'values, indices = tf.math.top_k(in1, k=in1.shape[0])\\n'\n",
      " 'out = tf.scatter_nd(indices, values, tf.constant([in1.shape[0], '\n",
      " 'tf.reduce_max(indices)+1]))\\n'\n",
      " 'return out',\n",
      " 'values, indices = tf.math.top_k(in1, k=in1.shape[0])\\n'\n",
      " 'sparse_tensor = tf.scatter_nd(tf.expand_dims(indices,1), values, '\n",
      " 'tf.constant([in1.shape[0]]))\\n'\n",
      " 'return sparse_tensor',\n",
      " 'top_values, top_indices = tf.math.top_k(in1, k=tf.shape(in1)[0])\\n'\n",
      " 'sparse_tensor = tf.scatter_nd(tf.expand_dims(top_indices, 1), top_values, '\n",
      " 'tf.shape(in1))\\n'\n",
      " 'transformed_tensor = tf.gather(sparse_tensor, in2)\\n'\n",
      " 'return transformed_tensor',\n",
      " 'values, indices = tf.math.top_k(in1, len(in1))\\n'\n",
      " 'return tf.scatter_nd(tf.cast(in2, tf.int64), values, [3,5])',\n",
      " 'values, indices = tf.nn.top_k(in1, len(in1))\\n'\n",
      " 'sparse_tensor = tf.scatter_nd(indices, values, '\n",
      " 'tf.constant([tf.reduce_max(indices) + 1, len(in1)]))\\n'\n",
      " 'return sparse_tensor',\n",
      " 'values, indices = tf.math.top_k(in1, k=len(in1))\\n'\n",
      " 'updates = tf.ones(tf.shape(values))\\n'\n",
      " 'sparse_tensor = tf.scatter_nd(indices=tf.expand_dims(indices, 1), '\n",
      " 'updates=updates, shape=[tf.reduce_max(indices) + 1])\\n'\n",
      " 'return tf.transpose(sparse_tensor)',\n",
      " 'val, idx = tf.math.top_k(in1)\\n'\n",
      " 'out = tf.scatter_nd(tf.cast(idx[None], tf.int64), val, tf.constant(in2))\\n'\n",
      " 'return tf.reshape(out, (-1, in2[-1][1]+1))',\n",
      " 'values, indices = tf.math.top_k(in1, k=tf.shape(in1)[0])\\n'\n",
      " 'sparse_tensor = tf.scatter_nd(tf.reshape(indices, (-1, 1)), values, '\n",
      " '[tf.shape(in1)[0]])\\n'\n",
      " 'dense_tensor = tf.reshape(sparse_tensor, (tf.shape(in2)[0], '\n",
      " 'tf.shape(in2)[1]))\\n'\n",
      " 'return dense_tensor']\n",
      "\n",
      "Prompting for task: stackoverflow_41, description: copy all elements except at the given index\n",
      "['indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'mask = tf.not_equal(indices, in2)\\n'\n",
      " 'return tf.boolean_mask(in1, mask)',\n",
      " 'indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'mask = tf.not_equal(indices, in2)\\n'\n",
      " 'return tf.boolean_mask(in1, mask)',\n",
      " 'return tf.boolean_mask(in1, tf.not_equal(tf.range(tf.shape(in1)[0]), in2))',\n",
      " 'indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'mask = tf.not_equal(indices, in2)\\n'\n",
      " 'return tf.boolean_mask(in1, mask)',\n",
      " 'in1 = tf.constant(in1)\\n'\n",
      " '     indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " '     mask = tf.not_equal(indices, in2)\\n'\n",
      " '     out = tf.boolean_mask(in1, mask)\\n'\n",
      " '     return out.numpy()',\n",
      " 'indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'mask = tf.not_equal(indices, in2)\\n'\n",
      " 'return tf.boolean_mask(in1, mask)',\n",
      " 'indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " 'mask = tf.not_equal(indices, in2)\\n'\n",
      " 'out = tf.boolean_mask(in1, mask)\\n'\n",
      " 'return out',\n",
      " 'in1 = tf.constant(in1)\\n'\n",
      " '     in2 = tf.constant(in2)\\n'\n",
      " '     indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " '     mask = tf.not_equal(indices, in2)\\n'\n",
      " '     return tf.boolean_mask(in1, mask)',\n",
      " 'return tf.concat([in1[:in2], in1[in2+1:]], axis=0)',\n",
      " 'indices = tf.range(tf.shape(in1)[0])\\n'\n",
      " '    return tf.boolean_mask(in1, tf.not_equal(indices, in2))']\n",
      "\n",
      "Prompting for task: stackoverflow_42, description: create a binary vector where the max element is 1\n",
      "['max_elem = tf.reduce_max(in1)\\n'\n",
      " 'equal_mask = tf.equal(in1, max_elem)\\n'\n",
      " 'binary_vector = tf.cast(equal_mask, tf.int32)\\n'\n",
      " 'return binary_vector',\n",
      " 'max_val = tf.reduce_max(in1)\\n'\n",
      " 'binary_vec = tf.equal(in1, max_val)\\n'\n",
      " 'binary_vec = tf.cast(binary_vec, tf.int32)\\n'\n",
      " 'return binary_vec',\n",
      " 'max_elem = tf.reduce_max(in1)\\n'\n",
      " 'binary_vector = tf.where(tf.equal(in1, max_elem), 1, 0)\\n'\n",
      " 'return binary_vector',\n",
      " 'max_value_index = tf.argmax(in1, 0)\\n'\n",
      " 'output = tf.one_hot(max_value_index, tf.size(in1))\\n'\n",
      " 'return output.numpy()',\n",
      " 'max_elem = tf.reduce_max(in1)\\n'\n",
      " 'return tf.cast(tf.equal(in1, max_elem), tf.int32)',\n",
      " 'max_val = tf.reduce_max(in1)\\n'\n",
      " 'result = tf.where(tf.equal(in1, max_val), 1, 0)\\n'\n",
      " 'return result',\n",
      " 'max_value = tf.reduce_max(in1)\\n'\n",
      " 'return tf.cast(tf.equal(in1, max_value), tf.int32)',\n",
      " 'max_value = tf.reduce_max(in1)\\n'\n",
      " 'out = tf.cast(tf.equal(in1, max_value), tf.int32)\\n'\n",
      " 'return out',\n",
      " 'max_val = tf.reduce_max(in1)\\n'\n",
      " 'binary_vec = tf.where(tf.equal(in1, max_val), 1, 0)\\n'\n",
      " 'return binary_vec',\n",
      " 'max_value = tf.reduce_max(in1)\\n'\n",
      " 'return tf.cast(tf.equal(in1, max_value), tf.int32)']\n",
      "\n",
      "Prompting for task: stackoverflow_43, description: extract elements of a tensor given row indices\n",
      "['return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], '\n",
      " 'axis=1))',\n",
      " 'return tf.gather_nd(in1, tf.transpose(tf.stack([in2, '\n",
      " 'tf.range(tf.shape(in2)[0])])))',\n",
      " 'return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], '\n",
      " 'axis=-1))',\n",
      " 'return tf.gather(in1, in2, axis=1)',\n",
      " 'return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], '\n",
      " 'axis=1))',\n",
      " 'return tf.gather_nd(in1, tf.stack((tf.range(tf.shape(in2)[0]), in2), '\n",
      " 'axis=-1))',\n",
      " 'return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], '\n",
      " 'axis=1))',\n",
      " 'return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], '\n",
      " 'axis=1))',\n",
      " 'return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], '\n",
      " 'axis=1))',\n",
      " 'return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], '\n",
      " 'axis=1))']\n",
      "\n",
      "Prompting for task: stackoverflow_44, description: sum across columns for pairs of consecutive rows\n",
      "['pairs = tf.reshape(in1, (-1, 2, in1.shape[-1]))\\n'\n",
      " 'return tf.reduce_sum(pairs, axis=1)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)',\n",
      " 'res = []\\n'\n",
      " '     for i in range(0, len(in1), 2):\\n'\n",
      " '          res.append(tf.add(in1[i], in1[i+1]))\\n'\n",
      " '     return np.array(res)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, [-1, 2, in1.shape[1]]), axis=1)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)',\n",
      " 'reshaped = tf.reshape(in1, (-1, 2, in1.shape[1]))\\n'\n",
      " '     return tf.reduce_sum(reshaped, axis=1)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), 1)',\n",
      " 'return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)']\n",
      "\n",
      "Prompting for task: stackoverflow_45, description: reverse the order in the marked rows\n",
      "['return tf.where(tf.broadcast_to(tf.expand_dims(in2, '\n",
      " 'axis=-1),tf.shape(in1)),tf.reverse(in1,[2]),in1)',\n",
      " 'indices = tf.constant([[i] for i in range(len(in2))])\\n'\n",
      " '    reverse_mask = tf.boolean_mask(indices, in2) \\n'\n",
      " '    out1 = tf.reverse(in1[reverse_mask], [1])\\n'\n",
      " '    updates = tf.where(in2, out1, in1)\\n'\n",
      " '    return tf.reshape(updates, tf.shape(in1))',\n",
      " 'return tf.where(tf.cast(in2, bool), tf.reverse(in1, [-1]), in1)',\n",
      " 'return tf.where(tf.expand_dims(in2, -1), tf.reverse(in1, [-1]), in1)',\n",
      " 'reverse_mask = tf.boolean_mask(in1, in2, axis=1)\\n'\n",
      " '     reverse_mask = tf.reverse(reverse_mask, axis=[-1])\\n'\n",
      " '     in1 = tf.boolean_mask(in1, tf.logical_not(in2), axis=1)\\n'\n",
      " '\\n'\n",
      " '     indices = tf.where(in2)\\n'\n",
      " '     updates = tf.reshape(reverse_mask, [-1])\\n'\n",
      " '     shape = tf.shape(in1)\\n'\n",
      " '\\n'\n",
      " '     return tf.tensor_scatter_nd_update(in1, indices, updates)',\n",
      " 'return tf.where(tf.broadcast_to(tf.reshape(in2,(-1,1)), tf.shape(in1)), '\n",
      " 'tf.reverse(in1,[-1]), in1)',\n",
      " 'return tf.where(tf.expand_dims(in2, -1), tf.reverse(in1, [-1]), in1)',\n",
      " 'return tf.where(tf.cast(tf.expand_dims(in2, axis=-1), tf.bool), '\n",
      " 'tf.reverse(in1, axis=[-1]), in1)',\n",
      " 'out = tf.where(tf.reshape(in2,(-1,1)), tf.reverse(in1,[-1]), in1)\\n'\n",
      " 'return out',\n",
      " 'return tf.where(tf.broadcast_to(tf.expand_dims(in2, axis=-1), '\n",
      " 'tf.shape(in1)), tf.reverse(in1, axis=[-1]), in1)']\n",
      "\n",
      "Prompting for task: stackoverflow_46, description: convert segment lengths to segment ids\n",
      "['segment_lengths = tf.constant(in1, dtype=tf.int32)\\n'\n",
      " 'segment_positions = tf.range(tf.reduce_sum(segment_lengths))\\n'\n",
      " 'segment_ids = tf.minimum(tf.searchsorted(segment_lengths, segment_positions, '\n",
      " \"side='right'), tf.size(segment_lengths) - 1)\\n\"\n",
      " 'return segment_ids.numpy().tolist()',\n",
      " 'return tf.repeat(tf.range(tf.size(in1)), in1)',\n",
      " 'return tf.repeat(tf.range(tf.shape(in1)[0]), in1)',\n",
      " 'return tf.cumsum(tf.ones_like(in1), exclusive=True)',\n",
      " 'return tf.repeat(tf.range(tf.size(in1)), in1)',\n",
      " 'ids = tf.repeat(tf.range(tf.size(in1)), in1)\\nreturn ids',\n",
      " 'return tf.repeat(tf.range(tf.size(in1)), in1)',\n",
      " 'return tf.repeat(tf.range(tf.size(in1)), in1)',\n",
      " 'return tf.repeat(tf.range(tf.shape(in1)[0]), in1)',\n",
      " 'return tf.repeat(tf.range(tf.shape(in1)[0]), in1)']\n",
      "\n",
      "Prompting for task: stackoverflow_47, description: put given values into a sequence mask\n",
      "['return tf.where(in2, np.reshape(tf.range(tf.size(in2)), tf.shape(in2)), 0)',\n",
      " 'indices = tf.where(in2)\\n'\n",
      " '     out = tf.tensor_scatter_nd_update(in2, indices, in1)\\n'\n",
      " '     return tf.cast(out, tf.int32)',\n",
      " 'seq_mask = tf.cast(in2, tf.int32)\\n'\n",
      " 'count_mask = tf.reduce_sum(seq_mask, axis=1)\\n'\n",
      " '\\n'\n",
      " 'indices = tf.range(tf.reduce_sum(count_mask))\\n'\n",
      " '\\n'\n",
      " 'updates = tf.gather(in1, indices)\\n'\n",
      " '\\n'\n",
      " 'shape = tf.shape(in2, out_type=tf.int32)\\n'\n",
      " '\\n'\n",
      " 'fun_output = tf.scatter_nd(tf.where(in2), updates, shape)\\n'\n",
      " '\\n'\n",
      " 'return fun_output',\n",
      " 'out = tf.where(in2, tf.reshape(in1, tf.shape(in2)), 0)\\nreturn out',\n",
      " 'sequence = tf.cast(in1, dtype=tf.int32)\\n'\n",
      " 'mask = tf.cast(in2, dtype=tf.bool)\\n'\n",
      " 'shape = tf.shape(mask)\\n'\n",
      " '\\n'\n",
      " '# Calculate the maximum number of elements to store in each row of the final '\n",
      " 'output\\n'\n",
      " 'max_vals = tf.reduce_sum(tf.cast(mask, dtype=tf.int32), axis=1)\\n'\n",
      " '\\n'\n",
      " '# Create indices for each element in the original input\\n'\n",
      " 'indices = tf.expand_dims(tf.range(tf.reduce_sum(max_vals)), axis=0)\\n'\n",
      " '\\n'\n",
      " '# Assign the indices to its corresponding value in the mask\\n'\n",
      " 'mask_indices = tf.reshape(tf.boolean_mask(indices, mask), shape)\\n'\n",
      " '\\n'\n",
      " '# Create placeholder for the final output, filled with zeroes\\n'\n",
      " 'output = tf.fill(shape, 0)\\n'\n",
      " '\\n'\n",
      " '# Insert elements of the sequence into their corresponding place in the '\n",
      " 'output\\n'\n",
      " 'output = tf.tensor_scatter_nd_update(output, tf.where(mask), sequence)\\n'\n",
      " '\\n'\n",
      " 'return output',\n",
      " 'mask = tf.boolean_mask(in1, tf.reshape(in2, [-1]))\\n'\n",
      " '     filled_mask = tf.tensor_scatter_nd_update(tf.zeros_like(in2, '\n",
      " 'dtype=in1.dtype),\\n'\n",
      " '                                               tf.where(in2),\\n'\n",
      " '                                               mask)\\n'\n",
      " '     return filled_mask',\n",
      " 'out = tf.where(in2, tf.reshape(in1[:tf.reduce_sum(tf.cast(in2, tf.int32))], '\n",
      " 'tf.shape(in2)), 0)\\n'\n",
      " 'return out',\n",
      " 'mask = tf.cast(in2, tf.int32)\\n'\n",
      " 'accumulated_mask = tf.cumsum(mask, axis=-1)\\n'\n",
      " 'flattened_mask = tf.reshape(accumulated_mask, [-1])\\n'\n",
      " 'in1_gathered = tf.gather(in1, flattened_mask - 1)\\n'\n",
      " 'result = tf.reshape(in1_gathered, tf.shape(in2))\\n'\n",
      " 'result *= in2\\n'\n",
      " 'return result',\n",
      " 'return tf.where(in2, tf.reshape(in1, in2.shape), 0)',\n",
      " '# find the indices where the mask is True\\n'\n",
      " '  indices = tf.where(in2)\\n'\n",
      " '  # Gather the required values from the input array\\n'\n",
      " '  values = tf.gather(in1, indices[:, 0])\\n'\n",
      " '  # Use scatter_nd to replace the True values in the mask with the gathered '\n",
      " 'values\\n'\n",
      " '  result = tf.scatter_nd(indices, values, tf.shape(in2))\\n'\n",
      " '  return result']\n",
      "\n",
      "Prompting for task: stackoverflow_48, description: find the indices of all elements\n",
      "['return [tf.where(tf.equal(in1, n)).numpy()[0][0] for n in in2]',\n",
      " 'return [tf.where(tf.equal(in1, x))[0] for x in in2]',\n",
      " 'return tf.where(tf.equal(tf.expand_dims(in1, axis=-1), in2)).numpy()[:, 1]',\n",
      " 'return tf.where(tf.equal(tf.expand_dims(in1, 1), in2)).numpy()[:, 1]',\n",
      " 'return tf.where(tf.equal(tf.expand_dims(in1, axis=-1), in2)).numpy()[:,1]',\n",
      " 'return [tf.where(tf.equal(in1, x)).numpy()[0][0] for x in in2]',\n",
      " 'return [tf.where(tf.equal(in1, x)).numpy()[0][0] for x in in2]',\n",
      " 'return tf.where(tf.equal(tf.expand_dims(in1, 1), in2)).numpy()[:,1]',\n",
      " 'return tf.where(tf.equal(tf.expand_dims(in1, 1), '\n",
      " 'in2)).numpy().flatten().tolist()',\n",
      " 'return [tf.where(tf.equal(in1, x)).numpy() for x in in2]']\n",
      "\n",
      "Prompting for task: stackoverflow_49, description: multiply tensors by scalars in a batched way\n",
      "['return tf.multiply(in1, tf.expand_dims(tf.expand_dims(tf.expand_dims(in2, '\n",
      " '-1), -1), -1))',\n",
      " 'return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(in2, axis=[1,2,3]))',\n",
      " 'in1 = tf.constant(in1)\\n'\n",
      " '     in2 = tf.expand_dims(tf.expand_dims(tf.expand_dims(in2, axis=-1), '\n",
      " 'axis=-1), axis=-1)\\n'\n",
      " '     return tf.multiply(in1, in2)',\n",
      " 'return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))',\n",
      " 'return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))',\n",
      " 'in2 = tf.reshape(in2, [-1, 1, 1, 1])\\n return tf.multiply(in1, in2)',\n",
      " 'return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))',\n",
      " 'return tf.multiply(in1, tf.expand_dims(tf.expand_dims(tf.expand_dims(in2, '\n",
      " 'axis=-1), axis=-1), axis=-1))',\n",
      " 'return tf.multiply(in1, tf.reshape(in2, (-1, 1, 1, 1)))']\n",
      "\n",
      "Prompting for task: stackoverflow_50, description: create a binary matrix where a specified column is set to one\n",
      "['column = tf.constant(in1)\\n'\n",
      " 'eye = tf.eye(5, 6)\\n'\n",
      " 'column_vector = tf.gather(eye, column, axis=1)\\n'\n",
      " 'return tf.cast(column_vector, tf.int32)',\n",
      " 'matrix = tf.zeros([5, 5], tf.int32)\\n'\n",
      " 'to_append = tf.ones([5, 1], tf.int32)\\n'\n",
      " '\\n'\n",
      " 'result = tf.concat([matrix[:,:in1], to_append, matrix[:, in1+1:]], axis=1)\\n'\n",
      " 'return result',\n",
      " 'ones = tf.ones((5, 1))\\n'\n",
      " 'zeros_1 = tf.zeros((5, in1))\\n'\n",
      " 'zeros_2 = tf.zeros((5, 5-in1-1))\\n'\n",
      " 'return tf.concat([zeros_1, ones, zeros_2], axis=1)',\n",
      " 'return tf.eye(5, num_columns=in1+2)[:, [in1]]',\n",
      " 'return tf.transpose(tf.one_hot(in1, 5))',\n",
      " 'return tf.one_hot(tf.zeros(in1, dtype=tf.int32), in1, axis=1)',\n",
      " 'ten_zeros = tf.zeros([5, 6])\\n'\n",
      " 'ten_ones = tf.ones([5, 1])\\n'\n",
      " 'ten_zeros = tf.concat([ten_zeros[:, :in1], ten_ones, ten_zeros[:, in1+1:]], '\n",
      " 'axis=1)\\n'\n",
      " 'return ten_zeros',\n",
      " '# first, create a zeros matrix of shape [in1, in1] using tf.zeros.\\n'\n",
      " '# then, use tf.tensor_scatter_nd_update to update the specified column of '\n",
      " 'the zeros matrix to become all ones.\\n'\n",
      " 'def transform(in1):\\n'\n",
      " '    zeros = tf.zeros([in1, in1])\\n'\n",
      " '    indices = [[i, 3] for i in range(in1)]\\n'\n",
      " '    updates = tf.ones(in1)\\n'\n",
      " '    return tf.tensor_scatter_nd_update(zeros, indices, updates)',\n",
      " 'return tf.one_hot(tf.zeros(5, dtype=tf.int32), in1, axis=1)',\n",
      " 'matrix = tf.zeros([5, 5], dtype=tf.dtypes.int32)\\n'\n",
      " 'vector = tf.eye(5, dtype=tf.dtypes.int32)[:, in1]\\n'\n",
      " 'vector_reshaped = tf.reshape(vector, [5, 1])\\n'\n",
      " 'result = tf.concat([matrix[:, :in1], vector_reshaped, matrix[:, in1+1:]], '\n",
      " 'axis=1)\\n'\n",
      " 'return result']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_COMPLETIONS = 10\n",
    "i = 0\n",
    "for task_name, task in TASK_JSONS.items():\n",
    "    if \"completions\" in task:\n",
    "        continue \n",
    "    print(f\"Prompting for task: {task['name']}, description: {task['description']}\")\n",
    "    completions = prompt(SYSTEM_PROMPT, make_user_message(task, shuffle_operators=False), NUM_COMPLETIONS)\n",
    "    task[\"completions\"] = completions\n",
    "    pprint(completions)\n",
    "    print()\n",
    "    # i += 1\n",
    "    # if i > 10:\n",
    "    #     break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS_WITH_COMPLETIONS_FILE = CURRENT_DIRECTORY / \"tfcoder_dataset_with_completions.json\"\n",
    "for name, task in TASK_JSONS.items():\n",
    "    if \"parsed_examples\" in task:\n",
    "        del task[\"parsed_examples\"]\n",
    "TASKS_WITH_COMPLETIONS_FILE.write_text(json.dumps(DATASET, indent=4))\n",
    "for name, task in TASK_JSONS.items():\n",
    "    task[\"parsed_examples\"] = Example.from_json(task[\"examples\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract tf operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tf_operators(code_snippet):\n",
    "    pattern = r\"tf\\.[a-zA-Z_][a-zA-Z0-9_]*(?:\\.[a-zA-Z_][a-zA-Z0-9_]*)*\"\n",
    "    return set(re.findall(pattern, code_snippet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tf_operator_coverage_and_count(target_operators, completion_operators):\n",
    "    \"\"\"Extend to include all completion operators and mark those used in the target program.\"\"\"\n",
    "    completion_operators_count = Counter(completion_operators)\n",
    "    tf_operators_dict = {op: completion_operators_count[op] for op in completion_operators_count}\n",
    "\n",
    "    # Calculate coverage based on target program operators found in completions\n",
    "    covered_operators = set(target_operators).intersection(completion_operators)\n",
    "    coverage_percentage = len(covered_operators) / len(target_operators) * 100 if target_operators else 0\n",
    "\n",
    "    return {\n",
    "        \"tf_operators\": tf_operators_dict,\n",
    "        \"coverage_percentage\": coverage_percentage,\n",
    "        \"total_in_target\": len(target_operators),\n",
    "        \"total_covered\": len(covered_operators)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, task in TASK_JSONS.items():\n",
    "    if \"completions\" not in task:\n",
    "        continue\n",
    "    completions = task[\"completions\"]\n",
    "    completion_tf_operators = [op for completion in completions for op in extract_tf_operators(completion)]\n",
    "    target_program = task[\"target_program\"]\n",
    "    target_tf_operators = extract_tf_operators(target_program)\n",
    "    tf_operator_info = calculate_tf_operator_coverage_and_count(target_tf_operators, completion_tf_operators)\n",
    "\n",
    "    task[\"response\"] = {\n",
    "        \"task_id\": task.get(\"name\", \"unknown\"),\n",
    "        \"completions\": completions,\n",
    "        \"target-program\": task[\"target_program\"],\n",
    "        \"description\": task[\"description\"],\n",
    "        **tf_operator_info  # Includes adjusted tf_operators dictionary\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS_WITH_COMPLETIONS_FILE = CURRENT_DIRECTORY / \"tfcoder_dataset_with_completions.json\"\n",
    "for name, task in TASK_JSONS.items():\n",
    "    if \"parsed_examples\" in task:\n",
    "        del task[\"parsed_examples\"]\n",
    "TASKS_WITH_COMPLETIONS_FILE.write_text(json.dumps(DATASET, indent=4))\n",
    "for name, task in TASK_JSONS.items():\n",
    "    task[\"parsed_examples\"] = Example.from_json(task[\"examples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVERAGE_PERCENTAGES = [task[\"response\"][\"coverage_percentage\"] for task in list(TASK_JSONS.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.57407407407408"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average coverage percentage\n",
    "sum(COVERAGE_PERCENTAGES) / len(COVERAGE_PERCENTAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.0"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# median coverage percentage\n",
    "sorted_coverage_percentages = sorted(COVERAGE_PERCENTAGES)\n",
    "median_index = len(sorted_coverage_percentages) // 2\n",
    "sorted_coverage_percentages[median_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.95833333333334"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OLD_OUTPUT_FILE = CURRENT_DIRECTORY / \"output_tfcoder.old.json\"\n",
    "OLD_OUTPUT_JSON = json.loads(OLD_OUTPUT_FILE.read_text())\n",
    "\n",
    "OLD_COVERAGE_PERCENTAGES = [task[\"coverage_percentage\"] for task in OLD_OUTPUT_JSON]\n",
    "sum(OLD_COVERAGE_PERCENTAGES) / len(OLD_COVERAGE_PERCENTAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.0"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# median coverage percentage\n",
    "sorted_old_coverage_percentages = sorted(OLD_COVERAGE_PERCENTAGES)\n",
    "median_index = len(sorted_old_coverage_percentages) // 2\n",
    "sorted_old_coverage_percentages[median_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
