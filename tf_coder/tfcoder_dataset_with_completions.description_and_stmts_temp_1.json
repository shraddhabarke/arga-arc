[
    {
        "constants": "[]",
        "description": "Convert index tensor into pairs for SparseTensor indexing",
        "target_program": "tf.cast(tf.where(tf.sequence_mask(tf.math.bincount(in1))), tf.int32)",
        "source": "From an internal Google chat room, 09/07/2018",
        "name": "google_01",
        "examples": {
            "inputs": "[[0, 0, 0, 1, 3, 3],]",
            "outputs": "[[0, 0], [0, 1], [0, 2], [1, 0], [3, 0], [3, 1]]"
        },
        "response": {
            "task_id": "google_01",
            "completions": [
                "pairs = tf.stack([tf.math.bincount(in1), tf.range(tf.shape(in1)[0])], axis=1)\n     idx = tf.where(tf.not_equal(pairs[:, 0], 0))\n     pairs = tf.gather(pairs, idx)\n     return pairs[:, 0]",
                "return tf.stack([tf.math.floor_div(in1, 4), tf.math.floormod(in1, 4)], axis=-1)",
                "indices = tf.range(tf.shape(in1)[0])\nuniques, idx = tf.unique_with_counts(in1)\nreturn tf.stack([in1, tf.gather(tf.math.bincount(idx), idx)], axis=-1)",
                "return tf.stack([tf.math.bincount(in1), tf.gather(tf.range(tf.size(in1)), tf.argsort(in1))], axis=1)",
                "# We want to convert simple indices to pairs \n# First, We count the frequency of occurrence of each element in the input tensor\n# Then We create a sequence for each unique element in the input tensor up to its count\n# Finally, we gather all these sequences into our final output tensor.\n\ndef transform(in1):\n    count = tf.math.bincount(in1)  # count occurrences of each index\n    unique, _ = tf.unique_with_counts(in1)  # get unique indices\n    result = tf.concat([tf.stack([tf.tile([u], [c]), tf.range(c)], axis=1)\n                        for u, c in zip(unique.numpy(), count.numpy()[unique.numpy()])], axis=0)\n    return result",
                "return tf.stack([in1, tf.math.bincount(in1)], axis=1)",
                "return tf.stack([in1, tf.math.bincount(in1)], axis=1)",
                "return tf.stack([tf.math.floor_divide(in1, tf.reduce_max(in1) + 1), tf.math.floormod(in1,  tf.reduce_max(in1) + 1)], axis=1)",
                "range_tensor = tf.range(tf.shape(in1)[0])\nreturn tf.stack([in1, range_tensor], axis=1)",
                "indices = tf.range(tf.size(in1), dtype=in1.dtype)\nresult = tf.stack([in1, indices], axis=1)\nreturn result"
            ],
            "target-program": "tf.cast(tf.where(tf.sequence_mask(tf.math.bincount(in1))), tf.int32)",
            "description": "Convert index tensor into pairs for SparseTensor indexing",
            "tf_operators": {
                "tf.shape": 3,
                "tf.not_equal": 1,
                "tf.stack": 10,
                "tf.where": 1,
                "tf.gather": 3,
                "tf.range": 6,
                "tf.math.bincount": 6,
                "tf.math.floor_div": 1,
                "tf.math.floormod": 2,
                "tf.unique_with_counts": 2,
                "tf.size": 2,
                "tf.argsort": 1,
                "tf.tile": 1,
                "tf.concat": 1,
                "tf.reduce_max": 1,
                "tf.math.floor_divide": 1
            },
            "coverage_percentage": 40.0,
            "total_in_target": 5,
            "total_covered": 2
        },
        "completions": [
            "pairs = tf.stack([tf.math.bincount(in1), tf.range(tf.shape(in1)[0])], axis=1)\n     idx = tf.where(tf.not_equal(pairs[:, 0], 0))\n     pairs = tf.gather(pairs, idx)\n     return pairs[:, 0]",
            "return tf.stack([tf.math.floor_div(in1, 4), tf.math.floormod(in1, 4)], axis=-1)",
            "indices = tf.range(tf.shape(in1)[0])\nuniques, idx = tf.unique_with_counts(in1)\nreturn tf.stack([in1, tf.gather(tf.math.bincount(idx), idx)], axis=-1)",
            "return tf.stack([tf.math.bincount(in1), tf.gather(tf.range(tf.size(in1)), tf.argsort(in1))], axis=1)",
            "# We want to convert simple indices to pairs \n# First, We count the frequency of occurrence of each element in the input tensor\n# Then We create a sequence for each unique element in the input tensor up to its count\n# Finally, we gather all these sequences into our final output tensor.\n\ndef transform(in1):\n    count = tf.math.bincount(in1)  # count occurrences of each index\n    unique, _ = tf.unique_with_counts(in1)  # get unique indices\n    result = tf.concat([tf.stack([tf.tile([u], [c]), tf.range(c)], axis=1)\n                        for u, c in zip(unique.numpy(), count.numpy()[unique.numpy()])], axis=0)\n    return result",
            "return tf.stack([in1, tf.math.bincount(in1)], axis=1)",
            "return tf.stack([in1, tf.math.bincount(in1)], axis=1)",
            "return tf.stack([tf.math.floor_divide(in1, tf.reduce_max(in1) + 1), tf.math.floormod(in1,  tf.reduce_max(in1) + 1)], axis=1)",
            "range_tensor = tf.range(tf.shape(in1)[0])\nreturn tf.stack([in1, range_tensor], axis=1)",
            "indices = tf.range(tf.size(in1), dtype=in1.dtype)\nresult = tf.stack([in1, indices], axis=1)\nreturn result"
        ]
    },
    {
        "constants": "[]",
        "description": "Divide each row by the sum of that row",
        "target_program": "tf.divide(in1, tf.expand_dims(tf.reduce_sum(in1, axis=1), 1))",
        "source": "Real task encountered by Googler, 11/01/2018",
        "name": "google_02",
        "examples": {
            "inputs": "[[[0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 1.0, 0.0], [1.0, 1.0, 1.0, 1.0]],]",
            "outputs": "[[0.0, 1.0, 0.0, 0.0],    [0.0, 0.5, 0.5, 0.0],    [0.25, 0.25, 0.25, 0.25]]"
        },
        "response": {
            "task_id": "google_02",
            "completions": [
                "row_sums = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sums)",
                "row_sums = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sums)",
                "row_sums = tf.reduce_sum(in1, axis=1)\nrow_sums_reshaped = tf.reshape(row_sums, [-1, 1])\noutput = tf.divide(in1, row_sums_reshaped)\nreturn output",
                "return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))",
                "return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))",
                "row_sum = tf.reduce_sum(in1, axis=1, keepdims=True)\noutput = tf.divide(in1, row_sum)\nreturn output",
                "return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))",
                "row_sum = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sum)",
                "row_sums = tf.reduce_sum(in1, axis=1)\nrow_sums_exp = tf.expand_dims(row_sums, axis=1)\nresult = tf.divide(in1, row_sums_exp)\nreturn result",
                "return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))"
            ],
            "target-program": "tf.divide(in1, tf.expand_dims(tf.reduce_sum(in1, axis=1), 1))",
            "description": "Divide each row by the sum of that row",
            "tf_operators": {
                "tf.divide": 10,
                "tf.reduce_sum": 10,
                "tf.reshape": 1,
                "tf.expand_dims": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 3,
            "total_covered": 3
        },
        "completions": [
            "row_sums = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sums)",
            "row_sums = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sums)",
            "row_sums = tf.reduce_sum(in1, axis=1)\nrow_sums_reshaped = tf.reshape(row_sums, [-1, 1])\noutput = tf.divide(in1, row_sums_reshaped)\nreturn output",
            "return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))",
            "return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))",
            "row_sum = tf.reduce_sum(in1, axis=1, keepdims=True)\noutput = tf.divide(in1, row_sum)\nreturn output",
            "return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))",
            "row_sum = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sum)",
            "row_sums = tf.reduce_sum(in1, axis=1)\nrow_sums_exp = tf.expand_dims(row_sums, axis=1)\nresult = tf.divide(in1, row_sums_exp)\nreturn result",
            "return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))"
        ]
    },
    {
        "constants": "[]",
        "description": "Slice the first dimension of a SparseTensor",
        "target_program": "tf.divide(in1, tf.expand_dims(tf.reduce_sum(in1, axis=1), 1))",
        "source": "Real task encountered by Googler, 11/01/2018",
        "name": "google_03",
        "examples": {
            "inputs": "tf.SparseTensor(indices=[[0, 0, 0], [0, 1, 1], [1, 1, 1], [1, 1, 2]], values=[1., 1., 1., 1.], dense_shape=[2, 2, 800])",
            "outputs": "tf.SparseTensor(indices=[[0, 0, 0], [0, 1, 1]], values=[1., 1.], dense_shape=[1, 2, 800])"
        },
        "response": {
            "task_id": "google_03",
            "completions": [
                "# In this TensorFlow task, we need to slice the first dimension of a SparseTensor. For this, we can use the 'tf.sparse.slice' function.\n# The required 'start' and 'size' parameters will respectively be an array of zeros (same length as SparseTensor dimensions) and an array having '1' for the first element and '-1' for the rest.\n\nimport tensorflow as tf\n\ndef transform(sparse_tensor):\n    dims = len(sparse_tensor.dense_shape.numpy())\n    start = [0] * dims\n    size = [-1] * dims\n    size[0] = 1\n    return tf.sparse.slice(sparse_tensor, start, size)",
                "indices = in1.indices\n    values = in1.values\n    dense_shape = in1.dense_shape\n\n    mask = tf.less(indices[:, 0], 1)\n    new_indices = tf.boolean_mask(indices, mask)\n    new_values = tf.boolean_mask(values, mask)\n\n    new_dense_shape = tf.concat([[1], dense_shape[1:]], 0)\n\n    return tf.SparseTensor(indices=new_indices, values=new_values, dense_shape=new_dense_shape)",
                "condition = tf.less(in1.indices[:, 0], 1)\nindices = tf.boolean_mask(in1.indices, condition)\nvalues = tf.boolean_mask(in1.values, condition)\ndense_shape = tf.concat([[1], in1.dense_shape[1:]], axis=0)\nreturn tf.SparseTensor(indices, values, dense_shape)",
                "# we want to slice the first dimension \n# first let's find the indices where the first column of `indices` is zero, which denotes the first dimension\nmask = tf.equal(in1.indices[:,0], 0)\n# now we select those indices using `boolean_mask`\nindices = tf.boolean_mask(in1.indices, mask)\n# we also select the corresponding values\nvalues = tf.boolean_mask(in1.values, mask)\n# we need to adjust the dense_shape by setting the first element to 1 because we sliced the first dimension\ndense_shape = tf.concat([[1], in1.dense_shape[1:]], 0)\n# finally we return the new SparseTensor\nreturn tf.SparseTensor(indices, values, dense_shape)",
                "indices = tf.where(in1.indices[:, 0] < 1)\nnew_indices = tf.gather(in1.indices, indices)[:,0]\nnew_values = tf.gather(in1.values, indices)[:,0]\nnew_shape = tf.concat([[1], in1.dense_shape[1:]], axis=0)\nreturn tf.SparseTensor(new_indices, new_values, new_shape)",
                "# first, we convert the sparse tensor to dense tensor \n# then we slice the first dimension \nslice_tensor=tf.slice(tf.sparse.to_dense(in1),[0,0,0],[-1,-1,-1])\n# Now we find the indices where the tensor is not zero\nindices = tf.where(slice_tensor != 0)\n# Now we gather the values from tensor for these indices\nvalues = tf.gather_nd(slice_tensor, indices)\n# Now we create a new sparse tensor with these indices and values \n# but we need to adjust the first dimension of the dense shape\nshape = [1]\nshape.extend(in1.dense_shape.numpy()[1:].tolist())\nreturn tf.SparseTensor(indices=indices, values=values, dense_shape=shape)",
                "# Use tf.sparse.slice to make a slice along the first dimension\n    return tf.sparse.slice(in1, [0, 0, 0], [1, -1, -1])",
                "return tf.sparse.slice(in1, [0, 0, 0], [1, -1, -1])",
                "# Create a mask that returns True for entries in the SparseTensor where the first index is 0\nmask = tf.equal(in1.indices[:, 0], 0)\n\n# Use the mask to retain the entries where the first index is 0\nresult = tf.sparse.retain(in1, mask)\n\n# Reset the dense_shape of the result to reflect the sliced dimension\nresult = tf.sparse.reset_shape(result, [1] + in1.dense_shape.numpy().tolist()[1:])\n\nreturn result",
                "out = tf.sparse.slice(in1, start=[0, 0, 0], size=[1, -1, -1])\nreturn out"
            ],
            "target-program": "tf.divide(in1, tf.expand_dims(tf.reduce_sum(in1, axis=1), 1))",
            "description": "Slice the first dimension of a SparseTensor",
            "tf_operators": {
                "tf.sparse.slice": 4,
                "tf.SparseTensor": 5,
                "tf.less": 2,
                "tf.boolean_mask": 3,
                "tf.concat": 4,
                "tf.equal": 2,
                "tf.gather": 1,
                "tf.where": 2,
                "tf.sparse.to_dense": 1,
                "tf.slice": 1,
                "tf.gather_nd": 1,
                "tf.sparse.reset_shape": 1,
                "tf.sparse.retain": 1
            },
            "coverage_percentage": 0.0,
            "total_in_target": 3,
            "total_covered": 0
        },
        "completions": [
            "# In this TensorFlow task, we need to slice the first dimension of a SparseTensor. For this, we can use the 'tf.sparse.slice' function.\n# The required 'start' and 'size' parameters will respectively be an array of zeros (same length as SparseTensor dimensions) and an array having '1' for the first element and '-1' for the rest.\n\nimport tensorflow as tf\n\ndef transform(sparse_tensor):\n    dims = len(sparse_tensor.dense_shape.numpy())\n    start = [0] * dims\n    size = [-1] * dims\n    size[0] = 1\n    return tf.sparse.slice(sparse_tensor, start, size)",
            "indices = in1.indices\n    values = in1.values\n    dense_shape = in1.dense_shape\n\n    mask = tf.less(indices[:, 0], 1)\n    new_indices = tf.boolean_mask(indices, mask)\n    new_values = tf.boolean_mask(values, mask)\n\n    new_dense_shape = tf.concat([[1], dense_shape[1:]], 0)\n\n    return tf.SparseTensor(indices=new_indices, values=new_values, dense_shape=new_dense_shape)",
            "condition = tf.less(in1.indices[:, 0], 1)\nindices = tf.boolean_mask(in1.indices, condition)\nvalues = tf.boolean_mask(in1.values, condition)\ndense_shape = tf.concat([[1], in1.dense_shape[1:]], axis=0)\nreturn tf.SparseTensor(indices, values, dense_shape)",
            "# we want to slice the first dimension \n# first let's find the indices where the first column of `indices` is zero, which denotes the first dimension\nmask = tf.equal(in1.indices[:,0], 0)\n# now we select those indices using `boolean_mask`\nindices = tf.boolean_mask(in1.indices, mask)\n# we also select the corresponding values\nvalues = tf.boolean_mask(in1.values, mask)\n# we need to adjust the dense_shape by setting the first element to 1 because we sliced the first dimension\ndense_shape = tf.concat([[1], in1.dense_shape[1:]], 0)\n# finally we return the new SparseTensor\nreturn tf.SparseTensor(indices, values, dense_shape)",
            "indices = tf.where(in1.indices[:, 0] < 1)\nnew_indices = tf.gather(in1.indices, indices)[:,0]\nnew_values = tf.gather(in1.values, indices)[:,0]\nnew_shape = tf.concat([[1], in1.dense_shape[1:]], axis=0)\nreturn tf.SparseTensor(new_indices, new_values, new_shape)",
            "# first, we convert the sparse tensor to dense tensor \n# then we slice the first dimension \nslice_tensor=tf.slice(tf.sparse.to_dense(in1),[0,0,0],[-1,-1,-1])\n# Now we find the indices where the tensor is not zero\nindices = tf.where(slice_tensor != 0)\n# Now we gather the values from tensor for these indices\nvalues = tf.gather_nd(slice_tensor, indices)\n# Now we create a new sparse tensor with these indices and values \n# but we need to adjust the first dimension of the dense shape\nshape = [1]\nshape.extend(in1.dense_shape.numpy()[1:].tolist())\nreturn tf.SparseTensor(indices=indices, values=values, dense_shape=shape)",
            "# Use tf.sparse.slice to make a slice along the first dimension\n    return tf.sparse.slice(in1, [0, 0, 0], [1, -1, -1])",
            "return tf.sparse.slice(in1, [0, 0, 0], [1, -1, -1])",
            "# Create a mask that returns True for entries in the SparseTensor where the first index is 0\nmask = tf.equal(in1.indices[:, 0], 0)\n\n# Use the mask to retain the entries where the first index is 0\nresult = tf.sparse.retain(in1, mask)\n\n# Reset the dense_shape of the result to reflect the sliced dimension\nresult = tf.sparse.reset_shape(result, [1] + in1.dense_shape.numpy().tolist()[1:])\n\nreturn result",
            "out = tf.sparse.slice(in1, start=[0, 0, 0], size=[1, -1, -1])\nreturn out"
        ]
    },
    {
        "constants": "[]",
        "description": "Reshape a flat array into a rank 3 tensor",
        "target_program": "tf.reshape(in1, shape=(4, 3, 2))",
        "source": "Real task encountered by Googler, 3/21/2019",
        "name": "google_04",
        "examples": {
            "inputs": "[[111, 112, 121, 122, 131, 132, 211, 212, 221, 222, 231, 232, 311, 312, 321, 322, 331, 332, 411, 412, 421, 422, 431, 432],]",
            "outputs": "[[[111, 112], [121, 122], [131, 132]],    [[211, 212], [221, 222], [231, 232]],    [[311, 312], [321, 322], [331, 332]],    [[411, 412], [421, 422], [431, 432]]]"
        },
        "response": {
            "task_id": "google_04",
            "completions": [
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])"
            ],
            "target-program": "tf.reshape(in1, shape=(4, 3, 2))",
            "description": "Reshape a flat array into a rank 3 tensor",
            "tf_operators": {
                "tf.reshape": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])"
        ]
    },
    {
        "constants": "[6]",
        "description": "Repeat each input entry 6 times",
        "target_program": "tf.tile(tf.expand_dims(in1, 1), (1, 6, 1))",
        "source": "Real task encountered by Googler, 3/22/2019",
        "name": "google_05",
        "examples": {
            "inputs": "[[[1, 2, 3, 4], [5, 6, 7, 8]],]",
            "outputs": "[[[1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4],     [1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4]],    [[5, 6, 7, 8], [5, 6, 7, 8], [5, 6, 7, 8],     [5, 6, 7, 8], [5, 6, 7, 8], [5, 6, 7, 8]]]"
        },
        "response": {
            "task_id": "google_05",
            "completions": [
                "return tf.repeat(in1, repeats=6, axis=1)",
                "return tf.repeat(in1, repeats=6, axis=0)",
                "return tf.repeat(tf.expand_dims(in1, axis=1), repeats=6, axis=1)",
                "return tf.repeat(in1, repeats=6, axis=0)",
                "return tf.repeat(in1, 6, axis=0)",
                "return tf.repeat(in1, [6], axis=0)",
                "return tf.repeat(in1, repeats=6, axis=0)",
                "return tf.repeat(tf.expand_dims(in1, axis=1), repeats=6, axis=1)",
                "return tf.repeat(tf.expand_dims(in1, axis=1), repeats=6, axis=1)",
                "return tf.repeat(in1, repeats=6, axis=0)"
            ],
            "target-program": "tf.tile(tf.expand_dims(in1, 1), (1, 6, 1))",
            "description": "Repeat each input entry 6 times",
            "tf_operators": {
                "tf.repeat": 10,
                "tf.expand_dims": 3
            },
            "coverage_percentage": 50.0,
            "total_in_target": 2,
            "total_covered": 1
        },
        "completions": [
            "return tf.repeat(in1, repeats=6, axis=1)",
            "return tf.repeat(in1, repeats=6, axis=0)",
            "return tf.repeat(tf.expand_dims(in1, axis=1), repeats=6, axis=1)",
            "return tf.repeat(in1, repeats=6, axis=0)",
            "return tf.repeat(in1, 6, axis=0)",
            "return tf.repeat(in1, [6], axis=0)",
            "return tf.repeat(in1, repeats=6, axis=0)",
            "return tf.repeat(tf.expand_dims(in1, axis=1), repeats=6, axis=1)",
            "return tf.repeat(tf.expand_dims(in1, axis=1), repeats=6, axis=1)",
            "return tf.repeat(in1, repeats=6, axis=0)"
        ]
    },
    {
        "constants": "[]",
        "description": "Take the max from each group of elements",
        "target_program": "tf.math.segment_max(in2, in1)",
        "source": "Real task encountered by Googler, 3/28/2019",
        "name": "google_06",
        "examples": {
            "inputs": "[[0, 1, 1, 2, 3, 3, 3, 3],[1, 3, 4, 5, 10, 8, 9, 4],]",
            "outputs": "[1, 4, 5, 10]"
        },
        "response": {
            "task_id": "google_06",
            "completions": [
                "return tf.math.segment_max(in2, in1)",
                "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1).numpy()",
                "unique_elements, id_map = tf.unique(in1)\ngroups_max = tf.math.segment_max(in2, id_map)\nreturn groups_max",
                "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1)+1)",
                "return tf.math.segment_max(in2, in1)",
                "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1).numpy().tolist()",
                "return tf.math.segment_max(in2, in1)",
                "return tf.math.segment_max(in2, in1).numpy().tolist()",
                "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1)+1).numpy().tolist()",
                "segments = tf.constant(in1)\ndata = tf.constant(in2)\nmax_of_segments = tf.math.segment_max(data, segments)\nreturn max_of_segments.numpy().tolist()"
            ],
            "target-program": "tf.math.segment_max(in2, in1)",
            "description": "Take the max from each group of elements",
            "tf_operators": {
                "tf.math.segment_max": 6,
                "tf.reduce_max": 4,
                "tf.math.unsorted_segment_max": 4,
                "tf.unique": 1,
                "tf.constant": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.math.segment_max(in2, in1)",
            "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1).numpy()",
            "unique_elements, id_map = tf.unique(in1)\ngroups_max = tf.math.segment_max(in2, id_map)\nreturn groups_max",
            "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1)+1)",
            "return tf.math.segment_max(in2, in1)",
            "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1).numpy().tolist()",
            "return tf.math.segment_max(in2, in1)",
            "return tf.math.segment_max(in2, in1).numpy().tolist()",
            "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1)+1).numpy().tolist()",
            "segments = tf.constant(in1)\ndata = tf.constant(in2)\nmax_of_segments = tf.math.segment_max(data, segments)\nreturn max_of_segments.numpy().tolist()"
        ]
    },
    {
        "constants": "[]",
        "description": "Take the argmax of each group of elements",
        "target_program": "tf.cast(tf.argmax((tf.sequence_mask(tf.cumsum(tf.math.bincount(in1)), dtype=tf.int32) - tf.sequence_mask(tf.cumsum(tf.math.bincount(in1), exclusive=True), dtype=tf.int32, maxlen=in1.shape[0])) * in2, axis=1), tf.int32) - tf.cumsum(tf.math.bincount(in1), exclusive=True)",
        "source": "Real task encountered by Googler, 3/29/2019",
        "name": "google_07",
        "examples": {
            "inputs": "[[0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 4, 4, 5, 5],[4, 1, 8, 2, 5, 7, 9, 3, 7, 3, 1, 42, 1, 2, 4, 0],]",
            "outputs": "[2, 3, 1, 0, 1, 0]"
        },
        "response": {
            "task_id": "google_07",
            "completions": [
                "unique, indices, counts = tf.unique_with_counts(in1)\nmax_values = [tf.reduce_max(tf.boolean_mask(in2, tf.equal(in1, u))) for u in unique.numpy()]\nreturn max_values",
                "group_ids = tf.unique_with_counts(in1).y\ncounts = tf.unique_with_counts(in1).count\n\nstart_index = tf.cumsum(counts, exclusive=True)\nend_index = tf.cumsum(counts, exclusive=False)\n\nrange_vals = tf.reshape(tf.range(start_index, end_index), (-1, 1))\nargmax_indices = tf.argmax(tf.gather(in2, range_vals), axis=1)\n\nreturn tf.gather(in2, argmax_indices)",
                "return tf.math.segment_max(in2, in1).numpy().tolist()",
                "segments = tf.cast(in1, tf.int32)\nvalues = tf.cast(in2, tf.int32)\nresult = tf.math.segment_max(values, segments)\nreturn result",
                "return tf.math.segment_max(in2, in1)",
                "segment_ids = tf.constant(in1)\ndata = tf.constant(in2)\nreturn tf.math.segment_max(data, segment_ids)",
                "segment_ids = tf.cast(in1, tf.int32)\ndata = tf.cast(in2, tf.int32)\nargmax_indices = tf.math.segment_max(data, segment_ids)\nreturn argmax_indices",
                "segment_ids = tf.constant(in1)\ndata = tf.constant(in2)\nout = tf.argmax(tf.math.unsorted_segment_max(data, segment_ids, tf.reduce_max(segment_ids)+1))\nreturn tf.cast(out, tf.int32).numpy().tolist()",
                "return tf.math.segment_max(in2, in1).numpy().tolist()",
                "import tensorflow as tf\n\ndef transform(in1,in2):\n    unique_values, indices, counts = tf.unique_with_counts(in1)\n    segments = tf.cumsum(counts)[:-1]\n    segment_max = tf.math.unsorted_segment_max(in2, indices, tf.reduce_max(indices) + 1)\n    return tf.gather(indices, tf.math.argmax(segment_max))"
            ],
            "target-program": "tf.cast(tf.argmax((tf.sequence_mask(tf.cumsum(tf.math.bincount(in1)), dtype=tf.int32) - tf.sequence_mask(tf.cumsum(tf.math.bincount(in1), exclusive=True), dtype=tf.int32, maxlen=in1.shape[0])) * in2, axis=1), tf.int32) - tf.cumsum(tf.math.bincount(in1), exclusive=True)",
            "description": "Take the argmax of each group of elements",
            "tf_operators": {
                "tf.reduce_max": 3,
                "tf.unique_with_counts": 3,
                "tf.boolean_mask": 1,
                "tf.equal": 1,
                "tf.reshape": 1,
                "tf.argmax": 2,
                "tf.gather": 2,
                "tf.range": 1,
                "tf.cumsum": 2,
                "tf.math.segment_max": 6,
                "tf.int32": 3,
                "tf.cast": 3,
                "tf.constant": 2,
                "tf.math.unsorted_segment_max": 2,
                "tf.math.argmax": 1
            },
            "coverage_percentage": 66.66666666666666,
            "total_in_target": 6,
            "total_covered": 4
        },
        "completions": [
            "unique, indices, counts = tf.unique_with_counts(in1)\nmax_values = [tf.reduce_max(tf.boolean_mask(in2, tf.equal(in1, u))) for u in unique.numpy()]\nreturn max_values",
            "group_ids = tf.unique_with_counts(in1).y\ncounts = tf.unique_with_counts(in1).count\n\nstart_index = tf.cumsum(counts, exclusive=True)\nend_index = tf.cumsum(counts, exclusive=False)\n\nrange_vals = tf.reshape(tf.range(start_index, end_index), (-1, 1))\nargmax_indices = tf.argmax(tf.gather(in2, range_vals), axis=1)\n\nreturn tf.gather(in2, argmax_indices)",
            "return tf.math.segment_max(in2, in1).numpy().tolist()",
            "segments = tf.cast(in1, tf.int32)\nvalues = tf.cast(in2, tf.int32)\nresult = tf.math.segment_max(values, segments)\nreturn result",
            "return tf.math.segment_max(in2, in1)",
            "segment_ids = tf.constant(in1)\ndata = tf.constant(in2)\nreturn tf.math.segment_max(data, segment_ids)",
            "segment_ids = tf.cast(in1, tf.int32)\ndata = tf.cast(in2, tf.int32)\nargmax_indices = tf.math.segment_max(data, segment_ids)\nreturn argmax_indices",
            "segment_ids = tf.constant(in1)\ndata = tf.constant(in2)\nout = tf.argmax(tf.math.unsorted_segment_max(data, segment_ids, tf.reduce_max(segment_ids)+1))\nreturn tf.cast(out, tf.int32).numpy().tolist()",
            "return tf.math.segment_max(in2, in1).numpy().tolist()",
            "import tensorflow as tf\n\ndef transform(in1,in2):\n    unique_values, indices, counts = tf.unique_with_counts(in1)\n    segments = tf.cumsum(counts)[:-1]\n    segment_max = tf.math.unsorted_segment_max(in2, indices, tf.reduce_max(indices) + 1)\n    return tf.gather(indices, tf.math.argmax(segment_max))"
        ]
    },
    {
        "constants": "[5]",
        "description": "create a mask for sequences of the given lengths",
        "target_program": "tf.cast(tf.greater(tf.expand_dims(in1, 1), tf.range(5)), tf.int32)",
        "source": "Real task encountered by Googler, 4/11/2019",
        "name": "google_08",
        "examples": {
            "inputs": "[[3, 4, 2, 1],]",
            "outputs": "[[1, 1, 1, 0, 0],    [1, 1, 1, 1, 0],    [1, 1, 0, 0, 0],    [1, 0, 0, 0, 0]]"
        },
        "response": {
            "task_id": "google_08",
            "completions": [
                "return tf.sequence_mask(in1, tf.reduce_max(in1))",
                "return tf.sequence_mask(in1, maxlen=tf.reduce_max(in1))",
                "return tf.sequence_mask(in1).numpy().astype(int)",
                "return tf.sequence_mask(in1, maxlen=tf.reduce_max(in1)).numpy()",
                "return tf.sequence_mask(in1, tf.reduce_max(in1))",
                "return tf.sequence_mask(in1).numpy()",
                "return tf.sequence_mask(in1, tf.reduce_max(in1))",
                "return tf.sequence_mask(in1, tf.reduce_max(in1))",
                "return tf.sequence_mask(in1, tf.reduce_max(in1))",
                "return tf.sequence_mask(in1, tf.reduce_max(in1)).numpy().astype(int)"
            ],
            "target-program": "tf.cast(tf.greater(tf.expand_dims(in1, 1), tf.range(5)), tf.int32)",
            "description": "create a mask for sequences of the given lengths",
            "tf_operators": {
                "tf.reduce_max": 8,
                "tf.sequence_mask": 10
            },
            "coverage_percentage": 0.0,
            "total_in_target": 5,
            "total_covered": 0
        },
        "completions": [
            "return tf.sequence_mask(in1, tf.reduce_max(in1))",
            "return tf.sequence_mask(in1, maxlen=tf.reduce_max(in1))",
            "return tf.sequence_mask(in1).numpy().astype(int)",
            "return tf.sequence_mask(in1, maxlen=tf.reduce_max(in1)).numpy()",
            "return tf.sequence_mask(in1, tf.reduce_max(in1))",
            "return tf.sequence_mask(in1).numpy()",
            "return tf.sequence_mask(in1, tf.reduce_max(in1))",
            "return tf.sequence_mask(in1, tf.reduce_max(in1))",
            "return tf.sequence_mask(in1, tf.reduce_max(in1))",
            "return tf.sequence_mask(in1, tf.reduce_max(in1)).numpy().astype(int)"
        ]
    },
    {
        "constants": "[]",
        "description": "sort the segments",
        "target_program": "tf.gather(in2, tf.argsort(in1, stable=True))",
        "source": "Real task encountered by Googler, 8/9/2019",
        "name": "google_09",
        "examples": {
            "inputs": "[[1, 1, 1, 0, 0, 2],[10, 20, 30, 14, 15, 26],]",
            "outputs": "[14, 15, 10, 20, 30, 26]"
        },
        "response": {
            "task_id": "google_09",
            "completions": [
                "# Sorting the segments in in2 according to their corresponding segment IDs in in1.\n# This is done by using the tf.math.unsorted_segment_max and tf.argsort functions to get the sorting order of the segments,\n# and then using tf.gather to reorder the segments.\n\ndef transform(in1,in2):\n    sorted_segments = tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1)\n    sorted_order = tf.argsort(sorted_segments)\n    reorder = tf.gather(in1, sorted_order)\n    result = tf.gather(in2, reorder)\n    return result",
                "# sort the input segment wise, we first gather the elements of each segment and then sorts them. \n# We then concatenate the sorted segments again to form the final answer.\n\nsegment_ids = tf.constant(in1)\nto_segment = tf.constant(in2)\n\n# Get the unique segment identifiers and sort them.\nunique_segment_ids, _ = tf.unique(segment_ids) \nsorted_segment_ids = tf.sort(unique_segment_ids)\n\n# For each segment identifier...\nsegments = [tf.boolean_mask(to_segment, tf.equal(segment_ids, segment_id)) for segment_id in sorted_segment_ids]\n\n# Sort the elements of each segment.\nsorted_segments = [tf.sort(segment) for segment in segments]\n\n# Concatenate the sorted segments to obtain the final sorted tensor.\nsorted_tensor = tf.concat(sorted_segments, axis=0)\n\nreturn sorted_tensor.numpy().tolist()",
                "# Create a sparse tensor with in1 as segments and in2 as values, then use sparse_to_dense to sort\n    return tf.sparse.to_dense(tf.SparseTensor(tf.expand_dims(in1, axis=-1), in2, tf.shape(in2))).numpy().tolist()",
                "# create a function that takes two inputs, sorts the second input based on the first input\ndef transform(in1, in2):\n    sorted_indices = tf.argsort(in1, axis=-1, stable=True)\n    sorted_segments = tf.gather(in2, sorted_indices)\n    return sorted_segments",
                "# The aim is to sort the elements within each segment in ascending order.\n# We first determine the number of segments using the `reduce_max` function.\n# The `unsorted_segment_sort` function isn't directly available, but can be achieved by obtaining sorted indices using `argsort`\n# in each segment, then gathering elements from the input tensor based on these indices.\n\nimport tensorflow as tf\n\ndef transform(ids, values):\n    num_segments = tf.reduce_max(ids) + 1\n    sorted_indices_in_segment = tf.argsort(tf.concat([\n            tf.boolean_mask(values, tf.equal(ids, i)) for i in tf.range(num_segments)], \n        axis=0))\n    return tf.gather(values, sorted_indices_in_segment)",
                "indices = tf.argsort(in1, axis=-1, stable=True)\nreturn tf.gather(in2, indices)",
                "# First, we will map the indices and its corresponding values using tf.stack\n# Then, we will use tf.argsort to sort our values in ascending order\n# At the end, we will gather our data according to our sorted indices\n\n    mapping = tf.stack([in1, in2], axis=1)\n    sorted_indices = tf.argsort(mapping[:, 1])\n    sorted_segments = tf.gather(mapping[:, 0], sorted_indices)\n    return sorted_segments",
                "segments = tf.constant(in1)\nvalues = tf.constant(in2)\nnum_segments = tf.reduce_max(segments) + 1\noutput = tf.math.unsorted_segment_sum(values, segments, num_segments)\nsorted_segments = tf.argsort(output)\nsorted_values = tf.gather(output, sorted_segments)\nreturn sorted_values.numpy().tolist()",
                "# First we zip the given input lists\n# Then we sort them\n# After sorting, we unzip them\n# Finally we return the sorted values\n\nz = tf.stack([tf.constant(in1), tf.constant(in2)], axis=-1)\nsorted_z = tf.sort(z, axis=0)\nres = tf.unstack(sorted_z, axis=-1)\nreturn res[1].numpy()",
                "data = tf.constant(in2)\nsegment_ids = tf.constant(in1)\nnum_segments = tf.reduce_max(in1) + 1\nsegment_min = tf.math.unsorted_segment_min(data, segment_ids, num_segments)\nsegment_max = tf.math.unsorted_segment_max(data, segment_ids, num_segments)\nmin_locs = tf.where(tf.equal(data, tf.broadcast_to(segment_min, tf.shape(in1))))\nmax_locs = tf.where(tf.equal(data, tf.broadcast_to(segment_max, tf.shape(in1))))\ntemp = tf.tensor_scatter_nd_update(data, min_locs, segment_max)\nresult = tf.tensor_scatter_nd_update(temp, max_locs, segment_min)\nreturn result.numpy()"
            ],
            "target-program": "tf.gather(in2, tf.argsort(in1, stable=True))",
            "description": "sort the segments",
            "tf_operators": {
                "tf.reduce_max": 4,
                "tf.gather": 6,
                "tf.argsort": 6,
                "tf.math.unsorted_segment_max": 2,
                "tf.boolean_mask": 2,
                "tf.sort": 2,
                "tf.unique": 1,
                "tf.concat": 2,
                "tf.constant": 4,
                "tf.equal": 3,
                "tf.SparseTensor": 1,
                "tf.shape": 2,
                "tf.sparse.to_dense": 1,
                "tf.expand_dims": 1,
                "tf.range": 1,
                "tf.stack": 2,
                "tf.math.unsorted_segment_sum": 1,
                "tf.unstack": 1,
                "tf.broadcast_to": 1,
                "tf.where": 1,
                "tf.tensor_scatter_nd_update": 1,
                "tf.math.unsorted_segment_min": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 2,
            "total_covered": 2
        },
        "completions": [
            "# Sorting the segments in in2 according to their corresponding segment IDs in in1.\n# This is done by using the tf.math.unsorted_segment_max and tf.argsort functions to get the sorting order of the segments,\n# and then using tf.gather to reorder the segments.\n\ndef transform(in1,in2):\n    sorted_segments = tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1)\n    sorted_order = tf.argsort(sorted_segments)\n    reorder = tf.gather(in1, sorted_order)\n    result = tf.gather(in2, reorder)\n    return result",
            "# sort the input segment wise, we first gather the elements of each segment and then sorts them. \n# We then concatenate the sorted segments again to form the final answer.\n\nsegment_ids = tf.constant(in1)\nto_segment = tf.constant(in2)\n\n# Get the unique segment identifiers and sort them.\nunique_segment_ids, _ = tf.unique(segment_ids) \nsorted_segment_ids = tf.sort(unique_segment_ids)\n\n# For each segment identifier...\nsegments = [tf.boolean_mask(to_segment, tf.equal(segment_ids, segment_id)) for segment_id in sorted_segment_ids]\n\n# Sort the elements of each segment.\nsorted_segments = [tf.sort(segment) for segment in segments]\n\n# Concatenate the sorted segments to obtain the final sorted tensor.\nsorted_tensor = tf.concat(sorted_segments, axis=0)\n\nreturn sorted_tensor.numpy().tolist()",
            "# Create a sparse tensor with in1 as segments and in2 as values, then use sparse_to_dense to sort\n    return tf.sparse.to_dense(tf.SparseTensor(tf.expand_dims(in1, axis=-1), in2, tf.shape(in2))).numpy().tolist()",
            "# create a function that takes two inputs, sorts the second input based on the first input\ndef transform(in1, in2):\n    sorted_indices = tf.argsort(in1, axis=-1, stable=True)\n    sorted_segments = tf.gather(in2, sorted_indices)\n    return sorted_segments",
            "# The aim is to sort the elements within each segment in ascending order.\n# We first determine the number of segments using the `reduce_max` function.\n# The `unsorted_segment_sort` function isn't directly available, but can be achieved by obtaining sorted indices using `argsort`\n# in each segment, then gathering elements from the input tensor based on these indices.\n\nimport tensorflow as tf\n\ndef transform(ids, values):\n    num_segments = tf.reduce_max(ids) + 1\n    sorted_indices_in_segment = tf.argsort(tf.concat([\n            tf.boolean_mask(values, tf.equal(ids, i)) for i in tf.range(num_segments)], \n        axis=0))\n    return tf.gather(values, sorted_indices_in_segment)",
            "indices = tf.argsort(in1, axis=-1, stable=True)\nreturn tf.gather(in2, indices)",
            "# First, we will map the indices and its corresponding values using tf.stack\n# Then, we will use tf.argsort to sort our values in ascending order\n# At the end, we will gather our data according to our sorted indices\n\n    mapping = tf.stack([in1, in2], axis=1)\n    sorted_indices = tf.argsort(mapping[:, 1])\n    sorted_segments = tf.gather(mapping[:, 0], sorted_indices)\n    return sorted_segments",
            "segments = tf.constant(in1)\nvalues = tf.constant(in2)\nnum_segments = tf.reduce_max(segments) + 1\noutput = tf.math.unsorted_segment_sum(values, segments, num_segments)\nsorted_segments = tf.argsort(output)\nsorted_values = tf.gather(output, sorted_segments)\nreturn sorted_values.numpy().tolist()",
            "# First we zip the given input lists\n# Then we sort them\n# After sorting, we unzip them\n# Finally we return the sorted values\n\nz = tf.stack([tf.constant(in1), tf.constant(in2)], axis=-1)\nsorted_z = tf.sort(z, axis=0)\nres = tf.unstack(sorted_z, axis=-1)\nreturn res[1].numpy()",
            "data = tf.constant(in2)\nsegment_ids = tf.constant(in1)\nnum_segments = tf.reduce_max(in1) + 1\nsegment_min = tf.math.unsorted_segment_min(data, segment_ids, num_segments)\nsegment_max = tf.math.unsorted_segment_max(data, segment_ids, num_segments)\nmin_locs = tf.where(tf.equal(data, tf.broadcast_to(segment_min, tf.shape(in1))))\nmax_locs = tf.where(tf.equal(data, tf.broadcast_to(segment_max, tf.shape(in1))))\ntemp = tf.tensor_scatter_nd_update(data, min_locs, segment_max)\nresult = tf.tensor_scatter_nd_update(temp, max_locs, segment_min)\nreturn result.numpy()"
        ]
    },
    {
        "constants": "[]",
        "description": "gather the marked elements",
        "target_program": "tf.boolean_mask(in1, tf.cast(in2, tf.bool))",
        "source": null,
        "name": "google_10",
        "examples": {
            "inputs": "[[10, 20, 0, 40, 0, 30],[1, 1, 0, 1, 0, 1],]",
            "outputs": "[10, 20, 40, 30]"
        },
        "response": {
            "task_id": "google_10",
            "completions": [
                "return tf.boolean_mask(in1, tf.cast(in2, tf.bool))",
                "return tf.boolean_mask(in1, in2).numpy().tolist()",
                "return tf.boolean_mask(in1, tf.cast(in2, bool)).numpy()",
                "return tf.boolean_mask(in1, in2)",
                "return tf.boolean_mask(in1, in2)",
                "return tf.boolean_mask(in1, in2).numpy()",
                "return tf.boolean_mask(in1, in2)",
                "return tf.boolean_mask(in1, tf.cast(in2, tf.bool))",
                "return tf.boolean_mask(in1, tf.equal(in2, 1))",
                "return tf.boolean_mask(in1, tf.cast(in2, tf.bool)).numpy()"
            ],
            "target-program": "tf.boolean_mask(in1, tf.cast(in2, tf.bool))",
            "description": "gather the marked elements",
            "tf_operators": {
                "tf.boolean_mask": 10,
                "tf.cast": 4,
                "tf.bool": 3,
                "tf.equal": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 3,
            "total_covered": 3
        },
        "completions": [
            "return tf.boolean_mask(in1, tf.cast(in2, tf.bool))",
            "return tf.boolean_mask(in1, in2).numpy().tolist()",
            "return tf.boolean_mask(in1, tf.cast(in2, bool)).numpy()",
            "return tf.boolean_mask(in1, in2)",
            "return tf.boolean_mask(in1, in2)",
            "return tf.boolean_mask(in1, in2).numpy()",
            "return tf.boolean_mask(in1, in2)",
            "return tf.boolean_mask(in1, tf.cast(in2, tf.bool))",
            "return tf.boolean_mask(in1, tf.equal(in2, 1))",
            "return tf.boolean_mask(in1, tf.cast(in2, tf.bool)).numpy()"
        ]
    },
    {
        "constants": "[]",
        "description": "count the number of elements greater than 0 in each row",
        "target_program": "tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
        "source": "Real task encountered by Googler, 8/26/2019",
        "name": "google_11",
        "examples": {
            "inputs": "[[[1.0, 0.3, -4.2, 0.0, 2.1, 0.4], [-0.1, 0.0, 1.4, -1.0, 0.4, 0.0], [0.1, 0.0, 0.7, -0.3, 0.5, -0.1], [1.4, 2.5, 0.3, 0.01, 0.0, 1.2]],]",
            "outputs": "[4, 2, 3, 5]"
        },
        "response": {
            "task_id": "google_11",
            "completions": [
                "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
                "return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
                "return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
                "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
                "return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
                "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
                "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
                "return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
                "return tf.reduce_sum(tf.cast(tf.greater(in1, 0), dtype=tf.int32), axis=1)",
                "return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)"
            ],
            "target-program": "tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
            "description": "count the number of elements greater than 0 in each row",
            "tf_operators": {
                "tf.greater": 10,
                "tf.math.count_nonzero": 4,
                "tf.cast": 6,
                "tf.int32": 6,
                "tf.reduce_sum": 6
            },
            "coverage_percentage": 100.0,
            "total_in_target": 4,
            "total_covered": 4
        },
        "completions": [
            "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
            "return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
            "return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
            "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
            "return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
            "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
            "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
            "return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
            "return tf.reduce_sum(tf.cast(tf.greater(in1, 0), dtype=tf.int32), axis=1)",
            "return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)"
        ]
    },
    {
        "constants": "[]",
        "description": "identify elements between 0 and 1",
        "target_program": "tf.cast(tf.logical_and(0 <= in1, in1 <= 1), tf.int32)",
        "source": "Real task encountered by Googler, 8/26/2019",
        "name": "google_12",
        "examples": {
            "inputs": "[[[1.0, 0.3, -4.2, 0.0, 2.1], [-0.1, 0.0, 1.4, -1.0, 0.4], [0.1, 0.0, 0.7, -0.3, 0.5], [1.4, 2.5, 0.3, -0.1, 0.0]],]",
            "outputs": "[[1, 1, 0, 1, 0],    [0, 1, 0, 0, 1],    [1, 1, 1, 0, 1],    [0, 0, 1, 0, 1]]"
        },
        "response": {
            "task_id": "google_12",
            "completions": [
                "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), dtype=tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), dtype=tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), dtype=tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), int)",
                "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), dtype=tf.int32)"
            ],
            "target-program": "tf.cast(tf.logical_and(0 <= in1, in1 <= 1), tf.int32)",
            "description": "identify elements between 0 and 1",
            "tf_operators": {
                "tf.logical_and": 10,
                "tf.cast": 10,
                "tf.less": 10,
                "tf.int32": 9,
                "tf.greater": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 3,
            "total_covered": 3
        },
        "completions": [
            "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), dtype=tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), dtype=tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), dtype=tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), int)",
            "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), dtype=tf.int32)"
        ]
    },
    {
        "constants": "[]",
        "description": "Concatenate batches of sequences",
        "target_program": "tf.concat([in1, in2], axis=1)",
        "source": "Real task encountered by Googler, 9/13/2019",
        "name": "google_13",
        "examples": {
            "inputs": "[[[1, 2], [10, 20]],[[3, 4, 5], [30, 40, 50]],]",
            "outputs": "[[1, 2, 3, 4, 5], [10, 20, 30, 40, 50]]"
        },
        "response": {
            "task_id": "google_13",
            "completions": [
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1,in2], axis=1)",
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1, in2], axis=-1)"
            ],
            "target-program": "tf.concat([in1, in2], axis=1)",
            "description": "Concatenate batches of sequences",
            "tf_operators": {
                "tf.concat": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1,in2], axis=1)",
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1, in2], axis=-1)"
        ]
    },
    {
        "constants": "[]",
        "description": "circular buffer",
        "target_program": "tf.roll(in1, 1, 1)",
        "source": "From internal Colab, 10/17/2019",
        "name": "google_14",
        "examples": {
            "inputs": "[[[1, 3, 2, 0, 0], [4, 6, 5, 0, 0], [8, 7, 9, 0, 0]],]",
            "outputs": "[[0, 1, 3, 2, 0], [0, 4, 6, 5, 0], [0, 8, 7, 9, 0]]"
        },
        "response": {
            "task_id": "google_14",
            "completions": [
                "return tf.roll(in1, shift=1, axis=1)",
                "return tf.roll(in1, shift=1, axis=1)",
                "return tf.roll(in1, shift = 1, axis = 1)",
                "return tf.roll(in1, shift=1, axis=1)",
                "return tf.roll(in1, shift=1, axis=1)",
                "return tf.roll(in1, shift=1, axis=1)",
                "return tf.roll(in1, shift=1, axis=1)",
                "# We are essentially shifting the input array to the right by one position and filling the first position by 0\n# We can achieve this by using tf.roll for shifting and tf.tensor_scatter_nd_update for setting the first position to 0\n\ndef transform(in1):\n    shifted = tf.roll(in1, shift=1, axis=1)\n    indices = tf.constant([[i, 0] for i in range(tf.shape(in1)[0])])\n    result = tf.tensor_scatter_nd_update(shifted, indices, tf.zeros(tf.shape(in1)[0]))\n    return result",
                "return tf.roll(in1, shift=1, axis=1)",
                "return tf.pad(in1, [[0, 0], [1, 1]])"
            ],
            "target-program": "tf.roll(in1, 1, 1)",
            "description": "circular buffer",
            "tf_operators": {
                "tf.roll": 9,
                "tf.shape": 1,
                "tf.tensor_scatter_nd_update": 1,
                "tf.constant": 1,
                "tf.zeros": 1,
                "tf.pad": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.roll(in1, shift=1, axis=1)",
            "return tf.roll(in1, shift=1, axis=1)",
            "return tf.roll(in1, shift = 1, axis = 1)",
            "return tf.roll(in1, shift=1, axis=1)",
            "return tf.roll(in1, shift=1, axis=1)",
            "return tf.roll(in1, shift=1, axis=1)",
            "return tf.roll(in1, shift=1, axis=1)",
            "# We are essentially shifting the input array to the right by one position and filling the first position by 0\n# We can achieve this by using tf.roll for shifting and tf.tensor_scatter_nd_update for setting the first position to 0\n\ndef transform(in1):\n    shifted = tf.roll(in1, shift=1, axis=1)\n    indices = tf.constant([[i, 0] for i in range(tf.shape(in1)[0])])\n    result = tf.tensor_scatter_nd_update(shifted, indices, tf.zeros(tf.shape(in1)[0]))\n    return result",
            "return tf.roll(in1, shift=1, axis=1)",
            "return tf.pad(in1, [[0, 0], [1, 1]])"
        ]
    },
    {
        "constants": "[]",
        "description": "pad a zero column",
        "target_program": "tf.pad(in1, [[0, 0], [0, 1]], 'CONSTANT')",
        "source": "Real task encountered by Googler, 10/23/2019",
        "name": "google_15",
        "examples": {
            "inputs": "[[[1, 3, 5, 7], [2, 4, 6, 8]],]",
            "outputs": "[[1, 3, 5, 7, 0], [2, 4, 6, 8, 0]]"
        },
        "response": {
            "task_id": "google_15",
            "completions": [
                "import tensorflow as tf\n\ndef transform(in1):\n    zero_column = tf.zeros([tf.shape(in1)[0], 1], dtype=in1.dtype)\n    return tf.concat([in1, zero_column], axis=1)",
                "return tf.concat([in1, tf.zeros_like(in1[:, :1])], axis=1)",
                "return tf.pad(in1, [[0, 0], [0, 1]])",
                "return tf.concat([in1, tf.zeros([tf.shape(in1)[0], 1], dtype=in1.dtype)], axis=1)",
                "padded_tensor = tf.pad(in1, paddings=[[0, 0], [0, 1]])\n     return padded_tensor",
                "return tf.pad(in1, tf.constant([[0, 0], [0, 1]]))",
                "return tf.pad(in1, [[0,0],[0,1]])",
                "return tf.pad(in1, [[0, 0], [0, 1]])",
                "return tf.pad(in1, [[0, 0], [0, 1]])",
                "return tf.pad(in1, [[0, 0], [0, 1]])"
            ],
            "target-program": "tf.pad(in1, [[0, 0], [0, 1]], 'CONSTANT')",
            "description": "pad a zero column",
            "tf_operators": {
                "tf.shape": 2,
                "tf.concat": 3,
                "tf.zeros": 2,
                "tf.zeros_like": 1,
                "tf.pad": 7,
                "tf.constant": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "import tensorflow as tf\n\ndef transform(in1):\n    zero_column = tf.zeros([tf.shape(in1)[0], 1], dtype=in1.dtype)\n    return tf.concat([in1, zero_column], axis=1)",
            "return tf.concat([in1, tf.zeros_like(in1[:, :1])], axis=1)",
            "return tf.pad(in1, [[0, 0], [0, 1]])",
            "return tf.concat([in1, tf.zeros([tf.shape(in1)[0], 1], dtype=in1.dtype)], axis=1)",
            "padded_tensor = tf.pad(in1, paddings=[[0, 0], [0, 1]])\n     return padded_tensor",
            "return tf.pad(in1, tf.constant([[0, 0], [0, 1]]))",
            "return tf.pad(in1, [[0,0],[0,1]])",
            "return tf.pad(in1, [[0, 0], [0, 1]])",
            "return tf.pad(in1, [[0, 0], [0, 1]])",
            "return tf.pad(in1, [[0, 0], [0, 1]])"
        ]
    },
    {
        "constants": "[]",
        "description": "replicate elements a given number of times",
        "target_program": "tf.gather(in1, tf.where(tf.sequence_mask(in2))[:, 0])",
        "source": "From an internal Google forum",
        "name": "google_16",
        "examples": {
            "inputs": "[[1, 2, 0, 3],[2, 1, 2, 3],]",
            "outputs": "[1, 1, 2, 0, 0, 3, 3, 3]"
        },
        "response": {
            "task_id": "google_16",
            "completions": [
                "return tf.repeat(in1, in2).numpy()",
                "return tf.repeat(in1, in2).numpy()",
                "return tf.repeat(in1, in2).numpy().tolist()",
                "return tf.reshape(tf.repeat(in1, in2), [-1])",
                "return tf.repeat(in1, in2).numpy().tolist()",
                "return tf.repeat(in1, in2)",
                "return tf.repeat(in1, in2).numpy()",
                "return tf.repeat(in1, in2).numpy()",
                "return tf.repeat(in1, in2).numpy()",
                "return tf.repeat(in1, in2).numpy()"
            ],
            "target-program": "tf.gather(in1, tf.where(tf.sequence_mask(in2))[:, 0])",
            "description": "replicate elements a given number of times",
            "tf_operators": {
                "tf.repeat": 10,
                "tf.reshape": 1
            },
            "coverage_percentage": 0.0,
            "total_in_target": 3,
            "total_covered": 0
        },
        "completions": [
            "return tf.repeat(in1, in2).numpy()",
            "return tf.repeat(in1, in2).numpy()",
            "return tf.repeat(in1, in2).numpy().tolist()",
            "return tf.reshape(tf.repeat(in1, in2), [-1])",
            "return tf.repeat(in1, in2).numpy().tolist()",
            "return tf.repeat(in1, in2)",
            "return tf.repeat(in1, in2).numpy()",
            "return tf.repeat(in1, in2).numpy()",
            "return tf.repeat(in1, in2).numpy()",
            "return tf.repeat(in1, in2).numpy()"
        ]
    },
    {
        "constants": "[-10]",
        "description": "use bool tensor as condition",
        "target_program": "tf.where(in1, in2, tf.multiply(in2, -10))",
        "source": "From an internal Google forum",
        "name": "google_17",
        "examples": {
            "inputs": "[[True, False, False, True, False],[1, 2, 3, 4, 5],]",
            "outputs": "[1, -20, -30, 4, -50]"
        },
        "response": {
            "task_id": "google_17",
            "completions": [
                "return tf.where(in1, in2, tf.multiply(in2, -10))",
                "return tf.where(in1, in2, tf.multiply(in2, -10))",
                "return tf.where(in1, in2, in2 * -10)",
                "return tf.where(in1, in2, tf.multiply(in2, -10))",
                "return tf.where(in1, in2, tf.multiply(in2, -10))",
                "return tf.where(in1, in2, tf.multiply(in2, -10))",
                "return tf.where(in1, in2, in2* -10)",
                "return tf.where(in1,in2,tf.multiply(in2, -10))",
                "return tf.where(in1, in2, tf.multiply(in2, -10))",
                "return tf.where(in1, in2, tf.multiply(in2, -10))"
            ],
            "target-program": "tf.where(in1, in2, tf.multiply(in2, -10))",
            "description": "use bool tensor as condition",
            "tf_operators": {
                "tf.multiply": 8,
                "tf.where": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 2,
            "total_covered": 2
        },
        "completions": [
            "return tf.where(in1, in2, tf.multiply(in2, -10))",
            "return tf.where(in1, in2, tf.multiply(in2, -10))",
            "return tf.where(in1, in2, in2 * -10)",
            "return tf.where(in1, in2, tf.multiply(in2, -10))",
            "return tf.where(in1, in2, tf.multiply(in2, -10))",
            "return tf.where(in1, in2, tf.multiply(in2, -10))",
            "return tf.where(in1, in2, in2* -10)",
            "return tf.where(in1,in2,tf.multiply(in2, -10))",
            "return tf.where(in1, in2, tf.multiply(in2, -10))",
            "return tf.where(in1, in2, tf.multiply(in2, -10))"
        ]
    },
    {
        "constants": "[]",
        "description": "(\\'sum of elements in the first tensor but partitioned by the second tensor\\')",
        "target_program": "tf.linalg.matvec(tf.cast(tf.equal(in2[:, None], in2), tf.int32), in1)",
        "source": "From an internal Google forum",
        "name": "google_18",
        "examples": {
            "inputs": "[[5, 7, -12, 10, 20],[1, 2, 3, 1, 2],]",
            "outputs": "[15, 27, -12, 15, 27]"
        },
        "response": {
            "task_id": "google_18",
            "completions": [
                "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1).numpy()",
                "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)",
                "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1).numpy().tolist()",
                "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + 1)",
                "out = tf.math.segment_sum(in1, in2)\nreturn out",
                "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1).numpy()[in2]",
                "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)",
                "return tf.math.unsorted_segment_sum(in1,in2,tf.reduce_max(in2)+1)",
                "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)",
                "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + 1)"
            ],
            "target-program": "tf.linalg.matvec(tf.cast(tf.equal(in2[:, None], in2), tf.int32), in1)",
            "description": "(\\'sum of elements in the first tensor but partitioned by the second tensor\\')",
            "tf_operators": {
                "tf.math.unsorted_segment_sum": 9,
                "tf.reduce_max": 9,
                "tf.math.segment_sum": 1
            },
            "coverage_percentage": 0.0,
            "total_in_target": 4,
            "total_covered": 0
        },
        "completions": [
            "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1).numpy()",
            "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)",
            "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1).numpy().tolist()",
            "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + 1)",
            "out = tf.math.segment_sum(in1, in2)\nreturn out",
            "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1).numpy()[in2]",
            "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)",
            "return tf.math.unsorted_segment_sum(in1,in2,tf.reduce_max(in2)+1)",
            "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)",
            "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + 1)"
        ]
    },
    {
        "constants": "[]",
        "description": "scatter a 2-D tensor with indices",
        "target_program": "tf.gather(in1, tf.argsort(in2, axis=1), batch_dims=1)",
        "source": "From an internal Google forum",
        "name": "google_19",
        "examples": {
            "inputs": "[[[11, 12, 13], [30, 20, 10], [77, 88, 99]],[[2, 0, 1], [1, 0, 2], [0, 2, 1]],]",
            "outputs": "[[12, 13, 11],    [20, 30, 10],    [77, 99, 88]]"
        },
        "response": {
            "task_id": "google_19",
            "completions": [
                "return tf.tensor_scatter_nd_update(in1, tf.stack([tf.range(in1.shape[0]), in2], axis=1), tf.gather_nd(in1, tf.stack([tf.range(in1.shape[0]), in2], axis=1)))",
                "return tf.gather(in1, in2, axis=1)",
                "return tf.gather(in1, in2, axis=1, batch_dims=1)",
                "out = tf.gather(in1, in2, axis=1)\nreturn out",
                "return tf.gather(in1, in2, axis=1, batch_dims=1)",
                "return tf.gather(in1, in2, batch_dims=1)",
                "return tf.gather(in1, in2, axis=-1)",
                "return tf.gather(in1, in2, batch_dims=1)",
                "return tf.gather(in1, in2, axis=1)",
                "shape = tf.shape(in1)\nflat_in2 = tf.reshape(in2, [-1])\nflat_in1 = tf.reshape(in1, [-1])\nflat_out = tf.gather(flat_in1, flat_in2)\nreturn tf.reshape(flat_out, shape)"
            ],
            "target-program": "tf.gather(in1, tf.argsort(in2, axis=1), batch_dims=1)",
            "description": "scatter a 2-D tensor with indices",
            "tf_operators": {
                "tf.stack": 1,
                "tf.range": 1,
                "tf.tensor_scatter_nd_update": 1,
                "tf.gather_nd": 1,
                "tf.gather": 9,
                "tf.shape": 1,
                "tf.reshape": 1
            },
            "coverage_percentage": 50.0,
            "total_in_target": 2,
            "total_covered": 1
        },
        "completions": [
            "return tf.tensor_scatter_nd_update(in1, tf.stack([tf.range(in1.shape[0]), in2], axis=1), tf.gather_nd(in1, tf.stack([tf.range(in1.shape[0]), in2], axis=1)))",
            "return tf.gather(in1, in2, axis=1)",
            "return tf.gather(in1, in2, axis=1, batch_dims=1)",
            "out = tf.gather(in1, in2, axis=1)\nreturn out",
            "return tf.gather(in1, in2, axis=1, batch_dims=1)",
            "return tf.gather(in1, in2, batch_dims=1)",
            "return tf.gather(in1, in2, axis=-1)",
            "return tf.gather(in1, in2, batch_dims=1)",
            "return tf.gather(in1, in2, axis=1)",
            "shape = tf.shape(in1)\nflat_in2 = tf.reshape(in2, [-1])\nflat_in1 = tf.reshape(in1, [-1])\nflat_out = tf.gather(flat_in1, flat_in2)\nreturn tf.reshape(flat_out, shape)"
        ]
    },
    {
        "constants": "[]",
        "description": "sort a tensor and return sorted index in original order",
        "target_program": "tf.cast(tf.argsort(tf.argsort(in1)), tf.int32)",
        "source": "From an internal Google forum",
        "name": "google_20",
        "examples": {
            "inputs": "[[10, 7, 4, 3, 2, 8],]",
            "outputs": "[5, 3, 2, 1, 0, 4]"
        },
        "response": {
            "task_id": "google_20",
            "completions": [
                "return tf.argsort(tf.argsort(in1)).numpy()",
                "return tf.argsort(tf.argsort(in1)).numpy().tolist()",
                "sorted_idxs = tf.argsort(in1)\nreturn tf.argsort(sorted_idxs)",
                "sorted_indices = tf.argsort(in1)\noriginal_order_indices = tf.argsort(sorted_indices)\nreturn original_order_indices",
                "return tf.argsort(tf.argsort(in1))",
                "return tf.argsort(tf.argsort(in1)).numpy()",
                "sorted_indices = tf.argsort(in1)\nreturn tf.argsort(sorted_indices)",
                "sorted_indices = tf.argsort(in1)\nreturn tf.argsort(sorted_indices)",
                "sorted_index = tf.argsort(in1)\ninverse_permutation = tf.argsort(sorted_index)\nreturn inverse_permutation",
                "return tf.argsort(tf.argsort(in1)).numpy()"
            ],
            "target-program": "tf.cast(tf.argsort(tf.argsort(in1)), tf.int32)",
            "description": "sort a tensor and return sorted index in original order",
            "tf_operators": {
                "tf.argsort": 10
            },
            "coverage_percentage": 33.33333333333333,
            "total_in_target": 3,
            "total_covered": 1
        },
        "completions": [
            "return tf.argsort(tf.argsort(in1)).numpy()",
            "return tf.argsort(tf.argsort(in1)).numpy().tolist()",
            "sorted_idxs = tf.argsort(in1)\nreturn tf.argsort(sorted_idxs)",
            "sorted_indices = tf.argsort(in1)\noriginal_order_indices = tf.argsort(sorted_indices)\nreturn original_order_indices",
            "return tf.argsort(tf.argsort(in1))",
            "return tf.argsort(tf.argsort(in1)).numpy()",
            "sorted_indices = tf.argsort(in1)\nreturn tf.argsort(sorted_indices)",
            "sorted_indices = tf.argsort(in1)\nreturn tf.argsort(sorted_indices)",
            "sorted_index = tf.argsort(in1)\ninverse_permutation = tf.argsort(sorted_index)\nreturn inverse_permutation",
            "return tf.argsort(tf.argsort(in1)).numpy()"
        ]
    },
    {
        "constants": "[]",
        "description": "update a tensor at the given indices",
        "target_program": "tf.tensor_scatter_nd_update(tensor, indices, tf.reshape(updates, (-1,)))",
        "source": "Real task encountered by Googler, 12/15/2020",
        "name": "google_21",
        "examples": {
            "inputs": "{'tensor': [[1, 2, 3, 4, 5], [4, 5, 6, 7, 8], [7, 8, 9, 10, 11]], 'indices': [[0, 0], [0, 2], [1, 1], [1, 3], [2, 2], [2, 4]], 'updates': [[0, -2], [-1, -3], [-2, -4]],}",
            "outputs": "[[0, 2, -2, 4, 5], [4, -1, 6, -3, 8], [7, 8, -2, 10, -4]]"
        },
        "response": {
            "task_id": "google_21",
            "completions": [
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])"
            ],
            "target-program": "tf.tensor_scatter_nd_update(tensor, indices, tf.reshape(updates, (-1,)))",
            "description": "update a tensor at the given indices",
            "tf_operators": {
                "tf.tensor_scatter_nd_update": 10
            },
            "coverage_percentage": 50.0,
            "total_in_target": 2,
            "total_covered": 1
        },
        "completions": [
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])"
        ]
    },
    {
        "constants": "[]",
        "description": "pair with row index",
        "target_program": "tf.cast(tf.where(tf.reduce_max(tf.one_hot(in1, tf.reduce_max(in1) + 1), axis=1)), tf.int32)",
        "source": "Real task encountered by Googler, 12/15/2020",
        "name": "google_22",
        "examples": {
            "inputs": "[[[0, 2], [1, 3], [2, 4]],]",
            "outputs": "[[0, 0], [0, 2], [1, 1], [1, 3], [2, 2], [2, 4]]"
        },
        "response": {
            "task_id": "google_22",
            "completions": [
                "# get the indices of the input matrix as pairs\n    indices = tf.where(tf.ones_like(in1))\n\n    # get the input matrix and flatten it to 1-D\n    flattened_in1 = tf.reshape(in1, [-1])\n\n    # gather elements from flattened_in1 using the second column of the indices\n    gathered = tf.gather(flattened_in1, indices[:, 1])\n\n    # stack the indices and gathered data along the second dimension\n    result = tf.stack([indices, gathered], axis=-1)\n\n    # reshape the result back to 2-D matrix\n    result = tf.reshape(result, [-1, 2])\n\n    # return the transformed matrix\n    return result",
                "indices = tf.range(tf.shape(in1)[0])\n     indices = tf.expand_dims(indices, axis=-1)\n     repeated_indices = tf.repeat(indices, tf.shape(in1)[1], axis=1)\n     flattened_indices = tf.reshape(repeated_indices, [-1, 1])\n     flattened_in1 = tf.reshape(in1, [-1, 1])\n     result = tf.concat([flattened_indices, flattened_in1], axis=1)\n     return result",
                "indices = tf.range(tf.shape(in1)[0])\nindices = tf.reshape(indices, [-1, 1])\nindices = tf.tile(indices, [1, tf.shape(in1)[1]])\nindices = tf.reshape(indices, [-1, 1])\nin1 = tf.reshape(in1, [-1, 1])\nout1 = tf.concat([indices, in1], axis=-1)\nreturn out1",
                "indices = tf.range(tf.shape(in1)[0])\nindices = tf.reshape(indices, [-1, 1])\nindices = tf.tile(indices, [1, tf.shape(in1)[1]])\nindices = tf.reshape(indices, [-1, 1])\nin1 = tf.reshape(in1, [-1, 1])\nreturn tf.concat([indices, in1], axis=1)",
                "import tensorflow as tf\n\ndef transform(in1):\n    row_indices = tf.range(tf.shape(in1)[0])\n    repeated_row_indices = tf.repeat(row_indices, tf.shape(in1)[1])\n    flat_in1 = tf.reshape(in1, [-1])\n    return tf.stack([repeated_row_indices, flat_in1], axis=1)",
                "indices = tf.range(tf.shape(in1)[0])\nindices = tf.reshape(indices, [-1,1])\nindices = tf.broadcast_to(indices, tf.shape(in1))\nout = tf.stack([indices, in1], axis=-1)\nout = tf.reshape(out, [-1,2])\nreturn out",
                "indices = tf.range(tf.shape(in1)[0])\n     indices = tf.reshape(indices, (-1, 1))\n     extended_indices = tf.tile(indices, [1, tf.shape(in1)[1]])\n     reshaped_in1 = tf.reshape(in1, (-1, 1))\n\n     return tf.concat([tf.reshape(extended_indices, (-1, 1)), reshaped_in1], axis=1)",
                "indices = tf.range(tf.shape(in1)[0])\nindices = tf.expand_dims(indices, axis=-1)\nfinal = tf.broadcast_to(indices, tf.shape(in1))\nreturn tf.stack([final, in1], axis=-1)",
                "# For every element in the input, create a pair of [row index, element value]. This can be done by using tf.range to generate row indices, tf.repeat to repeat each index n times, tf.reshape to match the shape of the input, and finally using tf.concat to pair each index with the corresponding element.\n\nreturn tf.concat([tf.reshape(tf.repeat(tf.range(tf.shape(in1)[0]), tf.shape(in1)[1]), in1.shape), in1], axis=1)",
                "import tensorflow as tf\n\ndef transform(in1):\n    row_indices = tf.range(tf.shape(in1)[0])\n    expanded_row_indices = tf.expand_dims(row_indices, axis=-1)\n    tiled_row_indices = tf.tile(expanded_row_indices, [1, tf.shape(in1)[1]])\n    reshaped_row_indices = tf.reshape(tiled_row_indices, [-1, 1])\n\n    in1_reshaped = tf.reshape(in1, [-1, 1])\n\n    return tf.concat([reshaped_row_indices, in1_reshaped], axis=1)"
            ],
            "target-program": "tf.cast(tf.where(tf.reduce_max(tf.one_hot(in1, tf.reduce_max(in1) + 1), axis=1)), tf.int32)",
            "description": "pair with row index",
            "tf_operators": {
                "tf.reshape": 9,
                "tf.stack": 4,
                "tf.where": 1,
                "tf.gather": 1,
                "tf.ones_like": 1,
                "tf.shape": 9,
                "tf.repeat": 3,
                "tf.concat": 6,
                "tf.range": 9,
                "tf.expand_dims": 3,
                "tf.tile": 4,
                "tf.broadcast_to": 2
            },
            "coverage_percentage": 20.0,
            "total_in_target": 5,
            "total_covered": 1
        },
        "completions": [
            "# get the indices of the input matrix as pairs\n    indices = tf.where(tf.ones_like(in1))\n\n    # get the input matrix and flatten it to 1-D\n    flattened_in1 = tf.reshape(in1, [-1])\n\n    # gather elements from flattened_in1 using the second column of the indices\n    gathered = tf.gather(flattened_in1, indices[:, 1])\n\n    # stack the indices and gathered data along the second dimension\n    result = tf.stack([indices, gathered], axis=-1)\n\n    # reshape the result back to 2-D matrix\n    result = tf.reshape(result, [-1, 2])\n\n    # return the transformed matrix\n    return result",
            "indices = tf.range(tf.shape(in1)[0])\n     indices = tf.expand_dims(indices, axis=-1)\n     repeated_indices = tf.repeat(indices, tf.shape(in1)[1], axis=1)\n     flattened_indices = tf.reshape(repeated_indices, [-1, 1])\n     flattened_in1 = tf.reshape(in1, [-1, 1])\n     result = tf.concat([flattened_indices, flattened_in1], axis=1)\n     return result",
            "indices = tf.range(tf.shape(in1)[0])\nindices = tf.reshape(indices, [-1, 1])\nindices = tf.tile(indices, [1, tf.shape(in1)[1]])\nindices = tf.reshape(indices, [-1, 1])\nin1 = tf.reshape(in1, [-1, 1])\nout1 = tf.concat([indices, in1], axis=-1)\nreturn out1",
            "indices = tf.range(tf.shape(in1)[0])\nindices = tf.reshape(indices, [-1, 1])\nindices = tf.tile(indices, [1, tf.shape(in1)[1]])\nindices = tf.reshape(indices, [-1, 1])\nin1 = tf.reshape(in1, [-1, 1])\nreturn tf.concat([indices, in1], axis=1)",
            "import tensorflow as tf\n\ndef transform(in1):\n    row_indices = tf.range(tf.shape(in1)[0])\n    repeated_row_indices = tf.repeat(row_indices, tf.shape(in1)[1])\n    flat_in1 = tf.reshape(in1, [-1])\n    return tf.stack([repeated_row_indices, flat_in1], axis=1)",
            "indices = tf.range(tf.shape(in1)[0])\nindices = tf.reshape(indices, [-1,1])\nindices = tf.broadcast_to(indices, tf.shape(in1))\nout = tf.stack([indices, in1], axis=-1)\nout = tf.reshape(out, [-1,2])\nreturn out",
            "indices = tf.range(tf.shape(in1)[0])\n     indices = tf.reshape(indices, (-1, 1))\n     extended_indices = tf.tile(indices, [1, tf.shape(in1)[1]])\n     reshaped_in1 = tf.reshape(in1, (-1, 1))\n\n     return tf.concat([tf.reshape(extended_indices, (-1, 1)), reshaped_in1], axis=1)",
            "indices = tf.range(tf.shape(in1)[0])\nindices = tf.expand_dims(indices, axis=-1)\nfinal = tf.broadcast_to(indices, tf.shape(in1))\nreturn tf.stack([final, in1], axis=-1)",
            "# For every element in the input, create a pair of [row index, element value]. This can be done by using tf.range to generate row indices, tf.repeat to repeat each index n times, tf.reshape to match the shape of the input, and finally using tf.concat to pair each index with the corresponding element.\n\nreturn tf.concat([tf.reshape(tf.repeat(tf.range(tf.shape(in1)[0]), tf.shape(in1)[1]), in1.shape), in1], axis=1)",
            "import tensorflow as tf\n\ndef transform(in1):\n    row_indices = tf.range(tf.shape(in1)[0])\n    expanded_row_indices = tf.expand_dims(row_indices, axis=-1)\n    tiled_row_indices = tf.tile(expanded_row_indices, [1, tf.shape(in1)[1]])\n    reshaped_row_indices = tf.reshape(tiled_row_indices, [-1, 1])\n\n    in1_reshaped = tf.reshape(in1, [-1, 1])\n\n    return tf.concat([reshaped_row_indices, in1_reshaped], axis=1)"
        ]
    },
    {
        "constants": "[]",
        "description": "reshape by separating and duplicating columns",
        "target_program": "tf.transpose(tf.cast((in1, in1), tf.float32))",
        "source": "https://stackoverflow.com/questions/40441503/tensorflow-tensor-reshape",
        "name": "stackoverflow_01",
        "examples": {
            "inputs": "[[[5., 2.], [1., 3.], [0., -1.]],]",
            "outputs": "[[[5., 5.], [1., 1.], [0., 0.]],    [[2., 2.], [3., 3.], [-1., -1.]]]"
        },
        "response": {
            "task_id": "stackoverflow_01",
            "completions": [
                "return tf.reshape(tf.repeat(in1, 2, axis=1), [2, in1.shape[0], 2])",
                "reshaped = tf.expand_dims(in1, axis=0)\ntransposed = tf.transpose(reshaped, perm=[2, 1, 0])\nduplicated = tf.tile(transposed, multiples=[1, 1, 2])\nreturn duplicated",
                "in1 = tf.constant(in1)\nin1_sep = tf.unstack(in1, axis=1)\nin1_dup = [tf.expand_dims(tf.tile(tf.reshape(el, (-1, 1)), [1, 2]), axis=0) for el in in1_sep]\nreturn tf.concat(in1_dup, axis=0)",
                "in1 = tf.expand_dims(in1, -1)\nin1 = tf.tile(in1, [1, 1, 2])\nin1 = tf.transpose(in1, [2, 0, 1])\nreturn in1",
                "in1 = tf.expand_dims(in1, axis=0)\nin1 = tf.tile(in1, [2,1,2])\nout = tf.unstack(in1, axis=2)\nreturn out",
                "return tf.reshape(tf.tile(in1, [1, 2]), [tf.shape(in1)[1], tf.shape(in1)[0], 2])",
                "return tf.reshape(tf.tile(in1, [2, 1]), [2, tf.shape(in1)[0], 2])",
                "return tf.reshape(tf.tile(in1, [1, 2]), [2, tf.shape(in1)[0], -1])",
                "return tf.reshape(tf.tile(in1, [1, 2]), [2, tf.shape(in1)[0], 2])",
                "reshaped = tf.reshape(in1, [in1.shape[1], in1.shape[0], 1])\nreturn tf.tile(reshaped, [1, 1, 2])"
            ],
            "target-program": "tf.transpose(tf.cast((in1, in1), tf.float32))",
            "description": "reshape by separating and duplicating columns",
            "tf_operators": {
                "tf.reshape": 7,
                "tf.repeat": 1,
                "tf.transpose": 2,
                "tf.tile": 9,
                "tf.expand_dims": 4,
                "tf.unstack": 2,
                "tf.concat": 1,
                "tf.constant": 1,
                "tf.shape": 4
            },
            "coverage_percentage": 33.33333333333333,
            "total_in_target": 3,
            "total_covered": 1
        },
        "completions": [
            "return tf.reshape(tf.repeat(in1, 2, axis=1), [2, in1.shape[0], 2])",
            "reshaped = tf.expand_dims(in1, axis=0)\ntransposed = tf.transpose(reshaped, perm=[2, 1, 0])\nduplicated = tf.tile(transposed, multiples=[1, 1, 2])\nreturn duplicated",
            "in1 = tf.constant(in1)\nin1_sep = tf.unstack(in1, axis=1)\nin1_dup = [tf.expand_dims(tf.tile(tf.reshape(el, (-1, 1)), [1, 2]), axis=0) for el in in1_sep]\nreturn tf.concat(in1_dup, axis=0)",
            "in1 = tf.expand_dims(in1, -1)\nin1 = tf.tile(in1, [1, 1, 2])\nin1 = tf.transpose(in1, [2, 0, 1])\nreturn in1",
            "in1 = tf.expand_dims(in1, axis=0)\nin1 = tf.tile(in1, [2,1,2])\nout = tf.unstack(in1, axis=2)\nreturn out",
            "return tf.reshape(tf.tile(in1, [1, 2]), [tf.shape(in1)[1], tf.shape(in1)[0], 2])",
            "return tf.reshape(tf.tile(in1, [2, 1]), [2, tf.shape(in1)[0], 2])",
            "return tf.reshape(tf.tile(in1, [1, 2]), [2, tf.shape(in1)[0], -1])",
            "return tf.reshape(tf.tile(in1, [1, 2]), [2, tf.shape(in1)[0], 2])",
            "reshaped = tf.reshape(in1, [in1.shape[1], in1.shape[0], 1])\nreturn tf.tile(reshaped, [1, 1, 2])"
        ]
    },
    {
        "constants": "[1]",
        "description": "clip values that are greater than 1",
        "target_program": "tf.minimum(in1, tf.constant(1))",
        "source": "https://stackoverflow.com/questions/46408839/tensorflow-trim-values-in-tensor",
        "name": "stackoverflow_02",
        "examples": {
            "inputs": "[[5, 1, 0, 3, 0, -1, 2, -10, 2],]",
            "outputs": "[[1, 1, 0, 1, 0, -1, 1, -10, 1]]"
        },
        "response": {
            "task_id": "stackoverflow_02",
            "completions": [
                "return tf.clip_by_value(in1, -1 * tf.float32.max, 1)",
                "return tf.clip_by_value(in1, -np.inf, 1)",
                "return tf.clip_by_value(in1, -np.inf, 1)",
                "return tf.clip_by_value(in1, -tf.float32.max, 1)",
                "return tf.clip_by_value(in1, -tf.float32.max, 1)",
                "return tf.clip_by_value(in1, -np.inf, 1)",
                "return tf.clip_by_value(in1, -np.inf, 1)",
                "return tf.clip_by_value(in1, -np.inf, 1)",
                "return tf.clip_by_value(in1, -np.inf, 1)",
                "return tf.clip_by_value(in1, -np.inf, 1)"
            ],
            "target-program": "tf.minimum(in1, tf.constant(1))",
            "description": "clip values that are greater than 1",
            "tf_operators": {
                "tf.clip_by_value": 10,
                "tf.float32.max": 3
            },
            "coverage_percentage": 0.0,
            "total_in_target": 2,
            "total_covered": 0
        },
        "completions": [
            "return tf.clip_by_value(in1, -1 * tf.float32.max, 1)",
            "return tf.clip_by_value(in1, -np.inf, 1)",
            "return tf.clip_by_value(in1, -np.inf, 1)",
            "return tf.clip_by_value(in1, -tf.float32.max, 1)",
            "return tf.clip_by_value(in1, -tf.float32.max, 1)",
            "return tf.clip_by_value(in1, -np.inf, 1)",
            "return tf.clip_by_value(in1, -np.inf, 1)",
            "return tf.clip_by_value(in1, -np.inf, 1)",
            "return tf.clip_by_value(in1, -np.inf, 1)",
            "return tf.clip_by_value(in1, -np.inf, 1)"
        ]
    },
    {
        "constants": "[3, 4, 5]",
        "description": "replace certain columns with columns from the other tensor",
        "target_program": "tf.reduce_sum(tf.one_hot(tf.range(3, 5), depth=in1.shape[1], dtype=tf.int32), axis=0) * in2 + (1 - tf.reduce_sum(tf.one_hot(tf.range(3, 5), depth=in1.shape[1], dtype=tf.int32), axis=0)) * in1",
        "source": "https://stackoverflow.com/questions/44657388/how-to-replace-certain-values-in-tensorflow-tensor-with-the-values-of-the-other",
        "name": "stackoverflow_03",
        "examples": {
            "inputs": "[[[11, 22, 33, 44, 55, 66, 77], [70, 60, 50, 40, 30, 20, 10]],[[-9, -8, -7, -6, -5, -4, -3], [11, 12, 13, 14, 15, 16, 17]],]",
            "outputs": "[[[11, 22, 33, -6, -5, 66, 77], [70, 60, 50, 14, 15, 20, 10]]]"
        },
        "response": {
            "task_id": "stackoverflow_03",
            "completions": [
                "indices = tf.constant([3, 4])\nreturn tf.tensor_scatter_nd_update(in1, tf.expand_dims(indices, axis=-1), tf.transpose(tf.gather(in2, indices, axis=1)))",
                "in1 = tf.constant(in1)\nin2 = tf.constant(in2)\n\nindices = tf.constant([[0, 3], [0, 4], [1, 3], [1, 4]])\nupdates = tf.gather_nd(in2, indices)\n\nout = tf.tensor_scatter_nd_update(in1, indices, updates)\n\nreturn out",
                "indices = tf.constant([3,4]) # columns to replace\n     in1 = tf.gather(in1, indices, axis=1)\n     in2 = tf.gather(in2, indices, axis=1)\n\n     # Concatenate the tensors along the second axis (columns)\n     return tf.concat([in1, in2], axis=1)",
                "return tf.tensor_scatter_nd_update(in1, [[0,3], [0,4],[1,3], [1,4]], [in2[0,3], in2[0,4], in2[1,3], in2[1,4]])",
                "return tf.tensor_scatter_nd_update(in1, [[0,3],[0,4],[1,3],[1,4]], tf.gather_nd(in2, [[0,3],[0,4],[1,3],[1,4]]))",
                "in1 = tf.constant(in1)\nin2 = tf.constant(in2)\ncols_to_replace = [3,4]\nreturn tf.tensor_scatter_nd_update(in1,\n                                  tf.expand_dims(tf.constant(cols_to_replace),1),\n                                  tf.gather(in2,cols_to_replace, axis=1))",
                "in1 = tf.constant(in1)\n     in2 = tf.constant(in2)\n\n     swapped_tensor = tf.tensor_scatter_nd_update(in1, [[0,3],[0,4],[1,3],[1,4]], [in2[0][3], in2[0][4], in2[1][3], in2[1][4]])\n     return tf.reshape(swapped_tensor, [1, tf.shape(swapped_tensor)[0], tf.shape(swapped_tensor)[1]])",
                "in1 = tf.constant(in1)\n     in2 = tf.constant(in2)\n     in1 = tf.tensor_scatter_nd_update(in1, [[0,3], [0,4], [1,3], [1,4]], [in2[0,3], in2[0,4], in2[1,3], in2[1,4]])\n     return tf.expand_dims(in1, 0)",
                "indices = tf.constant([3, 4])\n     return tf.tensor_scatter_nd_update(in1, tf.stack([tf.range(tf.shape(in1)[0]), indices], axis=-1), tf.gather(in2, indices, axis=-1))",
                "in1 = tf.constant(in1)\nin2 = tf.constant(in2)\nindices = tf.constant([3, 4])  # columns to replace\nin1_gathered = tf.gather(in1, indices, axis=1)\nin2_gathered = tf.gather(in2, indices, axis=1)\nres = tf.tensor_scatter_nd_update(in1, tf.expand_dims(indices, 1), in2_gathered)\nreturn tf.expand_dims(res, 0)"
            ],
            "target-program": "tf.reduce_sum(tf.one_hot(tf.range(3, 5), depth=in1.shape[1], dtype=tf.int32), axis=0) * in2 + (1 - tf.reduce_sum(tf.one_hot(tf.range(3, 5), depth=in1.shape[1], dtype=tf.int32), axis=0)) * in1",
            "description": "replace certain columns with columns from the other tensor",
            "tf_operators": {
                "tf.transpose": 1,
                "tf.gather": 5,
                "tf.constant": 8,
                "tf.expand_dims": 4,
                "tf.tensor_scatter_nd_update": 9,
                "tf.gather_nd": 2,
                "tf.concat": 1,
                "tf.shape": 2,
                "tf.reshape": 1,
                "tf.range": 1,
                "tf.stack": 1
            },
            "coverage_percentage": 25.0,
            "total_in_target": 4,
            "total_covered": 1
        },
        "completions": [
            "indices = tf.constant([3, 4])\nreturn tf.tensor_scatter_nd_update(in1, tf.expand_dims(indices, axis=-1), tf.transpose(tf.gather(in2, indices, axis=1)))",
            "in1 = tf.constant(in1)\nin2 = tf.constant(in2)\n\nindices = tf.constant([[0, 3], [0, 4], [1, 3], [1, 4]])\nupdates = tf.gather_nd(in2, indices)\n\nout = tf.tensor_scatter_nd_update(in1, indices, updates)\n\nreturn out",
            "indices = tf.constant([3,4]) # columns to replace\n     in1 = tf.gather(in1, indices, axis=1)\n     in2 = tf.gather(in2, indices, axis=1)\n\n     # Concatenate the tensors along the second axis (columns)\n     return tf.concat([in1, in2], axis=1)",
            "return tf.tensor_scatter_nd_update(in1, [[0,3], [0,4],[1,3], [1,4]], [in2[0,3], in2[0,4], in2[1,3], in2[1,4]])",
            "return tf.tensor_scatter_nd_update(in1, [[0,3],[0,4],[1,3],[1,4]], tf.gather_nd(in2, [[0,3],[0,4],[1,3],[1,4]]))",
            "in1 = tf.constant(in1)\nin2 = tf.constant(in2)\ncols_to_replace = [3,4]\nreturn tf.tensor_scatter_nd_update(in1,\n                                  tf.expand_dims(tf.constant(cols_to_replace),1),\n                                  tf.gather(in2,cols_to_replace, axis=1))",
            "in1 = tf.constant(in1)\n     in2 = tf.constant(in2)\n\n     swapped_tensor = tf.tensor_scatter_nd_update(in1, [[0,3],[0,4],[1,3],[1,4]], [in2[0][3], in2[0][4], in2[1][3], in2[1][4]])\n     return tf.reshape(swapped_tensor, [1, tf.shape(swapped_tensor)[0], tf.shape(swapped_tensor)[1]])",
            "in1 = tf.constant(in1)\n     in2 = tf.constant(in2)\n     in1 = tf.tensor_scatter_nd_update(in1, [[0,3], [0,4], [1,3], [1,4]], [in2[0,3], in2[0,4], in2[1,3], in2[1,4]])\n     return tf.expand_dims(in1, 0)",
            "indices = tf.constant([3, 4])\n     return tf.tensor_scatter_nd_update(in1, tf.stack([tf.range(tf.shape(in1)[0]), indices], axis=-1), tf.gather(in2, indices, axis=-1))",
            "in1 = tf.constant(in1)\nin2 = tf.constant(in2)\nindices = tf.constant([3, 4])  # columns to replace\nin1_gathered = tf.gather(in1, indices, axis=1)\nin2_gathered = tf.gather(in2, indices, axis=1)\nres = tf.tensor_scatter_nd_update(in1, tf.expand_dims(indices, 1), in2_gathered)\nreturn tf.expand_dims(res, 0)"
        ]
    },
    {
        "constants": "[]",
        "description": "index into the tensor",
        "target_program": "tf.gather_nd(in1, tf.stack((in2, in3), axis=-1))",
        "source": "https://stackoverflow.com/questions/33736795/tensorflow-numpy-like-tensor-indexing",
        "name": "stackoverflow_04",
        "examples": {
            "inputs": "[  [[5., 2.], [1., 3.], [0., -1.]]]",
            "outputs": "[[[5., 5.], [1., 1.], [0., 0.]],  [[2., 2.], [3., 3.], [-1., -1.]]]"
        },
        "response": {
            "task_id": "stackoverflow_04",
            "completions": [
                "return tf.stack([tf.gather(in1, 0, axis=1), tf.gather(in1, 1, axis=1)], axis=0)",
                "return tf.gather(in1, tf.argsort(in1, axis=-1, stable=True), axis=1)",
                "return tf.gather(in1, tf.constant([0, 1]), axis=1)",
                "return tf.transpose(tf.broadcast_to(in1, [2,3,2]))",
                "return tf.transpose(tf.expand_dims(in1, axis=0), perm=[2, 1, 0])",
                "return tf.transpose(tf.expand_dims(in1, -1), perm=[2, 0, 1])",
                "return tf.broadcast_to(in1, [2, *tf.shape(in1)])",
                "return tf.gather(in1, [[0, 0], [1, 1]], axis=1)",
                "return tf.gather(tf.transpose(in1), [0, 1], axis=0)",
                "return tf.transpose(tf.stack([in1, in1]), perm=[1, 2, 0])"
            ],
            "target-program": "tf.gather_nd(in1, tf.stack((in2, in3), axis=-1))",
            "description": "index into the tensor",
            "tf_operators": {
                "tf.gather": 5,
                "tf.stack": 2,
                "tf.argsort": 1,
                "tf.constant": 1,
                "tf.broadcast_to": 2,
                "tf.transpose": 5,
                "tf.expand_dims": 2,
                "tf.shape": 1
            },
            "coverage_percentage": 50.0,
            "total_in_target": 2,
            "total_covered": 1
        },
        "completions": [
            "return tf.stack([tf.gather(in1, 0, axis=1), tf.gather(in1, 1, axis=1)], axis=0)",
            "return tf.gather(in1, tf.argsort(in1, axis=-1, stable=True), axis=1)",
            "return tf.gather(in1, tf.constant([0, 1]), axis=1)",
            "return tf.transpose(tf.broadcast_to(in1, [2,3,2]))",
            "return tf.transpose(tf.expand_dims(in1, axis=0), perm=[2, 1, 0])",
            "return tf.transpose(tf.expand_dims(in1, -1), perm=[2, 0, 1])",
            "return tf.broadcast_to(in1, [2, *tf.shape(in1)])",
            "return tf.gather(in1, [[0, 0], [1, 1]], axis=1)",
            "return tf.gather(tf.transpose(in1), [0, 1], axis=0)",
            "return tf.transpose(tf.stack([in1, in1]), perm=[1, 2, 0])"
        ]
    },
    {
        "constants": "[]",
        "description": "tensor multiplication like np.tensordot",
        "target_program": "tf.tensordot(in1, in2, 1)",
        "source": "https://stackoverflow.com/questions/43067338/tensor-multiplication-in-tensorflow",
        "name": "stackoverflow_05",
        "examples": {
            "inputs": "[[[4, 3, 1], [6, 5, 2]],[[[5, 5]], [[1, 5]], [[6, 0]]],]",
            "outputs": "[[[29, 35]], [[47, 55]]]"
        },
        "response": {
            "task_id": "stackoverflow_05",
            "completions": [
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=[[1], [0]])",
                "return tf.tensordot(in1, in2, axes=[[1], [1]])",
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=[[1], [0]])"
            ],
            "target-program": "tf.tensordot(in1, in2, 1)",
            "description": "tensor multiplication like np.tensordot",
            "tf_operators": {
                "tf.tensordot": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=[[1], [0]])",
            "return tf.tensordot(in1, in2, axes=[[1], [1]])",
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=[[1], [0]])"
        ]
    },
    {
        "constants": "[]",
        "description": "binary tensor from vector indicating if elements are equal",
        "target_program": "tf.cast(tf.equal(in1, tf.expand_dims(in1, 1)), tf.float32)",
        "source": "https://stackoverflow.com/questions/47816231/create-binary-tensor-from-vector-in-tensorflow",
        "name": "stackoverflow_06",
        "examples": {
            "inputs": "[[3, 5, 0, 2, 3, 3, 0],]",
            "outputs": "[[1., 0., 0., 0., 1., 1., 0.],    [0., 1., 0., 0., 0., 0., 0.],    [0., 0., 1., 0., 0., 0., 1.],    [0., 0., 0., 1., 0., 0., 0.],    [1., 0., 0., 0., 1., 1., 0.],    [1., 0., 0., 0., 1., 1., 0.],    [0., 0., 1., 0., 0., 0., 1.]]"
        },
        "response": {
            "task_id": "stackoverflow_06",
            "completions": [
                "return tf.cast(tf.equal(tf.expand_dims(in1, 0), tf.expand_dims(in1, 1)), tf.int32)",
                "return tf.cast(tf.equal(tf.expand_dims(in1, 0), tf.expand_dims(in1, 1)), tf.float32)",
                "return tf.cast(tf.equal(tf.reshape(in1, [-1, 1]), in1), tf.float32)",
                "return tf.cast(tf.equal(tf.expand_dims(in1, 0), tf.expand_dims(in1, 1)), tf.float32)",
                "import tensorflow as tf\n\ndef transform(in1):\n    return tf.cast(tf.equal(tf.expand_dims(in1, axis=0), tf.expand_dims(in1, axis=1)), tf.float32)",
                "return tf.cast(tf.equal(tf.expand_dims(in1, 0), tf.expand_dims(in1, 1)), tf.float32)",
                "return tf.cast(tf.equal(tf.reshape(in1, [-1, 1]), tf.reshape(in1, [1, -1])), dtype=float)",
                "return tf.cast(tf.equal(in1[:, tf.newaxis], in1), tf.float32)",
                "return tf.cast(tf.equal(tf.expand_dims(in1, 1), tf.expand_dims(in1, 0)), tf.float32)",
                "return tf.cast(tf.equal(tf.expand_dims(in1, 0), tf.expand_dims(in1, 1)), dtype=tf.float32)"
            ],
            "target-program": "tf.cast(tf.equal(in1, tf.expand_dims(in1, 1)), tf.float32)",
            "description": "binary tensor from vector indicating if elements are equal",
            "tf_operators": {
                "tf.expand_dims": 7,
                "tf.int32": 1,
                "tf.equal": 10,
                "tf.cast": 10,
                "tf.float32": 8,
                "tf.reshape": 2,
                "tf.newaxis": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 4,
            "total_covered": 4
        },
        "completions": [
            "return tf.cast(tf.equal(tf.expand_dims(in1, 0), tf.expand_dims(in1, 1)), tf.int32)",
            "return tf.cast(tf.equal(tf.expand_dims(in1, 0), tf.expand_dims(in1, 1)), tf.float32)",
            "return tf.cast(tf.equal(tf.reshape(in1, [-1, 1]), in1), tf.float32)",
            "return tf.cast(tf.equal(tf.expand_dims(in1, 0), tf.expand_dims(in1, 1)), tf.float32)",
            "import tensorflow as tf\n\ndef transform(in1):\n    return tf.cast(tf.equal(tf.expand_dims(in1, axis=0), tf.expand_dims(in1, axis=1)), tf.float32)",
            "return tf.cast(tf.equal(tf.expand_dims(in1, 0), tf.expand_dims(in1, 1)), tf.float32)",
            "return tf.cast(tf.equal(tf.reshape(in1, [-1, 1]), tf.reshape(in1, [1, -1])), dtype=float)",
            "return tf.cast(tf.equal(in1[:, tf.newaxis], in1), tf.float32)",
            "return tf.cast(tf.equal(tf.expand_dims(in1, 1), tf.expand_dims(in1, 0)), tf.float32)",
            "return tf.cast(tf.equal(tf.expand_dims(in1, 0), tf.expand_dims(in1, 1)), dtype=tf.float32)"
        ]
    },
    {
        "constants": "[]",
        "description": "swap the first two dimensions of the tensor",
        "target_program": "tf.cast(tf.unstack(in1, axis=1), tf.int32)",
        "source": "https://stackoverflow.com/questions/38212205/swap-tensor-axes-in-tensorflow",
        "name": "stackoverflow_07",
        "examples": {
            "inputs": "[[[[8, 4, 6], [2, 12, 3]], [[11, 12, 5], [9, 12, 12]], [[9, 2, 13], [7, 0, 7]], [[2, 10, 5], [7, 1, 2]]],]",
            "outputs": "[[[8, 4, 6], [11, 12, 5], [9, 2, 13], [2, 10, 5]],    [[2, 12, 3], [9, 12, 12], [7, 0, 7], [7, 1, 2]]]"
        },
        "response": {
            "task_id": "stackoverflow_07",
            "completions": [
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(a=in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])"
            ],
            "target-program": "tf.cast(tf.unstack(in1, axis=1), tf.int32)",
            "description": "swap the first two dimensions of the tensor",
            "tf_operators": {
                "tf.transpose": 10
            },
            "coverage_percentage": 0.0,
            "total_in_target": 3,
            "total_covered": 0
        },
        "completions": [
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(a=in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])"
        ]
    },
    {
        "constants": "[1]",
        "description": "(\\'select the values in the second tensor where the first tensor is greater than 1\\')",
        "target_program": "tf.boolean_mask(in2, tf.greater(in1, tf.constant(1)))",
        "source": "https://stackoverflow.com/questions/33769041/tensorflow-indexing-with-boolean-tensor",
        "name": "stackoverflow_08",
        "examples": {
            "inputs": "[[-1, 0, -3, 2, 1, 3, 5, -1, -9, 2, 10],[12, 3, 45, 6, 7, 8, 9, 87, 65, 4, 32],]",
            "outputs": "[6, 8, 9, 4, 32]"
        },
        "response": {
            "task_id": "stackoverflow_08",
            "completions": [
                "return tf.boolean_mask(in2, tf.greater(in1, 1)).numpy()",
                "return tf.boolean_mask(in2, tf.greater(in1, 1))",
                "mask = tf.greater(in1, 1)\n     return tf.boolean_mask(in2, mask)",
                "return tf.boolean_mask(in2, tf.greater(in1, tf.constant(1)))",
                "mask = tf.greater(in1, 1)\n     return tf.boolean_mask(in2, mask)",
                "mask = tf.greater(in1, 1)\nreturn tf.boolean_mask(in2, mask)",
                "return tf.boolean_mask(in2, tf.greater(in1, 1))",
                "mask = tf.greater(in1, 1)\n     return tf.boolean_mask(in2, mask)",
                "mask = tf.greater(in1, 1)\nout = tf.boolean_mask(in2, mask)\nreturn out",
                "mask = tf.greater(in1, 1)\n     return tf.boolean_mask(in2, mask)"
            ],
            "target-program": "tf.boolean_mask(in2, tf.greater(in1, tf.constant(1)))",
            "description": "(\\'select the values in the second tensor where the first tensor is greater than 1\\')",
            "tf_operators": {
                "tf.greater": 10,
                "tf.boolean_mask": 10,
                "tf.constant": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 3,
            "total_covered": 3
        },
        "completions": [
            "return tf.boolean_mask(in2, tf.greater(in1, 1)).numpy()",
            "return tf.boolean_mask(in2, tf.greater(in1, 1))",
            "mask = tf.greater(in1, 1)\n     return tf.boolean_mask(in2, mask)",
            "return tf.boolean_mask(in2, tf.greater(in1, tf.constant(1)))",
            "mask = tf.greater(in1, 1)\n     return tf.boolean_mask(in2, mask)",
            "mask = tf.greater(in1, 1)\nreturn tf.boolean_mask(in2, mask)",
            "return tf.boolean_mask(in2, tf.greater(in1, 1))",
            "mask = tf.greater(in1, 1)\n     return tf.boolean_mask(in2, mask)",
            "mask = tf.greater(in1, 1)\nout = tf.boolean_mask(in2, mask)\nreturn out",
            "mask = tf.greater(in1, 1)\n     return tf.boolean_mask(in2, mask)"
        ]
    },
    {
        "constants": "[]",
        "description": "group items by value and get the group indices",
        "target_program": "tf.unique_with_counts(in1)[1]",
        "source": "https://stackoverflow.com/questions/53054668/assign-values-between-0-and-n-1-for-a-vector-of-length-l-with-n-different-eleme",
        "name": "stackoverflow_09",
        "examples": {
            "inputs": "[[37, 42, 42, 37, 28, 15, 42, 15],]",
            "outputs": "[0, 1, 1, 0, 2, 3, 1, 3]"
        },
        "response": {
            "task_id": "stackoverflow_09",
            "completions": [
                "_, indices = tf.unique_with_counts(in1)\nreturn tf.gather(indices, in1)",
                "_, idx = tf.unique_with_counts(in1)\nreturn idx.numpy()",
                "_, idx = tf.unique_with_counts(in1)\nout = tf.gather(idx, in1)\nreturn out",
                "_, idx = tf.unique_with_counts(in1)\nreturn tf.gather(idx, in1)",
                "uniques, idx = tf.unique_with_counts(in1)\nidx_parts = tf.math.bincount(idx)\nstart = tf.roll(tf.math.cumsum(idx_parts), shift=1, axis=0)\nstart = tf.concat([[0], start[:-1]], axis=0)\ngroup_idx = tf.zeros_like(in1)\nfor i in range(tf.reduce_max(idx)):\n    mask = tf.equal(idx, i)\n    group_idx = tf.where(mask, i, group_idx)\nreturn group_idx",
                "unique_values, unique_indices = tf.unique(in1)\nreturn tf.gather(unique_indices, in1)",
                "_, idx = tf.unique_with_counts(in1)\nreturn idx.numpy()",
                "_, indices = tf.unique(in1)\nreturn tf.cast(indices, tf.int32)",
                "_, unique_indices = tf.unique_with_counts(in1)\nreturn tf.gather(unique_indices.indices, in1)",
                "_, idx = tf.unique(in1)\nreturn tf.cast(idx, tf.int32).numpy()"
            ],
            "target-program": "tf.unique_with_counts(in1)[1]",
            "description": "group items by value and get the group indices",
            "tf_operators": {
                "tf.gather": 5,
                "tf.unique_with_counts": 7,
                "tf.roll": 1,
                "tf.math.cumsum": 1,
                "tf.reduce_max": 1,
                "tf.zeros_like": 1,
                "tf.concat": 1,
                "tf.where": 1,
                "tf.equal": 1,
                "tf.math.bincount": 1,
                "tf.unique": 3,
                "tf.int32": 2,
                "tf.cast": 2
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "_, indices = tf.unique_with_counts(in1)\nreturn tf.gather(indices, in1)",
            "_, idx = tf.unique_with_counts(in1)\nreturn idx.numpy()",
            "_, idx = tf.unique_with_counts(in1)\nout = tf.gather(idx, in1)\nreturn out",
            "_, idx = tf.unique_with_counts(in1)\nreturn tf.gather(idx, in1)",
            "uniques, idx = tf.unique_with_counts(in1)\nidx_parts = tf.math.bincount(idx)\nstart = tf.roll(tf.math.cumsum(idx_parts), shift=1, axis=0)\nstart = tf.concat([[0], start[:-1]], axis=0)\ngroup_idx = tf.zeros_like(in1)\nfor i in range(tf.reduce_max(idx)):\n    mask = tf.equal(idx, i)\n    group_idx = tf.where(mask, i, group_idx)\nreturn group_idx",
            "unique_values, unique_indices = tf.unique(in1)\nreturn tf.gather(unique_indices, in1)",
            "_, idx = tf.unique_with_counts(in1)\nreturn idx.numpy()",
            "_, indices = tf.unique(in1)\nreturn tf.cast(indices, tf.int32)",
            "_, unique_indices = tf.unique_with_counts(in1)\nreturn tf.gather(unique_indices.indices, in1)",
            "_, idx = tf.unique(in1)\nreturn tf.cast(idx, tf.int32).numpy()"
        ]
    },
    {
        "constants": "[]",
        "description": "perform matrix multiplication",
        "target_program": "tf.matmul(tf.expand_dims(in1, -1), tf.expand_dims(in2, 1))",
        "source": "https://stackoverflow.com/questions/53094212/tensorflow-sxn-matrix-multiply-with-sxd-matrix-to-output-sxnxd-array",
        "name": "stackoverflow_10",
        "examples": {
            "inputs": "[[[15, 10], [20, -5]],[[2, 3, 1], [-2, 5, 0]],]",
            "outputs": "[[[30, 45, 15], [20, 30, 10]],[[-40, 100, 0], [10, -25, 0]]]"
        },
        "response": {
            "task_id": "stackoverflow_10",
            "completions": [
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1,in2)",
                "return tf.matmul(in1, in2)"
            ],
            "target-program": "tf.matmul(tf.expand_dims(in1, -1), tf.expand_dims(in2, 1))",
            "description": "perform matrix multiplication",
            "tf_operators": {
                "tf.matmul": 10
            },
            "coverage_percentage": 50.0,
            "total_in_target": 2,
            "total_covered": 1
        },
        "completions": [
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1,in2)",
            "return tf.matmul(in1, in2)"
        ]
    },
    {
        "constants": "[]",
        "description": "count the number of occurences of each distinct number",
        "target_program": "tf.math.bincount(in1)",
        "source": "https://stackoverflow.com/questions/45194672/how-to-count-elements-in-tensorflow-tensor",
        "name": "stackoverflow_11",
        "examples": {
            "inputs": "[[4, 0, 1, 1, 0, 4, 0, 0, 3, 4, 1],]",
            "outputs": "[4, 3, 0, 1, 3]"
        },
        "response": {
            "task_id": "stackoverflow_11",
            "completions": [
                "counts = tf.math.bincount(in1)\nindices = tf.where(counts > 0)\nreturn tf.gather(indices, 0)",
                "_, _, count = tf.unique_with_counts(in1)\nreturn count",
                "_, _, count = tf.unique_with_counts(in1)\nreturn count",
                "return tf.math.bincount(in1)",
                "out1 = tf.math.bincount(in1)\nreturn out1",
                "return tf.math.bincount(in1).numpy().tolist()",
                "return tf.math.bincount(in1).numpy().tolist()",
                "return tf.math.bincount(in1)",
                "result = tf.math.bincount(in1)\nreturn result",
                "# We can use TensorFlow's bincount function to count occurences of each number\nimport tensorflow as tf\n\ndef transform(in1):\n    return tf.math.bincount(in1).numpy()"
            ],
            "target-program": "tf.math.bincount(in1)",
            "description": "count the number of occurences of each distinct number",
            "tf_operators": {
                "tf.where": 1,
                "tf.gather": 1,
                "tf.math.bincount": 8,
                "tf.unique_with_counts": 2
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "counts = tf.math.bincount(in1)\nindices = tf.where(counts > 0)\nreturn tf.gather(indices, 0)",
            "_, _, count = tf.unique_with_counts(in1)\nreturn count",
            "_, _, count = tf.unique_with_counts(in1)\nreturn count",
            "return tf.math.bincount(in1)",
            "out1 = tf.math.bincount(in1)\nreturn out1",
            "return tf.math.bincount(in1).numpy().tolist()",
            "return tf.math.bincount(in1).numpy().tolist()",
            "return tf.math.bincount(in1)",
            "result = tf.math.bincount(in1)\nreturn result",
            "# We can use TensorFlow's bincount function to count occurences of each number\nimport tensorflow as tf\n\ndef transform(in1):\n    return tf.math.bincount(in1).numpy()"
        ]
    },
    {
        "constants": "[0, 1, 2]",
        "description": "remove a column from the tensor",
        "target_program": "tf.gather(in1, (0, 2), axis=1, batch_dims=0)",
        "source": "https://stackoverflow.com/questions/47447183/remove-a-set-of-tensors-from-a-tensor-in-tensorflow",
        "name": "stackoverflow_12",
        "examples": {
            "inputs": "[[[12, 34, 56], [33, 22, 11]]]",
            "outputs": "[[12, 56], [33, 11]]"
        },
        "response": {
            "task_id": "stackoverflow_12",
            "completions": [
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.gather(in1, [0,2], axis=1)",
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.gather(in1, [0,2], axis=1)",
                "return tf.gather(in1, [0, 2], axis=1)"
            ],
            "target-program": "tf.gather(in1, (0, 2), axis=1, batch_dims=0)",
            "description": "remove a column from the tensor",
            "tf_operators": {
                "tf.gather": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.gather(in1, [0,2], axis=1)",
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.gather(in1, [0,2], axis=1)",
            "return tf.gather(in1, [0, 2], axis=1)"
        ]
    },
    {
        "constants": "[]",
        "description": "multiply vectors by tensor",
        "target_program": "tf.tensordot(in1, in2, (1, 1))",
        "source": "https://stackoverflow.com/questions/50777704/n-d-tensor-matrix-multiplication-with-tensorflow",
        "name": "stackoverflow_13",
        "examples": {
            "inputs": "[[[3, 5], [10, 2]],[[[1, 0], [5, 4]], [[3, 10], [2, -2]]],]",
            "outputs": "[[[28, 20], [19, 20]], [[20, 8], [34, 96]]]"
        },
        "response": {
            "task_id": "stackoverflow_13",
            "completions": [
                "return tf.matmul(in2, tf.transpose(in1))",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1,in2)",
                "return tf.matmul(in2, tf.expand_dims(in1, -1)).numpy().squeeze(-1)",
                "return tf.matmul(in2, tf.expand_dims(in1, 2)).numpy().squeeze(2)",
                "return tf.matmul(in2, tf.transpose(in1))",
                "return tf.matmul(in2, tf.expand_dims(in1, 2))[:,:,0]",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in2, tf.expand_dims(in1, 2))[:,:,0]",
                "return tf.matmul(in1,in2)"
            ],
            "target-program": "tf.tensordot(in1, in2, (1, 1))",
            "description": "multiply vectors by tensor",
            "tf_operators": {
                "tf.transpose": 2,
                "tf.matmul": 10,
                "tf.expand_dims": 4
            },
            "coverage_percentage": 0.0,
            "total_in_target": 1,
            "total_covered": 0
        },
        "completions": [
            "return tf.matmul(in2, tf.transpose(in1))",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1,in2)",
            "return tf.matmul(in2, tf.expand_dims(in1, -1)).numpy().squeeze(-1)",
            "return tf.matmul(in2, tf.expand_dims(in1, 2)).numpy().squeeze(2)",
            "return tf.matmul(in2, tf.transpose(in1))",
            "return tf.matmul(in2, tf.expand_dims(in1, 2))[:,:,0]",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in2, tf.expand_dims(in1, 2))[:,:,0]",
            "return tf.matmul(in1,in2)"
        ]
    },
    {
        "constants": "[]",
        "description": "choose True if any value in a row is True, False otherwise",
        "target_program": "tf.reduce_any(in1, axis=-1)",
        "source": "https://stackoverflow.com/questions/35657003/aggregate-each-element-of-tensor-in-tensorflow",
        "name": "stackoverflow_14",
        "examples": {
            "inputs": "[[[[False, False, True],  [False, False, False],  [True, False, True],  [False, True, False],  [False, False, False],  [True, True, True],  [True, True, False]]],]",
            "outputs": "[[True, False, True, True, False, True, True]]"
        },
        "response": {
            "task_id": "stackoverflow_14",
            "completions": [
                "return tf.reduce_any(in1, axis=2)",
                "return tf.reduce_any(in1, axis=2)",
                "return tf.reduce_any(in1, axis=2)",
                "return tf.reduce_any(in1, axis=2)",
                "return tf.reduce_any(in1, axis=-1)",
                "return tf.reduce_any(in1, axis=-1)",
                "return tf.reduce_any(in1, axis=2)",
                "return tf.reduce_any(in1, axis=-1)",
                "return tf.reduce_any(in1, axis=2)",
                "return tf.reduce_any(in1, axis=2)"
            ],
            "target-program": "tf.reduce_any(in1, axis=-1)",
            "description": "choose True if any value in a row is True, False otherwise",
            "tf_operators": {
                "tf.reduce_any": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.reduce_any(in1, axis=2)",
            "return tf.reduce_any(in1, axis=2)",
            "return tf.reduce_any(in1, axis=2)",
            "return tf.reduce_any(in1, axis=2)",
            "return tf.reduce_any(in1, axis=-1)",
            "return tf.reduce_any(in1, axis=-1)",
            "return tf.reduce_any(in1, axis=2)",
            "return tf.reduce_any(in1, axis=-1)",
            "return tf.reduce_any(in1, axis=2)",
            "return tf.reduce_any(in1, axis=2)"
        ]
    },
    {
        "constants": "[0, 1]",
        "description": "set all instances of 1 to 0",
        "target_program": "tf.subtract(in1, tf.cast(tf.equal(in1, tf.constant(1)), tf.int32))",
        "source": "https://stackoverflow.com/questions/39045797/conditional-assignment-of-tensor-values-in-tensorflow",
        "name": "stackoverflow_15",
        "examples": {
            "inputs": "[[3, 1, 2, 0, 1, -1, 10, 1, -10],]",
            "outputs": "[3, 0, 2, 0, 0, -1, 10, 0, -10]"
        },
        "response": {
            "task_id": "stackoverflow_15",
            "completions": [
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)"
            ],
            "target-program": "tf.subtract(in1, tf.cast(tf.equal(in1, tf.constant(1)), tf.int32))",
            "description": "set all instances of 1 to 0",
            "tf_operators": {
                "tf.equal": 10,
                "tf.where": 10
            },
            "coverage_percentage": 20.0,
            "total_in_target": 5,
            "total_covered": 1
        },
        "completions": [
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)"
        ]
    },
    {
        "constants": "[]",
        "description": "multiply tensors across the first axis",
        "target_program": "tf.multiply(in1, tf.expand_dims(in2, 1))",
        "source": "https://stackoverflow.com/questions/46240646/tensor-multiply-along-axis-in-tensorflow",
        "name": "stackoverflow_16",
        "examples": {
            "inputs": "[[[2, 5], [3, 0], [8, -7]],[4, 10, -6],]",
            "outputs": "[[8, 20], [30, 0], [-48, 42]]"
        },
        "response": {
            "task_id": "stackoverflow_16",
            "completions": [
                "return tf.multiply(in1, tf.reshape(in2, [-1, 1]))",
                "return tf.multiply(in1, tf.reshape(in2, [-1, 1]))",
                "return tf.multiply(in1, tf.expand_dims(in2,1))",
                "return tf.multiply(in1, tf.expand_dims(in2, 1))",
                "return tf.multiply(in1, tf.reshape(in2, [-1, 1]))",
                "return tf.multiply(in1, tf.expand_dims(in2, 1))",
                "return tf.multiply(in1, tf.expand_dims(in2, 1))",
                "return tf.multiply(in1, tf.expand_dims(in2, axis=-1))",
                "return tf.multiply(in1, tf.expand_dims(in2, axis=1))",
                "return tf.multiply(in1, tf.expand_dims(in2, 1))"
            ],
            "target-program": "tf.multiply(in1, tf.expand_dims(in2, 1))",
            "description": "multiply tensors across the first axis",
            "tf_operators": {
                "tf.multiply": 10,
                "tf.reshape": 3,
                "tf.expand_dims": 7
            },
            "coverage_percentage": 100.0,
            "total_in_target": 2,
            "total_covered": 2
        },
        "completions": [
            "return tf.multiply(in1, tf.reshape(in2, [-1, 1]))",
            "return tf.multiply(in1, tf.reshape(in2, [-1, 1]))",
            "return tf.multiply(in1, tf.expand_dims(in2,1))",
            "return tf.multiply(in1, tf.expand_dims(in2, 1))",
            "return tf.multiply(in1, tf.reshape(in2, [-1, 1]))",
            "return tf.multiply(in1, tf.expand_dims(in2, 1))",
            "return tf.multiply(in1, tf.expand_dims(in2, 1))",
            "return tf.multiply(in1, tf.expand_dims(in2, axis=-1))",
            "return tf.multiply(in1, tf.expand_dims(in2, axis=1))",
            "return tf.multiply(in1, tf.expand_dims(in2, 1))"
        ]
    },
    {
        "constants": "[]",
        "description": "duplicate each element of a tensor",
        "target_program": "tf.stack((in1, in1), axis=1)",
        "source": "https://stackoverflow.com/questions/51761353/about-tensor-of-tensorflow",
        "name": "stackoverflow_17",
        "examples": {
            "inputs": "[[17, -32, 99],]",
            "outputs": "[[17, 17], [-32, -32], [99, 99]]"
        },
        "response": {
            "task_id": "stackoverflow_17",
            "completions": [
                "return tf.reshape(tf.tile(in1, [2]), (-1, 2))",
                "return tf.repeat(tf.expand_dims(in1, axis=1), 2, axis=1)",
                "return tf.reshape(tf.repeat(in1, 2), (-1, 2))",
                "return tf.repeat(in1, 2, axis=-1)",
                "return tf.repeat(in1, repeats=2, axis=-1).numpy().reshape(len(in1),2)",
                "return tf.reshape(tf.tile(in1, [2]), [-1, 2])",
                "return tf.reshape(tf.tile(in1, [2]), [-1, 2])",
                "return tf.repeat(in1, repeats=[2], axis=1)",
                "return tf.reshape(tf.tile(in1, [2]), [-1, 2])",
                "return tf.repeat(in1, repeats=2, axis=-1)"
            ],
            "target-program": "tf.stack((in1, in1), axis=1)",
            "description": "duplicate each element of a tensor",
            "tf_operators": {
                "tf.reshape": 5,
                "tf.tile": 4,
                "tf.repeat": 6,
                "tf.expand_dims": 1
            },
            "coverage_percentage": 0.0,
            "total_in_target": 1,
            "total_covered": 0
        },
        "completions": [
            "return tf.reshape(tf.tile(in1, [2]), (-1, 2))",
            "return tf.repeat(tf.expand_dims(in1, axis=1), 2, axis=1)",
            "return tf.reshape(tf.repeat(in1, 2), (-1, 2))",
            "return tf.repeat(in1, 2, axis=-1)",
            "return tf.repeat(in1, repeats=2, axis=-1).numpy().reshape(len(in1),2)",
            "return tf.reshape(tf.tile(in1, [2]), [-1, 2])",
            "return tf.reshape(tf.tile(in1, [2]), [-1, 2])",
            "return tf.repeat(in1, repeats=[2], axis=1)",
            "return tf.reshape(tf.tile(in1, [2]), [-1, 2])",
            "return tf.repeat(in1, repeats=2, axis=-1)"
        ]
    },
    {
        "constants": "[]",
        "description": "multiply 3D tensor and 2D tensor and add another tensor",
        "target_program": "tf.add(in3, tf.matmul(in1, in2))",
        "source": "https://stackoverflow.com/questions/38222126/tensorflow-efficient-way-for-tensor-multiplication",
        "name": "stackoverflow_18",
        "examples": {
            "inputs": "[[[[1, 1, 1], [1, 0, 1]], [[1, 2, 3], [4, 5, 6]]], [[1, 1, 1, 1], [1, 2, 3, 4], [5, 6, 7, 8]], [100, 200, 300, 400],]",
            "outputs": "[[[107, 209, 311, 413], [106, 207, 308, 409]], [[118, 223, 328, 433], [139, 250, 361, 472]]]"
        },
        "response": {
            "task_id": "stackoverflow_18",
            "completions": [
                "mult_2d_3d = tf.tensordot(in1, in2, axes=[[2], [0]])\nreturn tf.add(mult_2d_3d, in3)",
                "result = tf.add(tf.matmul(in1, in2), in3)\nreturn result",
                "multiplied = tf.tensordot(in1, in2, axes=1)\nresult = tf.add(multiplied, in3)\nreturn result",
                "# We first extend 2D tensor into 3D to match the first tensor\n# Then we multiply the tensors and add another tensor to it.\n# We need to ensure that the shape of each tensor match to each others.\n# As for tf.tensordot, when axes is an integer, it treats the last axes dimensions as vectors and does\n# the inner product with them.\nresult = tf.add(tf.tensordot(in1, in2, axes=[[2], [0]]), in3)\nreturn result",
                "# cast the third input as tensor\n    in3 = tf.constant(in3)\n    # calculate the product of the first and second input\n    product = tf.tensordot(in1, in2, axes=[[2],[0]])\n    # add the third input to the product \n    result = tf.add(product, in3)\n\n    return result",
                "product = tf.tensordot(in1, in2, axes=1)\nresult = tf.add(product, in3)\nreturn result",
                "result = tf.add(tf.matmul(in1, in2), in3)\nreturn result",
                "product = tf.matmul(in1, in2)\nreturn tf.add(product, in3)",
                "# multiply the 3D tensor and 2D tensor\n    mul = tf.matmul(in1, in2)\n\n    # add another tensor\n    result = tf.add(mul, in3)\n    \n    return result",
                "temp = tf.tensordot(in1, in2, axes=1)\nresult = tf.add(temp, in3)\nreturn result"
            ],
            "target-program": "tf.add(in3, tf.matmul(in1, in2))",
            "description": "multiply 3D tensor and 2D tensor and add another tensor",
            "tf_operators": {
                "tf.add": 10,
                "tf.tensordot": 6,
                "tf.matmul": 4,
                "tf.constant": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 2,
            "total_covered": 2
        },
        "completions": [
            "mult_2d_3d = tf.tensordot(in1, in2, axes=[[2], [0]])\nreturn tf.add(mult_2d_3d, in3)",
            "result = tf.add(tf.matmul(in1, in2), in3)\nreturn result",
            "multiplied = tf.tensordot(in1, in2, axes=1)\nresult = tf.add(multiplied, in3)\nreturn result",
            "# We first extend 2D tensor into 3D to match the first tensor\n# Then we multiply the tensors and add another tensor to it.\n# We need to ensure that the shape of each tensor match to each others.\n# As for tf.tensordot, when axes is an integer, it treats the last axes dimensions as vectors and does\n# the inner product with them.\nresult = tf.add(tf.tensordot(in1, in2, axes=[[2], [0]]), in3)\nreturn result",
            "# cast the third input as tensor\n    in3 = tf.constant(in3)\n    # calculate the product of the first and second input\n    product = tf.tensordot(in1, in2, axes=[[2],[0]])\n    # add the third input to the product \n    result = tf.add(product, in3)\n\n    return result",
            "product = tf.tensordot(in1, in2, axes=1)\nresult = tf.add(product, in3)\nreturn result",
            "result = tf.add(tf.matmul(in1, in2), in3)\nreturn result",
            "product = tf.matmul(in1, in2)\nreturn tf.add(product, in3)",
            "# multiply the 3D tensor and 2D tensor\n    mul = tf.matmul(in1, in2)\n\n    # add another tensor\n    result = tf.add(mul, in3)\n    \n    return result",
            "temp = tf.tensordot(in1, in2, axes=1)\nresult = tf.add(temp, in3)\nreturn result"
        ]
    },
    {
        "constants": "[]",
        "description": "(\\'sort a tensor considering the first column, breaking ties using the second column\\')",
        "target_program": "tf.gather(tf.gather(in1, tf.argsort(in1[:, 1], stable=True)), tf.argsort(tf.gather(in1, tf.argsort(in1[:, 1], stable=True))[:, 0], stable=True))",
        "source": "https://stackoverflow.com/questions/49399198/sort-a-tensor-based-on-two-columns-in-tensorflow",
        "name": "stackoverflow_19",
        "examples": {
            "inputs": "[[[3, 1, 2], [1, 0, 4], [1, 2, 3], [0, 5, 1], [1, 1, 2], [2, 3, 1], [2, 1, 0]],]",
            "outputs": "[[0, 5, 1],    [1, 0, 4],    [1, 1, 2],    [1, 2, 3],    [2, 1, 0],    [2, 3, 1],    [3, 1, 2]]"
        },
        "response": {
            "task_id": "stackoverflow_19",
            "completions": [
                "return tf.sort(in1, axis=0)",
                "return tf.gather(in1, tf.argsort(in1, axis=0, stable=True))",
                "return tf.sort(in1, axis=0)",
                "return tf.sort(in1, axis=0)",
                "return tf.sort(in1, axis=0)",
                "return tf.sort(in1, axis=0)",
                "return tf.gather(in1, tf.argsort(in1, axis=0, stable=True))",
                "return tf.sort(in1, axis=0)",
                "return tf.gather(in1, tf.argsort(in1[:, :2], axis=0, stable=True))",
                "return tf.sort(in1, axis=0)"
            ],
            "target-program": "tf.gather(tf.gather(in1, tf.argsort(in1[:, 1], stable=True)), tf.argsort(tf.gather(in1, tf.argsort(in1[:, 1], stable=True))[:, 0], stable=True))",
            "description": "(\\'sort a tensor considering the first column, breaking ties using the second column\\')",
            "tf_operators": {
                "tf.sort": 7,
                "tf.gather": 3,
                "tf.argsort": 3
            },
            "coverage_percentage": 100.0,
            "total_in_target": 2,
            "total_covered": 2
        },
        "completions": [
            "return tf.sort(in1, axis=0)",
            "return tf.gather(in1, tf.argsort(in1, axis=0, stable=True))",
            "return tf.sort(in1, axis=0)",
            "return tf.sort(in1, axis=0)",
            "return tf.sort(in1, axis=0)",
            "return tf.sort(in1, axis=0)",
            "return tf.gather(in1, tf.argsort(in1, axis=0, stable=True))",
            "return tf.sort(in1, axis=0)",
            "return tf.gather(in1, tf.argsort(in1[:, :2], axis=0, stable=True))",
            "return tf.sort(in1, axis=0)"
        ]
    },
    {
        "constants": "[]",
        "description": "compute argmax in each tensor and set it to 1",
        "target_program": "tf.cast(tf.one_hot(tf.argmax(in1, axis=1), 3), tf.int32)",
        "source": "https://stackoverflow.com/questions/44834739/argmax-on-a-tensor-and-ceiling-in-tensorflow",
        "name": "stackoverflow_20",
        "examples": {
            "inputs": "[[[0.7, 0.2, 0.1], [0.4, 0.5, 0.1], [0.4, 0.4, 0.2], [0.3, 0.4, 0.3], [0.0, 0.0, 1.0]],]",
            "outputs": "[[1, 0, 0],    [0, 1, 0],    [1, 0, 0],    [0, 1, 0],    [0, 0, 1]]"
        },
        "response": {
            "task_id": "stackoverflow_20",
            "completions": [
                "import tensorflow as tf\n    \n    # Find indices of maximum values\n    arg_max_indices = tf.argmax(in1, axis=1)\n\n    # Convert indices to one hot\n    one_hot_max = tf.one_hot(arg_max_indices, depth=in1.shape[1])\n    \n    return one_hot_max",
                "index = tf.argmax(in1, axis=-1)\none_hot = tf.one_hot(index, in1.shape[-1])\nreturn one_hot",
                "import tensorflow as tf\n\ndef transform(in1):\n    argmax_indx = tf.argmax(in1, axis=1)\n    one_hot_indx = tf.one_hot(argmax_indx, depth=in1.shape[1])\n    return one_hot_indx.numpy()",
                "# First we compute the argmax in each tensor along the last axis\n    idx_max = tf.argmax(in1, axis=-1)\n    # We create a matrix of zeros with the same shape as the input\n    mat_zero = tf.zeros_like(in1, dtype=tf.int32)\n    # Then we create a matrix of ones with a shape that fits the argmax matrix\n    mat_one = tf.ones_like(idx_max, dtype=tf.int32)\n    # As Tensorflow only allows to modify a tensor by an entire axis we need to expand the dimensions\n    idx_max = tf.expand_dims(idx_max, 1)\n    mat_one = tf.expand_dims(mat_one, 1)\n    # We then use tensor_scatter_nd_update to set the position of the maximum value to 1\n    result = tf.tensor_scatter_nd_update(mat_zero, idx_max, mat_one)\n    return result",
                "import tensorflow as tf\n\ndef transform(in1):\n    in1 = tf.constant(in1)\n    argmax = tf.argmax(in1, axis=1)\n    mask = tf.one_hot(argmax, depth=in1.shape[1])\n    return mask.numpy()",
                "idx = tf.argmax(in1, axis=1)\nout = tf.one_hot(idx, depth=in1.shape[1])\nreturn tf.cast(out, dtype=tf.int32)",
                "max_indices = tf.argmax(in1, axis=1)\nrows = tf.range(tf.shape(in1)[0])\nindices = tf.stack([rows, max_indices], axis=1)\nupdates = tf.ones(shape=(tf.shape(in1)[0],), dtype=tf.int32)\nshape = tf.shape(in1)\nresult = tf.scatter_nd(indices, updates, shape)\nreturn result",
                "argmax = tf.argmax(in1, axis=1)\nindices = tf.range(tf.shape(in1)[0])\nindices = tf.stack([indices, argmax], axis=1)\nones = tf.ones(tf.shape(indices)[0], dtype=tf.float32)\nupdates = tf.scatter_nd(indices, ones, tf.shape(in1))\nreturn updates",
                "#First we get the indices of the max values\n    max_indices = tf.argmax(in1, axis=1)\n\n    #Generate a range to match the first dimension of the input array\n    range_values = tf.range(tf.shape(in1)[0])\n\n    #Stack the range and max indices together to get the coordinates\n    indices = tf.stack([range_values, max_indices], axis=1)\n\n    #Create a ones array of the same size as the number of max_indices to use as updates\n    updates = tf.ones_like(max_indices, dtype=tf.float32)\n    \n    #Use scatter_nd to create a new tensor with 1's at the argmax locations and zeros elsewhere\n    return tf.tensor_scatter_nd_update(tf.zeros_like(in1), indices, updates)",
                "argmax_values = tf.argmax(in1, axis=1)\none_hot = tf.one_hot(argmax_values, depth=in1.shape[1])\nreturn one_hot.numpy().astype(int)"
            ],
            "target-program": "tf.cast(tf.one_hot(tf.argmax(in1, axis=1), 3), tf.int32)",
            "description": "compute argmax in each tensor and set it to 1",
            "tf_operators": {
                "tf.one_hot": 6,
                "tf.argmax": 10,
                "tf.zeros_like": 2,
                "tf.int32": 3,
                "tf.ones_like": 2,
                "tf.expand_dims": 1,
                "tf.tensor_scatter_nd_update": 2,
                "tf.constant": 1,
                "tf.cast": 1,
                "tf.shape": 3,
                "tf.stack": 3,
                "tf.scatter_nd": 2,
                "tf.ones": 2,
                "tf.range": 3,
                "tf.float32": 2
            },
            "coverage_percentage": 100.0,
            "total_in_target": 4,
            "total_covered": 4
        },
        "completions": [
            "import tensorflow as tf\n    \n    # Find indices of maximum values\n    arg_max_indices = tf.argmax(in1, axis=1)\n\n    # Convert indices to one hot\n    one_hot_max = tf.one_hot(arg_max_indices, depth=in1.shape[1])\n    \n    return one_hot_max",
            "index = tf.argmax(in1, axis=-1)\none_hot = tf.one_hot(index, in1.shape[-1])\nreturn one_hot",
            "import tensorflow as tf\n\ndef transform(in1):\n    argmax_indx = tf.argmax(in1, axis=1)\n    one_hot_indx = tf.one_hot(argmax_indx, depth=in1.shape[1])\n    return one_hot_indx.numpy()",
            "# First we compute the argmax in each tensor along the last axis\n    idx_max = tf.argmax(in1, axis=-1)\n    # We create a matrix of zeros with the same shape as the input\n    mat_zero = tf.zeros_like(in1, dtype=tf.int32)\n    # Then we create a matrix of ones with a shape that fits the argmax matrix\n    mat_one = tf.ones_like(idx_max, dtype=tf.int32)\n    # As Tensorflow only allows to modify a tensor by an entire axis we need to expand the dimensions\n    idx_max = tf.expand_dims(idx_max, 1)\n    mat_one = tf.expand_dims(mat_one, 1)\n    # We then use tensor_scatter_nd_update to set the position of the maximum value to 1\n    result = tf.tensor_scatter_nd_update(mat_zero, idx_max, mat_one)\n    return result",
            "import tensorflow as tf\n\ndef transform(in1):\n    in1 = tf.constant(in1)\n    argmax = tf.argmax(in1, axis=1)\n    mask = tf.one_hot(argmax, depth=in1.shape[1])\n    return mask.numpy()",
            "idx = tf.argmax(in1, axis=1)\nout = tf.one_hot(idx, depth=in1.shape[1])\nreturn tf.cast(out, dtype=tf.int32)",
            "max_indices = tf.argmax(in1, axis=1)\nrows = tf.range(tf.shape(in1)[0])\nindices = tf.stack([rows, max_indices], axis=1)\nupdates = tf.ones(shape=(tf.shape(in1)[0],), dtype=tf.int32)\nshape = tf.shape(in1)\nresult = tf.scatter_nd(indices, updates, shape)\nreturn result",
            "argmax = tf.argmax(in1, axis=1)\nindices = tf.range(tf.shape(in1)[0])\nindices = tf.stack([indices, argmax], axis=1)\nones = tf.ones(tf.shape(indices)[0], dtype=tf.float32)\nupdates = tf.scatter_nd(indices, ones, tf.shape(in1))\nreturn updates",
            "#First we get the indices of the max values\n    max_indices = tf.argmax(in1, axis=1)\n\n    #Generate a range to match the first dimension of the input array\n    range_values = tf.range(tf.shape(in1)[0])\n\n    #Stack the range and max indices together to get the coordinates\n    indices = tf.stack([range_values, max_indices], axis=1)\n\n    #Create a ones array of the same size as the number of max_indices to use as updates\n    updates = tf.ones_like(max_indices, dtype=tf.float32)\n    \n    #Use scatter_nd to create a new tensor with 1's at the argmax locations and zeros elsewhere\n    return tf.tensor_scatter_nd_update(tf.zeros_like(in1), indices, updates)",
            "argmax_values = tf.argmax(in1, axis=1)\none_hot = tf.one_hot(argmax_values, depth=in1.shape[1])\nreturn one_hot.numpy().astype(int)"
        ]
    },
    {
        "constants": "[]",
        "description": "gather elements in a tensor along axis 1",
        "target_program": "tf.gather(in2, in1, axis=1, batch_dims=1)",
        "source": "https://stackoverflow.com/questions/51690095/how-to-gather-element-with-index-in-tensorflow",
        "name": "stackoverflow_21",
        "examples": {
            "inputs": "[[[2], [0], [1], [0]],[[0.2, 0.5, 0.3], [0.1, 0.3, 0.6], [0.1, 0.6, 0.3], [0.7, 0.0, 0.3]],]",
            "outputs": "[[0.3], [0.1], [0.6], [0.7]]"
        },
        "response": {
            "task_id": "stackoverflow_21",
            "completions": [
                "return tf.gather(in2, in1, axis=1, batch_dims=1)",
                "return tf.gather(in2, in1, axis=1)",
                "return tf.gather(in2, in1, axis=1)",
                "return tf.gather(in2, in1, axis=1)",
                "return tf.gather(in2, in1, axis=1)",
                "return tf.gather(in2, in1, axis=1)",
                "return tf.gather(in2,in1,axis=1)",
                "return tf.gather(in2, in1, axis=1, batch_dims=1)",
                "return tf.gather(in2, in1, axis=1)",
                "return tf.gather(in2, in1, axis=1)"
            ],
            "target-program": "tf.gather(in2, in1, axis=1, batch_dims=1)",
            "description": "gather elements in a tensor along axis 1",
            "tf_operators": {
                "tf.gather": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.gather(in2, in1, axis=1, batch_dims=1)",
            "return tf.gather(in2, in1, axis=1)",
            "return tf.gather(in2, in1, axis=1)",
            "return tf.gather(in2, in1, axis=1)",
            "return tf.gather(in2, in1, axis=1)",
            "return tf.gather(in2, in1, axis=1)",
            "return tf.gather(in2,in1,axis=1)",
            "return tf.gather(in2, in1, axis=1, batch_dims=1)",
            "return tf.gather(in2, in1, axis=1)",
            "return tf.gather(in2, in1, axis=1)"
        ]
    },
    {
        "constants": "[]",
        "description": "multiply a vector with a matrix without reshaping the vector",
        "target_program": "tf.tensordot(tf.cast(in1, tf.float32), in2, 1)",
        "source": "https://stackoverflow.com/questions/43284897/how-can-i-multiply-a-vector-and-a-matrix-in-tensorflow-without-reshaping",
        "name": "stackoverflow_22",
        "examples": {
            "inputs": "[[3, 1, 10],[[0.6, 0.4], [0.5, 1.0], [3.0, 4.0]],]",
            "outputs": "[32.3, 42.2]"
        },
        "response": {
            "task_id": "stackoverflow_22",
            "completions": [
                "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, in2), 0)",
                "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, in2), axis = 0)",
                "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)"
            ],
            "target-program": "tf.tensordot(tf.cast(in1, tf.float32), in2, 1)",
            "description": "multiply a vector with a matrix without reshaping the vector",
            "tf_operators": {
                "tf.multiply": 10,
                "tf.reduce_sum": 10
            },
            "coverage_percentage": 0.0,
            "total_in_target": 3,
            "total_covered": 0
        },
        "completions": [
            "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, in2), 0)",
            "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, in2), axis = 0)",
            "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)"
        ]
    },
    {
        "constants": "[]",
        "description": "place 1 at the indices in the input tensor",
        "target_program": "tf.cast(tf.reduce_max(tf.one_hot(in1, 9), axis=1), tf.int32)",
        "source": "https://stackoverflow.com/questions/53414433/tensorflow-tensor-binarization",
        "name": "stackoverflow_23",
        "examples": {
            "inputs": "[[[0, 5, 2], [3, 1, 4], [5, 1, 5]],]",
            "outputs": "[[1, 0, 1, 0, 0, 1, 0, 0, 0],    [0, 1, 0, 1, 1, 0, 0, 0, 0],    [0, 1, 0, 0, 0, 1, 0, 0, 0]]"
        },
        "response": {
            "task_id": "stackoverflow_23",
            "completions": [
                "return tf.one_hot(in1, tf.reduce_max(in1)+1, axis=-1)",
                "return tf.one_hot(in1, tf.reduce_max(in1) + 1, axis=-1)",
                "return tf.reduce_sum(tf.one_hot(in1, depth=tf.reduce_max(in1) + 1), axis=1)",
                "return tf.one_hot(in1, tf.reduce_max(in1) + 1)",
                "return tf.one_hot(in1, tf.reduce_max(in1)+1)",
                "return tf.scatter_nd(tf.expand_dims(in1, -1), tf.ones_like(in1), tf.constant([in1.shape[0], tf.reduce_max(in1)+1]))",
                "return tf.reduce_sum(tf.one_hot(in1, tf.reduce_max(in1) + 1), axis=1)",
                "return tf.one_hot(in1, tf.reduce_max(in1) + 1)",
                "return tf.one_hot(in1, depth=tf.reduce_max(in1)+1)",
                "return tf.one_hot(in1, tf.reduce_max(in1)+1)"
            ],
            "target-program": "tf.cast(tf.reduce_max(tf.one_hot(in1, 9), axis=1), tf.int32)",
            "description": "place 1 at the indices in the input tensor",
            "tf_operators": {
                "tf.reduce_max": 10,
                "tf.one_hot": 9,
                "tf.reduce_sum": 2,
                "tf.constant": 1,
                "tf.scatter_nd": 1,
                "tf.ones_like": 1,
                "tf.expand_dims": 1
            },
            "coverage_percentage": 50.0,
            "total_in_target": 4,
            "total_covered": 2
        },
        "completions": [
            "return tf.one_hot(in1, tf.reduce_max(in1)+1, axis=-1)",
            "return tf.one_hot(in1, tf.reduce_max(in1) + 1, axis=-1)",
            "return tf.reduce_sum(tf.one_hot(in1, depth=tf.reduce_max(in1) + 1), axis=1)",
            "return tf.one_hot(in1, tf.reduce_max(in1) + 1)",
            "return tf.one_hot(in1, tf.reduce_max(in1)+1)",
            "return tf.scatter_nd(tf.expand_dims(in1, -1), tf.ones_like(in1), tf.constant([in1.shape[0], tf.reduce_max(in1)+1]))",
            "return tf.reduce_sum(tf.one_hot(in1, tf.reduce_max(in1) + 1), axis=1)",
            "return tf.one_hot(in1, tf.reduce_max(in1) + 1)",
            "return tf.one_hot(in1, depth=tf.reduce_max(in1)+1)",
            "return tf.one_hot(in1, tf.reduce_max(in1)+1)"
        ]
    },
    {
        "constants": "[0]",
        "description": "(\\'like tf.divide(), but when dividing by 0, return the numerator\\')",
        "target_program": "tf.where(tf.cast(in2, tf.bool), x=tf.divide(in1, in2), y=in1)",
        "source": "https://stackoverflow.com/questions/53643339/tensorflow-overriding-tf-divide-to-return-the-numerator-when-dividing-by-0",
        "name": "stackoverflow_24",
        "examples": {
            "inputs": "[[3.0, 1.0, 4.0, 5.0, 2.0, 8.0, -6.0, -7.0],[0.5, 0.0, -2.0, 0.0, 1.0, -1.0, 0.0, 2.0],]",
            "outputs": "[6.0, 1.0, -2.0, 5.0, 2.0, -8.0, -6.0, -3.5]"
        },
        "response": {
            "task_id": "stackoverflow_24",
            "completions": [
                "return tf.math.divide_no_nan(in1,in2)",
                "return tf.math.divide_no_nan(in1, in2)",
                "return tf.math.divide_no_nan(in1, in2)",
                "return tf.math.divide_no_nan(in1, in2)",
                "return tf.math.divide_no_nan(in1, in2)",
                "return tf.math.divide_no_nan(in1, in2)",
                "return tf.math.divide_no_nan(in1, in2)",
                "return tf.math.divide_no_nan(in1, in2)",
                "return tf.math.divide_no_nan(in1, in2)",
                "return tf.math.divide_no_nan(in1, in2)"
            ],
            "target-program": "tf.where(tf.cast(in2, tf.bool), x=tf.divide(in1, in2), y=in1)",
            "description": "(\\'like tf.divide(), but when dividing by 0, return the numerator\\')",
            "tf_operators": {
                "tf.math.divide_no_nan": 10
            },
            "coverage_percentage": 0.0,
            "total_in_target": 4,
            "total_covered": 0
        },
        "completions": [
            "return tf.math.divide_no_nan(in1,in2)",
            "return tf.math.divide_no_nan(in1, in2)",
            "return tf.math.divide_no_nan(in1, in2)",
            "return tf.math.divide_no_nan(in1, in2)",
            "return tf.math.divide_no_nan(in1, in2)",
            "return tf.math.divide_no_nan(in1, in2)",
            "return tf.math.divide_no_nan(in1, in2)",
            "return tf.math.divide_no_nan(in1, in2)",
            "return tf.math.divide_no_nan(in1, in2)",
            "return tf.math.divide_no_nan(in1, in2)"
        ]
    },
    {
        "constants": "[]",
        "description": "copy the tensor tf.eye(3), 4 times",
        "target_program": "tf.tile(tf.eye(in1), (in2, 1))",
        "source": "https://stackoverflow.com/questions/53602691/duplicate-a-tensor-n-times",
        "name": "stackoverflow_25",
        "examples": {
            "inputs": "[3,4,]",
            "outputs": "[[1.0, 0.0, 0.0],    [0.0, 1.0, 0.0],    [0.0, 0.0, 1.0],    [1.0, 0.0, 0.0],    [0.0, 1.0, 0.0],    [0.0, 0.0, 1.0],    [1.0, 0.0, 0.0],    [0.0, 1.0, 0.0],    [0.0, 0.0, 1.0],    [1.0, 0.0, 0.0],    [0.0, 1.0, 0.0],    [0.0, 0.0, 1.0]]"
        },
        "response": {
            "task_id": "stackoverflow_25",
            "completions": [
                "return tf.tile(tf.eye(in1), [in2, 1])",
                "return tf.tile(tf.eye(in1), [in2, 1])",
                "return tf.tile(tf.eye(in1), [in2, 1])",
                "eye_tensor = tf.eye(in1)\n     return tf.tile(eye_tensor, [in2,1])",
                "return tf.tile(tf.eye(in1), [in2, 1])",
                "return tf.tile(tf.eye(in1), [in2, 1])",
                "return tf.tile(tf.eye(in1), [in2, 1])",
                "return tf.tile(tf.eye(in1), [in2, 1])",
                "return tf.tile(tf.eye(in1), [in2, 1])",
                "return tf.tile(tf.eye(in1), [in2, 1])"
            ],
            "target-program": "tf.tile(tf.eye(in1), (in2, 1))",
            "description": "copy the tensor tf.eye(3), 4 times",
            "tf_operators": {
                "tf.tile": 10,
                "tf.eye": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 2,
            "total_covered": 2
        },
        "completions": [
            "return tf.tile(tf.eye(in1), [in2, 1])",
            "return tf.tile(tf.eye(in1), [in2, 1])",
            "return tf.tile(tf.eye(in1), [in2, 1])",
            "eye_tensor = tf.eye(in1)\n     return tf.tile(eye_tensor, [in2,1])",
            "return tf.tile(tf.eye(in1), [in2, 1])",
            "return tf.tile(tf.eye(in1), [in2, 1])",
            "return tf.tile(tf.eye(in1), [in2, 1])",
            "return tf.tile(tf.eye(in1), [in2, 1])",
            "return tf.tile(tf.eye(in1), [in2, 1])",
            "return tf.tile(tf.eye(in1), [in2, 1])"
        ]
    },
    {
        "constants": "[]",
        "description": "reduction operation for multiple dimensions simultaneously",
        "target_program": "tf.reduce_sum(tf.reduce_sum(in1, axis=1), axis=1)",
        "source": "https://stackoverflow.com/questions/54294780/how-to-perform-reduce-op-on-multiple-dimensions-at-once",
        "name": "stackoverflow_26",
        "examples": {
            "inputs": "[[[[3, 4], [1, 2]], [[5, -2], [-10, 3]], [[10, 20], [-4, 7]]]]",
            "outputs": "[10, -4, 33]"
        },
        "response": {
            "task_id": "stackoverflow_26",
            "completions": [
                "return tf.reduce_sum(in1, axis=[0, 1]).numpy().tolist()",
                "return tf.reduce_max(tf.reduce_sum(in1, axis=2), axis=1)",
                "return tf.reduce_sum(in1, axis=[0, 1]).numpy().tolist()",
                "return tf.reduce_min(in1, axis=[0, 1]).numpy().tolist()",
                "return tf.reduce_sum(in1, axis=[0,1]).numpy().tolist()",
                "return tf.reduce_sum(in1, axis=[0,1]).numpy().tolist()",
                "return tf.reduce_sum(in1, axis=[0, 2]).numpy().tolist()",
                "return tf.reduce_sum(in1, axis=[0, 1]).numpy().tolist()",
                "return tf.reduce_sum(in1, axis=[0,1])",
                "return tf.reduce_sum(in1, axis=[0, 1]).numpy().tolist()"
            ],
            "target-program": "tf.reduce_sum(tf.reduce_sum(in1, axis=1), axis=1)",
            "description": "reduction operation for multiple dimensions simultaneously",
            "tf_operators": {
                "tf.reduce_sum": 9,
                "tf.reduce_max": 1,
                "tf.reduce_min": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.reduce_sum(in1, axis=[0, 1]).numpy().tolist()",
            "return tf.reduce_max(tf.reduce_sum(in1, axis=2), axis=1)",
            "return tf.reduce_sum(in1, axis=[0, 1]).numpy().tolist()",
            "return tf.reduce_min(in1, axis=[0, 1]).numpy().tolist()",
            "return tf.reduce_sum(in1, axis=[0,1]).numpy().tolist()",
            "return tf.reduce_sum(in1, axis=[0,1]).numpy().tolist()",
            "return tf.reduce_sum(in1, axis=[0, 2]).numpy().tolist()",
            "return tf.reduce_sum(in1, axis=[0, 1]).numpy().tolist()",
            "return tf.reduce_sum(in1, axis=[0,1])",
            "return tf.reduce_sum(in1, axis=[0, 1]).numpy().tolist()"
        ]
    },
    {
        "constants": "[]",
        "description": "boolean tensor with 1 at the indices in the input tensor",
        "target_program": "tf.cast(tf.reduce_max(tf.one_hot(in1, in2), axis=0), tf.int32)",
        "source": "https://stackoverflow.com/questions/54225704/how-do-i-get-a-tensor-representing-the-on-positions-in-the-original-tensor",
        "name": "stackoverflow_27",
        "examples": {
            "inputs": "[[0, 3, 5, 6],8,]",
            "outputs": "[1, 0, 0, 1, 0, 1, 1, 0]"
        },
        "response": {
            "task_id": "stackoverflow_27",
            "completions": [
                "return tf.cast(tf.reduce_any(tf.one_hot(in1, in2), axis=0), dtype=tf.int32)",
                "return tf.cast(tf.reduce_sum(tf.one_hot(in1, in2), axis=0), dtype=tf.int32)",
                "return tf.cast(tf.scatter_nd(tf.reshape(in1, [-1, 1]), tf.ones_like(in1), [in2]), tf.int32)",
                "return tf.cast(tf.reduce_any(tf.equal(tf.range(in2), tf.expand_dims(in1, 1)), axis=0), tf.int32)",
                "return tf.sparse.to_dense(tf.SparseTensor(in1[:,None], tf.ones(tf.shape(in1),dtype=tf.int32), [in2]))",
                "return tf.cast(tf.sequence_mask(in1,in2), dtype=tf.int32)",
                "return tf.cast(tf.reduce_sum(tf.one_hot(in1, in2), axis=0), tf.int32)",
                "return tf.cast(tf.scatter_nd(tf.expand_dims(in1, axis=1), tf.ones_like(in1, dtype=tf.int32), [in2]), tf.int32)",
                "return tf.cast(tf.reduce_sum(tf.one_hot(in1, in2), axis=0), tf.int32).numpy().tolist()",
                "return tf.cast(tf.reduce_max(tf.one_hot(in1, in2), axis=0), tf.int32)"
            ],
            "target-program": "tf.cast(tf.reduce_max(tf.one_hot(in1, in2), axis=0), tf.int32)",
            "description": "boolean tensor with 1 at the indices in the input tensor",
            "tf_operators": {
                "tf.reduce_any": 2,
                "tf.one_hot": 5,
                "tf.int32": 10,
                "tf.cast": 9,
                "tf.reduce_sum": 3,
                "tf.reshape": 1,
                "tf.scatter_nd": 2,
                "tf.ones_like": 2,
                "tf.equal": 1,
                "tf.range": 1,
                "tf.expand_dims": 2,
                "tf.SparseTensor": 1,
                "tf.shape": 1,
                "tf.sparse.to_dense": 1,
                "tf.ones": 1,
                "tf.sequence_mask": 1,
                "tf.reduce_max": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 4,
            "total_covered": 4
        },
        "completions": [
            "return tf.cast(tf.reduce_any(tf.one_hot(in1, in2), axis=0), dtype=tf.int32)",
            "return tf.cast(tf.reduce_sum(tf.one_hot(in1, in2), axis=0), dtype=tf.int32)",
            "return tf.cast(tf.scatter_nd(tf.reshape(in1, [-1, 1]), tf.ones_like(in1), [in2]), tf.int32)",
            "return tf.cast(tf.reduce_any(tf.equal(tf.range(in2), tf.expand_dims(in1, 1)), axis=0), tf.int32)",
            "return tf.sparse.to_dense(tf.SparseTensor(in1[:,None], tf.ones(tf.shape(in1),dtype=tf.int32), [in2]))",
            "return tf.cast(tf.sequence_mask(in1,in2), dtype=tf.int32)",
            "return tf.cast(tf.reduce_sum(tf.one_hot(in1, in2), axis=0), tf.int32)",
            "return tf.cast(tf.scatter_nd(tf.expand_dims(in1, axis=1), tf.ones_like(in1, dtype=tf.int32), [in2]), tf.int32)",
            "return tf.cast(tf.reduce_sum(tf.one_hot(in1, in2), axis=0), tf.int32).numpy().tolist()",
            "return tf.cast(tf.reduce_max(tf.one_hot(in1, in2), axis=0), tf.int32)"
        ]
    },
    {
        "constants": "[]",
        "description": "extract columns from a 3D tensor given column indices",
        "target_program": "tf.squeeze(tf.gather(in1, tf.expand_dims(in2, 1), axis=-1, batch_dims=1))",
        "source": "https://stackoverflow.com/questions/54274074/selecting-columns-from-3d-tensor-according-to-a-1d-tensor-of-indices-tensorflow",
        "name": "stackoverflow_28",
        "examples": {
            "inputs": "[[[[5, 3],  [0, 2]], [[7, 4],  [5, 1]], [[10, 20],  [15, 30]], [[11, 16],  [14, 12]], [[-2, -7],  [-4, 6]]],[1, 0, 1, 1, 0],]",
            "outputs": "[[3, 2], [7, 5], [20, 30], [16, 12], [-2, -4]]"
        },
        "response": {
            "task_id": "stackoverflow_28",
            "completions": [
                "indices = tf.stack([tf.range(tf.shape(in1)[0]), in2], axis=1)\n     return tf.gather_nd(in1, indices)",
                "return tf.gather(in1, tf.constant(in2), axis=2, batch_dims=1)",
                "return tf.gather(in1, in2, axis=2, batch_dims=1)",
                "return tf.gather(in1, in2, axis=2, batch_dims=1)",
                "return tf.gather(in1, in2, axis=2, batch_dims=1)",
                "return tf.gather(in1, in2, axis=2, batch_dims=1)",
                "return tf.gather(in1, in2, axis=2, batch_dims=1)",
                "return tf.gather(in1, in2, axis=2, batch_dims=1)",
                "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in1)[0]), in2], axis=1))",
                "return tf.gather(in1, in2, axis=2, batch_dims=1)"
            ],
            "target-program": "tf.squeeze(tf.gather(in1, tf.expand_dims(in2, 1), axis=-1, batch_dims=1))",
            "description": "extract columns from a 3D tensor given column indices",
            "tf_operators": {
                "tf.shape": 2,
                "tf.stack": 2,
                "tf.range": 2,
                "tf.gather_nd": 2,
                "tf.gather": 8,
                "tf.constant": 1
            },
            "coverage_percentage": 33.33333333333333,
            "total_in_target": 3,
            "total_covered": 1
        },
        "completions": [
            "indices = tf.stack([tf.range(tf.shape(in1)[0]), in2], axis=1)\n     return tf.gather_nd(in1, indices)",
            "return tf.gather(in1, tf.constant(in2), axis=2, batch_dims=1)",
            "return tf.gather(in1, in2, axis=2, batch_dims=1)",
            "return tf.gather(in1, in2, axis=2, batch_dims=1)",
            "return tf.gather(in1, in2, axis=2, batch_dims=1)",
            "return tf.gather(in1, in2, axis=2, batch_dims=1)",
            "return tf.gather(in1, in2, axis=2, batch_dims=1)",
            "return tf.gather(in1, in2, axis=2, batch_dims=1)",
            "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in1)[0]), in2], axis=1))",
            "return tf.gather(in1, in2, axis=2, batch_dims=1)"
        ]
    },
    {
        "constants": "[]",
        "description": "place continuous values into buckets given bucket boundaries",
        "target_program": "tf.searchsorted(in1, in2, side='left')",
        "source": "https://stackoverflow.com/questions/54155085/bucketing-continous-value-tensors-in-tensorflow",
        "name": "stackoverflow_29",
        "examples": {
            "inputs": "[[-1.0, -0.8, -0.6, -0.4, -0.2, 0.0, 0.2, 0.4, 0.6, 0.8, 1.0],[0.1, -10, -0.1, 1.1, 0.41],]",
            "outputs": "[6, 0, 5, 11, 8]"
        },
        "response": {
            "task_id": "stackoverflow_29",
            "completions": [
                "return tf.searchsorted(sorted_sequence=in1, values=in2, side='right').numpy().tolist()",
                "return tf.searchsorted(tf.constant(in1), tf.constant(in2)).numpy().tolist()",
                "return tf.searchsorted(in1, in2, side='right')",
                "return tf.searchsorted(tf.constant(in1), in2, side='left').numpy().tolist()",
                "return tf.searchsorted(in1, in2, side='left').numpy().tolist()",
                "return tf.searchsorted(tf.constant(in1), tf.constant(in2)).numpy().tolist()",
                "return tf.searchsorted(tf.constant(in1), tf.constant(in2)).numpy().tolist()",
                "return tf.searchsorted(tf.constant(in1), tf.constant(in2)).numpy().tolist()",
                "return tf.searchsorted(tf.constant(in1, dtype=tf.float32), tf.constant(in2, dtype=tf.float32))",
                "return tf.searchsorted(in1, in2, side='right').numpy().tolist()"
            ],
            "target-program": "tf.searchsorted(in1, in2, side='left')",
            "description": "place continuous values into buckets given bucket boundaries",
            "tf_operators": {
                "tf.searchsorted": 10,
                "tf.constant": 6,
                "tf.float32": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.searchsorted(sorted_sequence=in1, values=in2, side='right').numpy().tolist()",
            "return tf.searchsorted(tf.constant(in1), tf.constant(in2)).numpy().tolist()",
            "return tf.searchsorted(in1, in2, side='right')",
            "return tf.searchsorted(tf.constant(in1), in2, side='left').numpy().tolist()",
            "return tf.searchsorted(in1, in2, side='left').numpy().tolist()",
            "return tf.searchsorted(tf.constant(in1), tf.constant(in2)).numpy().tolist()",
            "return tf.searchsorted(tf.constant(in1), tf.constant(in2)).numpy().tolist()",
            "return tf.searchsorted(tf.constant(in1), tf.constant(in2)).numpy().tolist()",
            "return tf.searchsorted(tf.constant(in1, dtype=tf.float32), tf.constant(in2, dtype=tf.float32))",
            "return tf.searchsorted(in1, in2, side='right').numpy().tolist()"
        ]
    },
    {
        "constants": "[]",
        "description": "compute Euclidean distance between two tensors",
        "target_program": "tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, 1), tf.expand_dims(in2, 0))), axis=2))",
        "source": "https://stackoverflow.com/questions/54147780/tensorflow-how-to-calculate-the-euclidean-distance-between-two-tensor",
        "name": "stackoverflow_30",
        "examples": {
            "inputs": "[[[1., 2.], [3., 4.], [5., 6.]],[[9., 4.], [8., 5.], [7., 6.]],]",
            "outputs": "[[math.sqrt(68), math.sqrt(58), math.sqrt(52)],    [math.sqrt(36), math.sqrt(26), math.sqrt(20)],    [math.sqrt(20), math.sqrt(10), math.sqrt(4)]]"
        },
        "response": {
            "task_id": "stackoverflow_30",
            "completions": [
                "return tf.sqrt(tf.reduce_sum(tf.square(in1-in2), axis=1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis -1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))"
            ],
            "target-program": "tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, 1), tf.expand_dims(in2, 0))), axis=2))",
            "description": "compute Euclidean distance between two tensors",
            "tf_operators": {
                "tf.square": 10,
                "tf.sqrt": 10,
                "tf.reduce_sum": 10,
                "tf.subtract": 9
            },
            "coverage_percentage": 80.0,
            "total_in_target": 5,
            "total_covered": 4
        },
        "completions": [
            "return tf.sqrt(tf.reduce_sum(tf.square(in1-in2), axis=1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis -1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))"
        ]
    },
    {
        "constants": "[]",
        "description": "squared error between two tensors, one being a sparse tensor",
        "target_program": "tf.reduce_sum(tf.square(tf.subtract(in2, tf.sparse.to_dense(in1))))",
        "source": "https://stackoverflow.com/questions/45032668/tensorflow-how-to-compute-the-square-error-between-a-tensor-and-a-sparse-tensor",
        "name": "stackoverflow_31",
        "examples": {
            "inputs": "tf.SparseTensor(indices=[[0, 0], [0, 1], [1, 1]], values=[1.0, 1.5, -2.0], dense_shape=[2, 2]), [[3.0, 1.0], [0.2, -1.0]],",
            "outputs": "5.29"
        },
        "response": {
            "task_id": "stackoverflow_31",
            "completions": [
                "dense1 = tf.sparse.to_dense(in1[0])\n     square_diff = tf.math.squared_difference(dense1, in1[1])\n     return tf.reduce_sum(square_diff)",
                "sparse_tensor_input = tf.sparse.to_dense(in1[0])\ndense_tensor_input = tf.convert_to_tensor(in1[1])\n\nerror = tf.square(sparse_tensor_input - dense_tensor_input)\nsum_error = tf.reduce_sum(error)\n\nreturn sum_error.numpy()",
                "# Convert the sparse tensor to a dense tensor\n    dense_tensor = tf.sparse.to_dense(in1[0])\n    # Calculate the squared difference between the dense tensors\n    squared_diff = tf.math.squared_difference(dense_tensor, in1[1])\n    # Reduce sum to obtain scalar output\n    return tf.reduce_sum(squared_diff).numpy()",
                "dense1 = tf.sparse.to_dense(in1[0])\n    squared_diff = tf.math.squared_difference(dense1, in1[1])\n    return tf.reduce_sum(squared_diff).numpy()",
                "# Cast the input sparse tensor to a dense tensor.\n     dense1 = tf.sparse.to_dense(in1[0])\n     # Compute the squared difference between the dense tensor and the input tensor.\n     diff = tf.math.squared_difference(dense1, in1[1])\n     # Sum all the elements in the difference tensor.\n     output = tf.reduce_sum(diff)\n     return output",
                "sparse_tensor, dense_tensor = in1\ndense_tensor = tf.convert_to_tensor(dense_tensor, dtype=tf.float32)\nsparse_tensor = tf.sparse.to_dense(sparse_tensor)\nsquared_diff = tf.math.squared_difference(sparse_tensor, dense_tensor)\noutput = tf.reduce_sum(squared_diff)\nreturn output.numpy()",
                "dense_tensor = tf.sparse.to_dense(in1[0])\n    squared_error = tf.math.squared_difference(dense_tensor, in1[1])\n    return tf.reduce_sum(squared_error)",
                "sp_1, in2 = in1\ndense_1 = tf.sparse.to_dense(sp_1)\nerror = tf.math.squared_difference(dense_1, in2)\nreturn tf.reduce_sum(error)",
                "# First convert the sparse tensor to a dense tensor\r\ndense_tensor = tf.sparse.to_dense(in1[0])\r\n\r\n# Now calculate the squared difference between the dense versions of the two tensors\r\ndiff = tf.math.squared_difference(dense_tensor, in1[1])\r\n\r\n# Finally, sum all the elements of the resulting tensor to get the final output\r\noutput = tf.reduce_sum(diff)\r\n\r\nreturn output.numpy().item()",
                "dense_in1 = tf.sparse.to_dense(in1[0])\n    squared_diff = tf.math.squared_difference(dense_in1, in1[1])\n    return tf.reduce_sum(squared_diff)"
            ],
            "target-program": "tf.reduce_sum(tf.square(tf.subtract(in2, tf.sparse.to_dense(in1))))",
            "description": "squared error between two tensors, one being a sparse tensor",
            "tf_operators": {
                "tf.math.squared_difference": 9,
                "tf.sparse.to_dense": 10,
                "tf.reduce_sum": 10,
                "tf.square": 1,
                "tf.convert_to_tensor": 2,
                "tf.float32": 1
            },
            "coverage_percentage": 75.0,
            "total_in_target": 4,
            "total_covered": 3
        },
        "completions": [
            "dense1 = tf.sparse.to_dense(in1[0])\n     square_diff = tf.math.squared_difference(dense1, in1[1])\n     return tf.reduce_sum(square_diff)",
            "sparse_tensor_input = tf.sparse.to_dense(in1[0])\ndense_tensor_input = tf.convert_to_tensor(in1[1])\n\nerror = tf.square(sparse_tensor_input - dense_tensor_input)\nsum_error = tf.reduce_sum(error)\n\nreturn sum_error.numpy()",
            "# Convert the sparse tensor to a dense tensor\n    dense_tensor = tf.sparse.to_dense(in1[0])\n    # Calculate the squared difference between the dense tensors\n    squared_diff = tf.math.squared_difference(dense_tensor, in1[1])\n    # Reduce sum to obtain scalar output\n    return tf.reduce_sum(squared_diff).numpy()",
            "dense1 = tf.sparse.to_dense(in1[0])\n    squared_diff = tf.math.squared_difference(dense1, in1[1])\n    return tf.reduce_sum(squared_diff).numpy()",
            "# Cast the input sparse tensor to a dense tensor.\n     dense1 = tf.sparse.to_dense(in1[0])\n     # Compute the squared difference between the dense tensor and the input tensor.\n     diff = tf.math.squared_difference(dense1, in1[1])\n     # Sum all the elements in the difference tensor.\n     output = tf.reduce_sum(diff)\n     return output",
            "sparse_tensor, dense_tensor = in1\ndense_tensor = tf.convert_to_tensor(dense_tensor, dtype=tf.float32)\nsparse_tensor = tf.sparse.to_dense(sparse_tensor)\nsquared_diff = tf.math.squared_difference(sparse_tensor, dense_tensor)\noutput = tf.reduce_sum(squared_diff)\nreturn output.numpy()",
            "dense_tensor = tf.sparse.to_dense(in1[0])\n    squared_error = tf.math.squared_difference(dense_tensor, in1[1])\n    return tf.reduce_sum(squared_error)",
            "sp_1, in2 = in1\ndense_1 = tf.sparse.to_dense(sp_1)\nerror = tf.math.squared_difference(dense_1, in2)\nreturn tf.reduce_sum(error)",
            "# First convert the sparse tensor to a dense tensor\r\ndense_tensor = tf.sparse.to_dense(in1[0])\r\n\r\n# Now calculate the squared difference between the dense versions of the two tensors\r\ndiff = tf.math.squared_difference(dense_tensor, in1[1])\r\n\r\n# Finally, sum all the elements of the resulting tensor to get the final output\r\noutput = tf.reduce_sum(diff)\r\n\r\nreturn output.numpy().item()",
            "dense_in1 = tf.sparse.to_dense(in1[0])\n    squared_diff = tf.math.squared_difference(dense_in1, in1[1])\n    return tf.reduce_sum(squared_diff)"
        ]
    },
    {
        "constants": "[]",
        "description": "weighted sum across rows, where the column index is the weight",
        "target_program": "tf.tensordot(in1, tf.cast(tf.range(4), tf.float32), 1)",
        "source": "https://stackoverflow.com/questions/48659449/how-to-compute-the-weighted-sum-of-a-tensor-in-tensorflow",
        "name": "stackoverflow_32",
        "examples": {
            "inputs": "[[[0.1, 0.6, 0.2, 0.1], [0.3, 0.1, 0.4, 0.2], [0.2, 0.1, 0.2, 0.5]],]",
            "outputs": "[1.3, 1.5, 2.0]"
        },
        "response": {
            "task_id": "stackoverflow_32",
            "completions": [
                "return tf.reduce_sum(tf.multiply(in1, tf.range(tf.shape(in1)[1])), axis=1)",
                "weights = tf.range(tf.shape(in1)[1])\nweights = tf.cast(weights, dtype=in1.dtype)\n\nreturn tf.reduce_sum(in1 * weights, axis=1)",
                "return tf.reduce_sum(tf.multiply(in1, tf.range(tf.shape(in1)[1])), axis=1)",
                "weights = tf.range(tf.shape(in1)[1])\nweights = tf.cast(weights, tf.float32)\nresult = tf.reduce_sum(in1 * weights, axis=1)\nreturn result",
                "weights = tf.range(tf.shape(in1)[1], dtype=tf.float32)\nweighted_in1 = tf.multiply(in1, weights)\nresult = tf.reduce_sum(weighted_in1, axis=1)\nreturn result",
                "weights = tf.range(tf.shape(in1)[1])\nweights = tf.cast(weights, dtype=in1.dtype)\nweighted_in1 = tf.multiply(in1, weights)\nout = tf.reduce_sum(weighted_in1, axis=1)\nreturn out",
                "import tensorflow as tf\n\ndef transform(in1):\n    weights = tf.range(start=0, limit=tf.shape(in1)[1], dtype=tf.float32)\n    return tf.reduce_sum(in1 * weights, axis=1)",
                "return tf.reduce_sum(tf.multiply(in1, tf.range(tf.shape(in1)[1])), axis=1)",
                "return tf.reduce_sum(in1 * tf.range(tf.shape(in1)[1]), axis=1)",
                "weights = tf.range(start=0, limit=tf.shape(in1)[1])\nweighted_matrix = tf.multiply(in1, tf.cast(weights, tf.float32))\nweighted_sum = tf.reduce_sum(weighted_matrix, axis=1)\nreturn weighted_sum"
            ],
            "target-program": "tf.tensordot(in1, tf.cast(tf.range(4), tf.float32), 1)",
            "description": "weighted sum across rows, where the column index is the weight",
            "tf_operators": {
                "tf.shape": 10,
                "tf.multiply": 6,
                "tf.range": 10,
                "tf.reduce_sum": 10,
                "tf.cast": 4,
                "tf.float32": 4
            },
            "coverage_percentage": 75.0,
            "total_in_target": 4,
            "total_covered": 3
        },
        "completions": [
            "return tf.reduce_sum(tf.multiply(in1, tf.range(tf.shape(in1)[1])), axis=1)",
            "weights = tf.range(tf.shape(in1)[1])\nweights = tf.cast(weights, dtype=in1.dtype)\n\nreturn tf.reduce_sum(in1 * weights, axis=1)",
            "return tf.reduce_sum(tf.multiply(in1, tf.range(tf.shape(in1)[1])), axis=1)",
            "weights = tf.range(tf.shape(in1)[1])\nweights = tf.cast(weights, tf.float32)\nresult = tf.reduce_sum(in1 * weights, axis=1)\nreturn result",
            "weights = tf.range(tf.shape(in1)[1], dtype=tf.float32)\nweighted_in1 = tf.multiply(in1, weights)\nresult = tf.reduce_sum(weighted_in1, axis=1)\nreturn result",
            "weights = tf.range(tf.shape(in1)[1])\nweights = tf.cast(weights, dtype=in1.dtype)\nweighted_in1 = tf.multiply(in1, weights)\nout = tf.reduce_sum(weighted_in1, axis=1)\nreturn out",
            "import tensorflow as tf\n\ndef transform(in1):\n    weights = tf.range(start=0, limit=tf.shape(in1)[1], dtype=tf.float32)\n    return tf.reduce_sum(in1 * weights, axis=1)",
            "return tf.reduce_sum(tf.multiply(in1, tf.range(tf.shape(in1)[1])), axis=1)",
            "return tf.reduce_sum(in1 * tf.range(tf.shape(in1)[1]), axis=1)",
            "weights = tf.range(start=0, limit=tf.shape(in1)[1])\nweighted_matrix = tf.multiply(in1, tf.cast(weights, tf.float32))\nweighted_sum = tf.reduce_sum(weighted_matrix, axis=1)\nreturn weighted_sum"
        ]
    },
    {
        "constants": "[]",
        "description": "find the minimum distance between two sets of points",
        "target_program": "tf.reduce_min(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, 0), tf.expand_dims(in2, 1))), axis=2), axis=1)",
        "source": "https://stackoverflow.com/questions/40558251/computing-minimum-distance-for-each-element-in-a-tensor-relative-to-another-tens",
        "name": "stackoverflow_33",
        "examples": {
            "inputs": "[[[.3, .1, .4], [.1, .5, .9], [.2, .6, .5], [.3, .5, .8],[.9, .7, .9]],[[.3, .2, .3], [.8, .4, .6], [.2, .6, .4], [.3, .3, .8]],]",
            "outputs": "[0.02, 0.19, 0.01, 0.04]"
        },
        "response": {
            "task_id": "stackoverflow_33",
            "completions": [
                "distances = []\n    for point_1 in in1:\n        min_distance = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in2, point_1)), axis=1)))\n        distances.append(min_distance)\n    return tf.cast(distances, tf.float32)",
                "distances = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, 1), tf.expand_dims(in2, 0))), 2)), 1)\n     return distances",
                "distances = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=1), in2)), axis=2)), axis=1)\n     return distances",
                "distances = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1,1),tf.expand_dims(in2,0))),2)),1)\n     return distances",
                "distances = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=1), in2)), axis=2)), axis=1)\nreturn distances",
                "diffs = tf.subtract(tf.expand_dims(in1, 1), tf.expand_dims(in2, 0))\nsquared_diffs = tf.square(diffs)\ndistances = tf.sqrt(tf.reduce_sum(squared_diffs, axis=2))\nminimum_distance = tf.reduce_min(distances, axis=1)\nreturn minimum_distance",
                "distances = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.expand_dims(in1, axis=1) - tf.expand_dims(in2, axis=0)), axis=2)), axis=1)\nreturn distances",
                "distances = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1[:, tf.newaxis], in2)), axis=-1)), axis=-1)\nreturn distances",
                "distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=1), tf.expand_dims(in2, axis=0))), axis=2))\nmin_distance = tf.reduce_min(distances, axis=1)\nreturn min_distance",
                "differences = tf.subtract(tf.expand_dims(in1, 1), tf.expand_dims(in2, 0))\n     distances = tf.sqrt(tf.reduce_sum(tf.square(differences), axis=-1))\n     min_distances = tf.reduce_min(distances, axis=-1)\n     return min_distances"
            ],
            "target-program": "tf.reduce_min(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, 0), tf.expand_dims(in2, 1))), axis=2), axis=1)",
            "description": "find the minimum distance between two sets of points",
            "tf_operators": {
                "tf.sqrt": 10,
                "tf.cast": 1,
                "tf.square": 10,
                "tf.float32": 1,
                "tf.reduce_min": 10,
                "tf.subtract": 9,
                "tf.reduce_sum": 10,
                "tf.expand_dims": 8,
                "tf.newaxis": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 5,
            "total_covered": 5
        },
        "completions": [
            "distances = []\n    for point_1 in in1:\n        min_distance = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in2, point_1)), axis=1)))\n        distances.append(min_distance)\n    return tf.cast(distances, tf.float32)",
            "distances = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, 1), tf.expand_dims(in2, 0))), 2)), 1)\n     return distances",
            "distances = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=1), in2)), axis=2)), axis=1)\n     return distances",
            "distances = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1,1),tf.expand_dims(in2,0))),2)),1)\n     return distances",
            "distances = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=1), in2)), axis=2)), axis=1)\nreturn distances",
            "diffs = tf.subtract(tf.expand_dims(in1, 1), tf.expand_dims(in2, 0))\nsquared_diffs = tf.square(diffs)\ndistances = tf.sqrt(tf.reduce_sum(squared_diffs, axis=2))\nminimum_distance = tf.reduce_min(distances, axis=1)\nreturn minimum_distance",
            "distances = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.expand_dims(in1, axis=1) - tf.expand_dims(in2, axis=0)), axis=2)), axis=1)\nreturn distances",
            "distances = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1[:, tf.newaxis], in2)), axis=-1)), axis=-1)\nreturn distances",
            "distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=1), tf.expand_dims(in2, axis=0))), axis=2))\nmin_distance = tf.reduce_min(distances, axis=1)\nreturn min_distance",
            "differences = tf.subtract(tf.expand_dims(in1, 1), tf.expand_dims(in2, 0))\n     distances = tf.sqrt(tf.reduce_sum(tf.square(differences), axis=-1))\n     min_distances = tf.reduce_min(distances, axis=-1)\n     return min_distances"
        ]
    },
    {
        "constants": "[]",
        "description": "compute a weighted sum of tensors",
        "target_program": "tf.tensordot(in2, in1, 1)",
        "source": "https://stackoverflow.com/questions/49532371/compute-a-linear-combination-of-tensors-in-tensorflow",
        "name": "stackoverflow_34",
        "examples": {
            "inputs": "[[[[1, 2], [3, 4]],[[5, 6], [7, 8]],[[10, 20], [30, 40]]],[3, 5, 10],]",
            "outputs": "[[128, 236], [344, 452]]"
        },
        "response": {
            "task_id": "stackoverflow_34",
            "completions": [
                "return tf.reduce_sum(tf.multiply(in1,tf.expand_dims(tf.cast(in2, dtype=tf.int32), 1)), 0)",
                "return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, (-1,1,1))), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(in2, axis=-1)), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(in1, -1)), axis=0)",
                "# First, we convert the weights list to a tensor\n    weights = tf.convert_to_tensor(in2, dtype=tf.int32)\n\n    # Then, we expand the dimension of our weights tensor to match the dimensions of the input tensor\n    expanded_weights = tf.expand_dims(weights, axis=-1)\n\n    # Next, we multiply our input tensor by our weights tensor\n    weighted_inputs = tf.multiply(in1, expanded_weights)\n\n    # Lastly, we sum our weighted inputs along the first dimension\n    return tf.reduce_sum(weighted_inputs, axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(tf.cast(in2, tf.float32), -1)), axis=0)",
                "in1 = tf.constant(in1, dtype=tf.float32)\n     in2 = tf.constant(in2, dtype=tf.float32)\n     in2 = tf.expand_dims(in2, axis=1)\n     in2 = tf.expand_dims(in2, axis=2)\n     weighted_tensors = tf.multiply(in1, in2)\n     return tf.reduce_sum(weighted_tensors, axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, [-1, 1, 1])), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(tf.expand_dims(in2, 1), 1)), axis=0)",
                "weights = tf.expand_dims(tf.constant(in2, dtype=tf.int32), -1)\nweighted_tensors = tf.multiply(in1, weights)\nreturn tf.reduce_sum(weighted_tensors, axis=0)"
            ],
            "target-program": "tf.tensordot(in2, in1, 1)",
            "description": "compute a weighted sum of tensors",
            "tf_operators": {
                "tf.cast": 2,
                "tf.multiply": 10,
                "tf.int32": 3,
                "tf.expand_dims": 8,
                "tf.reduce_sum": 10,
                "tf.reshape": 2,
                "tf.convert_to_tensor": 1,
                "tf.float32": 2,
                "tf.constant": 2
            },
            "coverage_percentage": 0.0,
            "total_in_target": 1,
            "total_covered": 0
        },
        "completions": [
            "return tf.reduce_sum(tf.multiply(in1,tf.expand_dims(tf.cast(in2, dtype=tf.int32), 1)), 0)",
            "return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, (-1,1,1))), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(in2, axis=-1)), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(in1, -1)), axis=0)",
            "# First, we convert the weights list to a tensor\n    weights = tf.convert_to_tensor(in2, dtype=tf.int32)\n\n    # Then, we expand the dimension of our weights tensor to match the dimensions of the input tensor\n    expanded_weights = tf.expand_dims(weights, axis=-1)\n\n    # Next, we multiply our input tensor by our weights tensor\n    weighted_inputs = tf.multiply(in1, expanded_weights)\n\n    # Lastly, we sum our weighted inputs along the first dimension\n    return tf.reduce_sum(weighted_inputs, axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(tf.cast(in2, tf.float32), -1)), axis=0)",
            "in1 = tf.constant(in1, dtype=tf.float32)\n     in2 = tf.constant(in2, dtype=tf.float32)\n     in2 = tf.expand_dims(in2, axis=1)\n     in2 = tf.expand_dims(in2, axis=2)\n     weighted_tensors = tf.multiply(in1, in2)\n     return tf.reduce_sum(weighted_tensors, axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, [-1, 1, 1])), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(tf.expand_dims(in2, 1), 1)), axis=0)",
            "weights = tf.expand_dims(tf.constant(in2, dtype=tf.int32), -1)\nweighted_tensors = tf.multiply(in1, weights)\nreturn tf.reduce_sum(weighted_tensors, axis=0)"
        ]
    },
    {
        "constants": "[]",
        "description": "linear interpolation between two tensors",
        "target_program": "tf.add(in2, tf.multiply(tf.expand_dims(in3, 1), tf.subtract(in1, in2)))",
        "source": "https://stackoverflow.com/questions/49643371/keras-compute-convex-combination-of-two-tensors",
        "name": "stackoverflow_35",
        "examples": {
            "inputs": "[[[[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]], [[10., 20.], [30., 40.], [50., 60.]]],[[[9.0, 8.0], [7.0, 6.0], [5.0, 4.0]], [[90., 80.], [70., 60.], [50., 40.]]],[0.1, 0.4, 0.8],]",
            "outputs": "[[[8.2, 7.4], [5.4, 5.2], [5.0, 5.6]],    [[82., 74.], [54., 52.], [50., 56.]]]"
        },
        "response": {
            "task_id": "stackoverflow_35",
            "completions": [
                "return tf.add(tf.multiply(in1, tf.reshape(1 - in3, [len(in3), 1, 1])), tf.multiply(in2, tf.reshape(in3, [len(in3), 1, 1])))",
                "return tf.add(tf.multiply(in1, tf.reshape(1.0-in3, [in3.shape[0],1,1])), tf.multiply(in2, tf.reshape(in3, [in3.shape[0],1,1])))",
                "in1 = tf.constant(in1, dtype=tf.float32)\nin2 = tf.constant(in2, dtype=tf.float32)\nin3 = tf.expand_dims(tf.expand_dims(tf.constant(in3, dtype=tf.float32), -1),-1)\n\nreturn tf.add(tf.multiply(in1, 1.0 - in3), tf.multiply(in2, in3))",
                "return tf.add(tf.multiply(in1, tf.reshape(1 - in3, [len(in3), 1, 1])), tf.multiply(in2, tf.reshape(in3, [len(in3), 1, 1])))",
                "return in1 * (1 - tf.expand_dims(in3, -1)) + in2 * tf.expand_dims(in3, -1)",
                "return tf.add(tf.multiply(in1, tf.subtract(tf.constant(1.0), in3)), tf.multiply(in2, in3))",
                "return tf.add(tf.multiply(in1, tf.reshape(1.0 - in3, [-1, 1, 1])), tf.multiply(in2, tf.reshape(in3, [-1, 1, 1])))",
                "return tf.add(tf.multiply(in1, tf.expand_dims(tf.expand_dims(1 - in3, -1), -1)), tf.multiply(in2, tf.expand_dims(tf.expand_dims(in3, -1), -1)))",
                "return tf.add(tf.multiply(in1, tf.reshape(1 - in3, shape=[-1, 1, 1])), tf.multiply(in2, tf.reshape(in3, shape=[-1, 1, 1])))",
                "return tf.add(tf.multiply(in1, tf.reshape(1.0 - in3, (-1, 1, 1))), tf.multiply(in2, tf.reshape(in3, (-1, 1, 1))))"
            ],
            "target-program": "tf.add(in2, tf.multiply(tf.expand_dims(in3, 1), tf.subtract(in1, in2)))",
            "description": "linear interpolation between two tensors",
            "tf_operators": {
                "tf.add": 9,
                "tf.multiply": 9,
                "tf.reshape": 6,
                "tf.float32": 1,
                "tf.constant": 2,
                "tf.expand_dims": 3,
                "tf.subtract": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 4,
            "total_covered": 4
        },
        "completions": [
            "return tf.add(tf.multiply(in1, tf.reshape(1 - in3, [len(in3), 1, 1])), tf.multiply(in2, tf.reshape(in3, [len(in3), 1, 1])))",
            "return tf.add(tf.multiply(in1, tf.reshape(1.0-in3, [in3.shape[0],1,1])), tf.multiply(in2, tf.reshape(in3, [in3.shape[0],1,1])))",
            "in1 = tf.constant(in1, dtype=tf.float32)\nin2 = tf.constant(in2, dtype=tf.float32)\nin3 = tf.expand_dims(tf.expand_dims(tf.constant(in3, dtype=tf.float32), -1),-1)\n\nreturn tf.add(tf.multiply(in1, 1.0 - in3), tf.multiply(in2, in3))",
            "return tf.add(tf.multiply(in1, tf.reshape(1 - in3, [len(in3), 1, 1])), tf.multiply(in2, tf.reshape(in3, [len(in3), 1, 1])))",
            "return in1 * (1 - tf.expand_dims(in3, -1)) + in2 * tf.expand_dims(in3, -1)",
            "return tf.add(tf.multiply(in1, tf.subtract(tf.constant(1.0), in3)), tf.multiply(in2, in3))",
            "return tf.add(tf.multiply(in1, tf.reshape(1.0 - in3, [-1, 1, 1])), tf.multiply(in2, tf.reshape(in3, [-1, 1, 1])))",
            "return tf.add(tf.multiply(in1, tf.expand_dims(tf.expand_dims(1 - in3, -1), -1)), tf.multiply(in2, tf.expand_dims(tf.expand_dims(in3, -1), -1)))",
            "return tf.add(tf.multiply(in1, tf.reshape(1 - in3, shape=[-1, 1, 1])), tf.multiply(in2, tf.reshape(in3, shape=[-1, 1, 1])))",
            "return tf.add(tf.multiply(in1, tf.reshape(1.0 - in3, (-1, 1, 1))), tf.multiply(in2, tf.reshape(in3, (-1, 1, 1))))"
        ]
    },
    {
        "constants": "[]",
        "description": "divide each element by the column index",
        "target_program": "tf.cast(tf.divide(in1, tf.add(in1, tf.range(8))), tf.float32)",
        "source": "https://stackoverflow.com/questions/43306788/divide-elements-of-1-d-tensor-by-the-corrispondent-index",
        "name": "stackoverflow_36",
        "examples": {
            "inputs": "[[1, 0, 1, 1, 0, 1, 0, 1],]",
            "outputs": "[1., 0., 0.333333, 0.25, 0., 0.166667, 0., 0.125]"
        },
        "response": {
            "task_id": "stackoverflow_36",
            "completions": [
                "# First we need to reshape the input into 2D array where each column represents an index from\n# the original 1D array\n# Then we divide each element by the column index + 1 (to avoid division by zero)\n# Finally, we reshape the result back to 1D\n\nimport tensorflow as tf\n\ndef transform(in1):\n    tensor = tf.constant(in1, dtype=tf.float32)\n    tensor = tf.reshape(tensor, shape=(-1, 1))\n    indices = tf.range(start=1, limit=tf.shape(tensor)[0] + 1, dtype=tf.float32)\n    indices = tf.reshape(indices, shape=(-1, 1))\n    result = tf.divide(tensor, indices)\n    return tf.reshape(result, shape=(-1,)).numpy()",
                "# First transform the 1D tensor in1 into a 2D tensor.\n    in1_2d = tf.expand_dims(in1, axis=-1)\n    # Get the shape of the 2D tensor.\n    shape = tf.shape(in1_2d)\n    # Create a tensor where values are their column indices.\n    column_indices = tf.expand_dims(tf.range(shape[1]), axis=0)\n    # Broadcast the column_indices tensor to the shape of in1_2d.\n    column_indices_broad = tf.broadcast_to(column_indices, shape)\n    # Convert the column indices to float to avoid integer division.\n    indices_float = tf.cast(column_indices_broad, tf.float32)\n    # Now divide in1_2d by the float column indices. Add 1 to avoid division by zero.\n    return tf.divide(in1_2d, indices_float + 1)",
                "return tf.divide(in1, tf.range(1, tf.shape(in1)[0] + 1))",
                "import tensorflow as tf\n\ndef transform(in1):\n    in1 = tf.constant(in1, dtype=tf.float32)\n    column_indices = tf.range(1, tf.shape(in1)[0] + 1, dtype=tf.float32)\n    return tf.divide(in1, column_indices)",
                "in1 = tf.cast(in1, tf.float32)\nreturn tf.divide(in1,[1,2,3,4,5,6,7,8])",
                "return tf.divide(in1, tf.range(1, tf.shape(in1)[0] + 1, dtype=in1.dtype))",
                "# first we will reshape the 1D input array into 2D array \n# because we are told to divide by the colum index\n# So the input could be like [[1, 0, 1, 1, 0, 1, 0, 1]]\n# Now we can consider '1's index in each column as the column index\n# so reshaping is like framing the problem into a way we can understand\nin1 = tf.reshape(in1, (1, -1))\n\n# get the length of the array which will also be the number of columns\nlength = tf.shape(in1)[1]\n\n# generate a sequence from 1 to n, where n is the length\nindices = tf.range(1, length + 1, 1)\n\n# cast the indices to float as the input is of float type\nindices = tf.cast(indices, tf.float32)\n\n# divide the input array (2D) with the indices\noutput = tf.math.divide_no_nan(in1, indices)\n\n# the result is a 2D array with a single row, reshape it to 1D\noutput = tf.reshape(output, (-1,))\n\nreturn output",
                "import tensorflow as tf\n\ndef transform(in1):\n    indices = tf.range(1, tf.size(in1) + 1, dtype=in1.dtype)\n    return tf.divide(in1, indices)",
                "import tensorflow as tf\n\ndef transform(in1):\n    in1_shape = tf.shape(in1)\n    col_indices = tf.range(in1_shape[-1], dtype=in1.dtype)\n    col_indices = tf.add(col_indices, 1)\n    col_indices = tf.cast(col_indices, tf.float32)\n    in1 = tf.cast(in1, tf.float32)\n    return tf.divide(in1, col_indices)",
                "return tf.divide(in1, tf.range(1, tf.size(in1)+1, dtype=tf.float32))"
            ],
            "target-program": "tf.cast(tf.divide(in1, tf.add(in1, tf.range(8))), tf.float32)",
            "description": "divide each element by the column index",
            "tf_operators": {
                "tf.shape": 7,
                "tf.divide": 9,
                "tf.range": 9,
                "tf.reshape": 2,
                "tf.float32": 7,
                "tf.constant": 2,
                "tf.cast": 4,
                "tf.broadcast_to": 1,
                "tf.expand_dims": 1,
                "tf.math.divide_no_nan": 1,
                "tf.size": 2,
                "tf.add": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 5,
            "total_covered": 5
        },
        "completions": [
            "# First we need to reshape the input into 2D array where each column represents an index from\n# the original 1D array\n# Then we divide each element by the column index + 1 (to avoid division by zero)\n# Finally, we reshape the result back to 1D\n\nimport tensorflow as tf\n\ndef transform(in1):\n    tensor = tf.constant(in1, dtype=tf.float32)\n    tensor = tf.reshape(tensor, shape=(-1, 1))\n    indices = tf.range(start=1, limit=tf.shape(tensor)[0] + 1, dtype=tf.float32)\n    indices = tf.reshape(indices, shape=(-1, 1))\n    result = tf.divide(tensor, indices)\n    return tf.reshape(result, shape=(-1,)).numpy()",
            "# First transform the 1D tensor in1 into a 2D tensor.\n    in1_2d = tf.expand_dims(in1, axis=-1)\n    # Get the shape of the 2D tensor.\n    shape = tf.shape(in1_2d)\n    # Create a tensor where values are their column indices.\n    column_indices = tf.expand_dims(tf.range(shape[1]), axis=0)\n    # Broadcast the column_indices tensor to the shape of in1_2d.\n    column_indices_broad = tf.broadcast_to(column_indices, shape)\n    # Convert the column indices to float to avoid integer division.\n    indices_float = tf.cast(column_indices_broad, tf.float32)\n    # Now divide in1_2d by the float column indices. Add 1 to avoid division by zero.\n    return tf.divide(in1_2d, indices_float + 1)",
            "return tf.divide(in1, tf.range(1, tf.shape(in1)[0] + 1))",
            "import tensorflow as tf\n\ndef transform(in1):\n    in1 = tf.constant(in1, dtype=tf.float32)\n    column_indices = tf.range(1, tf.shape(in1)[0] + 1, dtype=tf.float32)\n    return tf.divide(in1, column_indices)",
            "in1 = tf.cast(in1, tf.float32)\nreturn tf.divide(in1,[1,2,3,4,5,6,7,8])",
            "return tf.divide(in1, tf.range(1, tf.shape(in1)[0] + 1, dtype=in1.dtype))",
            "# first we will reshape the 1D input array into 2D array \n# because we are told to divide by the colum index\n# So the input could be like [[1, 0, 1, 1, 0, 1, 0, 1]]\n# Now we can consider '1's index in each column as the column index\n# so reshaping is like framing the problem into a way we can understand\nin1 = tf.reshape(in1, (1, -1))\n\n# get the length of the array which will also be the number of columns\nlength = tf.shape(in1)[1]\n\n# generate a sequence from 1 to n, where n is the length\nindices = tf.range(1, length + 1, 1)\n\n# cast the indices to float as the input is of float type\nindices = tf.cast(indices, tf.float32)\n\n# divide the input array (2D) with the indices\noutput = tf.math.divide_no_nan(in1, indices)\n\n# the result is a 2D array with a single row, reshape it to 1D\noutput = tf.reshape(output, (-1,))\n\nreturn output",
            "import tensorflow as tf\n\ndef transform(in1):\n    indices = tf.range(1, tf.size(in1) + 1, dtype=in1.dtype)\n    return tf.divide(in1, indices)",
            "import tensorflow as tf\n\ndef transform(in1):\n    in1_shape = tf.shape(in1)\n    col_indices = tf.range(in1_shape[-1], dtype=in1.dtype)\n    col_indices = tf.add(col_indices, 1)\n    col_indices = tf.cast(col_indices, tf.float32)\n    in1 = tf.cast(in1, tf.float32)\n    return tf.divide(in1, col_indices)",
            "return tf.divide(in1, tf.range(1, tf.size(in1)+1, dtype=tf.float32))"
        ]
    },
    {
        "constants": "[]",
        "description": "dot product a vector with last dimension of a tensor",
        "target_program": "tf.tensordot(in1, in2, 1)",
        "source": "https://stackoverflow.com/questions/49206051/multiply-4-d-tensor-with-1-d-tensor",
        "name": "stackoverflow_37",
        "examples": {
            "inputs": "[[[[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]],  [[1.2, 3.4, 5.6], [7.8, 9.8, 7.6]]]],[0.5, 1.0, 2.0],]",
            "outputs": "[[[8.5, 19.0], [15.2, 28.9]]]"
        },
        "response": {
            "task_id": "stackoverflow_37",
            "completions": [
                "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
                "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
                "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
                "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
                "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
                "return tf.tensordot(in1, in2, axes=[[len(in1.shape)-1], [0]])",
                "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
                "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
                "return tf.tensordot(in1, in2, axes=[[-1],[0]])",
                "return tf.tensordot(in1, in2, axes=[[-1],[0]])"
            ],
            "target-program": "tf.tensordot(in1, in2, 1)",
            "description": "dot product a vector with last dimension of a tensor",
            "tf_operators": {
                "tf.tensordot": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
            "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
            "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
            "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
            "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
            "return tf.tensordot(in1, in2, axes=[[len(in1.shape)-1], [0]])",
            "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
            "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
            "return tf.tensordot(in1, in2, axes=[[-1],[0]])",
            "return tf.tensordot(in1, in2, axes=[[-1],[0]])"
        ]
    },
    {
        "constants": "[]",
        "description": "compute the product of marked elements",
        "target_program": "tf.reduce_prod(tf.maximum(tf.reduce_max(in2), tf.multiply(in1, in2)), axis=1)",
        "source": "https://stackoverflow.com/questions/49511529/tensorflow-compute-multiplication-by-binary-matrix",
        "name": "stackoverflow_38",
        "examples": {
            "inputs": "[[9, 2, 5, 3, 7, 4],[[0, 0, 1, 0, 1, 0], [1, 0, 0, 0, 0, 0], [0, 1, 1, 1, 0, 1]],]",
            "outputs": "[35, 9, 120]"
        },
        "response": {
            "task_id": "stackoverflow_38",
            "completions": [
                "return tf.reduce_prod(tf.boolean_mask(in1, in2), 1)",
                "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)",
                "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)",
                "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)",
                "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)",
                "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)",
                "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)",
                "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, dtype=tf.bool)), axis=1)",
                "return tf.reduce_prod(tf.boolean_mask(in1, tf.equal(in2, 1)), axis=1)",
                "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=-1)"
            ],
            "target-program": "tf.reduce_prod(tf.maximum(tf.reduce_max(in2), tf.multiply(in1, in2)), axis=1)",
            "description": "compute the product of marked elements",
            "tf_operators": {
                "tf.reduce_prod": 10,
                "tf.boolean_mask": 10,
                "tf.cast": 3,
                "tf.bool": 3,
                "tf.equal": 1
            },
            "coverage_percentage": 25.0,
            "total_in_target": 4,
            "total_covered": 1
        },
        "completions": [
            "return tf.reduce_prod(tf.boolean_mask(in1, in2), 1)",
            "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)",
            "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)",
            "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)",
            "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)",
            "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)",
            "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)",
            "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, dtype=tf.bool)), axis=1)",
            "return tf.reduce_prod(tf.boolean_mask(in1, tf.equal(in2, 1)), axis=1)",
            "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=-1)"
        ]
    },
    {
        "constants": "[]",
        "description": "(\\'set to 0 the elements with absolute value less than 1, and square the other elements\\')",
        "target_program": "tf.multiply(tf.square(in1), tf.cast(tf.cast(tf.cast(in1, tf.int32), tf.bool), tf.float32))",
        "source": "https://stackoverflow.com/questions/37912161/how-can-i-compute-element-wise-conditionals-on-batches-in-tensorflow",
        "name": "stackoverflow_39",
        "examples": {
            "inputs": "[[[-1.5, 1.0, 0.9, 2.0], [1.1, 0.0, -0.1, -0.9], [-1.0, 0.1, -1.1, 2.5]],]",
            "outputs": "[[2.25, 1.0, 0.0, 4.0],    [1.21, 0.0, 0.0, 0.0],    [1.0, 0.0, 1.21, 6.25]]"
        },
        "response": {
            "task_id": "stackoverflow_39",
            "completions": [
                "abs_in1 = tf.abs(in1)\nmask = tf.greater(abs_in1, 1)\nmasked_in1 = tf.boolean_mask(in1, mask)\nmasked_in1_squared = tf.square(masked_in1)\ntf.tensor_scatter_nd_update(in1, tf.where(mask), masked_in1_squared)",
                "# First we will calculate the absolute of all elements in the input tensor\n    abs_in1 = tf.abs(in1)\n\n    # Then we will make a mask of elements that are less than 1\n    mask = tf.less(abs_in1, 1)\n\n    # We will make a tensor of the same shape as the input tensor but filled with zeros\n    zeros = tf.zeros_like(in1)\n\n    # We will replace the elements that are less than 1 with zeroes\n    temp = tf.where(mask, zeros, in1)\n\n    # Lastly we will square the remaining (non-zero) elements of the tensor\n    result = tf.square(temp)\n\n    return result",
                "return tf.where(tf.abs(in1) < 1, 0, tf.square(in1))",
                "# Using tf.where, tf.abs and tf.square for conditional replacement and squaring\n# We have the condition as less than 1, so we catch them and set those positions as 0\n# For other positions we perform the square operation\n\nmask = tf.less(tf.abs(in1), 1)\nreturn tf.where(mask, tf.zeros_like(in1), tf.square(in1))",
                "in1_abs = tf.abs(in1)\nmask = tf.greater(in1_abs, 1)\nres = tf.where(mask, tf.square(in1), 0)\nreturn res",
                "# Check the absolute value of all elements in the tensor\n    abs_in1 = tf.abs(in1)\n\n    # Create a mask for elements with absolute value less than 1\n    mask = tf.less(abs_in1, 1)\n\n    # Replace the elements less than 1 by 0\n    in1_zeroed = tf.where(mask, 0, in1)\n\n    # Square the elements\n    result = tf.square(in1_zeroed)\n\n    return result",
                "# Import required tensorflow module\n    import tensorflow as tf\n\n    # Convert given input into tensor\n    in_tensor = tf.constant(in1)\n\n    # Find the absolute value of each element in the tensor\n    abs_vals = tf.abs(in_tensor)\n\n    # Create a mask where values less than 1 result in True\n    mask = tf.less(abs_vals, 1)\n\n    # Set the values in the tensor that are less than 1 to 0\n    in_tensor = tf.where(mask, 0., in_tensor)\n\n    # Square the remaining elements in the tensor\n    output = tf.square(in_tensor)\n\n    # Convert the tensor into numpy array and return\n    return output.numpy()",
                "abs_in1 = tf.abs(in1)\nmask = tf.greater(abs_in1, tf.constant(1.0))\nfiltered_in1 = tf.where(mask, tf.square(in1), tf.zeros_like(in1))\nreturn filtered_in1",
                "# create a mask for elements with absolute value less than 1\n    mask = tf.math.less(tf.abs(in1), 1)\n    # set to 0 the elements with absolute value less than 1\n    in1 = tf.where(mask, tf.zeros_like(in1), in1)\n    # square the other elements\n    return tf.square(in1)",
                "return tf.where(tf.abs(in1) < 1, 0, tf.square(in1))"
            ],
            "target-program": "tf.multiply(tf.square(in1), tf.cast(tf.cast(tf.cast(in1, tf.int32), tf.bool), tf.float32))",
            "description": "(\\'set to 0 the elements with absolute value less than 1, and square the other elements\\')",
            "tf_operators": {
                "tf.boolean_mask": 1,
                "tf.abs": 10,
                "tf.square": 10,
                "tf.where": 10,
                "tf.greater": 3,
                "tf.tensor_scatter_nd_update": 1,
                "tf.less": 4,
                "tf.zeros_like": 4,
                "tf.constant": 2,
                "tf.math.less": 1
            },
            "coverage_percentage": 16.666666666666664,
            "total_in_target": 6,
            "total_covered": 1
        },
        "completions": [
            "abs_in1 = tf.abs(in1)\nmask = tf.greater(abs_in1, 1)\nmasked_in1 = tf.boolean_mask(in1, mask)\nmasked_in1_squared = tf.square(masked_in1)\ntf.tensor_scatter_nd_update(in1, tf.where(mask), masked_in1_squared)",
            "# First we will calculate the absolute of all elements in the input tensor\n    abs_in1 = tf.abs(in1)\n\n    # Then we will make a mask of elements that are less than 1\n    mask = tf.less(abs_in1, 1)\n\n    # We will make a tensor of the same shape as the input tensor but filled with zeros\n    zeros = tf.zeros_like(in1)\n\n    # We will replace the elements that are less than 1 with zeroes\n    temp = tf.where(mask, zeros, in1)\n\n    # Lastly we will square the remaining (non-zero) elements of the tensor\n    result = tf.square(temp)\n\n    return result",
            "return tf.where(tf.abs(in1) < 1, 0, tf.square(in1))",
            "# Using tf.where, tf.abs and tf.square for conditional replacement and squaring\n# We have the condition as less than 1, so we catch them and set those positions as 0\n# For other positions we perform the square operation\n\nmask = tf.less(tf.abs(in1), 1)\nreturn tf.where(mask, tf.zeros_like(in1), tf.square(in1))",
            "in1_abs = tf.abs(in1)\nmask = tf.greater(in1_abs, 1)\nres = tf.where(mask, tf.square(in1), 0)\nreturn res",
            "# Check the absolute value of all elements in the tensor\n    abs_in1 = tf.abs(in1)\n\n    # Create a mask for elements with absolute value less than 1\n    mask = tf.less(abs_in1, 1)\n\n    # Replace the elements less than 1 by 0\n    in1_zeroed = tf.where(mask, 0, in1)\n\n    # Square the elements\n    result = tf.square(in1_zeroed)\n\n    return result",
            "# Import required tensorflow module\n    import tensorflow as tf\n\n    # Convert given input into tensor\n    in_tensor = tf.constant(in1)\n\n    # Find the absolute value of each element in the tensor\n    abs_vals = tf.abs(in_tensor)\n\n    # Create a mask where values less than 1 result in True\n    mask = tf.less(abs_vals, 1)\n\n    # Set the values in the tensor that are less than 1 to 0\n    in_tensor = tf.where(mask, 0., in_tensor)\n\n    # Square the remaining elements in the tensor\n    output = tf.square(in_tensor)\n\n    # Convert the tensor into numpy array and return\n    return output.numpy()",
            "abs_in1 = tf.abs(in1)\nmask = tf.greater(abs_in1, tf.constant(1.0))\nfiltered_in1 = tf.where(mask, tf.square(in1), tf.zeros_like(in1))\nreturn filtered_in1",
            "# create a mask for elements with absolute value less than 1\n    mask = tf.math.less(tf.abs(in1), 1)\n    # set to 0 the elements with absolute value less than 1\n    in1 = tf.where(mask, tf.zeros_like(in1), in1)\n    # square the other elements\n    return tf.square(in1)",
            "return tf.where(tf.abs(in1) < 1, 0, tf.square(in1))"
        ]
    },
    {
        "constants": "[]",
        "description": "use the output of tf.nn.top_k to make a sparse tensor",
        "target_program": "tf.sparse.to_dense(tf.SparseTensor(tf.cast(in2, tf.int64), in1, (3, 5)))",
        "source": "https://stackoverflow.com/questions/43996831/make-a-sparse-tensor-based-on-the-output-of-tf-nn-top-k",
        "name": "stackoverflow_40",
        "examples": {
            "inputs": "[[4, 5, 2, 7, 8, 6],[[0, 2], [0, 4], [1, 1], [1, 3], [2, 0], [2, 3]],]",
            "outputs": "[[0, 0, 4, 0, 5],[0, 2, 0, 7, 0],[8, 0, 0, 6, 0]]"
        },
        "response": {
            "task_id": "stackoverflow_40",
            "completions": [
                "values, indices = tf.math.top_k(in1)\nsparse_tensor = tf.SparseTensor(tf.cast(indices, dtype=tf.int64), tf.cast(values, dtype=tf.float32), dense_shape=tf.shape(in1))\nreturn tf.sparse.to_dense(sparse_tensor)",
                "values, indices = tf.math.top_k(in1, tf.shape(in1)[0])\nreturn tf.SparseTensor(tf.cast(in2, dtype=tf.int64), values, tf.constant([3,5], tf.int64))",
                "values, indices = tf.nn.top_k(in1, len(in1))\nreturn tf.sparse.to_dense(tf.SparseTensor(in2, values, tf.constant([len(in1), len(in1)])))",
                "values, indices = tf.math.top_k(in1, k=in1.shape[0])\nsparse_tensor = tf.sparse.SparseTensor(in2, values, dense_shape=[tf.reduce_max(in2[:, 0])+1, tf.reduce_max(in2[:, 1])+1])\nreturn tf.sparse.to_dense(sparse_tensor)",
                "values, indices = tf.math.top_k(in1, k=tf.shape(in1)[0])\nsparse_tensor = tf.SparseTensor(indices=tf.expand_dims(indices, 1), values=values, dense_shape=[tf.reduce_max(indices)+1])\ndense_tensor = tf.sparse.to_dense(sparse_tensor)\nreturn dense_tensor",
                "values, indices = tf.nn.top_k(in1, k=tf.size(in1)) # Find the largest 'k' values in the input\nsparse_tensor = tf.SparseTensor(indices=tf.expand_dims(indices, 1), values=values, dense_shape=[tf.size(in1)])\ndense_tensor = tf.sparse.to_dense(sparse_tensor, default_value=0) # Converts sparse representations to dense.\ndense_tensor = tf.reshape(dense_tensor, in2) # Reshape dense tensor to the shape of 'in2'\nreturn dense_tensor",
                "values, indices = tf.nn.top_k(in1, k=in1.shape[0])\nsparse_tensor = tf.SparseTensor(in2, values, [3,5])\nreturn tf.sparse.to_dense(sparse_tensor)",
                "values, indices = tf.nn.top_k(in1, k=len(in1))\nsparse_tensor = tf.SparseTensor(indices=tf.expand_dims(indices, 1), values=values, dense_shape=[len(in1)])\nreturn tf.sparse.to_dense(sparse_tensor, validate_indices=False)",
                "values, indices = tf.math.top_k(in1, k=len(in1))\nreturn tf.SparseTensor(indices=tf.expand_dims(in2, 1), values=values, dense_shape=[len(in1), tf.reduce_max(in2)+1]).to_dense()",
                "top_k_values, top_k_indices = tf.math.top_k(in1, k=tf.shape(in1)[0])\nreturn tf.SparseTensor(indices=in2, values=top_k_values, dense_shape=tf.shape(in1)).to_dense()"
            ],
            "target-program": "tf.sparse.to_dense(tf.SparseTensor(tf.cast(in2, tf.int64), in1, (3, 5)))",
            "description": "use the output of tf.nn.top_k to make a sparse tensor",
            "tf_operators": {
                "tf.SparseTensor": 9,
                "tf.shape": 4,
                "tf.int64": 2,
                "tf.sparse.to_dense": 7,
                "tf.cast": 2,
                "tf.math.top_k": 6,
                "tf.float32": 1,
                "tf.constant": 2,
                "tf.nn.top_k": 4,
                "tf.reduce_max": 3,
                "tf.sparse.SparseTensor": 1,
                "tf.expand_dims": 4,
                "tf.reshape": 1,
                "tf.size": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 4,
            "total_covered": 4
        },
        "completions": [
            "values, indices = tf.math.top_k(in1)\nsparse_tensor = tf.SparseTensor(tf.cast(indices, dtype=tf.int64), tf.cast(values, dtype=tf.float32), dense_shape=tf.shape(in1))\nreturn tf.sparse.to_dense(sparse_tensor)",
            "values, indices = tf.math.top_k(in1, tf.shape(in1)[0])\nreturn tf.SparseTensor(tf.cast(in2, dtype=tf.int64), values, tf.constant([3,5], tf.int64))",
            "values, indices = tf.nn.top_k(in1, len(in1))\nreturn tf.sparse.to_dense(tf.SparseTensor(in2, values, tf.constant([len(in1), len(in1)])))",
            "values, indices = tf.math.top_k(in1, k=in1.shape[0])\nsparse_tensor = tf.sparse.SparseTensor(in2, values, dense_shape=[tf.reduce_max(in2[:, 0])+1, tf.reduce_max(in2[:, 1])+1])\nreturn tf.sparse.to_dense(sparse_tensor)",
            "values, indices = tf.math.top_k(in1, k=tf.shape(in1)[0])\nsparse_tensor = tf.SparseTensor(indices=tf.expand_dims(indices, 1), values=values, dense_shape=[tf.reduce_max(indices)+1])\ndense_tensor = tf.sparse.to_dense(sparse_tensor)\nreturn dense_tensor",
            "values, indices = tf.nn.top_k(in1, k=tf.size(in1)) # Find the largest 'k' values in the input\nsparse_tensor = tf.SparseTensor(indices=tf.expand_dims(indices, 1), values=values, dense_shape=[tf.size(in1)])\ndense_tensor = tf.sparse.to_dense(sparse_tensor, default_value=0) # Converts sparse representations to dense.\ndense_tensor = tf.reshape(dense_tensor, in2) # Reshape dense tensor to the shape of 'in2'\nreturn dense_tensor",
            "values, indices = tf.nn.top_k(in1, k=in1.shape[0])\nsparse_tensor = tf.SparseTensor(in2, values, [3,5])\nreturn tf.sparse.to_dense(sparse_tensor)",
            "values, indices = tf.nn.top_k(in1, k=len(in1))\nsparse_tensor = tf.SparseTensor(indices=tf.expand_dims(indices, 1), values=values, dense_shape=[len(in1)])\nreturn tf.sparse.to_dense(sparse_tensor, validate_indices=False)",
            "values, indices = tf.math.top_k(in1, k=len(in1))\nreturn tf.SparseTensor(indices=tf.expand_dims(in2, 1), values=values, dense_shape=[len(in1), tf.reduce_max(in2)+1]).to_dense()",
            "top_k_values, top_k_indices = tf.math.top_k(in1, k=tf.shape(in1)[0])\nreturn tf.SparseTensor(indices=in2, values=top_k_values, dense_shape=tf.shape(in1)).to_dense()"
        ]
    },
    {
        "constants": "[]",
        "description": "copy all elements except at the given index",
        "target_program": "tf.boolean_mask(in1, tf.not_equal(tf.constant(in2), tf.range(10)))",
        "source": "https://stackoverflow.com/questions/54499051/elegant-way-to-access-python-list-and-tensor-in-tensorflow",
        "name": "stackoverflow_41",
        "examples": {
            "inputs": "[[5, 2, 8, 2, 4, 1, 1, 0, 2, 1],3,]",
            "outputs": "[5, 2, 8, 4, 1, 1, 0, 2, 1]"
        },
        "response": {
            "task_id": "stackoverflow_41",
            "completions": [
                "indices = tf.range(tf.shape(in1)[0])\nfiltered_indices = tf.boolean_mask(indices, indices != in2)\nreturn tf.gather(in1, filtered_indices)",
                "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, mask)",
                "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, mask)",
                "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nresult = tf.boolean_mask(in1, mask)\nreturn result",
                "indices = tf.range(tf.shape(in1)[0])\nindices_to_keep = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, indices_to_keep)",
                "idx_mask = tf.one_hot(in2, tf.shape(in1)[0])\nreturn tf.boolean_mask(in1, tf.logical_not(idx_mask))",
                "return tf.concat([in1[:in2], in1[in2+1:]], 0)",
                "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, mask)",
                "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, mask)",
                "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, mask)"
            ],
            "target-program": "tf.boolean_mask(in1, tf.not_equal(tf.constant(in2), tf.range(10)))",
            "description": "copy all elements except at the given index",
            "tf_operators": {
                "tf.gather": 1,
                "tf.shape": 9,
                "tf.range": 8,
                "tf.boolean_mask": 9,
                "tf.not_equal": 7,
                "tf.one_hot": 1,
                "tf.logical_not": 1,
                "tf.concat": 1
            },
            "coverage_percentage": 75.0,
            "total_in_target": 4,
            "total_covered": 3
        },
        "completions": [
            "indices = tf.range(tf.shape(in1)[0])\nfiltered_indices = tf.boolean_mask(indices, indices != in2)\nreturn tf.gather(in1, filtered_indices)",
            "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, mask)",
            "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, mask)",
            "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nresult = tf.boolean_mask(in1, mask)\nreturn result",
            "indices = tf.range(tf.shape(in1)[0])\nindices_to_keep = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, indices_to_keep)",
            "idx_mask = tf.one_hot(in2, tf.shape(in1)[0])\nreturn tf.boolean_mask(in1, tf.logical_not(idx_mask))",
            "return tf.concat([in1[:in2], in1[in2+1:]], 0)",
            "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, mask)",
            "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, mask)",
            "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, mask)"
        ]
    },
    {
        "constants": "[]",
        "description": "create a binary vector where the max element is 1",
        "target_program": "tf.cast(tf.equal(in1, tf.reduce_max(in1)), tf.int32)",
        "source": "https://stackoverflow.com/questions/54493814/binary-vector-of-max",
        "name": "stackoverflow_42",
        "examples": {
            "inputs": "[[4, 6, 2, 6, 7, 3, -3],]",
            "outputs": "[0, 0, 0, 0, 1, 0, 0]"
        },
        "response": {
            "task_id": "stackoverflow_42",
            "completions": [
                "max_val = tf.reduce_max(in1)\nreturn tf.cast(tf.equal(in1, max_val), int)",
                "return tf.one_hot(tf.argmax(in1), tf.size(in1))",
                "max_elem = tf.reduce_max(in1)\nmax_mask = tf.equal(in1, max_elem)\nreturn tf.cast(max_mask, tf.int32)",
                "max_value = tf.reduce_max(in1)\nbinary_vector = tf.where(tf.equal(in1, max_value), 1, 0)\nreturn binary_vector",
                "return tf.where(tf.equal(in1, tf.reduce_max(in1)), 1, 0)",
                "max_value = tf.reduce_max(in1)\nreturn tf.cast(tf.equal(in1, max_value), tf.int32)",
                "max_element = tf.reduce_max(in1)\nbinary_vector = tf.where(tf.equal(in1, max_element), 1, 0)\nreturn binary_vector",
                "max_value = tf.reduce_max(in1)\none_hot_map = tf.equal(in1, max_value)\none_hot_map = tf.cast(one_hot_map, tf.int32)\nreturn one_hot_map",
                "max_value = tf.reduce_max(in1)\nreturn tf.cast(tf.equal(in1, max_value), tf.int32)",
                "max_element = tf.reduce_max(in1)\nbinary_vector = tf.where(tf.equal(in1, max_element), 1, 0)\nreturn binary_vector"
            ],
            "target-program": "tf.cast(tf.equal(in1, tf.reduce_max(in1)), tf.int32)",
            "description": "create a binary vector where the max element is 1",
            "tf_operators": {
                "tf.reduce_max": 9,
                "tf.equal": 9,
                "tf.cast": 5,
                "tf.one_hot": 1,
                "tf.argmax": 1,
                "tf.size": 1,
                "tf.int32": 4,
                "tf.where": 4
            },
            "coverage_percentage": 100.0,
            "total_in_target": 4,
            "total_covered": 4
        },
        "completions": [
            "max_val = tf.reduce_max(in1)\nreturn tf.cast(tf.equal(in1, max_val), int)",
            "return tf.one_hot(tf.argmax(in1), tf.size(in1))",
            "max_elem = tf.reduce_max(in1)\nmax_mask = tf.equal(in1, max_elem)\nreturn tf.cast(max_mask, tf.int32)",
            "max_value = tf.reduce_max(in1)\nbinary_vector = tf.where(tf.equal(in1, max_value), 1, 0)\nreturn binary_vector",
            "return tf.where(tf.equal(in1, tf.reduce_max(in1)), 1, 0)",
            "max_value = tf.reduce_max(in1)\nreturn tf.cast(tf.equal(in1, max_value), tf.int32)",
            "max_element = tf.reduce_max(in1)\nbinary_vector = tf.where(tf.equal(in1, max_element), 1, 0)\nreturn binary_vector",
            "max_value = tf.reduce_max(in1)\none_hot_map = tf.equal(in1, max_value)\none_hot_map = tf.cast(one_hot_map, tf.int32)\nreturn one_hot_map",
            "max_value = tf.reduce_max(in1)\nreturn tf.cast(tf.equal(in1, max_value), tf.int32)",
            "max_element = tf.reduce_max(in1)\nbinary_vector = tf.where(tf.equal(in1, max_element), 1, 0)\nreturn binary_vector"
        ]
    },
    {
        "constants": "[]",
        "description": "extract elements of a tensor given row indices",
        "target_program": "tf.gather_nd(tf.transpose(in1), tf.expand_dims(in2, 1), batch_dims=1)",
        "source": "https://stackoverflow.com/questions/54455169/better-way-to-access-individual-elements-in-a-tensor",
        "name": "stackoverflow_43",
        "examples": {
            "inputs": "[[[12, 34, 56, 78, 90, 10], [99, 88, 77, 55, 44, 33], [-1, -2, -3, -4, -5, -6]],[0, 1, 1, 0, 2, 0],]",
            "outputs": "[12, 88, 77, 78, -5, 10]"
        },
        "response": {
            "task_id": "stackoverflow_43",
            "completions": [
                "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.size(in2))], axis=1))",
                "return tf.gather(in1, in2, axis=1)",
                "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1))",
                "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1))",
                "return tf.gather_nd(in1, tf.transpose([in2, tf.range(tf.shape(in2)[0])]))",
                "return tf.gather_nd(in1, tf.stack((tf.range(in2.shape[0]), in2), -1))",
                "return tf.gather(in1, in2)",
                "return tf.gather(in1, in2, axis=1)",
                "return tf.gather(in1,in2)",
                "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=-1))"
            ],
            "target-program": "tf.gather_nd(tf.transpose(in1), tf.expand_dims(in2, 1), batch_dims=1)",
            "description": "extract elements of a tensor given row indices",
            "tf_operators": {
                "tf.stack": 5,
                "tf.size": 1,
                "tf.range": 6,
                "tf.gather_nd": 6,
                "tf.gather": 4,
                "tf.shape": 4,
                "tf.transpose": 1
            },
            "coverage_percentage": 66.66666666666666,
            "total_in_target": 3,
            "total_covered": 2
        },
        "completions": [
            "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.size(in2))], axis=1))",
            "return tf.gather(in1, in2, axis=1)",
            "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1))",
            "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1))",
            "return tf.gather_nd(in1, tf.transpose([in2, tf.range(tf.shape(in2)[0])]))",
            "return tf.gather_nd(in1, tf.stack((tf.range(in2.shape[0]), in2), -1))",
            "return tf.gather(in1, in2)",
            "return tf.gather(in1, in2, axis=1)",
            "return tf.gather(in1,in2)",
            "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=-1))"
        ]
    },
    {
        "constants": "[2]",
        "description": "sum across columns for pairs of consecutive rows",
        "target_program": "tf.squeeze(tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1))",
        "source": "https://stackoverflow.com/questions/54402389/sum-the-columns-for-each-two-consecutive-rows-of-a-tensor-of-3-dimensions",
        "name": "stackoverflow_44",
        "examples": {
            "inputs": "[[[3, 5, 2], [6, 2, 3], [8, 7, 1], [0, -3, 5], [-4, 7, 3], [2, 1, 6], [10, 20, 30], [4, 5, 6]],]",
            "outputs": "[[9, 7, 5],    [8, 4, 6],    [-2, 8, 9],    [14, 25, 36]]"
        },
        "response": {
            "task_id": "stackoverflow_44",
            "completions": [
                "reshaped = tf.reshape(in1, (-1, 2, tf.shape(in1)[-1]))\n    out = tf.reduce_sum(reshaped, axis=1)\n    return out",
                "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
                "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
                "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
                "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
                "return tf.reduce_sum(tf.reshape(in1, [-1, 2, in1.shape[1]]), axis=1)",
                "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
                "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
                "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
                "return tf.reduce_sum(tf.reshape(in1, [-1, 2, tf.shape(in1)[-1]]), axis=1)"
            ],
            "target-program": "tf.squeeze(tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1))",
            "description": "sum across columns for pairs of consecutive rows",
            "tf_operators": {
                "tf.shape": 2,
                "tf.reshape": 10,
                "tf.reduce_sum": 10
            },
            "coverage_percentage": 66.66666666666666,
            "total_in_target": 3,
            "total_covered": 2
        },
        "completions": [
            "reshaped = tf.reshape(in1, (-1, 2, tf.shape(in1)[-1]))\n    out = tf.reduce_sum(reshaped, axis=1)\n    return out",
            "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
            "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
            "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
            "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
            "return tf.reduce_sum(tf.reshape(in1, [-1, 2, in1.shape[1]]), axis=1)",
            "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
            "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
            "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
            "return tf.reduce_sum(tf.reshape(in1, [-1, 2, tf.shape(in1)[-1]]), axis=1)"
        ]
    },
    {
        "constants": "[]",
        "description": "reverse the order in the marked rows",
        "target_program": "tf.where(tf.sequence_mask(in2), x=tf.roll(in1, 1, -1), y=in1)",
        "source": "https://stackoverflow.com/questions/54337925/reverse-order-of-some-elements-in-tensorflow",
        "name": "stackoverflow_45",
        "examples": {
            "inputs": "[[[[12, 34], [56, 78], [23, 54], [76, 78], [42, 24]]],[1, 0, 1, 0, 1],]",
            "outputs": "[[[34, 12], [56, 78], [54, 23], [76, 78], [24, 42]]]"
        },
        "response": {
            "task_id": "stackoverflow_45",
            "completions": [
                "return tf.where(tf.broadcast_to(tf.reshape(in2, [len(in2),1]), tf.shape(in1)), tf.reverse(in1,[1]), in1)",
                "out = [tf.reverse(in1[i], axis=[-1]) if in2[i] else in1[i] for i in range(len(in1))]\nreturn tf.stack(out, axis=0)",
                "return tf.where(tf.tile(tf.expand_dims(in2, axis=-1), [1, tf.shape(in1)[1]]), tf.reverse(in1, axis=-1), in1)",
                "return tf.where(tf.reshape(in2, (len(in2), 1)), tf.reverse(in1, [-1]), in1)",
                "output = tf.where(tf.reshape(in2, [-1, 1]), tf.reverse(in1, axis=[-1]), in1)\nreturn output",
                "return tf.where(tf.broadcast_to(tf.reshape(in2, [-1, 1]), tf.shape(in1)), \n                tf.reverse(in1, [-1]), \n                in1)",
                "return tf.where(tf.expand_dims(in2, axis=-1), tf.reverse(in1, axis=[-1]), in1)",
                "return tf.where(tf.broadcast_to(tf.reshape(in2,[-1,1]), tf.shape(in1)), tf.reverse(in1,[-1]), in1)",
                "out = tf.Tensor(in1.shape)  # initialize output tensor with the same shape as `in1`\nfor i, row in enumerate(in1):\n    if in2[i] == 1:   # if the row is marked for reversal\n        out[i] = tf.reverse(row, axis=-1)  # reverse the row\n    else:\n        out[i] = row  # keep the original row\nreturn out",
                "return tf.where(tf.expand_dims(in2, -1), tf.reverse(in1, [-1]), in1)"
            ],
            "target-program": "tf.where(tf.sequence_mask(in2), x=tf.roll(in1, 1, -1), y=in1)",
            "description": "reverse the order in the marked rows",
            "tf_operators": {
                "tf.shape": 4,
                "tf.reshape": 5,
                "tf.broadcast_to": 3,
                "tf.where": 8,
                "tf.reverse": 10,
                "tf.stack": 1,
                "tf.tile": 1,
                "tf.expand_dims": 3,
                "tf.Tensor": 1
            },
            "coverage_percentage": 33.33333333333333,
            "total_in_target": 3,
            "total_covered": 1
        },
        "completions": [
            "return tf.where(tf.broadcast_to(tf.reshape(in2, [len(in2),1]), tf.shape(in1)), tf.reverse(in1,[1]), in1)",
            "out = [tf.reverse(in1[i], axis=[-1]) if in2[i] else in1[i] for i in range(len(in1))]\nreturn tf.stack(out, axis=0)",
            "return tf.where(tf.tile(tf.expand_dims(in2, axis=-1), [1, tf.shape(in1)[1]]), tf.reverse(in1, axis=-1), in1)",
            "return tf.where(tf.reshape(in2, (len(in2), 1)), tf.reverse(in1, [-1]), in1)",
            "output = tf.where(tf.reshape(in2, [-1, 1]), tf.reverse(in1, axis=[-1]), in1)\nreturn output",
            "return tf.where(tf.broadcast_to(tf.reshape(in2, [-1, 1]), tf.shape(in1)), \n                tf.reverse(in1, [-1]), \n                in1)",
            "return tf.where(tf.expand_dims(in2, axis=-1), tf.reverse(in1, axis=[-1]), in1)",
            "return tf.where(tf.broadcast_to(tf.reshape(in2,[-1,1]), tf.shape(in1)), tf.reverse(in1,[-1]), in1)",
            "out = tf.Tensor(in1.shape)  # initialize output tensor with the same shape as `in1`\nfor i, row in enumerate(in1):\n    if in2[i] == 1:   # if the row is marked for reversal\n        out[i] = tf.reverse(row, axis=-1)  # reverse the row\n    else:\n        out[i] = row  # keep the original row\nreturn out",
            "return tf.where(tf.expand_dims(in2, -1), tf.reverse(in1, [-1]), in1)"
        ]
    },
    {
        "constants": "[]",
        "description": "convert segment lengths to segment ids",
        "target_program": "tf.cast(tf.where(tf.sequence_mask(in1))[:, 0], tf.int32)",
        "source": "https://stackoverflow.com/questions/58652161/how-to-convert-2-3-4-to-0-0-1-1-1-2-2-2-2-to-utilize-tf-math-segment-sum",
        "name": "stackoverflow_46",
        "examples": {
            "inputs": "[[3, 4, 1],]",
            "outputs": "[0, 0, 0, 1, 1, 1, 1, 2]"
        },
        "response": {
            "task_id": "stackoverflow_46",
            "completions": [
                "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
                "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
                "return tf.concat([tf.fill([in1[i]], i) for i in range(tf.size(in1))], 0)",
                "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
                "return tf.repeat(tf.range(tf.size(in1)), in1)",
                "return tf.repeat(tf.range(tf.size(in1)), in1)",
                "return tf.repeat(tf.range(tf.size(in1)), in1)",
                "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
                "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
                "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)"
            ],
            "target-program": "tf.cast(tf.where(tf.sequence_mask(in1))[:, 0], tf.int32)",
            "description": "convert segment lengths to segment ids",
            "tf_operators": {
                "tf.shape": 6,
                "tf.repeat": 9,
                "tf.range": 9,
                "tf.size": 4,
                "tf.fill": 1,
                "tf.concat": 1
            },
            "coverage_percentage": 0.0,
            "total_in_target": 4,
            "total_covered": 0
        },
        "completions": [
            "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
            "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
            "return tf.concat([tf.fill([in1[i]], i) for i in range(tf.size(in1))], 0)",
            "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
            "return tf.repeat(tf.range(tf.size(in1)), in1)",
            "return tf.repeat(tf.range(tf.size(in1)), in1)",
            "return tf.repeat(tf.range(tf.size(in1)), in1)",
            "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
            "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
            "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)"
        ]
    },
    {
        "constants": "[]",
        "description": "put given values into a sequence mask",
        "target_program": "tf.reshape(tf.gather(in1, tf.cumsum(tf.reshape(tf.cast(in2, tf.int32), [-1]), exclusive=True) * tf.reshape(tf.cast(in2, tf.int32), [-1])), in2.shape)",
        "source": "https://stackoverflow.com/questions/58641546/how-can-i-put-the-sequential-values-to-the-sequence-mask",
        "name": "stackoverflow_47",
        "examples": {
            "inputs": "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16],[[True, True, True, False, False], [True, True, False, False, False], [True, True, True, True, True], [True, True, True, True, False], [True, False, False, False, False], [True, True, False, False, False]],]",
            "outputs": "[[0, 1, 2, 0, 0],    [3, 4, 0, 0, 0],    [5, 6, 7, 8, 9],    [10, 11, 12, 13, 0],    [14, 0, 0, 0, 0],    [15, 16, 0, 0, 0]]"
        },
        "response": {
            "task_id": "stackoverflow_47",
            "completions": [
                "idx = tf.boolean_mask(tf.range(tf.size(in1)), tf.reshape(in2, [-1]))\n     result = tf.scatter_nd(tf.where(in2), idx, tf.shape(in2))\n     return result",
                "mask_indexes = tf.boolean_mask(tf.range(tf.size(in2)), tf.reshape(in2, [-1]))\nmask_values = tf.gather(in1, mask_indexes)\nmask_shape = tf.shape(in2, out_type=mask_indexes.dtype)\nreturn tf.scatter_nd(tf.where(in2), mask_values, mask_shape)",
                "return tf.where(in2, tf.reshape(in1, tf.shape(in2)), tf.zeros_like(in2))",
                "indices = tf.where(in2)\n     return tf.tensor_scatter_nd_update(tf.zeros_like(in2, dtype=in1.dtype), indices, tf.gather(in1, tf.range(tf.shape(indices)[0])))",
                "in1 = tf.boolean_mask(in1, tf.reshape(in2, [-1]))\n     out = tf.scatter_nd(tf.where(in2), in1, tf.shape(in2))\n     return out.numpy()",
                "output = tf.where(in2, tf.reshape(in1, tf.shape(in2)), tf.zeros_like(in2, dtype=in1.dtype))\nreturn output",
                "mask_lengths = tf.reduce_sum(tf.cast(in2, tf.int32), axis=-1)\nmasked_values = tf.RaggedTensor.from_row_lengths(in1, mask_lengths)\nreturn tf.cast(masked_values.to_tensor(), in1.dtype)",
                "out = tf.where(in2, tf.reshape(in1, tf.shape(in2)), 0)\nreturn out",
                "return tf.where(in2, tf.reshape(in1[:tf.reduce_sum(tf.cast(in2, tf.int32))], tf.shape(in2)), 0)",
                "# first create a zeros_like tensor from the sequence mask\n    tensor = tf.zeros_like(in2, dtype=in1.dtype)\n    \n    # get the indices where the mask is True\n    indices = tf.where(condition=in2)\n    \n    # gather the values from the original tensor based on the indices\n    values = tf.gather(params=in1, indices=tf.reshape(tensor=indices[:, 1], shape=[-1]))\n\n    # update the zeros tensor with the gathered values at the correct indices\n    result = tf.tensor_scatter_nd_update(tensor=tensor, indices=indices, updates=values)\n    \n    return result"
            ],
            "target-program": "tf.reshape(tf.gather(in1, tf.cumsum(tf.reshape(tf.cast(in2, tf.int32), [-1]), exclusive=True) * tf.reshape(tf.cast(in2, tf.int32), [-1])), in2.shape)",
            "description": "put given values into a sequence mask",
            "tf_operators": {
                "tf.shape": 8,
                "tf.boolean_mask": 3,
                "tf.reshape": 8,
                "tf.size": 2,
                "tf.scatter_nd": 3,
                "tf.where": 9,
                "tf.range": 3,
                "tf.gather": 3,
                "tf.zeros_like": 4,
                "tf.tensor_scatter_nd_update": 2,
                "tf.cast": 2,
                "tf.RaggedTensor.from_row_lengths": 1,
                "tf.int32": 2,
                "tf.reduce_sum": 2
            },
            "coverage_percentage": 80.0,
            "total_in_target": 5,
            "total_covered": 4
        },
        "completions": [
            "idx = tf.boolean_mask(tf.range(tf.size(in1)), tf.reshape(in2, [-1]))\n     result = tf.scatter_nd(tf.where(in2), idx, tf.shape(in2))\n     return result",
            "mask_indexes = tf.boolean_mask(tf.range(tf.size(in2)), tf.reshape(in2, [-1]))\nmask_values = tf.gather(in1, mask_indexes)\nmask_shape = tf.shape(in2, out_type=mask_indexes.dtype)\nreturn tf.scatter_nd(tf.where(in2), mask_values, mask_shape)",
            "return tf.where(in2, tf.reshape(in1, tf.shape(in2)), tf.zeros_like(in2))",
            "indices = tf.where(in2)\n     return tf.tensor_scatter_nd_update(tf.zeros_like(in2, dtype=in1.dtype), indices, tf.gather(in1, tf.range(tf.shape(indices)[0])))",
            "in1 = tf.boolean_mask(in1, tf.reshape(in2, [-1]))\n     out = tf.scatter_nd(tf.where(in2), in1, tf.shape(in2))\n     return out.numpy()",
            "output = tf.where(in2, tf.reshape(in1, tf.shape(in2)), tf.zeros_like(in2, dtype=in1.dtype))\nreturn output",
            "mask_lengths = tf.reduce_sum(tf.cast(in2, tf.int32), axis=-1)\nmasked_values = tf.RaggedTensor.from_row_lengths(in1, mask_lengths)\nreturn tf.cast(masked_values.to_tensor(), in1.dtype)",
            "out = tf.where(in2, tf.reshape(in1, tf.shape(in2)), 0)\nreturn out",
            "return tf.where(in2, tf.reshape(in1[:tf.reduce_sum(tf.cast(in2, tf.int32))], tf.shape(in2)), 0)",
            "# first create a zeros_like tensor from the sequence mask\n    tensor = tf.zeros_like(in2, dtype=in1.dtype)\n    \n    # get the indices where the mask is True\n    indices = tf.where(condition=in2)\n    \n    # gather the values from the original tensor based on the indices\n    values = tf.gather(params=in1, indices=tf.reshape(tensor=indices[:, 1], shape=[-1]))\n\n    # update the zeros tensor with the gathered values at the correct indices\n    result = tf.tensor_scatter_nd_update(tensor=tensor, indices=indices, updates=values)\n    \n    return result"
        ]
    },
    {
        "constants": "[]",
        "description": "find the indices of all elements",
        "target_program": "tf.cast(tf.argmax(tf.cast(tf.equal(in1, tf.expand_dims(in2, 1)), tf.int32), axis=1), tf.int32)",
        "source": "https://stackoverflow.com/questions/58481332/getting-the-indices-of-several-elements-in-a-tensorflow-at-once",
        "name": "stackoverflow_48",
        "examples": {
            "inputs": "[[32, 53, 45, 38, 29, 89, 64, 23],[38, 53, 89, 38, 32, 64],]",
            "outputs": "[3, 1, 5, 3, 0, 6]"
        },
        "response": {
            "task_id": "stackoverflow_48",
            "completions": [
                "return tf.argsort(tf.searchsorted(tf.sort(in1), in2)).numpy().tolist()",
                "return tf.where(tf.equal(tf.expand_dims(in1, 1), in2))[:, 1]",
                "return [tf.where(tf.equal(in1, x))[0].numpy()[0] for x in in2]",
                "return tf.where(tf.equal(tf.expand_dims(in1, 1), in2))[1]",
                "return tf.where(tf.equal(tf.expand_dims(in1, axis=-1), in2)).numpy()[:,1]",
                "return tf.argsort(tf.searchsorted(in1, in2)).numpy().tolist()",
                "return tf.argsort(tf.gather(in1, tf.argsort(in2))).numpy().tolist()",
                "return [tf.where(tf.equal(in1, x)).numpy()[0][0] for x in in2]",
                "return tf.argsort(tf.argsort(in2)).numpy().tolist()",
                "return tf.where(tf.equal(tf.expand_dims(in1, 1), in2)).numpy().flatten().tolist()"
            ],
            "target-program": "tf.cast(tf.argmax(tf.cast(tf.equal(in1, tf.expand_dims(in2, 1)), tf.int32), axis=1), tf.int32)",
            "description": "find the indices of all elements",
            "tf_operators": {
                "tf.searchsorted": 2,
                "tf.argsort": 4,
                "tf.sort": 1,
                "tf.expand_dims": 4,
                "tf.equal": 6,
                "tf.where": 6,
                "tf.gather": 1
            },
            "coverage_percentage": 40.0,
            "total_in_target": 5,
            "total_covered": 2
        },
        "completions": [
            "return tf.argsort(tf.searchsorted(tf.sort(in1), in2)).numpy().tolist()",
            "return tf.where(tf.equal(tf.expand_dims(in1, 1), in2))[:, 1]",
            "return [tf.where(tf.equal(in1, x))[0].numpy()[0] for x in in2]",
            "return tf.where(tf.equal(tf.expand_dims(in1, 1), in2))[1]",
            "return tf.where(tf.equal(tf.expand_dims(in1, axis=-1), in2)).numpy()[:,1]",
            "return tf.argsort(tf.searchsorted(in1, in2)).numpy().tolist()",
            "return tf.argsort(tf.gather(in1, tf.argsort(in2))).numpy().tolist()",
            "return [tf.where(tf.equal(in1, x)).numpy()[0][0] for x in in2]",
            "return tf.argsort(tf.argsort(in2)).numpy().tolist()",
            "return tf.where(tf.equal(tf.expand_dims(in1, 1), in2)).numpy().flatten().tolist()"
        ]
    },
    {
        "constants": "[]",
        "description": "multiply tensors by scalars in a batched way",
        "target_program": "tf.transpose(tf.multiply(in2, tf.transpose(in1)))",
        "source": "https://stackoverflow.com/questions/58466562/given-a-batch-of-n-images-how-to-scalar-multiply-each-image-by-a-different-scal",
        "name": "stackoverflow_49",
        "examples": {
            "inputs": "[[[[[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]]], [[[0.8, 1.0, 0.0], [0.6, 0.4, 0.2]]], [[[0.9, 0.8, 0.7], [0.1, 0.2, 0.3]]]],[2.0, 0.5, 1.0],]",
            "outputs": "[[[[0.2, 0.4, 0.6], [0.8, 1.0, 1.2]]],    [[[0.4, 0.5, 0.0], [0.3, 0.2, 0.1]]],    [[[0.9, 0.8, 0.7], [0.1, 0.2, 0.3]]]]"
        },
        "response": {
            "task_id": "stackoverflow_49",
            "completions": [
                "in2 = tf.reshape(in2, [-1, 1, 1, 1])\n     return tf.multiply(in1, in2)",
                "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
                "return tf.multiply(tf.expand_dims(in2, axis=[1,2,3]), in1)",
                "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
                "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
                "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
                "return tf.multiply(tf.expand_dims(in2, -1), in1)",
                "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
                "return tf.multiply(tf.expand_dims(in2, axis=-1), in1)",
                "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))"
            ],
            "target-program": "tf.transpose(tf.multiply(in2, tf.transpose(in1)))",
            "description": "multiply tensors by scalars in a batched way",
            "tf_operators": {
                "tf.multiply": 10,
                "tf.reshape": 7,
                "tf.expand_dims": 3
            },
            "coverage_percentage": 50.0,
            "total_in_target": 2,
            "total_covered": 1
        },
        "completions": [
            "in2 = tf.reshape(in2, [-1, 1, 1, 1])\n     return tf.multiply(in1, in2)",
            "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
            "return tf.multiply(tf.expand_dims(in2, axis=[1,2,3]), in1)",
            "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
            "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
            "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
            "return tf.multiply(tf.expand_dims(in2, -1), in1)",
            "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
            "return tf.multiply(tf.expand_dims(in2, axis=-1), in1)",
            "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))"
        ]
    },
    {
        "constants": "[]",
        "description": "create a binary matrix where a specified column is set to one",
        "target_program": "tf.cast(tf.one_hot(tf.fill((in1,), in3), in2), tf.int32)",
        "source": "https://stackoverflow.com/questions/58537495/tensorflow-initialize-a-sparse-tensor-with-only-one-line-column-not-zero",
        "name": "stackoverflow_50",
        "examples": {
            "inputs": "[5]",
            "outputs": "[[0, 0, 0, 1, 0, 0],    [0, 0, 0, 1, 0, 0],    [0, 0, 0, 1, 0, 0],    [0, 0, 0, 1, 0, 0],    [0, 0, 0, 1, 0, 0]]"
        },
        "response": {
            "task_id": "stackoverflow_50",
            "completions": [
                "return tf.concat([tf.zeros([in1, in1], dtype=tf.int32), tf.reshape(tf.ones([in1], dtype=tf.int32), [in1, 1]), tf.zeros([in1, in1], dtype=tf.int32)], axis=1)",
                "return tf.pad(tf.expand_dims(tf.eye(in1, dtype=tf.int32), 2), [[0,0],[0,1],[0,0]])[:, 3, :]",
                "return tf.one_hot(in1, depth=6, axis=1)",
                "return tf.concat([tf.zeros([in1, in1], dtype=tf.int32),\n                  tf.ones([in1, 1], dtype=tf.int32),\n                  tf.zeros([in1, in1], dtype=tf.int32)],\n                 axis=1)",
                "# In TensorFlow, the tf.ones and tf.zeros function is used to initialize a matrix to ones or zeros respectively. \n# The tf.scatter_nd function is used to create a tensor given the desired indices and updates.\n# To create a binary matrix where a specified column is set to one, we can initialize a zero matrix and set the specified column to one.\n# The function tf.eye creates an identity matrix of given size. If num_columns is not provided, it will default to num_rows.\n\ndef transform(column_no, size=5):\n    # Create a matrix full of zeros\n    matrix = tf.zeros([size, size], dtype=tf.int32)\n    \n    # Create a range to use as indices\n    indices = tf.range(size)\n    \n    # Prepare indices by concatenating with column_no\n    indices = tf.stack([indices, tf.fill([size], column_no)], axis=1)\n    \n    # Use scatter_nd to fill corresponding column with ones\n    transformed_matrix = tf.tensor_scatter_nd_update(matrix, indices, tf.ones([size], dtype=tf.int32))\n    \n    return transformed_matrix",
                "# First let's create a 2D tensor where all elements are zero with dimension (in1, in1)\n    matrix_zeros = tf.zeros([in1, in1], tf.int32)\n\n    # Now let's create a tensor with only one column set to one\n    column_ones = tf.one_hot(in1//2, in1, dtype=tf.int32)\n\n    # Replace the column in the zero matrix with the column of ones\n    result = tf.tensor_scatter_nd_update(matrix_zeros, [[i, in1//2] for i in range(in1)], column_ones)\n    \n    return result",
                "matrix = tf.zeros([5, 6])\nindex = 3\ncolumn = tf.one_hot(index, 6)\nreturn tf.broadcast_to(column, [5, 6])",
                "# The length of the matrix and the index of the column to set to 1 is not clear from the task description.\n# I'm assuming that the matrix is of shape 5x5 and the column at index 3 should be set to 1. If these assumptions are incorrect, please provide further information.\n\nmatrix = tf.zeros((5, 5))  # create a matrix of zeros\ncolumn = tf.ones((5, 1))  # create a column of ones\nmatrix = tf.tensor_scatter_nd_update(matrix, [[i, 3] for i in range(5)], column)  # update the specified column with ones\n   return matrix.numpy().astype(int)  # return the matrix as a numpy array of integers",
                "cols = tf.fill([5, 5], 0)\nones_column = tf.fill([5], 1)\nfinal_matrix = tf.tensor_scatter_nd_update(cols, [[i, in1] for i in range(5)], ones_column)\nreturn final_matrix.numpy()",
                "import tensorflow as tf\n\ndef transform(in1):\n    matrix = tf.zeros([5, 6], dtype=tf.int32)\n    updated_matrix = tf.tensor_scatter_nd_update(matrix, [[i, in1] for i in range(5)], tf.ones(5, dtype=tf.int32))\n    return updated_matrix.numpy()"
            ],
            "target-program": "tf.cast(tf.one_hot(tf.fill((in1,), in3), in2), tf.int32)",
            "description": "create a binary matrix where a specified column is set to one",
            "tf_operators": {
                "tf.reshape": 1,
                "tf.concat": 2,
                "tf.ones": 5,
                "tf.int32": 6,
                "tf.zeros": 7,
                "tf.eye": 2,
                "tf.pad": 1,
                "tf.expand_dims": 1,
                "tf.one_hot": 3,
                "tf.fill": 2,
                "tf.stack": 1,
                "tf.scatter_nd": 1,
                "tf.tensor_scatter_nd_update": 5,
                "tf.range": 1,
                "tf.broadcast_to": 1
            },
            "coverage_percentage": 75.0,
            "total_in_target": 4,
            "total_covered": 3
        },
        "completions": [
            "return tf.concat([tf.zeros([in1, in1], dtype=tf.int32), tf.reshape(tf.ones([in1], dtype=tf.int32), [in1, 1]), tf.zeros([in1, in1], dtype=tf.int32)], axis=1)",
            "return tf.pad(tf.expand_dims(tf.eye(in1, dtype=tf.int32), 2), [[0,0],[0,1],[0,0]])[:, 3, :]",
            "return tf.one_hot(in1, depth=6, axis=1)",
            "return tf.concat([tf.zeros([in1, in1], dtype=tf.int32),\n                  tf.ones([in1, 1], dtype=tf.int32),\n                  tf.zeros([in1, in1], dtype=tf.int32)],\n                 axis=1)",
            "# In TensorFlow, the tf.ones and tf.zeros function is used to initialize a matrix to ones or zeros respectively. \n# The tf.scatter_nd function is used to create a tensor given the desired indices and updates.\n# To create a binary matrix where a specified column is set to one, we can initialize a zero matrix and set the specified column to one.\n# The function tf.eye creates an identity matrix of given size. If num_columns is not provided, it will default to num_rows.\n\ndef transform(column_no, size=5):\n    # Create a matrix full of zeros\n    matrix = tf.zeros([size, size], dtype=tf.int32)\n    \n    # Create a range to use as indices\n    indices = tf.range(size)\n    \n    # Prepare indices by concatenating with column_no\n    indices = tf.stack([indices, tf.fill([size], column_no)], axis=1)\n    \n    # Use scatter_nd to fill corresponding column with ones\n    transformed_matrix = tf.tensor_scatter_nd_update(matrix, indices, tf.ones([size], dtype=tf.int32))\n    \n    return transformed_matrix",
            "# First let's create a 2D tensor where all elements are zero with dimension (in1, in1)\n    matrix_zeros = tf.zeros([in1, in1], tf.int32)\n\n    # Now let's create a tensor with only one column set to one\n    column_ones = tf.one_hot(in1//2, in1, dtype=tf.int32)\n\n    # Replace the column in the zero matrix with the column of ones\n    result = tf.tensor_scatter_nd_update(matrix_zeros, [[i, in1//2] for i in range(in1)], column_ones)\n    \n    return result",
            "matrix = tf.zeros([5, 6])\nindex = 3\ncolumn = tf.one_hot(index, 6)\nreturn tf.broadcast_to(column, [5, 6])",
            "# The length of the matrix and the index of the column to set to 1 is not clear from the task description.\n# I'm assuming that the matrix is of shape 5x5 and the column at index 3 should be set to 1. If these assumptions are incorrect, please provide further information.\n\nmatrix = tf.zeros((5, 5))  # create a matrix of zeros\ncolumn = tf.ones((5, 1))  # create a column of ones\nmatrix = tf.tensor_scatter_nd_update(matrix, [[i, 3] for i in range(5)], column)  # update the specified column with ones\n   return matrix.numpy().astype(int)  # return the matrix as a numpy array of integers",
            "cols = tf.fill([5, 5], 0)\nones_column = tf.fill([5], 1)\nfinal_matrix = tf.tensor_scatter_nd_update(cols, [[i, in1] for i in range(5)], ones_column)\nreturn final_matrix.numpy()",
            "import tensorflow as tf\n\ndef transform(in1):\n    matrix = tf.zeros([5, 6], dtype=tf.int32)\n    updated_matrix = tf.tensor_scatter_nd_update(matrix, [[i, in1] for i in range(5)], tf.ones(5, dtype=tf.int32))\n    return updated_matrix.numpy()"
        ]
    }
]