[
    {
        "constants": "[]",
        "description": "Convert index tensor into pairs for SparseTensor indexing",
        "target_program": "tf.cast(tf.where(tf.sequence_mask(tf.math.bincount(in1))), tf.int32)",
        "source": "From an internal Google chat room, 09/07/2018",
        "name": "google_01",
        "examples": {
            "inputs": "[[0, 0, 0, 1, 3, 3],]",
            "outputs": "[[0, 0], [0, 1], [0, 2], [1, 0], [3, 0], [3, 1]]"
        },
        "response": {
            "task_id": "google_01",
            "completions": [
                "indices = tf.range(tf.shape(in1)[0])\nvals, idx = tf.unique_with_counts(in1)\nreturn tf.stack([tf.repeat(vals, idx), tf.cast(tf.concat([tf.range(i) for i in idx], 0), tf.int32)], axis=-1)",
                "out1 = tf.range(tf.shape(in1)[0])\nout2 = tf.math.bincount(in1)\nout2 = tf.concat([[0], tf.math.cumsum(out2)[:-1]], axis=0)\nout2 = tf.gather(out2, in1)\nout = tf.stack([in1, out2], axis=1)\nreturn out",
                "indices = tf.range(tf.shape(in1)[0])\nidx, ids = tf.unique_with_counts(in1)\nb = tf.map_fn(lambda x: tf.range(x), ids, dtype=ids.dtype)\nc = tf.split(b, ids.numpy())\nout = tf.concat([tf.repeat(idx[i], tf.shape(c[i])[0]) for i in range(tf.shape(idx)[0])], axis=0)\ny = tf.concat(c, axis=0)\nreturn tf.stack([out, y], axis=1)",
                "indices = tf.where(tf.ones_like(in1))\nreturn indices.numpy()",
                "index = tf.range(tf.size(in1))\nreturn tf.stack([in1, index], axis=-1)",
                "indices = tf.range(tf.shape(in1)[0])\npairs = tf.stack([in1, indices], axis=1)\nreturn pairs",
                "return tf.stack([in1, tf.math.bincount(in1)], axis=1)",
                "indices = tf.where(tf.not_equal(in1, -1))\n     count = tf.math.bincount(indices[:, 0])\n     values = tf.range(tf.size(count))\n     diff = tf.expand_dims(count[tf.gather(in1, indices)[:, 0]] - values, -1)\n     return tf.concat([indices, diff], axis=-1)",
                "indices = tf.where(tf.equal(in1, in1))\n     result = tf.cast(indices, tf.int64)\n     return result",
                "indices = tf.range(len(in1))\npairs = tf.stack([in1, indices], axis=1)\nreturn pairs"
            ],
            "target-program": "tf.cast(tf.where(tf.sequence_mask(tf.math.bincount(in1))), tf.int32)",
            "description": "Convert index tensor into pairs for SparseTensor indexing",
            "tf_operators": {
                "tf.shape": 4,
                "tf.unique_with_counts": 2,
                "tf.repeat": 2,
                "tf.stack": 7,
                "tf.cast": 2,
                "tf.concat": 4,
                "tf.int32": 1,
                "tf.range": 7,
                "tf.math.cumsum": 1,
                "tf.gather": 2,
                "tf.math.bincount": 3,
                "tf.map_fn": 1,
                "tf.split": 1,
                "tf.ones_like": 1,
                "tf.where": 3,
                "tf.size": 2,
                "tf.not_equal": 1,
                "tf.expand_dims": 1,
                "tf.int64": 1,
                "tf.equal": 1
            },
            "coverage_percentage": 80.0,
            "total_in_target": 5,
            "total_covered": 4
        },
        "completions": [
            "indices = tf.range(tf.shape(in1)[0])\nvals, idx = tf.unique_with_counts(in1)\nreturn tf.stack([tf.repeat(vals, idx), tf.cast(tf.concat([tf.range(i) for i in idx], 0), tf.int32)], axis=-1)",
            "out1 = tf.range(tf.shape(in1)[0])\nout2 = tf.math.bincount(in1)\nout2 = tf.concat([[0], tf.math.cumsum(out2)[:-1]], axis=0)\nout2 = tf.gather(out2, in1)\nout = tf.stack([in1, out2], axis=1)\nreturn out",
            "indices = tf.range(tf.shape(in1)[0])\nidx, ids = tf.unique_with_counts(in1)\nb = tf.map_fn(lambda x: tf.range(x), ids, dtype=ids.dtype)\nc = tf.split(b, ids.numpy())\nout = tf.concat([tf.repeat(idx[i], tf.shape(c[i])[0]) for i in range(tf.shape(idx)[0])], axis=0)\ny = tf.concat(c, axis=0)\nreturn tf.stack([out, y], axis=1)",
            "indices = tf.where(tf.ones_like(in1))\nreturn indices.numpy()",
            "index = tf.range(tf.size(in1))\nreturn tf.stack([in1, index], axis=-1)",
            "indices = tf.range(tf.shape(in1)[0])\npairs = tf.stack([in1, indices], axis=1)\nreturn pairs",
            "return tf.stack([in1, tf.math.bincount(in1)], axis=1)",
            "indices = tf.where(tf.not_equal(in1, -1))\n     count = tf.math.bincount(indices[:, 0])\n     values = tf.range(tf.size(count))\n     diff = tf.expand_dims(count[tf.gather(in1, indices)[:, 0]] - values, -1)\n     return tf.concat([indices, diff], axis=-1)",
            "indices = tf.where(tf.equal(in1, in1))\n     result = tf.cast(indices, tf.int64)\n     return result",
            "indices = tf.range(len(in1))\npairs = tf.stack([in1, indices], axis=1)\nreturn pairs"
        ]
    },
    {
        "constants": "[]",
        "description": "Divide each row by the sum of that row",
        "target_program": "tf.divide(in1, tf.expand_dims(tf.reduce_sum(in1, axis=1), 1))",
        "source": "Real task encountered by Googler, 11/01/2018",
        "name": "google_02",
        "examples": {
            "inputs": "[[[0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 1.0, 0.0], [1.0, 1.0, 1.0, 1.0]],]",
            "outputs": "[[0.0, 1.0, 0.0, 0.0],    [0.0, 0.5, 0.5, 0.0],    [0.25, 0.25, 0.25, 0.25]]"
        },
        "response": {
            "task_id": "google_02",
            "completions": [
                "row_sums = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sums)",
                "return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))",
                "return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))",
                "return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))",
                "return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))",
                "row_sum = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sum)",
                "row_sum = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sum)",
                "row_sum = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sum)",
                "return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))",
                "sum_of_rows = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, sum_of_rows)"
            ],
            "target-program": "tf.divide(in1, tf.expand_dims(tf.reduce_sum(in1, axis=1), 1))",
            "description": "Divide each row by the sum of that row",
            "tf_operators": {
                "tf.divide": 10,
                "tf.reduce_sum": 10
            },
            "coverage_percentage": 66.66666666666666,
            "total_in_target": 3,
            "total_covered": 2
        },
        "completions": [
            "row_sums = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sums)",
            "return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))",
            "return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))",
            "return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))",
            "return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))",
            "row_sum = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sum)",
            "row_sum = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sum)",
            "row_sum = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sum)",
            "return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))",
            "sum_of_rows = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, sum_of_rows)"
        ]
    },
    {
        "constants": "[]",
        "description": "Slice the first dimension of a SparseTensor",
        "target_program": "tf.divide(in1, tf.expand_dims(tf.reduce_sum(in1, axis=1), 1))",
        "source": "Real task encountered by Googler, 11/01/2018",
        "name": "google_03",
        "examples": {
            "inputs": "tf.SparseTensor(indices=[[0, 0, 0], [0, 1, 1], [1, 1, 1], [1, 1, 2]], values=[1., 1., 1., 1.], dense_shape=[2, 2, 800])",
            "outputs": "tf.SparseTensor(indices=[[0, 0, 0], [0, 1, 1]], values=[1., 1.], dense_shape=[1, 2, 800])"
        },
        "response": {
            "task_id": "google_03",
            "completions": [
                "# First, we need to create a mask that marks True for the indices that belong to the first dimension\n# Then we'll use `tf.sparse.retain` to keep only those elements in the SparseTensor\nmask = tf.equal(in1.indices[:, 0], 0)\nreturn tf.sparse.retain(in1, mask)",
                "sparse_slice = tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\nreturn sparse_slice",
                "# Use tensorflow's tf.sparse.slice to slice the first dimension of a sparse tensor\nsliced = tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\nsliced = tf.sparse.reset_shape(sliced, new_shape=[1, in1.get_shape()[1], in1.get_shape()[2]])\nreturn sliced",
                "# First we compute a boolean mask where True values correspond to the first slice of the first dimension\n    mask = in1.indices[:, 0] == 0\n\n    # Then we retain only the values corresponding to the first slice\n    out1 = tf.sparse.retain(in1, mask)\n\n    # We reset the shape to reflect the new size of the first dimension\n    out1 = tf.sparse.reset_shape(out1, [1] + in1.dense_shape.numpy().tolist()[1:])\n\n    return out1",
                "slice_1d = tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\nreturn slice_1d",
                "# We use the tf.sparse.slice function to slice the first dimension of the SparseTensor\n# We only keep the entries where the first index is 0, effectively keeping the first \"slice\" of the tensor\nindices = in1.indices\nvalues = in1.values\ndense_shape = in1.dense_shape\n\n# Slice the indices to keep only the first dimension\nsliced_indices = indices[indices[:, 0] == 0]\n\n# Find the corresponding values\nsliced_values = tf.gather(values, tf.where(indices[:, 0] == 0))\n\n# Adjust the dense shape\nsliced_dense_shape = tf.concat([[1], dense_shape[1:]], 0)\n\nreturn tf.SparseTensor(sliced_indices, sliced_values, sliced_dense_shape)",
                "return tf.sparse.slice(sp_input=in1, start=[0,0,0], size=[1,-1,-1])",
                "# Identifying the indices that are 0 in the first dimension\n    mask = tf.equal(in1.indices[:, 0], 0)\n    # Selecting the indices and values that satisfy the condition\n    indices = tf.boolean_mask(in1.indices, mask)\n    values = tf.boolean_mask(in1.values, mask)\n    # Changing the first value of the dense_shape from 2 to 1\n    dense_shape = tf.tensor_scatter_nd_update(in1.dense_shape, [[0]], [[1]])\n    return tf.SparseTensor(indices, values, dense_shape)",
                "# Get the indices where the first dimension is zero\n    condition = tf.equal(in1.indices[:,0], 0)\n\n    # Get the indices of the non-zeros in the first dimension\n    idx_to_keep = tf.where(condition)\n    \n    # Get the new values and indices by indexing the original\n    new_values = tf.gather(in1.values, idx_to_keep[:,0])\n    new_indices = tf.gather(in1.indices, idx_to_keep[:,0])\n    \n    # Get the new dense shape\n    new_dense_shape = tf.concat([[1], in1.dense_shape[1:]], axis=0)\n\n    # Create the new SparseTensor\n    out1 = tf.SparseTensor(new_indices, new_values, new_dense_shape)\n\n    return out1",
                "values = tf.boolean_mask(in1.values, in1.indices[:, 0] == 0)\n    indices = tf.boolean_mask(in1.indices, in1.indices[:, 0] == 0)\n    dense_shape = tf.concat([[1], in1.dense_shape[1:]], axis = 0)\n    return tf.SparseTensor(indices, values, dense_shape)"
            ],
            "target-program": "tf.divide(in1, tf.expand_dims(tf.reduce_sum(in1, axis=1), 1))",
            "description": "Slice the first dimension of a SparseTensor",
            "tf_operators": {
                "tf.equal": 3,
                "tf.sparse.retain": 2,
                "tf.sparse.slice": 5,
                "tf.sparse.reset_shape": 2,
                "tf.SparseTensor": 4,
                "tf.concat": 3,
                "tf.where": 2,
                "tf.gather": 2,
                "tf.boolean_mask": 2,
                "tf.tensor_scatter_nd_update": 1
            },
            "coverage_percentage": 0.0,
            "total_in_target": 3,
            "total_covered": 0
        },
        "completions": [
            "# First, we need to create a mask that marks True for the indices that belong to the first dimension\n# Then we'll use `tf.sparse.retain` to keep only those elements in the SparseTensor\nmask = tf.equal(in1.indices[:, 0], 0)\nreturn tf.sparse.retain(in1, mask)",
            "sparse_slice = tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\nreturn sparse_slice",
            "# Use tensorflow's tf.sparse.slice to slice the first dimension of a sparse tensor\nsliced = tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\nsliced = tf.sparse.reset_shape(sliced, new_shape=[1, in1.get_shape()[1], in1.get_shape()[2]])\nreturn sliced",
            "# First we compute a boolean mask where True values correspond to the first slice of the first dimension\n    mask = in1.indices[:, 0] == 0\n\n    # Then we retain only the values corresponding to the first slice\n    out1 = tf.sparse.retain(in1, mask)\n\n    # We reset the shape to reflect the new size of the first dimension\n    out1 = tf.sparse.reset_shape(out1, [1] + in1.dense_shape.numpy().tolist()[1:])\n\n    return out1",
            "slice_1d = tf.sparse.slice(in1, start=[0,0,0], size=[1,-1,-1])\nreturn slice_1d",
            "# We use the tf.sparse.slice function to slice the first dimension of the SparseTensor\n# We only keep the entries where the first index is 0, effectively keeping the first \"slice\" of the tensor\nindices = in1.indices\nvalues = in1.values\ndense_shape = in1.dense_shape\n\n# Slice the indices to keep only the first dimension\nsliced_indices = indices[indices[:, 0] == 0]\n\n# Find the corresponding values\nsliced_values = tf.gather(values, tf.where(indices[:, 0] == 0))\n\n# Adjust the dense shape\nsliced_dense_shape = tf.concat([[1], dense_shape[1:]], 0)\n\nreturn tf.SparseTensor(sliced_indices, sliced_values, sliced_dense_shape)",
            "return tf.sparse.slice(sp_input=in1, start=[0,0,0], size=[1,-1,-1])",
            "# Identifying the indices that are 0 in the first dimension\n    mask = tf.equal(in1.indices[:, 0], 0)\n    # Selecting the indices and values that satisfy the condition\n    indices = tf.boolean_mask(in1.indices, mask)\n    values = tf.boolean_mask(in1.values, mask)\n    # Changing the first value of the dense_shape from 2 to 1\n    dense_shape = tf.tensor_scatter_nd_update(in1.dense_shape, [[0]], [[1]])\n    return tf.SparseTensor(indices, values, dense_shape)",
            "# Get the indices where the first dimension is zero\n    condition = tf.equal(in1.indices[:,0], 0)\n\n    # Get the indices of the non-zeros in the first dimension\n    idx_to_keep = tf.where(condition)\n    \n    # Get the new values and indices by indexing the original\n    new_values = tf.gather(in1.values, idx_to_keep[:,0])\n    new_indices = tf.gather(in1.indices, idx_to_keep[:,0])\n    \n    # Get the new dense shape\n    new_dense_shape = tf.concat([[1], in1.dense_shape[1:]], axis=0)\n\n    # Create the new SparseTensor\n    out1 = tf.SparseTensor(new_indices, new_values, new_dense_shape)\n\n    return out1",
            "values = tf.boolean_mask(in1.values, in1.indices[:, 0] == 0)\n    indices = tf.boolean_mask(in1.indices, in1.indices[:, 0] == 0)\n    dense_shape = tf.concat([[1], in1.dense_shape[1:]], axis = 0)\n    return tf.SparseTensor(indices, values, dense_shape)"
        ]
    },
    {
        "constants": "[]",
        "description": "Reshape a flat array into a rank 3 tensor",
        "target_program": "tf.reshape(in1, shape=(4, 3, 2))",
        "source": "Real task encountered by Googler, 3/21/2019",
        "name": "google_04",
        "examples": {
            "inputs": "[[111, 112, 121, 122, 131, 132, 211, 212, 221, 222, 231, 232, 311, 312, 321, 322, 331, 332, 411, 412, 421, 422, 431, 432],]",
            "outputs": "[[[111, 112], [121, 122], [131, 132]],    [[211, 212], [221, 222], [231, 232]],    [[311, 312], [321, 322], [331, 332]],    [[411, 412], [421, 422], [431, 432]]]"
        },
        "response": {
            "task_id": "google_04",
            "completions": [
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, (4, 3, 2))",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])"
            ],
            "target-program": "tf.reshape(in1, shape=(4, 3, 2))",
            "description": "Reshape a flat array into a rank 3 tensor",
            "tf_operators": {
                "tf.reshape": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, (4, 3, 2))",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])"
        ]
    },
    {
        "constants": "[6]",
        "description": "Repeat each input entry 6 times",
        "target_program": "tf.tile(tf.expand_dims(in1, 1), (1, 6, 1))",
        "source": "Real task encountered by Googler, 3/22/2019",
        "name": "google_05",
        "examples": {
            "inputs": "[[[1, 2, 3, 4], [5, 6, 7, 8]],]",
            "outputs": "[[[1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4],     [1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4]],    [[5, 6, 7, 8], [5, 6, 7, 8], [5, 6, 7, 8],     [5, 6, 7, 8], [5, 6, 7, 8], [5, 6, 7, 8]]]"
        },
        "response": {
            "task_id": "google_05",
            "completions": [
                "return tf.repeat(in1, repeats=[6], axis=0)",
                "return tf.repeat(in1, repeats=6, axis=0)",
                "return tf.repeat(tf.expand_dims(in1, axis=1), repeats=6, axis=1)",
                "return tf.repeat(in1, repeats=6, axis=0)",
                "return tf.repeat(in1, [6], axis=0)",
                "return tf.repeat(in1, 6, axis=0)",
                "return tf.repeat(in1, repeats=6, axis=0)",
                "return tf.repeat(in1, repeats=[6], axis=0)",
                "return tf.repeat(in1, [6], axis=0)",
                "return tf.repeat(tf.expand_dims(in1, 1), 6, axis=1)"
            ],
            "target-program": "tf.tile(tf.expand_dims(in1, 1), (1, 6, 1))",
            "description": "Repeat each input entry 6 times",
            "tf_operators": {
                "tf.repeat": 10,
                "tf.expand_dims": 2
            },
            "coverage_percentage": 50.0,
            "total_in_target": 2,
            "total_covered": 1
        },
        "completions": [
            "return tf.repeat(in1, repeats=[6], axis=0)",
            "return tf.repeat(in1, repeats=6, axis=0)",
            "return tf.repeat(tf.expand_dims(in1, axis=1), repeats=6, axis=1)",
            "return tf.repeat(in1, repeats=6, axis=0)",
            "return tf.repeat(in1, [6], axis=0)",
            "return tf.repeat(in1, 6, axis=0)",
            "return tf.repeat(in1, repeats=6, axis=0)",
            "return tf.repeat(in1, repeats=[6], axis=0)",
            "return tf.repeat(in1, [6], axis=0)",
            "return tf.repeat(tf.expand_dims(in1, 1), 6, axis=1)"
        ]
    },
    {
        "constants": "[]",
        "description": "Take the max from each group of elements",
        "target_program": "tf.math.segment_max(in2, in1)",
        "source": "Real task encountered by Googler, 3/28/2019",
        "name": "google_06",
        "examples": {
            "inputs": "[[0, 1, 1, 2, 3, 3, 3, 3],[1, 3, 4, 5, 10, 8, 9, 4],]",
            "outputs": "[1, 4, 5, 10]"
        },
        "response": {
            "task_id": "google_06",
            "completions": [
                "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1)+1)",
                "return tf.math.segment_max(in2, in1)",
                "segment_ids = tf.constant(in1, dtype=tf.int32)\ndata = tf.constant(in2, dtype=tf.int32)\nresult = tf.math.segment_max(data, segment_ids)\nreturn result.numpy().tolist()",
                "return tf.math.segment_max(in2, in1)",
                "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1)",
                "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1).numpy().tolist()",
                "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1).numpy().tolist()",
                "return tf.math.segment_max(in2, in1)",
                "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1)",
                "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1).numpy().tolist()"
            ],
            "target-program": "tf.math.segment_max(in2, in1)",
            "description": "Take the max from each group of elements",
            "tf_operators": {
                "tf.reduce_max": 6,
                "tf.math.unsorted_segment_max": 6,
                "tf.math.segment_max": 4,
                "tf.int32": 1,
                "tf.constant": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1)+1)",
            "return tf.math.segment_max(in2, in1)",
            "segment_ids = tf.constant(in1, dtype=tf.int32)\ndata = tf.constant(in2, dtype=tf.int32)\nresult = tf.math.segment_max(data, segment_ids)\nreturn result.numpy().tolist()",
            "return tf.math.segment_max(in2, in1)",
            "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1)",
            "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1).numpy().tolist()",
            "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1).numpy().tolist()",
            "return tf.math.segment_max(in2, in1)",
            "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1)",
            "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1).numpy().tolist()"
        ]
    },
    {
        "constants": "[]",
        "description": "Take the argmax of each group of elements",
        "target_program": "tf.cast(tf.argmax((tf.sequence_mask(tf.cumsum(tf.math.bincount(in1)), dtype=tf.int32) - tf.sequence_mask(tf.cumsum(tf.math.bincount(in1), exclusive=True), dtype=tf.int32, maxlen=in1.shape[0])) * in2, axis=1), tf.int32) - tf.cumsum(tf.math.bincount(in1), exclusive=True)",
        "source": "Real task encountered by Googler, 3/29/2019",
        "name": "google_07",
        "examples": {
            "inputs": "[[0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 4, 4, 5, 5],[4, 1, 8, 2, 5, 7, 9, 3, 7, 3, 1, 42, 1, 2, 4, 0],]",
            "outputs": "[2, 3, 1, 0, 1, 0]"
        },
        "response": {
            "task_id": "google_07",
            "completions": [
                "return tf.math.segment_max(in2, in1)",
                "return tf.segment_max(in2, in1)",
                "return tf.math.segment_max(in2, in1)",
                "return tf.math.segment_max(in2,in1).numpy().tolist()",
                "return tf.gather(in2, tf.math.segment_max(in1, in2))",
                "return tf.math.segment_max(in2, in1)",
                "segment_ids = tf.cast(in1, tf.int32)\ndata = tf.cast(in2, tf.int32)\nreturn tf.math.segment_max(data, segment_ids)",
                "segments = tf.cast(in1, tf.int32)\nvalues = tf.cast(in2, tf.float32)\noutput = tf.math.argmax(tf.math.segment_sum(values, segments))\nreturn output",
                "return tf.math.segment_max(in2, in1).numpy().tolist()",
                "out = tf.math.segment_max(in2, in1)\nindices = tf.where(tf.equal(in2, out))\nindices = tf.reduce_min(indices, axis = 0)\nreturn indices[:,0]"
            ],
            "target-program": "tf.cast(tf.argmax((tf.sequence_mask(tf.cumsum(tf.math.bincount(in1)), dtype=tf.int32) - tf.sequence_mask(tf.cumsum(tf.math.bincount(in1), exclusive=True), dtype=tf.int32, maxlen=in1.shape[0])) * in2, axis=1), tf.int32) - tf.cumsum(tf.math.bincount(in1), exclusive=True)",
            "description": "Take the argmax of each group of elements",
            "tf_operators": {
                "tf.math.segment_max": 8,
                "tf.segment_max": 1,
                "tf.gather": 1,
                "tf.int32": 2,
                "tf.cast": 2,
                "tf.float32": 1,
                "tf.math.argmax": 1,
                "tf.math.segment_sum": 1,
                "tf.reduce_min": 1,
                "tf.equal": 1,
                "tf.where": 1
            },
            "coverage_percentage": 33.33333333333333,
            "total_in_target": 6,
            "total_covered": 2
        },
        "completions": [
            "return tf.math.segment_max(in2, in1)",
            "return tf.segment_max(in2, in1)",
            "return tf.math.segment_max(in2, in1)",
            "return tf.math.segment_max(in2,in1).numpy().tolist()",
            "return tf.gather(in2, tf.math.segment_max(in1, in2))",
            "return tf.math.segment_max(in2, in1)",
            "segment_ids = tf.cast(in1, tf.int32)\ndata = tf.cast(in2, tf.int32)\nreturn tf.math.segment_max(data, segment_ids)",
            "segments = tf.cast(in1, tf.int32)\nvalues = tf.cast(in2, tf.float32)\noutput = tf.math.argmax(tf.math.segment_sum(values, segments))\nreturn output",
            "return tf.math.segment_max(in2, in1).numpy().tolist()",
            "out = tf.math.segment_max(in2, in1)\nindices = tf.where(tf.equal(in2, out))\nindices = tf.reduce_min(indices, axis = 0)\nreturn indices[:,0]"
        ]
    },
    {
        "constants": "[5]",
        "description": "create a mask for sequences of the given lengths",
        "target_program": "tf.cast(tf.greater(tf.expand_dims(in1, 1), tf.range(5)), tf.int32)",
        "source": "Real task encountered by Googler, 4/11/2019",
        "name": "google_08",
        "examples": {
            "inputs": "[[3, 4, 2, 1],]",
            "outputs": "[[1, 1, 1, 0, 0],    [1, 1, 1, 1, 0],    [1, 1, 0, 0, 0],    [1, 0, 0, 0, 0]]"
        },
        "response": {
            "task_id": "google_08",
            "completions": [
                "return tf.sequence_mask(in1, tf.reduce_max(in1))",
                "return tf.sequence_mask(in1).numpy().astype(int)",
                "return tf.sequence_mask(in1)",
                "mask = tf.sequence_mask(in1)\n     return tf.cast(mask, dtype=tf.int32)",
                "return tf.sequence_mask(in1).numpy().astype(int)",
                "return tf.sequence_mask(in1, tf.reduce_max(in1))",
                "return tf.sequence_mask(in1)",
                "return tf.sequence_mask(in1, maxlen=tf.reduce_max(in1)).numpy().astype(int)",
                "return tf.sequence_mask(in1, tf.reduce_max(in1))",
                "maxlen = tf.reduce_max(in1)\nreturn tf.sequence_mask(in1, maxlen)"
            ],
            "target-program": "tf.cast(tf.greater(tf.expand_dims(in1, 1), tf.range(5)), tf.int32)",
            "description": "create a mask for sequences of the given lengths",
            "tf_operators": {
                "tf.reduce_max": 5,
                "tf.sequence_mask": 10,
                "tf.int32": 1,
                "tf.cast": 1
            },
            "coverage_percentage": 40.0,
            "total_in_target": 5,
            "total_covered": 2
        },
        "completions": [
            "return tf.sequence_mask(in1, tf.reduce_max(in1))",
            "return tf.sequence_mask(in1).numpy().astype(int)",
            "return tf.sequence_mask(in1)",
            "mask = tf.sequence_mask(in1)\n     return tf.cast(mask, dtype=tf.int32)",
            "return tf.sequence_mask(in1).numpy().astype(int)",
            "return tf.sequence_mask(in1, tf.reduce_max(in1))",
            "return tf.sequence_mask(in1)",
            "return tf.sequence_mask(in1, maxlen=tf.reduce_max(in1)).numpy().astype(int)",
            "return tf.sequence_mask(in1, tf.reduce_max(in1))",
            "maxlen = tf.reduce_max(in1)\nreturn tf.sequence_mask(in1, maxlen)"
        ]
    },
    {
        "constants": "[]",
        "description": "sort the segments",
        "target_program": "tf.gather(in2, tf.argsort(in1, stable=True))",
        "source": "Real task encountered by Googler, 8/9/2019",
        "name": "google_09",
        "examples": {
            "inputs": "[[1, 1, 1, 0, 0, 2],[10, 20, 30, 14, 15, 26],]",
            "outputs": "[14, 15, 10, 20, 30, 26]"
        },
        "response": {
            "task_id": "google_09",
            "completions": [
                "return tf.gather(in2, tf.argsort(in1)).numpy().tolist()",
                "output = tf.tensor_scatter_nd_update(in2, tf.reshape(tf.argsort(in1), [-1, 1]), tf.sort(in2))\n     return output",
                "segments = tf.unique_with_counts(in1)[1]\nsegment_ids = tf.argsort(in1)\ndata = tf.gather(in2, segment_ids)\nsorted_data = tf.sort(data)\nindices = tf.math.cumsum(segments, exclusive=True)\nreturn tf.concat([tf.gather(sorted_data, tf.range(i, j)) for i, j in zip(indices[:-1], indices[1:])], axis=0)",
                "return tf.gather(in2, tf.argsort(in1))",
                "segment_ids = tf.constant(in1)\ndata = tf.constant(in2)\nreturn tf.math.unsorted_segment_sum(data, tf.argsort(segment_ids), tf.reduce_max(segment_ids) + 1)",
                "segments = tf.constant(in1)\nvalues = tf.constant(in2)\nnum_segments = tf.reduce_max(segments) + 1\nresult = tf.math.unsorted_segment_sum(values, segments, num_segments)\nsrt_idx = tf.argsort(result)\nsorted_result = tf.gather(result, srt_idx)\nreturn sorted_result",
                "segments = tf.unstack(tf.math.segment_sum(in2, in1))\n     sorted_segments = tf.sort(segments)\n     return tf.math.unsorted_segment_sum(sorted_segments, tf.argsort(in1), tf.reduce_max(in1) + 1)",
                "segment_ids = tf.constant(in1)\nsegments = tf.constant(in2)\ntoposort_order = tf.argsort(segments)\nsorted_segments = tf.gather(segments, toposort_order)\nreturn sorted_segments",
                "seg_ids, data = tf.constant(in1), tf.constant(in2)\nsorted_index = tf.argsort(data)\nsorted_seg_ids = tf.gather(seg_ids, sorted_index)\nsorted_data = tf.gather(data, sorted_index)\nidx = tf.argsort(sorted_seg_ids)\nreturn tf.gather(sorted_data, idx).numpy().tolist()",
                "segments = tf.constant(in1, dtype=tf.int32)\nvalues = tf.constant(in2, dtype=tf.int32)\nseg_max = tf.math.unsorted_segment_max(values, segments, tf.reduce_max(segments) + 1)\nindices = tf.argsort(seg_max)\nsorted_segments = tf.math.unsorted_segment_max(values, indices, tf.reduce_max(indices) + 1)\nreturn sorted_segments.numpy().tolist()"
            ],
            "target-program": "tf.gather(in2, tf.argsort(in1, stable=True))",
            "description": "sort the segments",
            "tf_operators": {
                "tf.gather": 6,
                "tf.argsort": 10,
                "tf.reshape": 1,
                "tf.sort": 3,
                "tf.tensor_scatter_nd_update": 1,
                "tf.unique_with_counts": 1,
                "tf.range": 1,
                "tf.math.cumsum": 1,
                "tf.concat": 1,
                "tf.math.unsorted_segment_sum": 3,
                "tf.constant": 5,
                "tf.reduce_max": 4,
                "tf.unstack": 1,
                "tf.math.segment_sum": 1,
                "tf.math.unsorted_segment_max": 1,
                "tf.int32": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 2,
            "total_covered": 2
        },
        "completions": [
            "return tf.gather(in2, tf.argsort(in1)).numpy().tolist()",
            "output = tf.tensor_scatter_nd_update(in2, tf.reshape(tf.argsort(in1), [-1, 1]), tf.sort(in2))\n     return output",
            "segments = tf.unique_with_counts(in1)[1]\nsegment_ids = tf.argsort(in1)\ndata = tf.gather(in2, segment_ids)\nsorted_data = tf.sort(data)\nindices = tf.math.cumsum(segments, exclusive=True)\nreturn tf.concat([tf.gather(sorted_data, tf.range(i, j)) for i, j in zip(indices[:-1], indices[1:])], axis=0)",
            "return tf.gather(in2, tf.argsort(in1))",
            "segment_ids = tf.constant(in1)\ndata = tf.constant(in2)\nreturn tf.math.unsorted_segment_sum(data, tf.argsort(segment_ids), tf.reduce_max(segment_ids) + 1)",
            "segments = tf.constant(in1)\nvalues = tf.constant(in2)\nnum_segments = tf.reduce_max(segments) + 1\nresult = tf.math.unsorted_segment_sum(values, segments, num_segments)\nsrt_idx = tf.argsort(result)\nsorted_result = tf.gather(result, srt_idx)\nreturn sorted_result",
            "segments = tf.unstack(tf.math.segment_sum(in2, in1))\n     sorted_segments = tf.sort(segments)\n     return tf.math.unsorted_segment_sum(sorted_segments, tf.argsort(in1), tf.reduce_max(in1) + 1)",
            "segment_ids = tf.constant(in1)\nsegments = tf.constant(in2)\ntoposort_order = tf.argsort(segments)\nsorted_segments = tf.gather(segments, toposort_order)\nreturn sorted_segments",
            "seg_ids, data = tf.constant(in1), tf.constant(in2)\nsorted_index = tf.argsort(data)\nsorted_seg_ids = tf.gather(seg_ids, sorted_index)\nsorted_data = tf.gather(data, sorted_index)\nidx = tf.argsort(sorted_seg_ids)\nreturn tf.gather(sorted_data, idx).numpy().tolist()",
            "segments = tf.constant(in1, dtype=tf.int32)\nvalues = tf.constant(in2, dtype=tf.int32)\nseg_max = tf.math.unsorted_segment_max(values, segments, tf.reduce_max(segments) + 1)\nindices = tf.argsort(seg_max)\nsorted_segments = tf.math.unsorted_segment_max(values, indices, tf.reduce_max(indices) + 1)\nreturn sorted_segments.numpy().tolist()"
        ]
    },
    {
        "constants": "[]",
        "description": "gather the marked elements",
        "target_program": "tf.boolean_mask(in1, tf.cast(in2, tf.bool))",
        "source": null,
        "name": "google_10",
        "examples": {
            "inputs": "[[10, 20, 0, 40, 0, 30],[1, 1, 0, 1, 0, 1],]",
            "outputs": "[10, 20, 40, 30]"
        },
        "response": {
            "task_id": "google_10",
            "completions": [
                "return tf.boolean_mask(in1, in2).numpy().tolist()",
                "return tf.boolean_mask(in1, in2)",
                "return tf.boolean_mask(in1, in2)",
                "return tf.boolean_mask(in1, tf.cast(in2, tf.bool))",
                "return tf.boolean_mask(in1, tf.cast(in2, tf.bool)).numpy()",
                "return tf.boolean_mask(in1, in2).numpy()",
                "return tf.boolean_mask(in1, in2).numpy()",
                "return tf.boolean_mask(in1,in2).numpy()",
                "return tf.boolean_mask(in1, tf.cast(in2, dtype=bool))",
                "return tf.boolean_mask(in1, in2)"
            ],
            "target-program": "tf.boolean_mask(in1, tf.cast(in2, tf.bool))",
            "description": "gather the marked elements",
            "tf_operators": {
                "tf.boolean_mask": 10,
                "tf.cast": 3,
                "tf.bool": 2
            },
            "coverage_percentage": 100.0,
            "total_in_target": 3,
            "total_covered": 3
        },
        "completions": [
            "return tf.boolean_mask(in1, in2).numpy().tolist()",
            "return tf.boolean_mask(in1, in2)",
            "return tf.boolean_mask(in1, in2)",
            "return tf.boolean_mask(in1, tf.cast(in2, tf.bool))",
            "return tf.boolean_mask(in1, tf.cast(in2, tf.bool)).numpy()",
            "return tf.boolean_mask(in1, in2).numpy()",
            "return tf.boolean_mask(in1, in2).numpy()",
            "return tf.boolean_mask(in1,in2).numpy()",
            "return tf.boolean_mask(in1, tf.cast(in2, dtype=bool))",
            "return tf.boolean_mask(in1, in2)"
        ]
    },
    {
        "constants": "[]",
        "description": "count the number of elements greater than 0 in each row",
        "target_program": "tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
        "source": "Real task encountered by Googler, 8/26/2019",
        "name": "google_11",
        "examples": {
            "inputs": "[[[1.0, 0.3, -4.2, 0.0, 2.1, 0.4], [-0.1, 0.0, 1.4, -1.0, 0.4, 0.0], [0.1, 0.0, 0.7, -0.3, 0.5, -0.1], [1.4, 2.5, 0.3, 0.01, 0.0, 1.2]],]",
            "outputs": "[4, 2, 3, 5]"
        },
        "response": {
            "task_id": "google_11",
            "completions": [
                "return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
                "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
                "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
                "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
                "return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
                "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
                "return tf.math.count_nonzero(in1 > 0, axis=1)",
                "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1).numpy().tolist()",
                "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
                "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)"
            ],
            "target-program": "tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
            "description": "count the number of elements greater than 0 in each row",
            "tf_operators": {
                "tf.cast": 2,
                "tf.greater": 9,
                "tf.int32": 2,
                "tf.reduce_sum": 2,
                "tf.math.count_nonzero": 8
            },
            "coverage_percentage": 100.0,
            "total_in_target": 4,
            "total_covered": 4
        },
        "completions": [
            "return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
            "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
            "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
            "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
            "return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
            "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
            "return tf.math.count_nonzero(in1 > 0, axis=1)",
            "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1).numpy().tolist()",
            "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
            "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)"
        ]
    },
    {
        "constants": "[]",
        "description": "identify elements between 0 and 1",
        "target_program": "tf.cast(tf.logical_and(0 <= in1, in1 <= 1), tf.int32)",
        "source": "Real task encountered by Googler, 8/26/2019",
        "name": "google_12",
        "examples": {
            "inputs": "[[[1.0, 0.3, -4.2, 0.0, 2.1], [-0.1, 0.0, 1.4, -1.0, 0.4], [0.1, 0.0, 0.7, -0.3, 0.5], [1.4, 2.5, 0.3, -0.1, 0.0]],]",
            "outputs": "[[1, 1, 0, 1, 0],    [0, 1, 0, 0, 1],    [1, 1, 1, 0, 1],    [0, 0, 1, 0, 1]]"
        },
        "response": {
            "task_id": "google_12",
            "completions": [
                "return tf.cast(tf.logical_and(tf.greater(in1, tf.constant(0.)), tf.less(in1, tf.constant(1.))), 'int32')",
                "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), dtype=tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater(in1, tf.zeros_like(in1)), tf.less(in1, tf.ones_like(in1))), dtype=tf.int32)"
            ],
            "target-program": "tf.cast(tf.logical_and(0 <= in1, in1 <= 1), tf.int32)",
            "description": "identify elements between 0 and 1",
            "tf_operators": {
                "tf.logical_and": 10,
                "tf.cast": 10,
                "tf.less": 10,
                "tf.constant": 1,
                "tf.greater": 10,
                "tf.int32": 9,
                "tf.zeros_like": 1,
                "tf.ones_like": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 3,
            "total_covered": 3
        },
        "completions": [
            "return tf.cast(tf.logical_and(tf.greater(in1, tf.constant(0.)), tf.less(in1, tf.constant(1.))), 'int32')",
            "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), dtype=tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater(in1, tf.zeros_like(in1)), tf.less(in1, tf.ones_like(in1))), dtype=tf.int32)"
        ]
    },
    {
        "constants": "[]",
        "description": "Concatenate batches of sequences",
        "target_program": "tf.concat([in1, in2], axis=1)",
        "source": "Real task encountered by Googler, 9/13/2019",
        "name": "google_13",
        "examples": {
            "inputs": "[[[1, 2], [10, 20]],[[3, 4, 5], [30, 40, 50]],]",
            "outputs": "[[1, 2, 3, 4, 5], [10, 20, 30, 40, 50]]"
        },
        "response": {
            "task_id": "google_13",
            "completions": [
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1,in2], axis=1)",
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1, in2], axis=-1)"
            ],
            "target-program": "tf.concat([in1, in2], axis=1)",
            "description": "Concatenate batches of sequences",
            "tf_operators": {
                "tf.concat": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1,in2], axis=1)",
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1, in2], axis=-1)"
        ]
    },
    {
        "constants": "[]",
        "description": "circular buffer",
        "target_program": "tf.roll(in1, 1, 1)",
        "source": "From internal Colab, 10/17/2019",
        "name": "google_14",
        "examples": {
            "inputs": "[[[1, 3, 2, 0, 0], [4, 6, 5, 0, 0], [8, 7, 9, 0, 0]],]",
            "outputs": "[[0, 1, 3, 2, 0], [0, 4, 6, 5, 0], [0, 8, 7, 9, 0]]"
        },
        "response": {
            "task_id": "google_14",
            "completions": [
                "return tf.roll(in1, shift=1, axis=1)",
                "return tf.roll(in1, shift=1, axis=1)",
                "return tf.roll(in1, shift=1, axis=1)",
                "return tf.roll(in1, shift=1, axis=1)",
                "return tf.pad(in1, [[0, 0], [1, 0]])",
                "return tf.pad(in1, tf.constant([[0, 0], [1, 1]]), \"CONSTANT\")",
                "return tf.roll(in1, shift=1, axis=1)",
                "# Shift all elements in each row of in1 to the right by one place, and pad with 0 at the start of each row\nreturn tf.roll(in1, shift=1, axis=1)",
                "return tf.roll(in1, shift=1, axis=1)",
                "return tf.roll(in1, shift=1, axis=1)"
            ],
            "target-program": "tf.roll(in1, 1, 1)",
            "description": "circular buffer",
            "tf_operators": {
                "tf.roll": 8,
                "tf.pad": 2,
                "tf.constant": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.roll(in1, shift=1, axis=1)",
            "return tf.roll(in1, shift=1, axis=1)",
            "return tf.roll(in1, shift=1, axis=1)",
            "return tf.roll(in1, shift=1, axis=1)",
            "return tf.pad(in1, [[0, 0], [1, 0]])",
            "return tf.pad(in1, tf.constant([[0, 0], [1, 1]]), \"CONSTANT\")",
            "return tf.roll(in1, shift=1, axis=1)",
            "# Shift all elements in each row of in1 to the right by one place, and pad with 0 at the start of each row\nreturn tf.roll(in1, shift=1, axis=1)",
            "return tf.roll(in1, shift=1, axis=1)",
            "return tf.roll(in1, shift=1, axis=1)"
        ]
    },
    {
        "constants": "[]",
        "description": "pad a zero column",
        "target_program": "tf.pad(in1, [[0, 0], [0, 1]], 'CONSTANT')",
        "source": "Real task encountered by Googler, 10/23/2019",
        "name": "google_15",
        "examples": {
            "inputs": "[[[1, 3, 5, 7], [2, 4, 6, 8]],]",
            "outputs": "[[1, 3, 5, 7, 0], [2, 4, 6, 8, 0]]"
        },
        "response": {
            "task_id": "google_15",
            "completions": [
                "# pad zeros on the last column\nreturn tf.pad(in1, [[0, 0], [0, 1]], mode='CONSTANT', constant_values=0)",
                "padding = tf.constant([[0, 0], [0, 1]])\n     return tf.pad(in1, padding)",
                "paddings = tf.constant([[0, 0], [0, 1]])\n     return tf.pad(in1, paddings)",
                "return tf.pad(in1, [[0,0],[0,1]], mode='CONSTANT')",
                "padding = tf.constant([[0, 0], [0, 1]])\nreturn tf.pad(in1, padding, \"CONSTANT\")",
                "paddings = tf.constant([[0, 0], [0, 1]])\n     return tf.pad(in1, paddings)",
                "return tf.concat([in1, tf.zeros((tf.shape(in1)[0], 1), dtype=in1.dtype)], axis=1)",
                "return tf.pad(in1, [[0, 0], [0, 1]], 'CONSTANT', 0)",
                "return tf.pad(in1, [[0, 0], [0, 1]])",
                "return tf.pad(in1, [[0,0],[0,1]])"
            ],
            "target-program": "tf.pad(in1, [[0, 0], [0, 1]], 'CONSTANT')",
            "description": "pad a zero column",
            "tf_operators": {
                "tf.pad": 9,
                "tf.constant": 4,
                "tf.shape": 1,
                "tf.zeros": 1,
                "tf.concat": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "# pad zeros on the last column\nreturn tf.pad(in1, [[0, 0], [0, 1]], mode='CONSTANT', constant_values=0)",
            "padding = tf.constant([[0, 0], [0, 1]])\n     return tf.pad(in1, padding)",
            "paddings = tf.constant([[0, 0], [0, 1]])\n     return tf.pad(in1, paddings)",
            "return tf.pad(in1, [[0,0],[0,1]], mode='CONSTANT')",
            "padding = tf.constant([[0, 0], [0, 1]])\nreturn tf.pad(in1, padding, \"CONSTANT\")",
            "paddings = tf.constant([[0, 0], [0, 1]])\n     return tf.pad(in1, paddings)",
            "return tf.concat([in1, tf.zeros((tf.shape(in1)[0], 1), dtype=in1.dtype)], axis=1)",
            "return tf.pad(in1, [[0, 0], [0, 1]], 'CONSTANT', 0)",
            "return tf.pad(in1, [[0, 0], [0, 1]])",
            "return tf.pad(in1, [[0,0],[0,1]])"
        ]
    },
    {
        "constants": "[]",
        "description": "replicate elements a given number of times",
        "target_program": "tf.gather(in1, tf.where(tf.sequence_mask(in2))[:, 0])",
        "source": "From an internal Google forum",
        "name": "google_16",
        "examples": {
            "inputs": "[[1, 2, 0, 3],[2, 1, 2, 3],]",
            "outputs": "[1, 1, 2, 0, 0, 3, 3, 3]"
        },
        "response": {
            "task_id": "google_16",
            "completions": [
                "return tf.repeat(in1, in2)",
                "return tf.reshape(tf.repeat(in1, in2), [-1])",
                "return tf.repeat(in1, in2)",
                "return tf.repeat(in1, in2).numpy().tolist()",
                "return tf.reshape(tf.repeat(in1, in2), [-1])",
                "return tf.repeat(in1, in2)",
                "return tf.reshape(tf.repeat(in1, in2), [-1]).numpy()",
                "return tf.repeat(in1, repeats=in2)",
                "return tf.reshape(tf.repeat(in1, in2), [-1])",
                "return tf.repeat(in1, in2).numpy().tolist()"
            ],
            "target-program": "tf.gather(in1, tf.where(tf.sequence_mask(in2))[:, 0])",
            "description": "replicate elements a given number of times",
            "tf_operators": {
                "tf.repeat": 10,
                "tf.reshape": 4
            },
            "coverage_percentage": 0.0,
            "total_in_target": 3,
            "total_covered": 0
        },
        "completions": [
            "return tf.repeat(in1, in2)",
            "return tf.reshape(tf.repeat(in1, in2), [-1])",
            "return tf.repeat(in1, in2)",
            "return tf.repeat(in1, in2).numpy().tolist()",
            "return tf.reshape(tf.repeat(in1, in2), [-1])",
            "return tf.repeat(in1, in2)",
            "return tf.reshape(tf.repeat(in1, in2), [-1]).numpy()",
            "return tf.repeat(in1, repeats=in2)",
            "return tf.reshape(tf.repeat(in1, in2), [-1])",
            "return tf.repeat(in1, in2).numpy().tolist()"
        ]
    },
    {
        "constants": "[-10]",
        "description": "use bool tensor as condition",
        "target_program": "tf.where(in1, in2, tf.multiply(in2, -10))",
        "source": "From an internal Google forum",
        "name": "google_17",
        "examples": {
            "inputs": "[[True, False, False, True, False],[1, 2, 3, 4, 5],]",
            "outputs": "[1, -20, -30, 4, -50]"
        },
        "response": {
            "task_id": "google_17",
            "completions": [
                "return tf.where(in1, in2, tf.multiply(in2, -10))",
                "return tf.where(in1, in2, in2 * -10)",
                "return tf.where(in1, in2, tf.multiply(in2, -10))",
                "return tf.where(in1, in2, tf.multiply(in2, -10))",
                "return tf.where(in1, in2, -10*in2)",
                "return tf.where(in1, in2, tf.multiply(in2, -10))",
                "return tf.where(in1, in2, in2*tf.constant(-10))",
                "return tf.where(in1, in2, in2 * -10)",
                "return tf.where(in1, in2, tf.multiply(in2, -10))",
                "return tf.where(in1, in2, in2*tf.constant(-10))"
            ],
            "target-program": "tf.where(in1, in2, tf.multiply(in2, -10))",
            "description": "use bool tensor as condition",
            "tf_operators": {
                "tf.multiply": 5,
                "tf.where": 10,
                "tf.constant": 2
            },
            "coverage_percentage": 100.0,
            "total_in_target": 2,
            "total_covered": 2
        },
        "completions": [
            "return tf.where(in1, in2, tf.multiply(in2, -10))",
            "return tf.where(in1, in2, in2 * -10)",
            "return tf.where(in1, in2, tf.multiply(in2, -10))",
            "return tf.where(in1, in2, tf.multiply(in2, -10))",
            "return tf.where(in1, in2, -10*in2)",
            "return tf.where(in1, in2, tf.multiply(in2, -10))",
            "return tf.where(in1, in2, in2*tf.constant(-10))",
            "return tf.where(in1, in2, in2 * -10)",
            "return tf.where(in1, in2, tf.multiply(in2, -10))",
            "return tf.where(in1, in2, in2*tf.constant(-10))"
        ]
    },
    {
        "constants": "[]",
        "description": "(\\'sum of elements in the first tensor but partitioned by the second tensor\\')",
        "target_program": "tf.linalg.matvec(tf.cast(tf.equal(in2[:, None], in2), tf.int32), in1)",
        "source": "From an internal Google forum",
        "name": "google_18",
        "examples": {
            "inputs": "[[5, 7, -12, 10, 20],[1, 2, 3, 1, 2],]",
            "outputs": "[15, 27, -12, 15, 27]"
        },
        "response": {
            "task_id": "google_18",
            "completions": [
                "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)",
                "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + 1)",
                "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)",
                "segment_sum = tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)\n     result = tf.gather(segment_sum, in2)\n     return result",
                "segments_ids = tf.subtract(in2, tf.constant(1))\noutput = tf.gather(tf.math.unsorted_segment_sum(in1, segments_ids, tf.reduce_max(segments_ids) + 1), segments_ids)\nreturn output",
                "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)",
                "segments = tf.constant(in2)\ndata = tf.constant(in1)\nsums = tf.math.unsorted_segment_sum(data, segments, tf.reduce_max(segment_ids)+1)\nreturn tf.gather(sums, segments)",
                "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + 1)",
                "segmented_sum = tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + 1)\n     out = tf.gather(segmented_sum, in2)\n     return out",
                "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)"
            ],
            "target-program": "tf.linalg.matvec(tf.cast(tf.equal(in2[:, None], in2), tf.int32), in1)",
            "description": "(\\'sum of elements in the first tensor but partitioned by the second tensor\\')",
            "tf_operators": {
                "tf.math.unsorted_segment_sum": 10,
                "tf.reduce_max": 10,
                "tf.gather": 4,
                "tf.constant": 2,
                "tf.subtract": 1
            },
            "coverage_percentage": 0.0,
            "total_in_target": 4,
            "total_covered": 0
        },
        "completions": [
            "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)",
            "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + 1)",
            "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)",
            "segment_sum = tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)\n     result = tf.gather(segment_sum, in2)\n     return result",
            "segments_ids = tf.subtract(in2, tf.constant(1))\noutput = tf.gather(tf.math.unsorted_segment_sum(in1, segments_ids, tf.reduce_max(segments_ids) + 1), segments_ids)\nreturn output",
            "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)",
            "segments = tf.constant(in2)\ndata = tf.constant(in1)\nsums = tf.math.unsorted_segment_sum(data, segments, tf.reduce_max(segment_ids)+1)\nreturn tf.gather(sums, segments)",
            "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + 1)",
            "segmented_sum = tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + 1)\n     out = tf.gather(segmented_sum, in2)\n     return out",
            "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)"
        ]
    },
    {
        "constants": "[]",
        "description": "scatter a 2-D tensor with indices",
        "target_program": "tf.gather(in1, tf.argsort(in2, axis=1), batch_dims=1)",
        "source": "From an internal Google forum",
        "name": "google_19",
        "examples": {
            "inputs": "[[[11, 12, 13], [30, 20, 10], [77, 88, 99]],[[2, 0, 1], [1, 0, 2], [0, 2, 1]],]",
            "outputs": "[[12, 13, 11],    [20, 30, 10],    [77, 99, 88]]"
        },
        "response": {
            "task_id": "google_19",
            "completions": [
                "return tf.gather(in1, in2, batch_dims=1)",
                "return tf.gather(in1, in2, axis=1)",
                "return tf.gather(in1, in2, axis=1)",
                "return tf.gather(in1,in2,axis=1)",
                "return tf.gather(in1, in2, axis=1)",
                "return tf.transpose(tf.gather(tf.transpose(in1), in2))",
                "return tf.gather(in1, in2, axis=1)",
                "return tf.map_fn(lambda x: tf.gather(*x), (in1, in2), dtype=tf.int32)",
                "return tf.gather(in1, in2, batch_dims=1)",
                "return tf.gather(in1, in2, batch_dims=1)"
            ],
            "target-program": "tf.gather(in1, tf.argsort(in2, axis=1), batch_dims=1)",
            "description": "scatter a 2-D tensor with indices",
            "tf_operators": {
                "tf.gather": 10,
                "tf.transpose": 1,
                "tf.map_fn": 1,
                "tf.int32": 1
            },
            "coverage_percentage": 50.0,
            "total_in_target": 2,
            "total_covered": 1
        },
        "completions": [
            "return tf.gather(in1, in2, batch_dims=1)",
            "return tf.gather(in1, in2, axis=1)",
            "return tf.gather(in1, in2, axis=1)",
            "return tf.gather(in1,in2,axis=1)",
            "return tf.gather(in1, in2, axis=1)",
            "return tf.transpose(tf.gather(tf.transpose(in1), in2))",
            "return tf.gather(in1, in2, axis=1)",
            "return tf.map_fn(lambda x: tf.gather(*x), (in1, in2), dtype=tf.int32)",
            "return tf.gather(in1, in2, batch_dims=1)",
            "return tf.gather(in1, in2, batch_dims=1)"
        ]
    },
    {
        "constants": "[]",
        "description": "sort a tensor and return sorted index in original order",
        "target_program": "tf.cast(tf.argsort(tf.argsort(in1)), tf.int32)",
        "source": "From an internal Google forum",
        "name": "google_20",
        "examples": {
            "inputs": "[[10, 7, 4, 3, 2, 8],]",
            "outputs": "[5, 3, 2, 1, 0, 4]"
        },
        "response": {
            "task_id": "google_20",
            "completions": [
                "return tf.argsort(tf.argsort(in1)).numpy().tolist()",
                "return tf.argsort(tf.argsort(in1))",
                "return tf.argsort(tf.argsort(in1)).numpy()",
                "return tf.argsort(tf.argsort(in1))",
                "return tf.argsort(tf.argsort(in1)).numpy().tolist()",
                "return tf.argsort(tf.argsort(in1))",
                "return tf.argsort(tf.argsort(in1)).numpy()",
                "return tf.argsort(tf.argsort(in1)).numpy().tolist()",
                "return tf.argsort(tf.argsort(in1)).numpy()",
                "sorted_indices = tf.argsort(in1)\noriginal_order = tf.argsort(sorted_indices)\nreturn original_order"
            ],
            "target-program": "tf.cast(tf.argsort(tf.argsort(in1)), tf.int32)",
            "description": "sort a tensor and return sorted index in original order",
            "tf_operators": {
                "tf.argsort": 10
            },
            "coverage_percentage": 33.33333333333333,
            "total_in_target": 3,
            "total_covered": 1
        },
        "completions": [
            "return tf.argsort(tf.argsort(in1)).numpy().tolist()",
            "return tf.argsort(tf.argsort(in1))",
            "return tf.argsort(tf.argsort(in1)).numpy()",
            "return tf.argsort(tf.argsort(in1))",
            "return tf.argsort(tf.argsort(in1)).numpy().tolist()",
            "return tf.argsort(tf.argsort(in1))",
            "return tf.argsort(tf.argsort(in1)).numpy()",
            "return tf.argsort(tf.argsort(in1)).numpy().tolist()",
            "return tf.argsort(tf.argsort(in1)).numpy()",
            "sorted_indices = tf.argsort(in1)\noriginal_order = tf.argsort(sorted_indices)\nreturn original_order"
        ]
    },
    {
        "constants": "[]",
        "description": "update a tensor at the given indices",
        "target_program": "tf.tensor_scatter_nd_update(tensor, indices, tf.reshape(updates, (-1,)))",
        "source": "Real task encountered by Googler, 12/15/2020",
        "name": "google_21",
        "examples": {
            "inputs": "{'tensor': [[1, 2, 3, 4, 5], [4, 5, 6, 7, 8], [7, 8, 9, 10, 11]], 'indices': [[0, 0], [0, 2], [1, 1], [1, 3], [2, 2], [2, 4]], 'updates': [[0, -2], [-1, -3], [-2, -4]],}",
            "outputs": "[[0, 2, -2, 4, 5], [4, -1, 6, -3, 8], [7, 8, -2, 10, -4]]"
        },
        "response": {
            "task_id": "google_21",
            "completions": [
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates']).numpy().tolist()",
                "return tf.tensor_scatter_nd_update(tf.constant(in1['tensor']), tf.constant(in1['indices']), tf.constant(in1['updates']))",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'],in1['indices'],in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates']).numpy()",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])"
            ],
            "target-program": "tf.tensor_scatter_nd_update(tensor, indices, tf.reshape(updates, (-1,)))",
            "description": "update a tensor at the given indices",
            "tf_operators": {
                "tf.tensor_scatter_nd_update": 10,
                "tf.constant": 1
            },
            "coverage_percentage": 50.0,
            "total_in_target": 2,
            "total_covered": 1
        },
        "completions": [
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates']).numpy().tolist()",
            "return tf.tensor_scatter_nd_update(tf.constant(in1['tensor']), tf.constant(in1['indices']), tf.constant(in1['updates']))",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'],in1['indices'],in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates']).numpy()",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])"
        ]
    },
    {
        "constants": "[]",
        "description": "pair with row index",
        "target_program": "tf.cast(tf.where(tf.reduce_max(tf.one_hot(in1, tf.reduce_max(in1) + 1), axis=1)), tf.int32)",
        "source": "Real task encountered by Googler, 12/15/2020",
        "name": "google_22",
        "examples": {
            "inputs": "[[[0, 2], [1, 3], [2, 4]],]",
            "outputs": "[[0, 0], [0, 2], [1, 1], [1, 3], [2, 2], [2, 4]]"
        },
        "response": {
            "task_id": "google_22",
            "completions": [
                "indices = tf.range(tf.shape(in1)[0])\nindices = tf.expand_dims(indices, axis=-1)\nindices = tf.repeat(indices, tf.shape(in1)[1], axis=-1)\n\npair_indices = tf.reshape(indices, (-1, 1))\npair_values = tf.reshape(in1, (-1, 1))\n\noutput = tf.concat([pair_indices, pair_values], axis=-1)\nreturn output",
                "return tf.concat([tf.expand_dims(tf.range(tf.shape(in1)[0]), axis=1), in1], axis=1)",
                "indices = tf.range(tf.shape(in1)[0])\n     indices = tf.expand_dims(indices, axis=-1)\n     indices = tf.repeat(indices, repeats=tf.shape(in1)[1], axis=1)\n     in1_flat = tf.reshape(in1, [-1])\n     indices_flat = tf.reshape(indices, [-1])\n     return tf.stack([indices_flat, in1_flat], axis=-1)",
                "out = tf.range(tf.shape(in1)[0])\nout = tf.expand_dims(out, 1)\nout = tf.tile(out, [1, tf.shape(in1)[1]])\nout = tf.expand_dims(out, 2)\nin1 = tf.expand_dims(in1, 2)\nreturn tf.reshape(tf.concat([out, in1], axis=2), [-1, 2])",
                "return tf.reshape(tf.concat([tf.expand_dims(tf.range(tf.shape(in1)[0]), axis=-1), in1], axis=-1), [-1, 2])",
                "index = tf.range(tf.shape(in1)[0])\n     index = tf.expand_dims(index, axis=1)\n     index = tf.tile(index, [1, tf.shape(in1)[1]])\n     return tf.stack([index, in1], axis=-1)",
                "rows_indices = tf.range(tf.shape(in1)[0])\nrows_indices_rep = tf.repeat(rows_indices, tf.shape(in1)[1])\nreshaped_indices = tf.reshape(rows_indices_rep, [-1, 1])\nin1_flattened = tf.reshape(in1, [-1, 1])\nreturn tf.concat([reshaped_indices, in1_flattened], axis=1)",
                "indices = tf.range(start=0, limit=tf.shape(in1)[0], delta=1)\n    indices = tf.expand_dims(indices, axis=-1)\n    indices = tf.broadcast_to(indices, shape=in1.shape)\n    indices = tf.reshape(indices, shape=(-1, 1))\n    in1 = tf.reshape(in1, shape=(-1, 1))\n    result = tf.concat([indices, in1], axis=1)\n    return result",
                "# create a range of indices for the rows\n    rows = tf.range(tf.shape(in1)[0])\n\n    # expand the dimensions of the rows\n    expanded_rows = tf.expand_dims(rows , axis = -1)\n   \n    # tile the expanded rows to match the shape of in1\n    tiled_rows = tf.tile(expanded_rows, [1, tf.shape(in1)[1]])\n   \n    # reshape the tiled rows to match the shape of in1\n    reshaped_rows = tf.reshape(tiled_rows, tf.shape(in1))\n   \n    # Concatenate reshaped_rows and in1 along axis 1\n    out1 = tf.concat([reshaped_rows, in1], axis=-1)\n   \n    # reshape out1 to match the shape of the output\n    out2 = tf.reshape(out1, [tf.shape(in1)[0]*2, -1])\n   \n    return out2",
                "indices = tf.range(start=0, limit=tf.shape(in1)[0])\n      indices = tf.reshape(indices, [-1, 1])\n      indices = tf.repeat(indices, repeats=2, axis=1) \n      flat_in1 = tf.reshape(in1, [-1, 2])\n      return tf.concat([indices, flat_in1], axis=1)"
            ],
            "target-program": "tf.cast(tf.where(tf.reduce_max(tf.one_hot(in1, tf.reduce_max(in1) + 1), axis=1)), tf.int32)",
            "description": "pair with row index",
            "tf_operators": {
                "tf.shape": 10,
                "tf.reshape": 8,
                "tf.repeat": 4,
                "tf.concat": 8,
                "tf.range": 10,
                "tf.expand_dims": 8,
                "tf.stack": 2,
                "tf.tile": 3,
                "tf.broadcast_to": 1
            },
            "coverage_percentage": 0.0,
            "total_in_target": 5,
            "total_covered": 0
        },
        "completions": [
            "indices = tf.range(tf.shape(in1)[0])\nindices = tf.expand_dims(indices, axis=-1)\nindices = tf.repeat(indices, tf.shape(in1)[1], axis=-1)\n\npair_indices = tf.reshape(indices, (-1, 1))\npair_values = tf.reshape(in1, (-1, 1))\n\noutput = tf.concat([pair_indices, pair_values], axis=-1)\nreturn output",
            "return tf.concat([tf.expand_dims(tf.range(tf.shape(in1)[0]), axis=1), in1], axis=1)",
            "indices = tf.range(tf.shape(in1)[0])\n     indices = tf.expand_dims(indices, axis=-1)\n     indices = tf.repeat(indices, repeats=tf.shape(in1)[1], axis=1)\n     in1_flat = tf.reshape(in1, [-1])\n     indices_flat = tf.reshape(indices, [-1])\n     return tf.stack([indices_flat, in1_flat], axis=-1)",
            "out = tf.range(tf.shape(in1)[0])\nout = tf.expand_dims(out, 1)\nout = tf.tile(out, [1, tf.shape(in1)[1]])\nout = tf.expand_dims(out, 2)\nin1 = tf.expand_dims(in1, 2)\nreturn tf.reshape(tf.concat([out, in1], axis=2), [-1, 2])",
            "return tf.reshape(tf.concat([tf.expand_dims(tf.range(tf.shape(in1)[0]), axis=-1), in1], axis=-1), [-1, 2])",
            "index = tf.range(tf.shape(in1)[0])\n     index = tf.expand_dims(index, axis=1)\n     index = tf.tile(index, [1, tf.shape(in1)[1]])\n     return tf.stack([index, in1], axis=-1)",
            "rows_indices = tf.range(tf.shape(in1)[0])\nrows_indices_rep = tf.repeat(rows_indices, tf.shape(in1)[1])\nreshaped_indices = tf.reshape(rows_indices_rep, [-1, 1])\nin1_flattened = tf.reshape(in1, [-1, 1])\nreturn tf.concat([reshaped_indices, in1_flattened], axis=1)",
            "indices = tf.range(start=0, limit=tf.shape(in1)[0], delta=1)\n    indices = tf.expand_dims(indices, axis=-1)\n    indices = tf.broadcast_to(indices, shape=in1.shape)\n    indices = tf.reshape(indices, shape=(-1, 1))\n    in1 = tf.reshape(in1, shape=(-1, 1))\n    result = tf.concat([indices, in1], axis=1)\n    return result",
            "# create a range of indices for the rows\n    rows = tf.range(tf.shape(in1)[0])\n\n    # expand the dimensions of the rows\n    expanded_rows = tf.expand_dims(rows , axis = -1)\n   \n    # tile the expanded rows to match the shape of in1\n    tiled_rows = tf.tile(expanded_rows, [1, tf.shape(in1)[1]])\n   \n    # reshape the tiled rows to match the shape of in1\n    reshaped_rows = tf.reshape(tiled_rows, tf.shape(in1))\n   \n    # Concatenate reshaped_rows and in1 along axis 1\n    out1 = tf.concat([reshaped_rows, in1], axis=-1)\n   \n    # reshape out1 to match the shape of the output\n    out2 = tf.reshape(out1, [tf.shape(in1)[0]*2, -1])\n   \n    return out2",
            "indices = tf.range(start=0, limit=tf.shape(in1)[0])\n      indices = tf.reshape(indices, [-1, 1])\n      indices = tf.repeat(indices, repeats=2, axis=1) \n      flat_in1 = tf.reshape(in1, [-1, 2])\n      return tf.concat([indices, flat_in1], axis=1)"
        ]
    },
    {
        "constants": "[]",
        "description": "reshape by separating and duplicating columns",
        "target_program": "tf.transpose(tf.cast((in1, in1), tf.float32))",
        "source": "https://stackoverflow.com/questions/40441503/tensorflow-tensor-reshape",
        "name": "stackoverflow_01",
        "examples": {
            "inputs": "[[[5., 2.], [1., 3.], [0., -1.]],]",
            "outputs": "[[[5., 5.], [1., 1.], [0., 0.]],    [[2., 2.], [3., 3.], [-1., -1.]]]"
        },
        "response": {
            "task_id": "stackoverflow_01",
            "completions": [
                "in1 = tf.transpose(in1)\nreturn tf.expand_dims(in1, -1)",
                "return tf.expand_dims(tf.transpose(in1), axis=-1)",
                "a = tf.expand_dims(in1, axis=0)\nb = tf.transpose(a, perm=[2, 1, 0])\nreturn tf.tile(b, [1, 1, 2])",
                "x = tf.unstack(in1, axis=1)\nx = [tf.reshape(i, shape=(-1, 1)) for i in x]\nx = [tf.concat([i, i], axis=1) for i in x]\nreturn tf.stack(x)",
                "reshaped_input = tf.reshape(in1, [in1.shape[1], in1.shape[0], 1])\nreturn tf.tile(reshaped_input, [1, 1, 2])",
                "return tf.stack([tf.broadcast_to(tf.expand_dims(in1[:, i], -1), tf.shape(in1)) for i in range(in1.shape[1])], axis=0)",
                "a = tf.transpose(in1)\n     b = tf.expand_dims(a, axis=2)\n     c = tf.repeat(b, repeats=[2], axis=2)\n     return c",
                "# The task requires to reshape the input array by separating each column and replicating them into two.\n\n# Steps:\n# 1. Firstly, transpose the input array to separate the columns\n# 2. Duplicate each row in the transposed array.\n# 3. Finally, reshape the array to match the final desired shape.\n\nin1 = tf.transpose(in1)  # Transposing the input\n# Expanding dimensions to duplicate rows.\n# Expanding along axis 1 as we want to duplicate rows.\nin1 = tf.expand_dims(in1, axis=1)\n# Duplicating rows using tf.tile\nin1 = tf.tile(in1, multiples=[1, 2, 1])\nreturn in1  # Returning the reshaped array.",
                "return tf.stack([tf.expand_dims(tf.transpose(in1)[i], axis=0) for i in range(tf.shape(in1)[1])])",
                "in1_transposed = tf.transpose(in1)\n     reshaped = tf.reshape(in1_transposed, [in1_transposed.shape[0], in1_transposed.shape[1], 1])\n     return tf.tile(reshaped, [1, 1, 2])"
            ],
            "target-program": "tf.transpose(tf.cast((in1, in1), tf.float32))",
            "description": "reshape by separating and duplicating columns",
            "tf_operators": {
                "tf.transpose": 7,
                "tf.expand_dims": 7,
                "tf.tile": 4,
                "tf.reshape": 3,
                "tf.stack": 3,
                "tf.concat": 1,
                "tf.unstack": 1,
                "tf.shape": 2,
                "tf.broadcast_to": 1,
                "tf.repeat": 1
            },
            "coverage_percentage": 33.33333333333333,
            "total_in_target": 3,
            "total_covered": 1
        },
        "completions": [
            "in1 = tf.transpose(in1)\nreturn tf.expand_dims(in1, -1)",
            "return tf.expand_dims(tf.transpose(in1), axis=-1)",
            "a = tf.expand_dims(in1, axis=0)\nb = tf.transpose(a, perm=[2, 1, 0])\nreturn tf.tile(b, [1, 1, 2])",
            "x = tf.unstack(in1, axis=1)\nx = [tf.reshape(i, shape=(-1, 1)) for i in x]\nx = [tf.concat([i, i], axis=1) for i in x]\nreturn tf.stack(x)",
            "reshaped_input = tf.reshape(in1, [in1.shape[1], in1.shape[0], 1])\nreturn tf.tile(reshaped_input, [1, 1, 2])",
            "return tf.stack([tf.broadcast_to(tf.expand_dims(in1[:, i], -1), tf.shape(in1)) for i in range(in1.shape[1])], axis=0)",
            "a = tf.transpose(in1)\n     b = tf.expand_dims(a, axis=2)\n     c = tf.repeat(b, repeats=[2], axis=2)\n     return c",
            "# The task requires to reshape the input array by separating each column and replicating them into two.\n\n# Steps:\n# 1. Firstly, transpose the input array to separate the columns\n# 2. Duplicate each row in the transposed array.\n# 3. Finally, reshape the array to match the final desired shape.\n\nin1 = tf.transpose(in1)  # Transposing the input\n# Expanding dimensions to duplicate rows.\n# Expanding along axis 1 as we want to duplicate rows.\nin1 = tf.expand_dims(in1, axis=1)\n# Duplicating rows using tf.tile\nin1 = tf.tile(in1, multiples=[1, 2, 1])\nreturn in1  # Returning the reshaped array.",
            "return tf.stack([tf.expand_dims(tf.transpose(in1)[i], axis=0) for i in range(tf.shape(in1)[1])])",
            "in1_transposed = tf.transpose(in1)\n     reshaped = tf.reshape(in1_transposed, [in1_transposed.shape[0], in1_transposed.shape[1], 1])\n     return tf.tile(reshaped, [1, 1, 2])"
        ]
    },
    {
        "constants": "[1]",
        "description": "clip values that are greater than 1",
        "target_program": "tf.minimum(in1, tf.constant(1))",
        "source": "https://stackoverflow.com/questions/46408839/tensorflow-trim-values-in-tensor",
        "name": "stackoverflow_02",
        "examples": {
            "inputs": "[[5, 1, 0, 3, 0, -1, 2, -10, 2],]",
            "outputs": "[[1, 1, 0, 1, 0, -1, 1, -10, 1]]"
        },
        "response": {
            "task_id": "stackoverflow_02",
            "completions": [
                "return tf.clip_by_value(in1, -tf.constant(float('inf')), tf.constant(1.0))",
                "return tf.clip_by_value(in1, -tf.float32.max, 1)",
                "return tf.clip_by_value(in1, -tf.constant(float('inf')), 1)",
                "return tf.clip_by_value(in1, -tf.float32.max, 1)",
                "return tf.clip_by_value(in1, float('-inf'), 1)",
                "return tf.clip_by_value(in1, -np.inf, 1)",
                "return tf.clip_by_value(in1, -np.inf, 1)",
                "return tf.clip_by_value(in1, -np.inf, 1)",
                "return tf.clip_by_value(in1, -np.inf, 1)",
                "return tf.clip_by_value(in1, -tf.float32.max, 1)"
            ],
            "target-program": "tf.minimum(in1, tf.constant(1))",
            "description": "clip values that are greater than 1",
            "tf_operators": {
                "tf.constant": 2,
                "tf.clip_by_value": 10,
                "tf.float32.max": 3
            },
            "coverage_percentage": 50.0,
            "total_in_target": 2,
            "total_covered": 1
        },
        "completions": [
            "return tf.clip_by_value(in1, -tf.constant(float('inf')), tf.constant(1.0))",
            "return tf.clip_by_value(in1, -tf.float32.max, 1)",
            "return tf.clip_by_value(in1, -tf.constant(float('inf')), 1)",
            "return tf.clip_by_value(in1, -tf.float32.max, 1)",
            "return tf.clip_by_value(in1, float('-inf'), 1)",
            "return tf.clip_by_value(in1, -np.inf, 1)",
            "return tf.clip_by_value(in1, -np.inf, 1)",
            "return tf.clip_by_value(in1, -np.inf, 1)",
            "return tf.clip_by_value(in1, -np.inf, 1)",
            "return tf.clip_by_value(in1, -tf.float32.max, 1)"
        ]
    },
    {
        "constants": "[3, 4, 5]",
        "description": "replace certain columns with columns from the other tensor",
        "target_program": "tf.reduce_sum(tf.one_hot(tf.range(3, 5), depth=in1.shape[1], dtype=tf.int32), axis=0) * in2 + (1 - tf.reduce_sum(tf.one_hot(tf.range(3, 5), depth=in1.shape[1], dtype=tf.int32), axis=0)) * in1",
        "source": "https://stackoverflow.com/questions/44657388/how-to-replace-certain-values-in-tensorflow-tensor-with-the-values-of-the-other",
        "name": "stackoverflow_03",
        "examples": {
            "inputs": "[[[11, 22, 33, 44, 55, 66, 77], [70, 60, 50, 40, 30, 20, 10]],[[-9, -8, -7, -6, -5, -4, -3], [11, 12, 13, 14, 15, 16, 17]],]",
            "outputs": "[[[11, 22, 33, -6, -5, 66, 77], [70, 60, 50, 14, 15, 20, 10]]]"
        },
        "response": {
            "task_id": "stackoverflow_03",
            "completions": [
                "in1 = tf.constant(in1)\nin2 = tf.constant(in2)\n\ncols_to_replace = [3, 4]\nreplacement = tf.gather(in2, cols_to_replace, axis=1)\n\nmodified = tf.tensor_scatter_nd_update(in1, tf.constant([[0, j] for j in cols_to_replace]), replacement)\n\nreturn modified",
                "in1 = tf.constant(in1)\nin2 = tf.constant(in2)\nindices = tf.constant([[0,3], [0,4], [1,3], [1,4]])\nupdates = tf.gather_nd(in2, indices)\nreturn tf.tensor_scatter_nd_update(in1, indices, updates).numpy()",
                "in1 = tf.convert_to_tensor(in1)\nin2 = tf.convert_to_tensor(in2)\nindices = tf.constant([3, 4])\nupdated_tensor = tf.tensor_scatter_nd_update(in1, tf.reshape(indices, [-1, 1]), tf.gather(in2, indices, axis=1))\nreturn updated_tensor",
                "in1 = tf.constant(in1)\nin2 = tf.constant(in2)\nindices = tf.constant([[0, 3], [0, 4], [1, 3], [1, 4]])\nupdates = tf.gather_nd(in2, indices)\nout = tf.tensor_scatter_nd_update(in1, indices, updates)\nreturn out",
                "in1[:, [3, 4]] = in2[:, [3, 4]]\nreturn in1",
                "in1 = tf.constant(in1, dtype=tf.int32)\nin2 = tf.constant(in2, dtype=tf.int32)\nindices = tf.constant([3,4]) # indices of columns to replace\nin1 = tf.unstack(in1, axis=1)\nin2 = tf.unstack(in2, axis=1)\nfor i in indices:\n    in1[i] = in2[i]\nout = tf.stack(in1, axis=1)\nreturn out.eval(session=tf.Session())",
                "in1_tf = tf.constant(in1)\nin2_tf = tf.constant(in2)\nindices_to_replace = [3, 4]\nfor index in indices_to_replace:\n    in1_tf = tf.tensor_scatter_nd_update(in1_tf, [[0, index], [1, index]], in2_tf[:, index])\nreturn in1_tf",
                "in1 = tf.constant(in1)\nin2 = tf.constant(in2)\nin1 = tf.cast(in1, tf.float32)\nin2 = tf.cast(in2, tf.float32)\ncolumns_to_replace = [3,4]\nreplacement_columns = tf.gather(in2, columns_to_replace, axis=1)\nupdated = tf.tensor_scatter_nd_update(in1, tf.constant([[i] for i in columns_to_replace]), replacement_columns)\nreturn updated",
                "in1 = tf.constant(in1)\nin2 = tf.constant(in2)\nindices = tf.constant([[3, 4]])  \nupdates = tf.gather_nd(in2, indices)\nout = tf.tensor_scatter_nd_update(in1, indices, updates)\nreturn out",
                "indices = tf.constant([3, 4])\n     out = tf.tensor_scatter_nd_update(in1, tf.expand_dims(indices, axis=-1), tf.gather(in2, indices, axis=1))\n     return out"
            ],
            "target-program": "tf.reduce_sum(tf.one_hot(tf.range(3, 5), depth=in1.shape[1], dtype=tf.int32), axis=0) * in2 + (1 - tf.reduce_sum(tf.one_hot(tf.range(3, 5), depth=in1.shape[1], dtype=tf.int32), axis=0)) * in1",
            "description": "replace certain columns with columns from the other tensor",
            "tf_operators": {
                "tf.gather": 4,
                "tf.constant": 9,
                "tf.tensor_scatter_nd_update": 8,
                "tf.gather_nd": 3,
                "tf.reshape": 1,
                "tf.convert_to_tensor": 1,
                "tf.unstack": 1,
                "tf.stack": 1,
                "tf.Session": 1,
                "tf.int32": 1,
                "tf.cast": 1,
                "tf.float32": 1,
                "tf.expand_dims": 1
            },
            "coverage_percentage": 25.0,
            "total_in_target": 4,
            "total_covered": 1
        },
        "completions": [
            "in1 = tf.constant(in1)\nin2 = tf.constant(in2)\n\ncols_to_replace = [3, 4]\nreplacement = tf.gather(in2, cols_to_replace, axis=1)\n\nmodified = tf.tensor_scatter_nd_update(in1, tf.constant([[0, j] for j in cols_to_replace]), replacement)\n\nreturn modified",
            "in1 = tf.constant(in1)\nin2 = tf.constant(in2)\nindices = tf.constant([[0,3], [0,4], [1,3], [1,4]])\nupdates = tf.gather_nd(in2, indices)\nreturn tf.tensor_scatter_nd_update(in1, indices, updates).numpy()",
            "in1 = tf.convert_to_tensor(in1)\nin2 = tf.convert_to_tensor(in2)\nindices = tf.constant([3, 4])\nupdated_tensor = tf.tensor_scatter_nd_update(in1, tf.reshape(indices, [-1, 1]), tf.gather(in2, indices, axis=1))\nreturn updated_tensor",
            "in1 = tf.constant(in1)\nin2 = tf.constant(in2)\nindices = tf.constant([[0, 3], [0, 4], [1, 3], [1, 4]])\nupdates = tf.gather_nd(in2, indices)\nout = tf.tensor_scatter_nd_update(in1, indices, updates)\nreturn out",
            "in1[:, [3, 4]] = in2[:, [3, 4]]\nreturn in1",
            "in1 = tf.constant(in1, dtype=tf.int32)\nin2 = tf.constant(in2, dtype=tf.int32)\nindices = tf.constant([3,4]) # indices of columns to replace\nin1 = tf.unstack(in1, axis=1)\nin2 = tf.unstack(in2, axis=1)\nfor i in indices:\n    in1[i] = in2[i]\nout = tf.stack(in1, axis=1)\nreturn out.eval(session=tf.Session())",
            "in1_tf = tf.constant(in1)\nin2_tf = tf.constant(in2)\nindices_to_replace = [3, 4]\nfor index in indices_to_replace:\n    in1_tf = tf.tensor_scatter_nd_update(in1_tf, [[0, index], [1, index]], in2_tf[:, index])\nreturn in1_tf",
            "in1 = tf.constant(in1)\nin2 = tf.constant(in2)\nin1 = tf.cast(in1, tf.float32)\nin2 = tf.cast(in2, tf.float32)\ncolumns_to_replace = [3,4]\nreplacement_columns = tf.gather(in2, columns_to_replace, axis=1)\nupdated = tf.tensor_scatter_nd_update(in1, tf.constant([[i] for i in columns_to_replace]), replacement_columns)\nreturn updated",
            "in1 = tf.constant(in1)\nin2 = tf.constant(in2)\nindices = tf.constant([[3, 4]])  \nupdates = tf.gather_nd(in2, indices)\nout = tf.tensor_scatter_nd_update(in1, indices, updates)\nreturn out",
            "indices = tf.constant([3, 4])\n     out = tf.tensor_scatter_nd_update(in1, tf.expand_dims(indices, axis=-1), tf.gather(in2, indices, axis=1))\n     return out"
        ]
    },
    {
        "constants": "[]",
        "description": "index into the tensor",
        "target_program": "tf.gather_nd(in1, tf.stack((in2, in3), axis=-1))",
        "source": "https://stackoverflow.com/questions/33736795/tensorflow-numpy-like-tensor-indexing",
        "name": "stackoverflow_04",
        "examples": {
            "inputs": "[  [[5., 2.], [1., 3.], [0., -1.]]]",
            "outputs": "[[[5., 5.], [1., 1.], [0., 0.]],  [[2., 2.], [3., 3.], [-1., -1.]]]"
        },
        "response": {
            "task_id": "stackoverflow_04",
            "completions": [
                "return tf.transpose(in1)",
                "return tf.gather(in1, [0, 1], axis=1)",
                "return tf.transpose(in1)",
                "out = tf.stack([tf.gather(in1, i, axis=1) for i in range(tf.shape(in1)[1])], axis=0)\nreturn out",
                "return tf.transpose(in1)",
                "return tf.gather(in1, tf.constant([0, 1]), axis=1)",
                "return tf.transpose(tf.broadcast_to(in1, [2, 3, 2]))",
                "return tf.transpose(in1)",
                "return tf.transpose(tf.broadcast_to(in1, [in1.shape[1]] + list(in1.shape)))",
                "return tf.gather(in1, tf.range(tf.shape(in1)[1]), axis=1)"
            ],
            "target-program": "tf.gather_nd(in1, tf.stack((in2, in3), axis=-1))",
            "description": "index into the tensor",
            "tf_operators": {
                "tf.transpose": 6,
                "tf.gather": 4,
                "tf.shape": 2,
                "tf.stack": 1,
                "tf.constant": 1,
                "tf.broadcast_to": 2,
                "tf.range": 1
            },
            "coverage_percentage": 50.0,
            "total_in_target": 2,
            "total_covered": 1
        },
        "completions": [
            "return tf.transpose(in1)",
            "return tf.gather(in1, [0, 1], axis=1)",
            "return tf.transpose(in1)",
            "out = tf.stack([tf.gather(in1, i, axis=1) for i in range(tf.shape(in1)[1])], axis=0)\nreturn out",
            "return tf.transpose(in1)",
            "return tf.gather(in1, tf.constant([0, 1]), axis=1)",
            "return tf.transpose(tf.broadcast_to(in1, [2, 3, 2]))",
            "return tf.transpose(in1)",
            "return tf.transpose(tf.broadcast_to(in1, [in1.shape[1]] + list(in1.shape)))",
            "return tf.gather(in1, tf.range(tf.shape(in1)[1]), axis=1)"
        ]
    },
    {
        "constants": "[]",
        "description": "tensor multiplication like np.tensordot",
        "target_program": "tf.tensordot(in1, in2, 1)",
        "source": "https://stackoverflow.com/questions/43067338/tensor-multiplication-in-tensorflow",
        "name": "stackoverflow_05",
        "examples": {
            "inputs": "[[[4, 3, 1], [6, 5, 2]],[[[5, 5]], [[1, 5]], [[6, 0]]],]",
            "outputs": "[[[29, 35]], [[47, 55]]]"
        },
        "response": {
            "task_id": "stackoverflow_05",
            "completions": [
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1,in2,axes=1)",
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=1)"
            ],
            "target-program": "tf.tensordot(in1, in2, 1)",
            "description": "tensor multiplication like np.tensordot",
            "tf_operators": {
                "tf.tensordot": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1,in2,axes=1)",
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=1)"
        ]
    },
    {
        "constants": "[]",
        "description": "binary tensor from vector indicating if elements are equal",
        "target_program": "tf.cast(tf.equal(in1, tf.expand_dims(in1, 1)), tf.float32)",
        "source": "https://stackoverflow.com/questions/47816231/create-binary-tensor-from-vector-in-tensorflow",
        "name": "stackoverflow_06",
        "examples": {
            "inputs": "[[3, 5, 0, 2, 3, 3, 0],]",
            "outputs": "[[1., 0., 0., 0., 1., 1., 0.],    [0., 1., 0., 0., 0., 0., 0.],    [0., 0., 1., 0., 0., 0., 1.],    [0., 0., 0., 1., 0., 0., 0.],    [1., 0., 0., 0., 1., 1., 0.],    [1., 0., 0., 0., 1., 1., 0.],    [0., 0., 1., 0., 0., 0., 1.]]"
        },
        "response": {
            "task_id": "stackoverflow_06",
            "completions": [
                "return tf.cast(tf.equal(tf.expand_dims(in1, 0), tf.expand_dims(in1, 1)), dtype=tf.float32)",
                "return tf.cast(tf.equal(tf.expand_dims(in1, 1), tf.expand_dims(in1, 0)), tf.float32)",
                "return tf.cast(tf.equal(tf.expand_dims(in1, 1), tf.expand_dims(in1, 0)), tf.float32)",
                "matrix = tf.equal(in1[:, None], in1[None, :])\n    return tf.cast(matrix, tf.float32)",
                "return tf.cast(tf.equal(in1[:, None], in1), dtype=tf.float32)",
                "return tf.cast(tf.equal(tf.reshape(in1, [-1, 1]), in1), tf.float32)",
                "in1 = tf.constant(in1, dtype=tf.float32)\nin1_mat = tf.expand_dims(in1, 1)\ncomp_matrix = tf.equal(in1_mat, tf.transpose(in1_mat))\nbinary_matrix = tf.cast(comp_matrix, tf.float32)\nreturn binary_matrix",
                "return tf.cast(tf.equal(tf.expand_dims(in1, 1), tf.expand_dims(in1, 0)), tf.float32)",
                "in2 = tf.expand_dims(in1, -1)\nreturn tf.cast(tf.equal(in2, tf.transpose(in2)), tf.float32)",
                "matrix = tf.equal(in1[:, None], in1[None, :])\nbinary_matrix = tf.cast(matrix , tf.int32)\nreturn binary_matrix"
            ],
            "target-program": "tf.cast(tf.equal(in1, tf.expand_dims(in1, 1)), tf.float32)",
            "description": "binary tensor from vector indicating if elements are equal",
            "tf_operators": {
                "tf.expand_dims": 6,
                "tf.float32": 9,
                "tf.equal": 10,
                "tf.cast": 10,
                "tf.reshape": 1,
                "tf.transpose": 2,
                "tf.constant": 1,
                "tf.int32": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 4,
            "total_covered": 4
        },
        "completions": [
            "return tf.cast(tf.equal(tf.expand_dims(in1, 0), tf.expand_dims(in1, 1)), dtype=tf.float32)",
            "return tf.cast(tf.equal(tf.expand_dims(in1, 1), tf.expand_dims(in1, 0)), tf.float32)",
            "return tf.cast(tf.equal(tf.expand_dims(in1, 1), tf.expand_dims(in1, 0)), tf.float32)",
            "matrix = tf.equal(in1[:, None], in1[None, :])\n    return tf.cast(matrix, tf.float32)",
            "return tf.cast(tf.equal(in1[:, None], in1), dtype=tf.float32)",
            "return tf.cast(tf.equal(tf.reshape(in1, [-1, 1]), in1), tf.float32)",
            "in1 = tf.constant(in1, dtype=tf.float32)\nin1_mat = tf.expand_dims(in1, 1)\ncomp_matrix = tf.equal(in1_mat, tf.transpose(in1_mat))\nbinary_matrix = tf.cast(comp_matrix, tf.float32)\nreturn binary_matrix",
            "return tf.cast(tf.equal(tf.expand_dims(in1, 1), tf.expand_dims(in1, 0)), tf.float32)",
            "in2 = tf.expand_dims(in1, -1)\nreturn tf.cast(tf.equal(in2, tf.transpose(in2)), tf.float32)",
            "matrix = tf.equal(in1[:, None], in1[None, :])\nbinary_matrix = tf.cast(matrix , tf.int32)\nreturn binary_matrix"
        ]
    },
    {
        "constants": "[]",
        "description": "swap the first two dimensions of the tensor",
        "target_program": "tf.cast(tf.unstack(in1, axis=1), tf.int32)",
        "source": "https://stackoverflow.com/questions/38212205/swap-tensor-axes-in-tensorflow",
        "name": "stackoverflow_07",
        "examples": {
            "inputs": "[[[[8, 4, 6], [2, 12, 3]], [[11, 12, 5], [9, 12, 12]], [[9, 2, 13], [7, 0, 7]], [[2, 10, 5], [7, 1, 2]]],]",
            "outputs": "[[[8, 4, 6], [11, 12, 5], [9, 2, 13], [2, 10, 5]],    [[2, 12, 3], [9, 12, 12], [7, 0, 7], [7, 1, 2]]]"
        },
        "response": {
            "task_id": "stackoverflow_07",
            "completions": [
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])"
            ],
            "target-program": "tf.cast(tf.unstack(in1, axis=1), tf.int32)",
            "description": "swap the first two dimensions of the tensor",
            "tf_operators": {
                "tf.transpose": 10
            },
            "coverage_percentage": 0.0,
            "total_in_target": 3,
            "total_covered": 0
        },
        "completions": [
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])"
        ]
    },
    {
        "constants": "[1]",
        "description": "(\\'select the values in the second tensor where the first tensor is greater than 1\\')",
        "target_program": "tf.boolean_mask(in2, tf.greater(in1, tf.constant(1)))",
        "source": "https://stackoverflow.com/questions/33769041/tensorflow-indexing-with-boolean-tensor",
        "name": "stackoverflow_08",
        "examples": {
            "inputs": "[[-1, 0, -3, 2, 1, 3, 5, -1, -9, 2, 10],[12, 3, 45, 6, 7, 8, 9, 87, 65, 4, 32],]",
            "outputs": "[6, 8, 9, 4, 32]"
        },
        "response": {
            "task_id": "stackoverflow_08",
            "completions": [
                "return tf.boolean_mask(in2, tf.greater(in1, 1))",
                "mask = tf.greater(in1,1)\n     return tf.boolean_mask(in2, mask)",
                "return tf.boolean_mask(in2, tf.greater(in1, 1))",
                "mask = tf.greater(in1, 1)\nreturn tf.boolean_mask(in2, mask)",
                "return tf.boolean_mask(in2, tf.greater(in1,1))",
                "mask = tf.greater(in1, 1)\nout = tf.boolean_mask(in2, mask)\nreturn out",
                "return tf.boolean_mask(in2, tf.greater(in1, 1))",
                "condition = tf.greater(in1, 1)\n     return tf.boolean_mask(in2, condition)",
                "mask = tf.greater(in1, 1)\nreturn tf.boolean_mask(in2, mask)",
                "condition = tf.greater(in1, 1)\n     result = tf.boolean_mask(in2, condition)\n     return result"
            ],
            "target-program": "tf.boolean_mask(in2, tf.greater(in1, tf.constant(1)))",
            "description": "(\\'select the values in the second tensor where the first tensor is greater than 1\\')",
            "tf_operators": {
                "tf.greater": 10,
                "tf.boolean_mask": 10
            },
            "coverage_percentage": 66.66666666666666,
            "total_in_target": 3,
            "total_covered": 2
        },
        "completions": [
            "return tf.boolean_mask(in2, tf.greater(in1, 1))",
            "mask = tf.greater(in1,1)\n     return tf.boolean_mask(in2, mask)",
            "return tf.boolean_mask(in2, tf.greater(in1, 1))",
            "mask = tf.greater(in1, 1)\nreturn tf.boolean_mask(in2, mask)",
            "return tf.boolean_mask(in2, tf.greater(in1,1))",
            "mask = tf.greater(in1, 1)\nout = tf.boolean_mask(in2, mask)\nreturn out",
            "return tf.boolean_mask(in2, tf.greater(in1, 1))",
            "condition = tf.greater(in1, 1)\n     return tf.boolean_mask(in2, condition)",
            "mask = tf.greater(in1, 1)\nreturn tf.boolean_mask(in2, mask)",
            "condition = tf.greater(in1, 1)\n     result = tf.boolean_mask(in2, condition)\n     return result"
        ]
    },
    {
        "constants": "[]",
        "description": "group items by value and get the group indices",
        "target_program": "tf.unique_with_counts(in1)[1]",
        "source": "https://stackoverflow.com/questions/53054668/assign-values-between-0-and-n-1-for-a-vector-of-length-l-with-n-different-eleme",
        "name": "stackoverflow_09",
        "examples": {
            "inputs": "[[37, 42, 42, 37, 28, 15, 42, 15],]",
            "outputs": "[0, 1, 1, 0, 2, 3, 1, 3]"
        },
        "response": {
            "task_id": "stackoverflow_09",
            "completions": [
                "_, idx = tf.unique_with_counts(in1)\nreturn idx",
                "_, ids = tf.unique_with_counts(in1)\nreturn tf.gather(ids, in1)",
                "_, idx = tf.unique_with_counts(in1)\nreturn tf.gather(idx, tf.argsort(in1))",
                "_, idx, count = tf.unique_with_counts(in1)\noutput = tf.gather(idx, in1)\nreturn output",
                "_, idx = tf.unique_with_counts(in1)\nreturn idx",
                "_, idx = tf.unique_with_counts(in1)\nreturn tf.gather(idx, tf.argsort(in1))",
                "_, idx = tf.unique(in1)\nreturn idx.numpy()",
                "_, idx = tf.unique(in1)\nreturn idx",
                "_, idx = tf.unique_with_counts(in1)\nreturn idx",
                "_, idx = tf.unique(in1)\nreturn idx"
            ],
            "target-program": "tf.unique_with_counts(in1)[1]",
            "description": "group items by value and get the group indices",
            "tf_operators": {
                "tf.unique_with_counts": 7,
                "tf.gather": 4,
                "tf.argsort": 2,
                "tf.unique": 3
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "_, idx = tf.unique_with_counts(in1)\nreturn idx",
            "_, ids = tf.unique_with_counts(in1)\nreturn tf.gather(ids, in1)",
            "_, idx = tf.unique_with_counts(in1)\nreturn tf.gather(idx, tf.argsort(in1))",
            "_, idx, count = tf.unique_with_counts(in1)\noutput = tf.gather(idx, in1)\nreturn output",
            "_, idx = tf.unique_with_counts(in1)\nreturn idx",
            "_, idx = tf.unique_with_counts(in1)\nreturn tf.gather(idx, tf.argsort(in1))",
            "_, idx = tf.unique(in1)\nreturn idx.numpy()",
            "_, idx = tf.unique(in1)\nreturn idx",
            "_, idx = tf.unique_with_counts(in1)\nreturn idx",
            "_, idx = tf.unique(in1)\nreturn idx"
        ]
    },
    {
        "constants": "[]",
        "description": "perform matrix multiplication",
        "target_program": "tf.matmul(tf.expand_dims(in1, -1), tf.expand_dims(in2, 1))",
        "source": "https://stackoverflow.com/questions/53094212/tensorflow-sxn-matrix-multiply-with-sxd-matrix-to-output-sxnxd-array",
        "name": "stackoverflow_10",
        "examples": {
            "inputs": "[[[15, 10], [20, -5]],[[2, 3, 1], [-2, 5, 0]],]",
            "outputs": "[[[30, 45, 15], [20, 30, 10]],[[-40, 100, 0], [10, -25, 0]]]"
        },
        "response": {
            "task_id": "stackoverflow_10",
            "completions": [
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1,in2)",
                "return tf.matmul(in1,in2)"
            ],
            "target-program": "tf.matmul(tf.expand_dims(in1, -1), tf.expand_dims(in2, 1))",
            "description": "perform matrix multiplication",
            "tf_operators": {
                "tf.matmul": 10
            },
            "coverage_percentage": 50.0,
            "total_in_target": 2,
            "total_covered": 1
        },
        "completions": [
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1,in2)",
            "return tf.matmul(in1,in2)"
        ]
    },
    {
        "constants": "[]",
        "description": "count the number of occurences of each distinct number",
        "target_program": "tf.math.bincount(in1)",
        "source": "https://stackoverflow.com/questions/45194672/how-to-count-elements-in-tensorflow-tensor",
        "name": "stackoverflow_11",
        "examples": {
            "inputs": "[[4, 0, 1, 1, 0, 4, 0, 0, 3, 4, 1],]",
            "outputs": "[4, 3, 0, 1, 3]"
        },
        "response": {
            "task_id": "stackoverflow_11",
            "completions": [
                "return tf.math.bincount(in1)",
                "return tf.math.bincount(in1)",
                "return tf.math.bincount(in1)",
                "return tf.math.bincount(in1)",
                "return tf.math.bincount(in1)",
                "return tf.math.bincount(in1)",
                "return tf.math.bincount(tf.cast(in1, dtype=tf.int32)).numpy()",
                "return tf.math.bincount(in1)",
                "return tf.math.bincount(in1)",
                "return tf.math.bincount(in1)"
            ],
            "target-program": "tf.math.bincount(in1)",
            "description": "count the number of occurences of each distinct number",
            "tf_operators": {
                "tf.math.bincount": 10,
                "tf.cast": 1,
                "tf.int32": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.math.bincount(in1)",
            "return tf.math.bincount(in1)",
            "return tf.math.bincount(in1)",
            "return tf.math.bincount(in1)",
            "return tf.math.bincount(in1)",
            "return tf.math.bincount(in1)",
            "return tf.math.bincount(tf.cast(in1, dtype=tf.int32)).numpy()",
            "return tf.math.bincount(in1)",
            "return tf.math.bincount(in1)",
            "return tf.math.bincount(in1)"
        ]
    },
    {
        "constants": "[0, 1, 2]",
        "description": "remove a column from the tensor",
        "target_program": "tf.gather(in1, (0, 2), axis=1, batch_dims=0)",
        "source": "https://stackoverflow.com/questions/47447183/remove-a-set-of-tensors-from-a-tensor-in-tensorflow",
        "name": "stackoverflow_12",
        "examples": {
            "inputs": "[[[12, 34, 56], [33, 22, 11]]]",
            "outputs": "[[12, 56], [33, 11]]"
        },
        "response": {
            "task_id": "stackoverflow_12",
            "completions": [
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.gather(in1, indices=[0,2], axis=1)",
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.reshape(tf.gather(in1, [0,2], axis=1), [-1, 2])"
            ],
            "target-program": "tf.gather(in1, (0, 2), axis=1, batch_dims=0)",
            "description": "remove a column from the tensor",
            "tf_operators": {
                "tf.gather": 10,
                "tf.reshape": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.gather(in1, indices=[0,2], axis=1)",
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.reshape(tf.gather(in1, [0,2], axis=1), [-1, 2])"
        ]
    },
    {
        "constants": "[]",
        "description": "multiply vectors by tensor",
        "target_program": "tf.tensordot(in1, in2, (1, 1))",
        "source": "https://stackoverflow.com/questions/50777704/n-d-tensor-matrix-multiplication-with-tensorflow",
        "name": "stackoverflow_13",
        "examples": {
            "inputs": "[[[3, 5], [10, 2]],[[[1, 0], [5, 4]], [[3, 10], [2, -2]]],]",
            "outputs": "[[[28, 20], [19, 20]], [[20, 8], [34, 96]]]"
        },
        "response": {
            "task_id": "stackoverflow_13",
            "completions": [
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, tf.transpose(in2, perm=[0, 2, 1]))",
                "return tf.matmul(in2, tf.expand_dims(in1, -1)).numpy().reshape(in2.shape)",
                "return tf.matmul(in2, tf.expand_dims(in1, 2))[:,:,0]",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in2, tf.expand_dims(in1, -1))[:,:,0]",
                "return tf.matmul(in2, tf.expand_dims(in1, -1))[:, :, 0]",
                "return tf.matmul(in2, tf.transpose(in1))",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in2, tf.transpose(in1))"
            ],
            "target-program": "tf.tensordot(in1, in2, (1, 1))",
            "description": "multiply vectors by tensor",
            "tf_operators": {
                "tf.matmul": 10,
                "tf.transpose": 3,
                "tf.expand_dims": 4
            },
            "coverage_percentage": 0.0,
            "total_in_target": 1,
            "total_covered": 0
        },
        "completions": [
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, tf.transpose(in2, perm=[0, 2, 1]))",
            "return tf.matmul(in2, tf.expand_dims(in1, -1)).numpy().reshape(in2.shape)",
            "return tf.matmul(in2, tf.expand_dims(in1, 2))[:,:,0]",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in2, tf.expand_dims(in1, -1))[:,:,0]",
            "return tf.matmul(in2, tf.expand_dims(in1, -1))[:, :, 0]",
            "return tf.matmul(in2, tf.transpose(in1))",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in2, tf.transpose(in1))"
        ]
    },
    {
        "constants": "[]",
        "description": "choose True if any value in a row is True, False otherwise",
        "target_program": "tf.reduce_any(in1, axis=-1)",
        "source": "https://stackoverflow.com/questions/35657003/aggregate-each-element-of-tensor-in-tensorflow",
        "name": "stackoverflow_14",
        "examples": {
            "inputs": "[[[[False, False, True],  [False, False, False],  [True, False, True],  [False, True, False],  [False, False, False],  [True, True, True],  [True, True, False]]],]",
            "outputs": "[[True, False, True, True, False, True, True]]"
        },
        "response": {
            "task_id": "stackoverflow_14",
            "completions": [
                "return tf.reduce_any(in1, axis=-1)",
                "return tf.reduce_any(in1, axis=2)",
                "return tf.reduce_any(in1, axis=-1)",
                "return tf.reduce_any(in1, axis=-1)",
                "return tf.reduce_any(in1, axis=2)",
                "return tf.reduce_any(in1, axis=2)",
                "return tf.reduce_any(in1, axis=2)",
                "return tf.reduce_any(in1, axis=2)",
                "return tf.reduce_any(in1, axis=2)",
                "return tf.reduce_any(in1, axis=-1)"
            ],
            "target-program": "tf.reduce_any(in1, axis=-1)",
            "description": "choose True if any value in a row is True, False otherwise",
            "tf_operators": {
                "tf.reduce_any": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.reduce_any(in1, axis=-1)",
            "return tf.reduce_any(in1, axis=2)",
            "return tf.reduce_any(in1, axis=-1)",
            "return tf.reduce_any(in1, axis=-1)",
            "return tf.reduce_any(in1, axis=2)",
            "return tf.reduce_any(in1, axis=2)",
            "return tf.reduce_any(in1, axis=2)",
            "return tf.reduce_any(in1, axis=2)",
            "return tf.reduce_any(in1, axis=2)",
            "return tf.reduce_any(in1, axis=-1)"
        ]
    },
    {
        "constants": "[0, 1]",
        "description": "set all instances of 1 to 0",
        "target_program": "tf.subtract(in1, tf.cast(tf.equal(in1, tf.constant(1)), tf.int32))",
        "source": "https://stackoverflow.com/questions/39045797/conditional-assignment-of-tensor-values-in-tensorflow",
        "name": "stackoverflow_15",
        "examples": {
            "inputs": "[[3, 1, 2, 0, 1, -1, 10, 1, -10],]",
            "outputs": "[3, 0, 2, 0, 0, -1, 10, 0, -10]"
        },
        "response": {
            "task_id": "stackoverflow_15",
            "completions": [
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), tf.zeros_like(in1), in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), tf.zeros_like(in1), in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)"
            ],
            "target-program": "tf.subtract(in1, tf.cast(tf.equal(in1, tf.constant(1)), tf.int32))",
            "description": "set all instances of 1 to 0",
            "tf_operators": {
                "tf.equal": 10,
                "tf.where": 10,
                "tf.zeros_like": 2
            },
            "coverage_percentage": 20.0,
            "total_in_target": 5,
            "total_covered": 1
        },
        "completions": [
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), tf.zeros_like(in1), in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), tf.zeros_like(in1), in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)"
        ]
    },
    {
        "constants": "[]",
        "description": "multiply tensors across the first axis",
        "target_program": "tf.multiply(in1, tf.expand_dims(in2, 1))",
        "source": "https://stackoverflow.com/questions/46240646/tensor-multiply-along-axis-in-tensorflow",
        "name": "stackoverflow_16",
        "examples": {
            "inputs": "[[[2, 5], [3, 0], [8, -7]],[4, 10, -6],]",
            "outputs": "[[8, 20], [30, 0], [-48, 42]]"
        },
        "response": {
            "task_id": "stackoverflow_16",
            "completions": [
                "return tf.multiply(in1, tf.expand_dims(in2, axis=-1))",
                "return tf.multiply(in1, tf.expand_dims(in2, 1))",
                "return tf.multiply(in1, tf.expand_dims(in2, axis=-1))",
                "return tf.multiply(in1, tf.expand_dims(in2, axis=1))",
                "return tf.multiply(in1, tf.expand_dims(in2, axis=1))",
                "return tf.multiply(in1, tf.expand_dims(in2, axis=1))",
                "return tf.multiply(in1, tf.expand_dims(in2, axis=1))",
                "return tf.multiply(in1, tf.expand_dims(in2, 1))",
                "return tf.multiply(in1, tf.expand_dims(in2, axis=1))",
                "return tf.multiply(in1, tf.expand_dims(in2, 1))"
            ],
            "target-program": "tf.multiply(in1, tf.expand_dims(in2, 1))",
            "description": "multiply tensors across the first axis",
            "tf_operators": {
                "tf.multiply": 10,
                "tf.expand_dims": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 2,
            "total_covered": 2
        },
        "completions": [
            "return tf.multiply(in1, tf.expand_dims(in2, axis=-1))",
            "return tf.multiply(in1, tf.expand_dims(in2, 1))",
            "return tf.multiply(in1, tf.expand_dims(in2, axis=-1))",
            "return tf.multiply(in1, tf.expand_dims(in2, axis=1))",
            "return tf.multiply(in1, tf.expand_dims(in2, axis=1))",
            "return tf.multiply(in1, tf.expand_dims(in2, axis=1))",
            "return tf.multiply(in1, tf.expand_dims(in2, axis=1))",
            "return tf.multiply(in1, tf.expand_dims(in2, 1))",
            "return tf.multiply(in1, tf.expand_dims(in2, axis=1))",
            "return tf.multiply(in1, tf.expand_dims(in2, 1))"
        ]
    },
    {
        "constants": "[]",
        "description": "duplicate each element of a tensor",
        "target_program": "tf.stack((in1, in1), axis=1)",
        "source": "https://stackoverflow.com/questions/51761353/about-tensor-of-tensorflow",
        "name": "stackoverflow_17",
        "examples": {
            "inputs": "[[17, -32, 99],]",
            "outputs": "[[17, 17], [-32, -32], [99, 99]]"
        },
        "response": {
            "task_id": "stackoverflow_17",
            "completions": [
                "return tf.repeat(in1, repeats=2, axis=-1)",
                "return tf.repeat(in1, repeats=2, axis=-1)",
                "return tf.reshape(tf.repeat(in1, 2), [tf.shape(in1)[0], 2])",
                "return tf.repeat(in1, repeats=2, axis=-1)",
                "return tf.reshape(tf.repeat(in1, repeats = 2), [tf.shape(in1)[0], 2])",
                "return tf.reshape(tf.repeat(in1, 2), [in1.shape[0], 2])",
                "return tf.repeat(in1, 2, axis=-1)",
                "return tf.tile(tf.expand_dims(in1, axis=-1), [1, 2])",
                "return tf.tile(tf.expand_dims(in1, axis=1), [1, 2])",
                "return tf.repeat(in1[:, tf.newaxis], 2, axis=-1)"
            ],
            "target-program": "tf.stack((in1, in1), axis=1)",
            "description": "duplicate each element of a tensor",
            "tf_operators": {
                "tf.repeat": 8,
                "tf.shape": 2,
                "tf.reshape": 3,
                "tf.tile": 2,
                "tf.expand_dims": 2,
                "tf.newaxis": 1
            },
            "coverage_percentage": 0.0,
            "total_in_target": 1,
            "total_covered": 0
        },
        "completions": [
            "return tf.repeat(in1, repeats=2, axis=-1)",
            "return tf.repeat(in1, repeats=2, axis=-1)",
            "return tf.reshape(tf.repeat(in1, 2), [tf.shape(in1)[0], 2])",
            "return tf.repeat(in1, repeats=2, axis=-1)",
            "return tf.reshape(tf.repeat(in1, repeats = 2), [tf.shape(in1)[0], 2])",
            "return tf.reshape(tf.repeat(in1, 2), [in1.shape[0], 2])",
            "return tf.repeat(in1, 2, axis=-1)",
            "return tf.tile(tf.expand_dims(in1, axis=-1), [1, 2])",
            "return tf.tile(tf.expand_dims(in1, axis=1), [1, 2])",
            "return tf.repeat(in1[:, tf.newaxis], 2, axis=-1)"
        ]
    },
    {
        "constants": "[]",
        "description": "multiply 3D tensor and 2D tensor and add another tensor",
        "target_program": "tf.add(in3, tf.matmul(in1, in2))",
        "source": "https://stackoverflow.com/questions/38222126/tensorflow-efficient-way-for-tensor-multiplication",
        "name": "stackoverflow_18",
        "examples": {
            "inputs": "[[[[1, 1, 1], [1, 0, 1]], [[1, 2, 3], [4, 5, 6]]], [[1, 1, 1, 1], [1, 2, 3, 4], [5, 6, 7, 8]], [100, 200, 300, 400],]",
            "outputs": "[[[107, 209, 311, 413], [106, 207, 308, 409]], [[118, 223, 328, 433], [139, 250, 361, 472]]]"
        },
        "response": {
            "task_id": "stackoverflow_18",
            "completions": [
                "expanded_tensor = tf.expand_dims(in1, -1)\n    mult = tf.matmul(expanded_tensor, in2)\n    summed = tf.squeeze(mult, axis=-2) + in3\n    return summed",
                "intermediate = tf.tensordot(in1, in2, [[2], [0]])\nreturn tf.add(intermediate, in3)",
                "expanded_in1 = tf.expand_dims(in1, -1)\nmul_result = tf.matmul(expanded_in1, in2)\nflat_in3 = tf.expand_dims(in3, 0)\nresult = tf.add(mul_result, flat_in3)\nreturn result",
                "intermediate = tf.tensordot(in1, in2, axes=1)\nresult = tf.add(intermediate, in3)\nreturn result",
                "return tf.add(tf.matmul(in1, in2), in3)",
                "result = tf.add(tf.tensordot(in1, in2, axes=1), in3)\nreturn result",
                "in1 = tf.expand_dims(in1, -1)\nresult = tf.add(tf.matmul(in1, in2), in3)\nreturn result",
                "result = tf.add(tf.matmul(in1, in2), in3)\nreturn result",
                "a = tf.tensordot(in1, in2, axes=1)\n     return tf.add(a, in3)",
                "inter = tf.tensordot(in1, in2, axes=1)\noutput = tf.add(inter, in3)\nreturn output"
            ],
            "target-program": "tf.add(in3, tf.matmul(in1, in2))",
            "description": "multiply 3D tensor and 2D tensor and add another tensor",
            "tf_operators": {
                "tf.squeeze": 1,
                "tf.expand_dims": 3,
                "tf.matmul": 5,
                "tf.add": 9,
                "tf.tensordot": 5
            },
            "coverage_percentage": 100.0,
            "total_in_target": 2,
            "total_covered": 2
        },
        "completions": [
            "expanded_tensor = tf.expand_dims(in1, -1)\n    mult = tf.matmul(expanded_tensor, in2)\n    summed = tf.squeeze(mult, axis=-2) + in3\n    return summed",
            "intermediate = tf.tensordot(in1, in2, [[2], [0]])\nreturn tf.add(intermediate, in3)",
            "expanded_in1 = tf.expand_dims(in1, -1)\nmul_result = tf.matmul(expanded_in1, in2)\nflat_in3 = tf.expand_dims(in3, 0)\nresult = tf.add(mul_result, flat_in3)\nreturn result",
            "intermediate = tf.tensordot(in1, in2, axes=1)\nresult = tf.add(intermediate, in3)\nreturn result",
            "return tf.add(tf.matmul(in1, in2), in3)",
            "result = tf.add(tf.tensordot(in1, in2, axes=1), in3)\nreturn result",
            "in1 = tf.expand_dims(in1, -1)\nresult = tf.add(tf.matmul(in1, in2), in3)\nreturn result",
            "result = tf.add(tf.matmul(in1, in2), in3)\nreturn result",
            "a = tf.tensordot(in1, in2, axes=1)\n     return tf.add(a, in3)",
            "inter = tf.tensordot(in1, in2, axes=1)\noutput = tf.add(inter, in3)\nreturn output"
        ]
    },
    {
        "constants": "[]",
        "description": "(\\'sort a tensor considering the first column, breaking ties using the second column\\')",
        "target_program": "tf.gather(tf.gather(in1, tf.argsort(in1[:, 1], stable=True)), tf.argsort(tf.gather(in1, tf.argsort(in1[:, 1], stable=True))[:, 0], stable=True))",
        "source": "https://stackoverflow.com/questions/49399198/sort-a-tensor-based-on-two-columns-in-tensorflow",
        "name": "stackoverflow_19",
        "examples": {
            "inputs": "[[[3, 1, 2], [1, 0, 4], [1, 2, 3], [0, 5, 1], [1, 1, 2], [2, 3, 1], [2, 1, 0]],]",
            "outputs": "[[0, 5, 1],    [1, 0, 4],    [1, 1, 2],    [1, 2, 3],    [2, 1, 0],    [2, 3, 1],    [3, 1, 2]]"
        },
        "response": {
            "task_id": "stackoverflow_19",
            "completions": [
                "return tf.sort(in1, axis=0)",
                "return tf.sort(in1, axis=0)",
                "return tf.sort(in1, axis=0)",
                "return tf.argsort(in1, axis=0, stable=True)",
                "return tf.sort(in1, axis=0)",
                "return tf.argsort(in1, axis=0)",
                "return tf.argsort(in1, axis=0, stable=True)",
                "return tf.sort(in1, axis=0)",
                "return tf.sort(in1, axis=0)",
                "return tf.sort(in1, axis=0)"
            ],
            "target-program": "tf.gather(tf.gather(in1, tf.argsort(in1[:, 1], stable=True)), tf.argsort(tf.gather(in1, tf.argsort(in1[:, 1], stable=True))[:, 0], stable=True))",
            "description": "(\\'sort a tensor considering the first column, breaking ties using the second column\\')",
            "tf_operators": {
                "tf.sort": 7,
                "tf.argsort": 3
            },
            "coverage_percentage": 50.0,
            "total_in_target": 2,
            "total_covered": 1
        },
        "completions": [
            "return tf.sort(in1, axis=0)",
            "return tf.sort(in1, axis=0)",
            "return tf.sort(in1, axis=0)",
            "return tf.argsort(in1, axis=0, stable=True)",
            "return tf.sort(in1, axis=0)",
            "return tf.argsort(in1, axis=0)",
            "return tf.argsort(in1, axis=0, stable=True)",
            "return tf.sort(in1, axis=0)",
            "return tf.sort(in1, axis=0)",
            "return tf.sort(in1, axis=0)"
        ]
    },
    {
        "constants": "[]",
        "description": "compute argmax in each tensor and set it to 1",
        "target_program": "tf.cast(tf.one_hot(tf.argmax(in1, axis=1), 3), tf.int32)",
        "source": "https://stackoverflow.com/questions/44834739/argmax-on-a-tensor-and-ceiling-in-tensorflow",
        "name": "stackoverflow_20",
        "examples": {
            "inputs": "[[[0.7, 0.2, 0.1], [0.4, 0.5, 0.1], [0.4, 0.4, 0.2], [0.3, 0.4, 0.3], [0.0, 0.0, 1.0]],]",
            "outputs": "[[1, 0, 0],    [0, 1, 0],    [1, 0, 0],    [0, 1, 0],    [0, 0, 1]]"
        },
        "response": {
            "task_id": "stackoverflow_20",
            "completions": [
                "# First find the indices of the maximum values in each tensor\n    max_indices = tf.argmax(in1, axis=1)\n    # Use one_hot to set the maximum values to 1.\n    result = tf.one_hot(max_indices, depth=in1.shape[1])\n    return result",
                "# Find the indices of maximum values along the last axis.\n    max_indices = tf.argmax(in1, axis=-1)\n    # Create a mask whose shape matches the input and set all elements to False initially.\n    mask = tf.zeros_like(in1, dtype=tf.bool)\n    # Convert the indices of maximum values to a 2D shape, where each row correspond to the index\n    # in each tensor of the input.\n    row_indices = tf.range(tf.shape(in1, out_type=max_indices.dtype)[0])[:, None]\n    max_indices = tf.concat([row_indices, max_indices[:, None]], axis=-1)\n    # Set the elements at the indices of maximum values to True.\n    mask = tf.tensor_scatter_nd_update(mask, max_indices, tf.ones_like(max_indices, dtype=tf.bool)[:, :, 0])\n    # Convert the boolean mask to integers.\n    return tf.cast(mask, in1.dtype)",
                "max_indices = tf.argmax(in1, axis=1)\noutput = tf.one_hot(max_indices, depth=in1.shape[1])\nreturn tf.cast(output, dtype=in1.dtype)",
                "argmax = tf.argmax(in1, axis=1)\nindices = tf.range(tf.shape(in1)[0], dtype=argmax.dtype)\nindices_argmax = tf.transpose(tf.stack([indices, argmax]))\nreturn tf.tensor_scatter_nd_update(tf.zeros_like(in1), indices_argmax, tf.ones(tf.shape(in1)[0]))",
                "# We first compute argmax across axis 1 (columns)\n    ind = tf.argmax(in1, 1)\n\n    # Calculate number of rows in the input tensor\n    row_num = tf.shape(in1)[0]\n\n    # Create a range tensor from 0 to the number of rows\n    ind_range = tf.range(row_num)\n\n    # Reshape argmax tensor from vector to a tensor\n    ind = tf.expand_dims(ind, -1)\n\n    # Create a tensor of indices by vertically stacking the range and argmax tensors\n    ind_concat = tf.concat([ind_range, ind], 1)\n\n    # Form updates for the scatter operation\n    updates = tf.fill([row_num], 1.)\n\n    # We then set a 1 to each argmax index of the tensor\n    result = tf.tensor_scatter_nd_update(tf.zeros_like(in1), ind_concat, updates)\n\n    # Cast result to int\n    result = tf.cast(result, tf.int32)\n\n    return result",
                "indices = tf.argmax(in1, axis=1)\noutput = tf.one_hot(indices, depth=in1.shape[1])\nreturn output.numpy().astype(int)",
                "argmax = tf.argmax(in1, axis=-1)\nshape = tf.shape(in1)\nmask = tf.one_hot(argmax, shape[-1])\nreturn tf.cast(mask, tf.int32)",
                "argmax_indices = tf.argmax(in1, axis=1)\none_hot_matrix = tf.one_hot(argmax_indices, depth=in1.shape[1])\nreturn tf.cast(one_hot_matrix, dtype=tf.int32)",
                "# Get the indices of the maximum element in each row\nmax_indices = tf.argmax(in1, axis=1)\n\n# Create a zero tensor of the same shape as the input\nout = tf.zeros_like(in1, dtype=tf.int32)\n\n# Get the indices of the elements in the tensor\nindices = tf.range(tf.shape(in1, out_type=tf.int64)[0])\n\n# Combine the indices with the max_indices\ncombined_indices = tf.transpose([indices, max_indices])\n\n# Update the output tensor with 1s at the positions of the maximum elements\nout = tf.tensor_scatter_nd_update(out, combined_indices, tf.ones(tf.shape(max_indices, out_type=tf.int32),  dtype=tf.int32))\n\nreturn out",
                "# Compute the argmax of each tensor along the last axis (axis=-1)\n    tensor_argmax_index = tf.argmax(in1, axis=-1)\n\n    # The shape of tensor_argmax_index is (5,) (1-rank tensor)\n    # Convert it to a 2-rank tensor with shape (5,1)\n    # which will be useful for scatter_nd\n    tensor_argmax_index = tf.expand_dims(tensor_argmax_index, axis=-1)\n\n    # Prepare updates, which consist of all ones\n    updates = tf.ones_like(tensor_argmax_index)\n    \n    # The desired output tensor has the same shape with 'in1'\n    desired_shape = tf.shape(in1)\n\n    # Use scatter_nd to place the updates at the correct indices\n    result = tf.scatter_nd(tensor_argmax_index, updates, desired_shape)\n\n    return result"
            ],
            "target-program": "tf.cast(tf.one_hot(tf.argmax(in1, axis=1), 3), tf.int32)",
            "description": "compute argmax in each tensor and set it to 1",
            "tf_operators": {
                "tf.one_hot": 5,
                "tf.argmax": 10,
                "tf.shape": 6,
                "tf.bool": 1,
                "tf.cast": 5,
                "tf.ones_like": 2,
                "tf.zeros_like": 4,
                "tf.concat": 2,
                "tf.range": 4,
                "tf.tensor_scatter_nd_update": 4,
                "tf.transpose": 2,
                "tf.stack": 1,
                "tf.ones": 2,
                "tf.fill": 1,
                "tf.int32": 4,
                "tf.expand_dims": 2,
                "tf.int64": 1,
                "tf.scatter_nd": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 4,
            "total_covered": 4
        },
        "completions": [
            "# First find the indices of the maximum values in each tensor\n    max_indices = tf.argmax(in1, axis=1)\n    # Use one_hot to set the maximum values to 1.\n    result = tf.one_hot(max_indices, depth=in1.shape[1])\n    return result",
            "# Find the indices of maximum values along the last axis.\n    max_indices = tf.argmax(in1, axis=-1)\n    # Create a mask whose shape matches the input and set all elements to False initially.\n    mask = tf.zeros_like(in1, dtype=tf.bool)\n    # Convert the indices of maximum values to a 2D shape, where each row correspond to the index\n    # in each tensor of the input.\n    row_indices = tf.range(tf.shape(in1, out_type=max_indices.dtype)[0])[:, None]\n    max_indices = tf.concat([row_indices, max_indices[:, None]], axis=-1)\n    # Set the elements at the indices of maximum values to True.\n    mask = tf.tensor_scatter_nd_update(mask, max_indices, tf.ones_like(max_indices, dtype=tf.bool)[:, :, 0])\n    # Convert the boolean mask to integers.\n    return tf.cast(mask, in1.dtype)",
            "max_indices = tf.argmax(in1, axis=1)\noutput = tf.one_hot(max_indices, depth=in1.shape[1])\nreturn tf.cast(output, dtype=in1.dtype)",
            "argmax = tf.argmax(in1, axis=1)\nindices = tf.range(tf.shape(in1)[0], dtype=argmax.dtype)\nindices_argmax = tf.transpose(tf.stack([indices, argmax]))\nreturn tf.tensor_scatter_nd_update(tf.zeros_like(in1), indices_argmax, tf.ones(tf.shape(in1)[0]))",
            "# We first compute argmax across axis 1 (columns)\n    ind = tf.argmax(in1, 1)\n\n    # Calculate number of rows in the input tensor\n    row_num = tf.shape(in1)[0]\n\n    # Create a range tensor from 0 to the number of rows\n    ind_range = tf.range(row_num)\n\n    # Reshape argmax tensor from vector to a tensor\n    ind = tf.expand_dims(ind, -1)\n\n    # Create a tensor of indices by vertically stacking the range and argmax tensors\n    ind_concat = tf.concat([ind_range, ind], 1)\n\n    # Form updates for the scatter operation\n    updates = tf.fill([row_num], 1.)\n\n    # We then set a 1 to each argmax index of the tensor\n    result = tf.tensor_scatter_nd_update(tf.zeros_like(in1), ind_concat, updates)\n\n    # Cast result to int\n    result = tf.cast(result, tf.int32)\n\n    return result",
            "indices = tf.argmax(in1, axis=1)\noutput = tf.one_hot(indices, depth=in1.shape[1])\nreturn output.numpy().astype(int)",
            "argmax = tf.argmax(in1, axis=-1)\nshape = tf.shape(in1)\nmask = tf.one_hot(argmax, shape[-1])\nreturn tf.cast(mask, tf.int32)",
            "argmax_indices = tf.argmax(in1, axis=1)\none_hot_matrix = tf.one_hot(argmax_indices, depth=in1.shape[1])\nreturn tf.cast(one_hot_matrix, dtype=tf.int32)",
            "# Get the indices of the maximum element in each row\nmax_indices = tf.argmax(in1, axis=1)\n\n# Create a zero tensor of the same shape as the input\nout = tf.zeros_like(in1, dtype=tf.int32)\n\n# Get the indices of the elements in the tensor\nindices = tf.range(tf.shape(in1, out_type=tf.int64)[0])\n\n# Combine the indices with the max_indices\ncombined_indices = tf.transpose([indices, max_indices])\n\n# Update the output tensor with 1s at the positions of the maximum elements\nout = tf.tensor_scatter_nd_update(out, combined_indices, tf.ones(tf.shape(max_indices, out_type=tf.int32),  dtype=tf.int32))\n\nreturn out",
            "# Compute the argmax of each tensor along the last axis (axis=-1)\n    tensor_argmax_index = tf.argmax(in1, axis=-1)\n\n    # The shape of tensor_argmax_index is (5,) (1-rank tensor)\n    # Convert it to a 2-rank tensor with shape (5,1)\n    # which will be useful for scatter_nd\n    tensor_argmax_index = tf.expand_dims(tensor_argmax_index, axis=-1)\n\n    # Prepare updates, which consist of all ones\n    updates = tf.ones_like(tensor_argmax_index)\n    \n    # The desired output tensor has the same shape with 'in1'\n    desired_shape = tf.shape(in1)\n\n    # Use scatter_nd to place the updates at the correct indices\n    result = tf.scatter_nd(tensor_argmax_index, updates, desired_shape)\n\n    return result"
        ]
    },
    {
        "constants": "[]",
        "description": "gather elements in a tensor along axis 1",
        "target_program": "tf.gather(in2, in1, axis=1, batch_dims=1)",
        "source": "https://stackoverflow.com/questions/51690095/how-to-gather-element-with-index-in-tensorflow",
        "name": "stackoverflow_21",
        "examples": {
            "inputs": "[[[2], [0], [1], [0]],[[0.2, 0.5, 0.3], [0.1, 0.3, 0.6], [0.1, 0.6, 0.3], [0.7, 0.0, 0.3]],]",
            "outputs": "[[0.3], [0.1], [0.6], [0.7]]"
        },
        "response": {
            "task_id": "stackoverflow_21",
            "completions": [
                "return tf.gather(in2, in1, axis=1)",
                "return tf.gather(in2, in1, axis=1)",
                "return tf.gather(in2, in1, axis=1)",
                "return tf.gather(in2, in1, axis=1, batch_dims=1)",
                "return tf.gather(in2, in1, axis=1)",
                "return tf.gather(in2, in1, axis=1, batch_dims=1)",
                "return tf.gather(in2, in1, axis=1, batch_dims=1)",
                "return tf.gather(in2, in1, axis=1, batch_dims=1)",
                "return tf.gather(in2, in1, axis=1)",
                "return tf.gather(in2, in1, axis=1)"
            ],
            "target-program": "tf.gather(in2, in1, axis=1, batch_dims=1)",
            "description": "gather elements in a tensor along axis 1",
            "tf_operators": {
                "tf.gather": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.gather(in2, in1, axis=1)",
            "return tf.gather(in2, in1, axis=1)",
            "return tf.gather(in2, in1, axis=1)",
            "return tf.gather(in2, in1, axis=1, batch_dims=1)",
            "return tf.gather(in2, in1, axis=1)",
            "return tf.gather(in2, in1, axis=1, batch_dims=1)",
            "return tf.gather(in2, in1, axis=1, batch_dims=1)",
            "return tf.gather(in2, in1, axis=1, batch_dims=1)",
            "return tf.gather(in2, in1, axis=1)",
            "return tf.gather(in2, in1, axis=1)"
        ]
    },
    {
        "constants": "[]",
        "description": "multiply a vector with a matrix without reshaping the vector",
        "target_program": "tf.tensordot(tf.cast(in1, tf.float32), in2, 1)",
        "source": "https://stackoverflow.com/questions/43284897/how-can-i-multiply-a-vector-and-a-matrix-in-tensorflow-without-reshaping",
        "name": "stackoverflow_22",
        "examples": {
            "inputs": "[[3, 1, 10],[[0.6, 0.4], [0.5, 1.0], [3.0, 4.0]],]",
            "outputs": "[32.3, 42.2]"
        },
        "response": {
            "task_id": "stackoverflow_22",
            "completions": [
                "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, in2), 0)",
                "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)"
            ],
            "target-program": "tf.tensordot(tf.cast(in1, tf.float32), in2, 1)",
            "description": "multiply a vector with a matrix without reshaping the vector",
            "tf_operators": {
                "tf.multiply": 10,
                "tf.reduce_sum": 10
            },
            "coverage_percentage": 0.0,
            "total_in_target": 3,
            "total_covered": 0
        },
        "completions": [
            "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, in2), 0)",
            "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)"
        ]
    },
    {
        "constants": "[]",
        "description": "place 1 at the indices in the input tensor",
        "target_program": "tf.cast(tf.reduce_max(tf.one_hot(in1, 9), axis=1), tf.int32)",
        "source": "https://stackoverflow.com/questions/53414433/tensorflow-tensor-binarization",
        "name": "stackoverflow_23",
        "examples": {
            "inputs": "[[[0, 5, 2], [3, 1, 4], [5, 1, 5]],]",
            "outputs": "[[1, 0, 1, 0, 0, 1, 0, 0, 0],    [0, 1, 0, 1, 1, 0, 0, 0, 0],    [0, 1, 0, 0, 0, 1, 0, 0, 0]]"
        },
        "response": {
            "task_id": "stackoverflow_23",
            "completions": [
                "shape = tf.shape(in1)\nlength = shape[0] * shape[1]\nflat = tf.reshape(in1, [length])\nout = tf.scatter_nd(tf.expand_dims(flat, 1), tf.ones_like(flat), [length, length])\nreturn tf.reshape(out, [shape[0], shape[1], -1])[:, :, 0]",
                "depth = tf.reduce_max(in1) + 1  # the maximum index that's going to be replaced with 1, plus 1 to avoid off-by-one errors\n     return tf.one_hot(in1, depth)",
                "depth = tf.reduce_max(in1) + 1\nreturn tf.one_hot(in1, depth)",
                "return tf.scatter_nd(tf.expand_dims(in1, -1), tf.ones_like(in1), tf.constant([in1.shape[0], in1.shape[1], 9]))[:,:,1]",
                "depth = tf.reduce_max(in1) + 1\n     return tf.one_hot(in1, depth)",
                "max_val = tf.reduce_max(in1)\none_hot_encoded = tf.one_hot(in1, max_val+1)\nresult = tf.reduce_sum(one_hot_encoded, axis=1)\nreturn tf.cast(result, tf.int32)",
                "return tf.scatter_nd(tf.expand_dims(in1, 1), tf.ones_like(in1), tf.shape(in1))",
                "out = tf.one_hot(in1, depth=6)\nreturn tf.reduce_sum(out, axis=1)",
                "depth = tf.reduce_max(in1) + 1\nreturn tf.one_hot(in1, depth)",
                "depth = tf.reduce_max(in1) + 1\nreturn tf.one_hot(in1, depth)"
            ],
            "target-program": "tf.cast(tf.reduce_max(tf.one_hot(in1, 9), axis=1), tf.int32)",
            "description": "place 1 at the indices in the input tensor",
            "tf_operators": {
                "tf.shape": 2,
                "tf.reshape": 1,
                "tf.scatter_nd": 3,
                "tf.ones_like": 3,
                "tf.expand_dims": 3,
                "tf.reduce_max": 6,
                "tf.one_hot": 7,
                "tf.constant": 1,
                "tf.cast": 1,
                "tf.int32": 1,
                "tf.reduce_sum": 2
            },
            "coverage_percentage": 100.0,
            "total_in_target": 4,
            "total_covered": 4
        },
        "completions": [
            "shape = tf.shape(in1)\nlength = shape[0] * shape[1]\nflat = tf.reshape(in1, [length])\nout = tf.scatter_nd(tf.expand_dims(flat, 1), tf.ones_like(flat), [length, length])\nreturn tf.reshape(out, [shape[0], shape[1], -1])[:, :, 0]",
            "depth = tf.reduce_max(in1) + 1  # the maximum index that's going to be replaced with 1, plus 1 to avoid off-by-one errors\n     return tf.one_hot(in1, depth)",
            "depth = tf.reduce_max(in1) + 1\nreturn tf.one_hot(in1, depth)",
            "return tf.scatter_nd(tf.expand_dims(in1, -1), tf.ones_like(in1), tf.constant([in1.shape[0], in1.shape[1], 9]))[:,:,1]",
            "depth = tf.reduce_max(in1) + 1\n     return tf.one_hot(in1, depth)",
            "max_val = tf.reduce_max(in1)\none_hot_encoded = tf.one_hot(in1, max_val+1)\nresult = tf.reduce_sum(one_hot_encoded, axis=1)\nreturn tf.cast(result, tf.int32)",
            "return tf.scatter_nd(tf.expand_dims(in1, 1), tf.ones_like(in1), tf.shape(in1))",
            "out = tf.one_hot(in1, depth=6)\nreturn tf.reduce_sum(out, axis=1)",
            "depth = tf.reduce_max(in1) + 1\nreturn tf.one_hot(in1, depth)",
            "depth = tf.reduce_max(in1) + 1\nreturn tf.one_hot(in1, depth)"
        ]
    },
    {
        "constants": "[0]",
        "description": "(\\'like tf.divide(), but when dividing by 0, return the numerator\\')",
        "target_program": "tf.where(tf.cast(in2, tf.bool), x=tf.divide(in1, in2), y=in1)",
        "source": "https://stackoverflow.com/questions/53643339/tensorflow-overriding-tf-divide-to-return-the-numerator-when-dividing-by-0",
        "name": "stackoverflow_24",
        "examples": {
            "inputs": "[[3.0, 1.0, 4.0, 5.0, 2.0, 8.0, -6.0, -7.0],[0.5, 0.0, -2.0, 0.0, 1.0, -1.0, 0.0, 2.0],]",
            "outputs": "[6.0, 1.0, -2.0, 5.0, 2.0, -8.0, -6.0, -3.5]"
        },
        "response": {
            "task_id": "stackoverflow_24",
            "completions": [
                "return tf.math.divide_no_nan(in1, in2)",
                "return tf.math.divide_no_nan(in1, in2)",
                "return tf.math.divide_no_nan(in1, in2)",
                "return tf.math.divide_no_nan(in1, in2)",
                "return tf.math.divide_no_nan(in1, in2)",
                "return tf.math.divide_no_nan(in1, in2)",
                "return tf.math.divide_no_nan(in1, in2)",
                "return tf.math.divide_no_nan(in1, in2)",
                "return tf.math.divide_no_nan(in1, in2)",
                "return tf.math.divide_no_nan(in1, in2)"
            ],
            "target-program": "tf.where(tf.cast(in2, tf.bool), x=tf.divide(in1, in2), y=in1)",
            "description": "(\\'like tf.divide(), but when dividing by 0, return the numerator\\')",
            "tf_operators": {
                "tf.math.divide_no_nan": 10
            },
            "coverage_percentage": 0.0,
            "total_in_target": 4,
            "total_covered": 0
        },
        "completions": [
            "return tf.math.divide_no_nan(in1, in2)",
            "return tf.math.divide_no_nan(in1, in2)",
            "return tf.math.divide_no_nan(in1, in2)",
            "return tf.math.divide_no_nan(in1, in2)",
            "return tf.math.divide_no_nan(in1, in2)",
            "return tf.math.divide_no_nan(in1, in2)",
            "return tf.math.divide_no_nan(in1, in2)",
            "return tf.math.divide_no_nan(in1, in2)",
            "return tf.math.divide_no_nan(in1, in2)",
            "return tf.math.divide_no_nan(in1, in2)"
        ]
    },
    {
        "constants": "[]",
        "description": "copy the tensor tf.eye(3), 4 times",
        "target_program": "tf.tile(tf.eye(in1), (in2, 1))",
        "source": "https://stackoverflow.com/questions/53602691/duplicate-a-tensor-n-times",
        "name": "stackoverflow_25",
        "examples": {
            "inputs": "[3,4,]",
            "outputs": "[[1.0, 0.0, 0.0],    [0.0, 1.0, 0.0],    [0.0, 0.0, 1.0],    [1.0, 0.0, 0.0],    [0.0, 1.0, 0.0],    [0.0, 0.0, 1.0],    [1.0, 0.0, 0.0],    [0.0, 1.0, 0.0],    [0.0, 0.0, 1.0],    [1.0, 0.0, 0.0],    [0.0, 1.0, 0.0],    [0.0, 0.0, 1.0]]"
        },
        "response": {
            "task_id": "stackoverflow_25",
            "completions": [
                "return tf.tile(tf.eye(in1), [in2, 1])",
                "tensor = tf.eye(in1)\nreturn tf.tile(tensor,[in2,1])",
                "return tf.tile(tf.eye(in1), [in2, 1])",
                "return tf.tile(tf.eye(in1), [in2, 1])",
                "return tf.tile(tf.eye(in1),(in2,1))",
                "return tf.tile(tf.eye(in1), [in2, 1])",
                "return tf.tile(tf.eye(in1), multiples=[in2, 1])",
                "return tf.tile(tf.eye(in1), [in2, 1])",
                "return tf.tile(tf.eye(in1), [in2, 1])",
                "return tf.tile(tf.eye(in1), [in2, 1])"
            ],
            "target-program": "tf.tile(tf.eye(in1), (in2, 1))",
            "description": "copy the tensor tf.eye(3), 4 times",
            "tf_operators": {
                "tf.tile": 10,
                "tf.eye": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 2,
            "total_covered": 2
        },
        "completions": [
            "return tf.tile(tf.eye(in1), [in2, 1])",
            "tensor = tf.eye(in1)\nreturn tf.tile(tensor,[in2,1])",
            "return tf.tile(tf.eye(in1), [in2, 1])",
            "return tf.tile(tf.eye(in1), [in2, 1])",
            "return tf.tile(tf.eye(in1),(in2,1))",
            "return tf.tile(tf.eye(in1), [in2, 1])",
            "return tf.tile(tf.eye(in1), multiples=[in2, 1])",
            "return tf.tile(tf.eye(in1), [in2, 1])",
            "return tf.tile(tf.eye(in1), [in2, 1])",
            "return tf.tile(tf.eye(in1), [in2, 1])"
        ]
    },
    {
        "constants": "[]",
        "description": "reduction operation for multiple dimensions simultaneously",
        "target_program": "tf.reduce_sum(tf.reduce_sum(in1, axis=1), axis=1)",
        "source": "https://stackoverflow.com/questions/54294780/how-to-perform-reduce-op-on-multiple-dimensions-at-once",
        "name": "stackoverflow_26",
        "examples": {
            "inputs": "[[[[3, 4], [1, 2]], [[5, -2], [-10, 3]], [[10, 20], [-4, 7]]]]",
            "outputs": "[10, -4, 33]"
        },
        "response": {
            "task_id": "stackoverflow_26",
            "completions": [
                "return tf.reduce_sum(in1, axis=[0, 1]).numpy().tolist()",
                "return tf.reduce_sum(in1, axis=[0,1]).numpy().tolist()",
                "return tf.reduce_sum(in1, axis=[0, 1])",
                "return tf.reduce_sum(in1, axis=[0,1])",
                "return tf.reduce_sum(in1, axis=[0, 1]).numpy().tolist()",
                "return tf.reduce_sum(in1, axis=[0,1])",
                "return tf.reduce_sum(in1, axis=[0, 1])",
                "return tf.reduce_sum(in1, axis=[0,1,2])",
                "return tf.reduce_sum(in1, axis=[0,1])",
                "return tf.reduce_sum(in1, axis=[0, 1])"
            ],
            "target-program": "tf.reduce_sum(tf.reduce_sum(in1, axis=1), axis=1)",
            "description": "reduction operation for multiple dimensions simultaneously",
            "tf_operators": {
                "tf.reduce_sum": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.reduce_sum(in1, axis=[0, 1]).numpy().tolist()",
            "return tf.reduce_sum(in1, axis=[0,1]).numpy().tolist()",
            "return tf.reduce_sum(in1, axis=[0, 1])",
            "return tf.reduce_sum(in1, axis=[0,1])",
            "return tf.reduce_sum(in1, axis=[0, 1]).numpy().tolist()",
            "return tf.reduce_sum(in1, axis=[0,1])",
            "return tf.reduce_sum(in1, axis=[0, 1])",
            "return tf.reduce_sum(in1, axis=[0,1,2])",
            "return tf.reduce_sum(in1, axis=[0,1])",
            "return tf.reduce_sum(in1, axis=[0, 1])"
        ]
    },
    {
        "constants": "[]",
        "description": "boolean tensor with 1 at the indices in the input tensor",
        "target_program": "tf.cast(tf.reduce_max(tf.one_hot(in1, in2), axis=0), tf.int32)",
        "source": "https://stackoverflow.com/questions/54225704/how-do-i-get-a-tensor-representing-the-on-positions-in-the-original-tensor",
        "name": "stackoverflow_27",
        "examples": {
            "inputs": "[[0, 3, 5, 6],8,]",
            "outputs": "[1, 0, 0, 1, 0, 1, 1, 0]"
        },
        "response": {
            "task_id": "stackoverflow_27",
            "completions": [
                "tensor = tf.one_hot(in1, in2)\n     return tf.reduce_max(tensor, axis=0)",
                "output = tf.scatter_nd(tf.expand_dims(in1, axis=1), tf.ones_like(in1), [in2])\n     return output",
                "return tf.cast(tf.reduce_sum(tf.one_hot(in1, in2), axis=0), tf.int32)",
                "output = tf.scatter_nd(tf.expand_dims(in1, 1), tf.ones_like(in1), [in2])\nreturn output.numpy()",
                "depth = tf.constant(in2)\nindices = tf.constant(in1)\nreturn tf.transpose(tf.one_hot(indices, depth))",
                "output = tf.scatter_nd(tf.expand_dims(in1, axis=-1), tf.ones_like(in1), [in2])\n     return tf.cast(output, tf.int32)",
                "out = tf.one_hot(in1, in2)\nreturn tf.reduce_sum(out, axis=0)",
                "return tf.cast(tf.reduce_any(tf.one_hot(in1, in2), axis=0), tf.int32)",
                "out = tf.Tensor(np.zeros(in2), dtype=tf.int32)\n     out = tf.tensor_scatter_nd_update(out, tf.reshape(in1, [in1.shape[0], 1]), tf.fill([in1.shape[0]], 1))\n     return out",
                "return tf.cast(tf.reduce_sum(tf.one_hot(in1, in2), axis=0), tf.int32)"
            ],
            "target-program": "tf.cast(tf.reduce_max(tf.one_hot(in1, in2), axis=0), tf.int32)",
            "description": "boolean tensor with 1 at the indices in the input tensor",
            "tf_operators": {
                "tf.reduce_max": 1,
                "tf.one_hot": 6,
                "tf.ones_like": 3,
                "tf.scatter_nd": 3,
                "tf.expand_dims": 3,
                "tf.reduce_sum": 3,
                "tf.int32": 5,
                "tf.cast": 4,
                "tf.constant": 1,
                "tf.transpose": 1,
                "tf.reduce_any": 1,
                "tf.Tensor": 1,
                "tf.fill": 1,
                "tf.reshape": 1,
                "tf.tensor_scatter_nd_update": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 4,
            "total_covered": 4
        },
        "completions": [
            "tensor = tf.one_hot(in1, in2)\n     return tf.reduce_max(tensor, axis=0)",
            "output = tf.scatter_nd(tf.expand_dims(in1, axis=1), tf.ones_like(in1), [in2])\n     return output",
            "return tf.cast(tf.reduce_sum(tf.one_hot(in1, in2), axis=0), tf.int32)",
            "output = tf.scatter_nd(tf.expand_dims(in1, 1), tf.ones_like(in1), [in2])\nreturn output.numpy()",
            "depth = tf.constant(in2)\nindices = tf.constant(in1)\nreturn tf.transpose(tf.one_hot(indices, depth))",
            "output = tf.scatter_nd(tf.expand_dims(in1, axis=-1), tf.ones_like(in1), [in2])\n     return tf.cast(output, tf.int32)",
            "out = tf.one_hot(in1, in2)\nreturn tf.reduce_sum(out, axis=0)",
            "return tf.cast(tf.reduce_any(tf.one_hot(in1, in2), axis=0), tf.int32)",
            "out = tf.Tensor(np.zeros(in2), dtype=tf.int32)\n     out = tf.tensor_scatter_nd_update(out, tf.reshape(in1, [in1.shape[0], 1]), tf.fill([in1.shape[0]], 1))\n     return out",
            "return tf.cast(tf.reduce_sum(tf.one_hot(in1, in2), axis=0), tf.int32)"
        ]
    },
    {
        "constants": "[]",
        "description": "extract columns from a 3D tensor given column indices",
        "target_program": "tf.squeeze(tf.gather(in1, tf.expand_dims(in2, 1), axis=-1, batch_dims=1))",
        "source": "https://stackoverflow.com/questions/54274074/selecting-columns-from-3d-tensor-according-to-a-1d-tensor-of-indices-tensorflow",
        "name": "stackoverflow_28",
        "examples": {
            "inputs": "[[[[5, 3],  [0, 2]], [[7, 4],  [5, 1]], [[10, 20],  [15, 30]], [[11, 16],  [14, 12]], [[-2, -7],  [-4, 6]]],[1, 0, 1, 1, 0],]",
            "outputs": "[[3, 2], [7, 5], [20, 30], [16, 12], [-2, -4]]"
        },
        "response": {
            "task_id": "stackoverflow_28",
            "completions": [
                "return tf.gather(in1, in2, axis=2, batch_dims=1)",
                "return tf.gather(in1, in2, axis=2, batch_dims=1)",
                "return tf.gather(in1, in2, axis=2, batch_dims=1)",
                "return tf.gather(in1,in2,axis=2)",
                "return tf.gather(in1, in2, axis=2, batch_dims=1)",
                "return tf.gather(in1, tf.expand_dims(in2, axis=-1), batch_dims=1, axis=2)",
                "# Use tf.gather to select columns by indices\n    result = tf.gather(in1, in2, axis=1, batch_dims=1)\n    return result",
                "return tf.gather(in1, in2, axis=2, batch_dims=1)",
                "return tf.gather(in1, in2, axis=-1)",
                "indices = tf.expand_dims(tf.range(tf.shape(in1)[0]), axis=-1)\nselected_indices = tf.concat([indices, tf.expand_dims(in2, axis=-1)], axis=-1)\nreturn tf.gather_nd(in1, selected_indices)"
            ],
            "target-program": "tf.squeeze(tf.gather(in1, tf.expand_dims(in2, 1), axis=-1, batch_dims=1))",
            "description": "extract columns from a 3D tensor given column indices",
            "tf_operators": {
                "tf.gather": 9,
                "tf.expand_dims": 2,
                "tf.shape": 1,
                "tf.concat": 1,
                "tf.range": 1,
                "tf.gather_nd": 1
            },
            "coverage_percentage": 66.66666666666666,
            "total_in_target": 3,
            "total_covered": 2
        },
        "completions": [
            "return tf.gather(in1, in2, axis=2, batch_dims=1)",
            "return tf.gather(in1, in2, axis=2, batch_dims=1)",
            "return tf.gather(in1, in2, axis=2, batch_dims=1)",
            "return tf.gather(in1,in2,axis=2)",
            "return tf.gather(in1, in2, axis=2, batch_dims=1)",
            "return tf.gather(in1, tf.expand_dims(in2, axis=-1), batch_dims=1, axis=2)",
            "# Use tf.gather to select columns by indices\n    result = tf.gather(in1, in2, axis=1, batch_dims=1)\n    return result",
            "return tf.gather(in1, in2, axis=2, batch_dims=1)",
            "return tf.gather(in1, in2, axis=-1)",
            "indices = tf.expand_dims(tf.range(tf.shape(in1)[0]), axis=-1)\nselected_indices = tf.concat([indices, tf.expand_dims(in2, axis=-1)], axis=-1)\nreturn tf.gather_nd(in1, selected_indices)"
        ]
    },
    {
        "constants": "[]",
        "description": "place continuous values into buckets given bucket boundaries",
        "target_program": "tf.searchsorted(in1, in2, side='left')",
        "source": "https://stackoverflow.com/questions/54155085/bucketing-continous-value-tensors-in-tensorflow",
        "name": "stackoverflow_29",
        "examples": {
            "inputs": "[[-1.0, -0.8, -0.6, -0.4, -0.2, 0.0, 0.2, 0.4, 0.6, 0.8, 1.0],[0.1, -10, -0.1, 1.1, 0.41],]",
            "outputs": "[6, 0, 5, 11, 8]"
        },
        "response": {
            "task_id": "stackoverflow_29",
            "completions": [
                "return tf.searchsorted(in1, in2, side='right').numpy().tolist()",
                "return tf.searchsorted(in1,in2).numpy().tolist()",
                "return tf.searchsorted(tf.constant(in1), tf.constant(in2)).numpy().tolist()",
                "return tf.searchsorted(in1, in2).numpy().tolist()",
                "return tf.searchsorted(sorted_sequence=in1, values=in2, side='right')",
                "return tf.searchsorted(tf.constant(in1), tf.constant(in2))",
                "return tf.searchsorted(tf.constant(in1), tf.constant(in2)).numpy().tolist()",
                "return tf.searchsorted(sorted_sequence=in1, values=in2, side='right')",
                "return tf.searchsorted(in1, in2, side='right')",
                "return tf.searchsorted(in1, in2, side='right')"
            ],
            "target-program": "tf.searchsorted(in1, in2, side='left')",
            "description": "place continuous values into buckets given bucket boundaries",
            "tf_operators": {
                "tf.searchsorted": 10,
                "tf.constant": 3
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.searchsorted(in1, in2, side='right').numpy().tolist()",
            "return tf.searchsorted(in1,in2).numpy().tolist()",
            "return tf.searchsorted(tf.constant(in1), tf.constant(in2)).numpy().tolist()",
            "return tf.searchsorted(in1, in2).numpy().tolist()",
            "return tf.searchsorted(sorted_sequence=in1, values=in2, side='right')",
            "return tf.searchsorted(tf.constant(in1), tf.constant(in2))",
            "return tf.searchsorted(tf.constant(in1), tf.constant(in2)).numpy().tolist()",
            "return tf.searchsorted(sorted_sequence=in1, values=in2, side='right')",
            "return tf.searchsorted(in1, in2, side='right')",
            "return tf.searchsorted(in1, in2, side='right')"
        ]
    },
    {
        "constants": "[]",
        "description": "compute Euclidean distance between two tensors",
        "target_program": "tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, 1), tf.expand_dims(in2, 0))), axis=2))",
        "source": "https://stackoverflow.com/questions/54147780/tensorflow-how-to-calculate-the-euclidean-distance-between-two-tensor",
        "name": "stackoverflow_30",
        "examples": {
            "inputs": "[[[1., 2.], [3., 4.], [5., 6.]],[[9., 4.], [8., 5.], [7., 6.]],]",
            "outputs": "[[math.sqrt(68), math.sqrt(58), math.sqrt(52)],    [math.sqrt(36), math.sqrt(26), math.sqrt(20)],    [math.sqrt(20), math.sqrt(10), math.sqrt(4)]]"
        },
        "response": {
            "task_id": "stackoverflow_30",
            "completions": [
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.expand_dims(in2, axis=1))), axis=2))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1,in2)), axis=1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.expand_dims(in2, 1))), axis=-1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1,in2)), axis=1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(in1 - in2), axis=1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1,in2)), axis=1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))"
            ],
            "target-program": "tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, 1), tf.expand_dims(in2, 0))), axis=2))",
            "description": "compute Euclidean distance between two tensors",
            "tf_operators": {
                "tf.sqrt": 10,
                "tf.square": 10,
                "tf.subtract": 9,
                "tf.expand_dims": 2,
                "tf.reduce_sum": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 5,
            "total_covered": 5
        },
        "completions": [
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.expand_dims(in2, axis=1))), axis=2))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1,in2)), axis=1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.expand_dims(in2, 1))), axis=-1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1,in2)), axis=1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(in1 - in2), axis=1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1,in2)), axis=1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))"
        ]
    },
    {
        "constants": "[]",
        "description": "squared error between two tensors, one being a sparse tensor",
        "target_program": "tf.reduce_sum(tf.square(tf.subtract(in2, tf.sparse.to_dense(in1))))",
        "source": "https://stackoverflow.com/questions/45032668/tensorflow-how-to-compute-the-square-error-between-a-tensor-and-a-sparse-tensor",
        "name": "stackoverflow_31",
        "examples": {
            "inputs": "tf.SparseTensor(indices=[[0, 0], [0, 1], [1, 1]], values=[1.0, 1.5, -2.0], dense_shape=[2, 2]), [[3.0, 1.0], [0.2, -1.0]],",
            "outputs": "5.29"
        },
        "response": {
            "task_id": "stackoverflow_31",
            "completions": [
                "dense1 = tf.sparse.to_dense(in1[0])\n     error = tf.math.squared_difference(in1[1], dense1)\n     return tf.reduce_sum(error).numpy()",
                "dense1 = tf.sparse.to_dense(in1[0])\n     error = tf.math.squared_difference(dense1, in1[1])\n     return tf.reduce_sum(error).numpy()",
                "in2 = tf.sparse.to_dense(in1[0], default_value=0)\n     error = tf.math.squared_difference(in2, in1[1])\n     return tf.reduce_sum(error).numpy()",
                "dense_tensor = tf.sparse.to_dense(in1[0])\n    error = tf.reduce_sum(tf.math.squared_difference(dense_tensor, in1[1]))\n    return error",
                "dense_from_sparse = tf.sparse.to_dense(in1[0])\n     return tf.reduce_sum(tf.math.squared_difference(dense_from_sparse, in1[1]))",
                "dense1 = tf.sparse.to_dense(in1[0])\n     return tf.reduce_sum(tf.square(tf.subtract(in1[1], dense1)))",
                "dense_tensor = in1[1]\nsparse_tensor = tf.sparse.to_dense(in1[0])\n\nsquared_difference = tf.math.squared_difference(sparse_tensor, dense_tensor)\n\nreturn tf.reduce_sum(squared_difference)",
                "sparse_tensor, dense_tensor = in1\ndense_from_sparse = tf.sparse.to_dense(sparse_tensor)\nsquare_error = tf.math.squared_difference(dense_from_sparse, dense_tensor)\nreturn tf.reduce_sum(square_error)",
                "dense1 = tf.sparse.to_dense(in1[0])\n     return tf.reduce_sum(tf.math.squared_difference(dense1, in1[1]))",
                "dense_in1 = tf.sparse.to_dense(in1[0])\n     diff = tf.subtract(dense_in1, in1[1])\n     square = tf.square(diff)\n     return tf.reduce_sum(square)"
            ],
            "target-program": "tf.reduce_sum(tf.square(tf.subtract(in2, tf.sparse.to_dense(in1))))",
            "description": "squared error between two tensors, one being a sparse tensor",
            "tf_operators": {
                "tf.math.squared_difference": 8,
                "tf.sparse.to_dense": 10,
                "tf.reduce_sum": 10,
                "tf.square": 2,
                "tf.subtract": 2
            },
            "coverage_percentage": 100.0,
            "total_in_target": 4,
            "total_covered": 4
        },
        "completions": [
            "dense1 = tf.sparse.to_dense(in1[0])\n     error = tf.math.squared_difference(in1[1], dense1)\n     return tf.reduce_sum(error).numpy()",
            "dense1 = tf.sparse.to_dense(in1[0])\n     error = tf.math.squared_difference(dense1, in1[1])\n     return tf.reduce_sum(error).numpy()",
            "in2 = tf.sparse.to_dense(in1[0], default_value=0)\n     error = tf.math.squared_difference(in2, in1[1])\n     return tf.reduce_sum(error).numpy()",
            "dense_tensor = tf.sparse.to_dense(in1[0])\n    error = tf.reduce_sum(tf.math.squared_difference(dense_tensor, in1[1]))\n    return error",
            "dense_from_sparse = tf.sparse.to_dense(in1[0])\n     return tf.reduce_sum(tf.math.squared_difference(dense_from_sparse, in1[1]))",
            "dense1 = tf.sparse.to_dense(in1[0])\n     return tf.reduce_sum(tf.square(tf.subtract(in1[1], dense1)))",
            "dense_tensor = in1[1]\nsparse_tensor = tf.sparse.to_dense(in1[0])\n\nsquared_difference = tf.math.squared_difference(sparse_tensor, dense_tensor)\n\nreturn tf.reduce_sum(squared_difference)",
            "sparse_tensor, dense_tensor = in1\ndense_from_sparse = tf.sparse.to_dense(sparse_tensor)\nsquare_error = tf.math.squared_difference(dense_from_sparse, dense_tensor)\nreturn tf.reduce_sum(square_error)",
            "dense1 = tf.sparse.to_dense(in1[0])\n     return tf.reduce_sum(tf.math.squared_difference(dense1, in1[1]))",
            "dense_in1 = tf.sparse.to_dense(in1[0])\n     diff = tf.subtract(dense_in1, in1[1])\n     square = tf.square(diff)\n     return tf.reduce_sum(square)"
        ]
    },
    {
        "constants": "[]",
        "description": "weighted sum across rows, where the column index is the weight",
        "target_program": "tf.tensordot(in1, tf.cast(tf.range(4), tf.float32), 1)",
        "source": "https://stackoverflow.com/questions/48659449/how-to-compute-the-weighted-sum-of-a-tensor-in-tensorflow",
        "name": "stackoverflow_32",
        "examples": {
            "inputs": "[[[0.1, 0.6, 0.2, 0.1], [0.3, 0.1, 0.4, 0.2], [0.2, 0.1, 0.2, 0.5]],]",
            "outputs": "[1.3, 1.5, 2.0]"
        },
        "response": {
            "task_id": "stackoverflow_32",
            "completions": [
                "weights = tf.range(tf.shape(in1)[1])\nweights = tf.cast(weights, in1.dtype)\nin1 = in1 * weights\nreturn tf.reduce_sum(in1, axis=1)",
                "weights = tf.range(tf.shape(in1)[-1])\nreturn tf.reduce_sum(tf.multiply(in1, weights), axis=-1)",
                "return tf.reduce_sum(tf.multiply(in1, tf.range(tf.shape(in1)[1])), axis=1)",
                "weights = tf.range(tf.shape(in1)[-1])\ntiled_weights = tf.broadcast_to(weights, tf.shape(in1))\nreturn tf.reduce_sum(tf.multiply(in1, tf.cast(tiled_weights, in1.dtype)), axis=-1)",
                "weights = tf.range(tf.shape(in1)[1], dtype=in1.dtype)\nweighted_sum = tf.reduce_sum(tf.multiply(in1, weights), axis=1)\nreturn weighted_sum",
                "weights = tf.range(tf.shape(in1)[1])\nweighted_values = tf.multiply(in1, tf.cast(weights, in1.dtype))\nout = tf.reduce_sum(weighted_values, axis=1)\nreturn out",
                "weights = tf.range(tf.shape(in1)[-1])\nweighted_sum = tf.reduce_sum(in1 * tf.cast(weights, tf.float32), axis=-1)\nreturn weighted_sum",
                "weights = tf.range(tf.shape(in1)[1], dtype=in1.dtype)\nexpanded_weights = tf.expand_dims(weights, axis=0)\nbroadcasted_weights = tf.broadcast_to(expanded_weights, tf.shape(in1))\nresult = tf.reduce_sum(in1 * broadcasted_weights, axis=1)\nreturn result",
                "weights = tf.range(start=0, limit=tf.shape(in1)[1], delta=1, dtype=in1.dtype)\nweighted = tf.multiply(in1, weights)\nreturn tf.reduce_sum(weighted, axis=1)",
                "weights = tf.range(tf.shape(in1)[-1])\nweighted_sum = tf.reduce_sum(tf.multiply(in1, weights), axis=-1)\nreturn weighted_sum"
            ],
            "target-program": "tf.tensordot(in1, tf.cast(tf.range(4), tf.float32), 1)",
            "description": "weighted sum across rows, where the column index is the weight",
            "tf_operators": {
                "tf.reduce_sum": 10,
                "tf.shape": 10,
                "tf.range": 10,
                "tf.cast": 4,
                "tf.multiply": 7,
                "tf.broadcast_to": 2,
                "tf.float32": 1,
                "tf.expand_dims": 1
            },
            "coverage_percentage": 75.0,
            "total_in_target": 4,
            "total_covered": 3
        },
        "completions": [
            "weights = tf.range(tf.shape(in1)[1])\nweights = tf.cast(weights, in1.dtype)\nin1 = in1 * weights\nreturn tf.reduce_sum(in1, axis=1)",
            "weights = tf.range(tf.shape(in1)[-1])\nreturn tf.reduce_sum(tf.multiply(in1, weights), axis=-1)",
            "return tf.reduce_sum(tf.multiply(in1, tf.range(tf.shape(in1)[1])), axis=1)",
            "weights = tf.range(tf.shape(in1)[-1])\ntiled_weights = tf.broadcast_to(weights, tf.shape(in1))\nreturn tf.reduce_sum(tf.multiply(in1, tf.cast(tiled_weights, in1.dtype)), axis=-1)",
            "weights = tf.range(tf.shape(in1)[1], dtype=in1.dtype)\nweighted_sum = tf.reduce_sum(tf.multiply(in1, weights), axis=1)\nreturn weighted_sum",
            "weights = tf.range(tf.shape(in1)[1])\nweighted_values = tf.multiply(in1, tf.cast(weights, in1.dtype))\nout = tf.reduce_sum(weighted_values, axis=1)\nreturn out",
            "weights = tf.range(tf.shape(in1)[-1])\nweighted_sum = tf.reduce_sum(in1 * tf.cast(weights, tf.float32), axis=-1)\nreturn weighted_sum",
            "weights = tf.range(tf.shape(in1)[1], dtype=in1.dtype)\nexpanded_weights = tf.expand_dims(weights, axis=0)\nbroadcasted_weights = tf.broadcast_to(expanded_weights, tf.shape(in1))\nresult = tf.reduce_sum(in1 * broadcasted_weights, axis=1)\nreturn result",
            "weights = tf.range(start=0, limit=tf.shape(in1)[1], delta=1, dtype=in1.dtype)\nweighted = tf.multiply(in1, weights)\nreturn tf.reduce_sum(weighted, axis=1)",
            "weights = tf.range(tf.shape(in1)[-1])\nweighted_sum = tf.reduce_sum(tf.multiply(in1, weights), axis=-1)\nreturn weighted_sum"
        ]
    },
    {
        "constants": "[]",
        "description": "find the minimum distance between two sets of points",
        "target_program": "tf.reduce_min(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, 0), tf.expand_dims(in2, 1))), axis=2), axis=1)",
        "source": "https://stackoverflow.com/questions/40558251/computing-minimum-distance-for-each-element-in-a-tensor-relative-to-another-tens",
        "name": "stackoverflow_33",
        "examples": {
            "inputs": "[[[.3, .1, .4], [.1, .5, .9], [.2, .6, .5], [.3, .5, .8],[.9, .7, .9]],[[.3, .2, .3], [.8, .4, .6], [.2, .6, .4], [.3, .3, .8]],]",
            "outputs": "[0.02, 0.19, 0.01, 0.04]"
        },
        "response": {
            "task_id": "stackoverflow_33",
            "completions": [
                "distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=1), tf.expand_dims(in2, axis=0))), axis=-1))\n     return tf.reduce_min(distances, axis=-1)",
                "distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=1), tf.expand_dims(in2, axis=0))), axis=2))\n     min_distances = tf.reduce_min(distances, axis=1)\n     return min_distances",
                "distances = tf.reduce_min(tf.reduce_sum(tf.square(tf.subtract(in1[:,tf.newaxis], in2)), 2), 1)\nreturn distances",
                "distances = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=1), tf.expand_dims(in2, axis=0))), axis=2)), axis=1)\n     return distances",
                "distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, 2), tf.expand_dims(in2, 0))), 1))\nmin_dists = tf.reduce_min(distances, 1)\nreturn min_dists",
                "distances = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=1), tf.expand_dims(in2, axis=0))), axis=-1)), axis=-1)\n     return distances",
                "distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=1), tf.expand_dims(in2, axis=0))), axis=-1))\nmin_distances = tf.reduce_min(distances, axis=-1)\nreturn min_distances",
                "distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=1), tf.expand_dims(in2, axis=0))), axis=2))\n     min_distances = tf.reduce_min(distances, axis=1)\n     return min_distances",
                "distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, 1), tf.expand_dims(in2, 0))), -1))\n     min_distance_idx = tf.argmin(distances, 1)\n     return tf.gather(tf.reshape(distances, [-1]), min_distance_idx)",
                "distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, 1), tf.expand_dims(in2, 0))), 2))\n     return tf.reduce_min(distances, 1)"
            ],
            "target-program": "tf.reduce_min(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, 0), tf.expand_dims(in2, 1))), axis=2), axis=1)",
            "description": "find the minimum distance between two sets of points",
            "tf_operators": {
                "tf.sqrt": 9,
                "tf.square": 10,
                "tf.reduce_min": 9,
                "tf.subtract": 10,
                "tf.expand_dims": 9,
                "tf.reduce_sum": 10,
                "tf.newaxis": 1,
                "tf.reshape": 1,
                "tf.argmin": 1,
                "tf.gather": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 5,
            "total_covered": 5
        },
        "completions": [
            "distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=1), tf.expand_dims(in2, axis=0))), axis=-1))\n     return tf.reduce_min(distances, axis=-1)",
            "distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=1), tf.expand_dims(in2, axis=0))), axis=2))\n     min_distances = tf.reduce_min(distances, axis=1)\n     return min_distances",
            "distances = tf.reduce_min(tf.reduce_sum(tf.square(tf.subtract(in1[:,tf.newaxis], in2)), 2), 1)\nreturn distances",
            "distances = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=1), tf.expand_dims(in2, axis=0))), axis=2)), axis=1)\n     return distances",
            "distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, 2), tf.expand_dims(in2, 0))), 1))\nmin_dists = tf.reduce_min(distances, 1)\nreturn min_dists",
            "distances = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=1), tf.expand_dims(in2, axis=0))), axis=-1)), axis=-1)\n     return distances",
            "distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=1), tf.expand_dims(in2, axis=0))), axis=-1))\nmin_distances = tf.reduce_min(distances, axis=-1)\nreturn min_distances",
            "distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=1), tf.expand_dims(in2, axis=0))), axis=2))\n     min_distances = tf.reduce_min(distances, axis=1)\n     return min_distances",
            "distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, 1), tf.expand_dims(in2, 0))), -1))\n     min_distance_idx = tf.argmin(distances, 1)\n     return tf.gather(tf.reshape(distances, [-1]), min_distance_idx)",
            "distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, 1), tf.expand_dims(in2, 0))), 2))\n     return tf.reduce_min(distances, 1)"
        ]
    },
    {
        "constants": "[]",
        "description": "compute a weighted sum of tensors",
        "target_program": "tf.tensordot(in2, in1, 1)",
        "source": "https://stackoverflow.com/questions/49532371/compute-a-linear-combination-of-tensors-in-tensorflow",
        "name": "stackoverflow_34",
        "examples": {
            "inputs": "[[[[1, 2], [3, 4]],[[5, 6], [7, 8]],[[10, 20], [30, 40]]],[3, 5, 10],]",
            "outputs": "[[128, 236], [344, 452]]"
        },
        "response": {
            "task_id": "stackoverflow_34",
            "completions": [
                "weighted_tensors = [tf.multiply(t, w) for t, w in zip(in1, in2)]\n     return tf.reduce_sum(tf.stack(weighted_tensors, axis=0), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, [-1, 1, 1])), axis=0)",
                "weights = tf.expand_dims(tf.cast(in2, dtype=tf.float32), -1)\nweighted_tensors = tf.multiply(in1, weights)\nresult = tf.reduce_sum(weighted_tensors, axis=0)\nreturn result",
                "output = tf.tensordot(in1, in2, axes=0)\n     return tf.reduce_sum(output, axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, [-1, 1, 1])), axis=0)",
                "return tf.tensordot(in1, in2, axes=0)",
                "in1 = tf.cast(in1, tf.float32)\nin2 = tf.reshape(in2, (-1, 1, 1))\nreturn tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
                "in1 = tf.constant(in1)\n     in2 = tf.constant(in2)\n     in2 = tf.expand_dims(in2, axis=1)\n     in2 = tf.expand_dims(in2, axis=2)\n     in2 = tf.broadcast_to(in2, tf.shape(in1))\n     out = tf.multiply(in1, in2)\n     out = tf.reduce_sum(out, axis=0)\n     return out.numpy()",
                "return tf.reduce_sum(tf.multiply(tf.expand_dims(in2, -1), in1), axis = 0)",
                "return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(tf.expand_dims(in2, -1), -1)), axis=0)"
            ],
            "target-program": "tf.tensordot(in2, in1, 1)",
            "description": "compute a weighted sum of tensors",
            "tf_operators": {
                "tf.multiply": 8,
                "tf.stack": 1,
                "tf.reduce_sum": 9,
                "tf.reshape": 3,
                "tf.cast": 2,
                "tf.float32": 2,
                "tf.expand_dims": 4,
                "tf.tensordot": 2,
                "tf.shape": 1,
                "tf.broadcast_to": 1,
                "tf.constant": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "weighted_tensors = [tf.multiply(t, w) for t, w in zip(in1, in2)]\n     return tf.reduce_sum(tf.stack(weighted_tensors, axis=0), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, [-1, 1, 1])), axis=0)",
            "weights = tf.expand_dims(tf.cast(in2, dtype=tf.float32), -1)\nweighted_tensors = tf.multiply(in1, weights)\nresult = tf.reduce_sum(weighted_tensors, axis=0)\nreturn result",
            "output = tf.tensordot(in1, in2, axes=0)\n     return tf.reduce_sum(output, axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, [-1, 1, 1])), axis=0)",
            "return tf.tensordot(in1, in2, axes=0)",
            "in1 = tf.cast(in1, tf.float32)\nin2 = tf.reshape(in2, (-1, 1, 1))\nreturn tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
            "in1 = tf.constant(in1)\n     in2 = tf.constant(in2)\n     in2 = tf.expand_dims(in2, axis=1)\n     in2 = tf.expand_dims(in2, axis=2)\n     in2 = tf.broadcast_to(in2, tf.shape(in1))\n     out = tf.multiply(in1, in2)\n     out = tf.reduce_sum(out, axis=0)\n     return out.numpy()",
            "return tf.reduce_sum(tf.multiply(tf.expand_dims(in2, -1), in1), axis = 0)",
            "return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(tf.expand_dims(in2, -1), -1)), axis=0)"
        ]
    },
    {
        "constants": "[]",
        "description": "linear interpolation between two tensors",
        "target_program": "tf.add(in2, tf.multiply(tf.expand_dims(in3, 1), tf.subtract(in1, in2)))",
        "source": "https://stackoverflow.com/questions/49643371/keras-compute-convex-combination-of-two-tensors",
        "name": "stackoverflow_35",
        "examples": {
            "inputs": "[[[[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]], [[10., 20.], [30., 40.], [50., 60.]]],[[[9.0, 8.0], [7.0, 6.0], [5.0, 4.0]], [[90., 80.], [70., 60.], [50., 40.]]],[0.1, 0.4, 0.8],]",
            "outputs": "[[[8.2, 7.4], [5.4, 5.2], [5.0, 5.6]],    [[82., 74.], [54., 52.], [50., 56.]]]"
        },
        "response": {
            "task_id": "stackoverflow_35",
            "completions": [
                "return tf.add(tf.multiply(in1, tf.reshape(1.0 - in3, [-1, 1, 1])), tf.multiply(in2, tf.reshape(in3, [-1, 1, 1])))",
                "return tf.add(tf.multiply(in1, tf.reshape(1.0 - in3, [-1, 1, 1])), tf.multiply(in2, tf.reshape(in3, [-1, 1, 1])))",
                "return tf.add(tf.multiply(in1, tf.reshape(1.0 - in3, [3, 1, 1])), tf.multiply(in2, tf.reshape(in3, [3, 1, 1])))",
                "return tf.add(tf.multiply(in1, tf.reshape(1.0 - in3, [-1, 1, 1])), tf.multiply(in2, tf.reshape(in3, [-1, 1, 1])))",
                "in3 = tf.reshape(in3, (-1,1,1))\nreturn (1-in3)*in1 + in3*in2",
                "return in1 + tf.multiply(in3[:, tf.newaxis, tf.newaxis], (in2 - in1))",
                "return tf.add(tf.multiply(in1, tf.subtract(1.0 ,in3)), tf.multiply(in2, in3))",
                "in3 = tf.reshape(in3, [-1, 1, 1])\n     return in1 * (1 - in3) + in2 * in3",
                "return tf.add(tf.multiply(in1, tf.broadcast_to(tf.reshape(1 - in3, [3, 1, 1]), [3, 3, 2])), tf.multiply(in2, tf.broadcast_to(tf.reshape(in3, [3, 1, 1]), [3, 3, 2])))",
                "return tf.add(tf.multiply(in1, tf.reshape(1.0 - in3, [-1, 1, 1])), tf.multiply(in2, tf.reshape(in3, [-1, 1, 1])))"
            ],
            "target-program": "tf.add(in2, tf.multiply(tf.expand_dims(in3, 1), tf.subtract(in1, in2)))",
            "description": "linear interpolation between two tensors",
            "tf_operators": {
                "tf.add": 7,
                "tf.multiply": 8,
                "tf.reshape": 8,
                "tf.newaxis": 1,
                "tf.subtract": 1,
                "tf.broadcast_to": 1
            },
            "coverage_percentage": 75.0,
            "total_in_target": 4,
            "total_covered": 3
        },
        "completions": [
            "return tf.add(tf.multiply(in1, tf.reshape(1.0 - in3, [-1, 1, 1])), tf.multiply(in2, tf.reshape(in3, [-1, 1, 1])))",
            "return tf.add(tf.multiply(in1, tf.reshape(1.0 - in3, [-1, 1, 1])), tf.multiply(in2, tf.reshape(in3, [-1, 1, 1])))",
            "return tf.add(tf.multiply(in1, tf.reshape(1.0 - in3, [3, 1, 1])), tf.multiply(in2, tf.reshape(in3, [3, 1, 1])))",
            "return tf.add(tf.multiply(in1, tf.reshape(1.0 - in3, [-1, 1, 1])), tf.multiply(in2, tf.reshape(in3, [-1, 1, 1])))",
            "in3 = tf.reshape(in3, (-1,1,1))\nreturn (1-in3)*in1 + in3*in2",
            "return in1 + tf.multiply(in3[:, tf.newaxis, tf.newaxis], (in2 - in1))",
            "return tf.add(tf.multiply(in1, tf.subtract(1.0 ,in3)), tf.multiply(in2, in3))",
            "in3 = tf.reshape(in3, [-1, 1, 1])\n     return in1 * (1 - in3) + in2 * in3",
            "return tf.add(tf.multiply(in1, tf.broadcast_to(tf.reshape(1 - in3, [3, 1, 1]), [3, 3, 2])), tf.multiply(in2, tf.broadcast_to(tf.reshape(in3, [3, 1, 1]), [3, 3, 2])))",
            "return tf.add(tf.multiply(in1, tf.reshape(1.0 - in3, [-1, 1, 1])), tf.multiply(in2, tf.reshape(in3, [-1, 1, 1])))"
        ]
    },
    {
        "constants": "[]",
        "description": "divide each element by the column index",
        "target_program": "tf.cast(tf.divide(in1, tf.add(in1, tf.range(8))), tf.float32)",
        "source": "https://stackoverflow.com/questions/43306788/divide-elements-of-1-d-tensor-by-the-corrispondent-index",
        "name": "stackoverflow_36",
        "examples": {
            "inputs": "[[1, 0, 1, 1, 0, 1, 0, 1],]",
            "outputs": "[1., 0., 0.333333, 0.25, 0., 0.166667, 0., 0.125]"
        },
        "response": {
            "task_id": "stackoverflow_36",
            "completions": [
                "in1 = tf.divide(in1, tf.range(1, tf.shape(in1)[0]+1))\n     return in1",
                "# We use the tf.divide function to divide each element by the column index with the help of tf.range and tf.cast functions.\n  \n    in1 = tf.cast(in1, tf.float32)   # Converting the input tensor to float32 for performing division\n    denom = tf.range(1, tf.shape(in1)[0] + 1, dtype=tf.float32) # Creating a tensor with column indices\n    return tf.divide(in1, denom) # Dividing each element of in1 by the corresponding column index. The broadcasting rule applies here.",
                "return tf.divide(in1, tf.range(1, tf.size(in1) + 1))",
                "shape = tf.shape(in1)\ncolumn_indices = tf.range(start=1, limit=shape[0]+1, delta=1)\ncolumn_indices = tf.cast(column_indices, dtype=tf.float32)\nreturn tf.divide(in1, column_indices)",
                "in1 = tf.constant(in1, dtype=tf.float32)\n     col_indices = tf.range(1, tf.size(in1) + 1, dtype=tf.float32)\n     return tf.divide(in1, col_indices)",
                "in1 = tf.cast(in1, dtype=tf.float32)\n     shape = tf.shape(in1)\n     divisor = tf.range(1, tf.cast(shape[-1], tf.float32) + 1)\n     divisor = tf.broadcast_to(divisor, shape)\n     return tf.divide(in1, divisor)",
                "import tensorflow as tf\ndef transform(in1):\n    in1 = tf.cast(in1, dtype=tf.float32)\n    col_indices = tf.range(start=1, limit=tf.shape(in1)[0]+1, delta=1, dtype=tf.float32)\n    return tf.divide(in1, col_indices)",
                "shape = tf.shape(in1)\ncol_indices = tf.range(1, shape[1] + 1, dtype=in1.dtype)\ncol_indices = tf.broadcast_to(col_indices, shape)\nreturn tf.divide(in1, col_indices)",
                "return tf.divide(in1, tf.range(1, tf.shape(in1)[0]+1))",
                "# First, we need to convert the input into a tensorflow tensor\n    tensor = tf.constant(in1, dtype=tf.float32)\n    # Then, we get the shape of the tensor, which gives us the column count\n    col_count = tf.shape(tensor)[0]\n    # We generate a range tensor from 1 to the column count\n    range_tensor = tf.range(1, col_count+1, dtype=tf.float32)\n    # Finally, we divide the input tensor by the range tensor\n    result = tf.divide(tensor, range_tensor)\n    return result"
            ],
            "target-program": "tf.cast(tf.divide(in1, tf.add(in1, tf.range(8))), tf.float32)",
            "description": "divide each element by the column index",
            "tf_operators": {
                "tf.shape": 8,
                "tf.range": 10,
                "tf.divide": 10,
                "tf.cast": 4,
                "tf.float32": 6,
                "tf.size": 2,
                "tf.constant": 2,
                "tf.broadcast_to": 2
            },
            "coverage_percentage": 80.0,
            "total_in_target": 5,
            "total_covered": 4
        },
        "completions": [
            "in1 = tf.divide(in1, tf.range(1, tf.shape(in1)[0]+1))\n     return in1",
            "# We use the tf.divide function to divide each element by the column index with the help of tf.range and tf.cast functions.\n  \n    in1 = tf.cast(in1, tf.float32)   # Converting the input tensor to float32 for performing division\n    denom = tf.range(1, tf.shape(in1)[0] + 1, dtype=tf.float32) # Creating a tensor with column indices\n    return tf.divide(in1, denom) # Dividing each element of in1 by the corresponding column index. The broadcasting rule applies here.",
            "return tf.divide(in1, tf.range(1, tf.size(in1) + 1))",
            "shape = tf.shape(in1)\ncolumn_indices = tf.range(start=1, limit=shape[0]+1, delta=1)\ncolumn_indices = tf.cast(column_indices, dtype=tf.float32)\nreturn tf.divide(in1, column_indices)",
            "in1 = tf.constant(in1, dtype=tf.float32)\n     col_indices = tf.range(1, tf.size(in1) + 1, dtype=tf.float32)\n     return tf.divide(in1, col_indices)",
            "in1 = tf.cast(in1, dtype=tf.float32)\n     shape = tf.shape(in1)\n     divisor = tf.range(1, tf.cast(shape[-1], tf.float32) + 1)\n     divisor = tf.broadcast_to(divisor, shape)\n     return tf.divide(in1, divisor)",
            "import tensorflow as tf\ndef transform(in1):\n    in1 = tf.cast(in1, dtype=tf.float32)\n    col_indices = tf.range(start=1, limit=tf.shape(in1)[0]+1, delta=1, dtype=tf.float32)\n    return tf.divide(in1, col_indices)",
            "shape = tf.shape(in1)\ncol_indices = tf.range(1, shape[1] + 1, dtype=in1.dtype)\ncol_indices = tf.broadcast_to(col_indices, shape)\nreturn tf.divide(in1, col_indices)",
            "return tf.divide(in1, tf.range(1, tf.shape(in1)[0]+1))",
            "# First, we need to convert the input into a tensorflow tensor\n    tensor = tf.constant(in1, dtype=tf.float32)\n    # Then, we get the shape of the tensor, which gives us the column count\n    col_count = tf.shape(tensor)[0]\n    # We generate a range tensor from 1 to the column count\n    range_tensor = tf.range(1, col_count+1, dtype=tf.float32)\n    # Finally, we divide the input tensor by the range tensor\n    result = tf.divide(tensor, range_tensor)\n    return result"
        ]
    },
    {
        "constants": "[]",
        "description": "dot product a vector with last dimension of a tensor",
        "target_program": "tf.tensordot(in1, in2, 1)",
        "source": "https://stackoverflow.com/questions/49206051/multiply-4-d-tensor-with-1-d-tensor",
        "name": "stackoverflow_37",
        "examples": {
            "inputs": "[[[[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]],  [[1.2, 3.4, 5.6], [7.8, 9.8, 7.6]]]],[0.5, 1.0, 2.0],]",
            "outputs": "[[[8.5, 19.0], [15.2, 28.9]]]"
        },
        "response": {
            "task_id": "stackoverflow_37",
            "completions": [
                "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
                "return tf.tensordot(in1, in2, axes=[[3],[0]])",
                "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
                "return tf.tensordot(in1, in2, axes=[[-1],[0]])",
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=[-1,0])",
                "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
                "return tf.tensordot(in1, in2, axes=[[-1],[0]])",
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=1)"
            ],
            "target-program": "tf.tensordot(in1, in2, 1)",
            "description": "dot product a vector with last dimension of a tensor",
            "tf_operators": {
                "tf.tensordot": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        },
        "completions": [
            "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
            "return tf.tensordot(in1, in2, axes=[[3],[0]])",
            "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
            "return tf.tensordot(in1, in2, axes=[[-1],[0]])",
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=[-1,0])",
            "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
            "return tf.tensordot(in1, in2, axes=[[-1],[0]])",
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=1)"
        ]
    },
    {
        "constants": "[]",
        "description": "compute the product of marked elements",
        "target_program": "tf.reduce_prod(tf.maximum(tf.reduce_max(in2), tf.multiply(in1, in2)), axis=1)",
        "source": "https://stackoverflow.com/questions/49511529/tensorflow-compute-multiplication-by-binary-matrix",
        "name": "stackoverflow_38",
        "examples": {
            "inputs": "[[9, 2, 5, 3, 7, 4],[[0, 0, 1, 0, 1, 0], [1, 0, 0, 0, 0, 0], [0, 1, 1, 1, 0, 1]],]",
            "outputs": "[35, 9, 120]"
        },
        "response": {
            "task_id": "stackoverflow_38",
            "completions": [
                "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)",
                "mask = tf.boolean_mask(in1, in2)\nres = tf.reduce_prod(mask, axis=1)\nreturn res",
                "return tf.reduce_prod(tf.boolean_mask(in1,in2),axis=1)",
                "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, bool)), axis=1)",
                "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1).numpy().tolist()",
                "masked_values = tf.boolean_mask(in1, in2)\n     result = tf.math.segment_prod(masked_values, tf.cumsum(in2, axis=1) - 1)\n     return result",
                "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)",
                "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)",
                "return tf.reduce_prod(tf.boolean_mask(in1,in2), axis=1)",
                "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)"
            ],
            "target-program": "tf.reduce_prod(tf.maximum(tf.reduce_max(in2), tf.multiply(in1, in2)), axis=1)",
            "description": "compute the product of marked elements",
            "tf_operators": {
                "tf.reduce_prod": 9,
                "tf.boolean_mask": 10,
                "tf.cast": 1,
                "tf.cumsum": 1,
                "tf.math.segment_prod": 1
            },
            "coverage_percentage": 25.0,
            "total_in_target": 4,
            "total_covered": 1
        },
        "completions": [
            "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)",
            "mask = tf.boolean_mask(in1, in2)\nres = tf.reduce_prod(mask, axis=1)\nreturn res",
            "return tf.reduce_prod(tf.boolean_mask(in1,in2),axis=1)",
            "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, bool)), axis=1)",
            "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1).numpy().tolist()",
            "masked_values = tf.boolean_mask(in1, in2)\n     result = tf.math.segment_prod(masked_values, tf.cumsum(in2, axis=1) - 1)\n     return result",
            "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)",
            "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)",
            "return tf.reduce_prod(tf.boolean_mask(in1,in2), axis=1)",
            "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)"
        ]
    },
    {
        "constants": "[]",
        "description": "(\\'set to 0 the elements with absolute value less than 1, and square the other elements\\')",
        "target_program": "tf.multiply(tf.square(in1), tf.cast(tf.cast(tf.cast(in1, tf.int32), tf.bool), tf.float32))",
        "source": "https://stackoverflow.com/questions/37912161/how-can-i-compute-element-wise-conditionals-on-batches-in-tensorflow",
        "name": "stackoverflow_39",
        "examples": {
            "inputs": "[[[-1.5, 1.0, 0.9, 2.0], [1.1, 0.0, -0.1, -0.9], [-1.0, 0.1, -1.1, 2.5]],]",
            "outputs": "[[2.25, 1.0, 0.0, 4.0],    [1.21, 0.0, 0.0, 0.0],    [1.0, 0.0, 1.21, 6.25]]"
        },
        "response": {
            "task_id": "stackoverflow_39",
            "completions": [
                "# we first create a mask of elements that are less than 1 in absolute value\n    mask = tf.less(tf.abs(in1), 1)\n\n    # we set these elements to 0\n    in1_zeroed = tf.where(mask, tf.zeros_like(in1), in1)\n\n    # we square the remaining elements\n    return tf.square(in1_zeroed)",
                "abs_in1 = tf.abs(in1)\nmask = tf.greater(abs_in1, 1.0)\nres = tf.where(mask, tf.square(in1), tf.zeros_like(in1))\nreturn res",
                "return tf.where(tf.abs(in1)<1, 0, tf.square(in1))",
                "mask = tf.abs(in1) < 1\nin1 = tf.where(mask, 0, tf.square(in1))\nreturn in1",
                "abs_input = tf.abs(in1)\nmask = tf.greater(abs_input, 1)\nsquared_input = tf.square(in1)\nzeros = tf.zeros_like(in1)\nreturn tf.where(mask, squared_input, zeros)",
                "in2 = tf.where(tf.abs(in1) < 1., tf.zeros_like(in1), in1)\n     return tf.square(in2)",
                "cond = tf.greater(tf.abs(in1), 1.0)\nout1 = tf.where(cond, tf.square(in1), 0.0)\nreturn out1",
                "filtered_elements = tf.where(tf.abs(in1) < 1, 0, in1)\nreturn tf.square(filtered_elements)",
                "abs_in1 = tf.abs(in1)\nmask = tf.greater(abs_in1, 1.0)\nout = tf.where(mask, tf.square(in1), tf.zeros_like(in1))\nreturn out",
                "return tf.where(tf.abs(in1) < 1, 0, tf.square(in1))"
            ],
            "target-program": "tf.multiply(tf.square(in1), tf.cast(tf.cast(tf.cast(in1, tf.int32), tf.bool), tf.float32))",
            "description": "(\\'set to 0 the elements with absolute value less than 1, and square the other elements\\')",
            "tf_operators": {
                "tf.abs": 10,
                "tf.less": 1,
                "tf.zeros_like": 5,
                "tf.square": 10,
                "tf.where": 10,
                "tf.greater": 4
            },
            "coverage_percentage": 16.666666666666664,
            "total_in_target": 6,
            "total_covered": 1
        },
        "completions": [
            "# we first create a mask of elements that are less than 1 in absolute value\n    mask = tf.less(tf.abs(in1), 1)\n\n    # we set these elements to 0\n    in1_zeroed = tf.where(mask, tf.zeros_like(in1), in1)\n\n    # we square the remaining elements\n    return tf.square(in1_zeroed)",
            "abs_in1 = tf.abs(in1)\nmask = tf.greater(abs_in1, 1.0)\nres = tf.where(mask, tf.square(in1), tf.zeros_like(in1))\nreturn res",
            "return tf.where(tf.abs(in1)<1, 0, tf.square(in1))",
            "mask = tf.abs(in1) < 1\nin1 = tf.where(mask, 0, tf.square(in1))\nreturn in1",
            "abs_input = tf.abs(in1)\nmask = tf.greater(abs_input, 1)\nsquared_input = tf.square(in1)\nzeros = tf.zeros_like(in1)\nreturn tf.where(mask, squared_input, zeros)",
            "in2 = tf.where(tf.abs(in1) < 1., tf.zeros_like(in1), in1)\n     return tf.square(in2)",
            "cond = tf.greater(tf.abs(in1), 1.0)\nout1 = tf.where(cond, tf.square(in1), 0.0)\nreturn out1",
            "filtered_elements = tf.where(tf.abs(in1) < 1, 0, in1)\nreturn tf.square(filtered_elements)",
            "abs_in1 = tf.abs(in1)\nmask = tf.greater(abs_in1, 1.0)\nout = tf.where(mask, tf.square(in1), tf.zeros_like(in1))\nreturn out",
            "return tf.where(tf.abs(in1) < 1, 0, tf.square(in1))"
        ]
    },
    {
        "constants": "[]",
        "description": "use the output of tf.nn.top_k to make a sparse tensor",
        "target_program": "tf.sparse.to_dense(tf.SparseTensor(tf.cast(in2, tf.int64), in1, (3, 5)))",
        "source": "https://stackoverflow.com/questions/43996831/make-a-sparse-tensor-based-on-the-output-of-tf-nn-top-k",
        "name": "stackoverflow_40",
        "examples": {
            "inputs": "[[4, 5, 2, 7, 8, 6],[[0, 2], [0, 4], [1, 1], [1, 3], [2, 0], [2, 3]],]",
            "outputs": "[[0, 0, 4, 0, 5],[0, 2, 0, 7, 0],[8, 0, 0, 6, 0]]"
        },
        "response": {
            "task_id": "stackoverflow_40",
            "completions": [
                "values, indices = tf.math.top_k(in1, len(in1))\nreturn tf.scatter_nd(in2, values, tf.constant([3, 5]))",
                "values, indices = tf.math.top_k(in1, k=in1.shape[0])\nreturn tf.scatter_nd(tf.expand_dims(indices, 1), values, tf.constant([in1.shape[0]]))",
                "values, indices = tf.math.top_k(in1, k=in1.shape[0])\nout = tf.scatter_nd(indices, values, tf.constant([in1.shape[0], tf.reduce_max(indices)+1]))\nreturn out",
                "values, indices = tf.math.top_k(in1, k=in1.shape[0])\nsparse_tensor = tf.scatter_nd(tf.expand_dims(indices,1), values, tf.constant([in1.shape[0]]))\nreturn sparse_tensor",
                "top_values, top_indices = tf.math.top_k(in1, k=tf.shape(in1)[0])\nsparse_tensor = tf.scatter_nd(tf.expand_dims(top_indices, 1), top_values, tf.shape(in1))\ntransformed_tensor = tf.gather(sparse_tensor, in2)\nreturn transformed_tensor",
                "values, indices = tf.math.top_k(in1, len(in1))\nreturn tf.scatter_nd(tf.cast(in2, tf.int64), values, [3,5])",
                "values, indices = tf.nn.top_k(in1, len(in1))\nsparse_tensor = tf.scatter_nd(indices, values, tf.constant([tf.reduce_max(indices) + 1, len(in1)]))\nreturn sparse_tensor",
                "values, indices = tf.math.top_k(in1, k=len(in1))\nupdates = tf.ones(tf.shape(values))\nsparse_tensor = tf.scatter_nd(indices=tf.expand_dims(indices, 1), updates=updates, shape=[tf.reduce_max(indices) + 1])\nreturn tf.transpose(sparse_tensor)",
                "val, idx = tf.math.top_k(in1)\nout = tf.scatter_nd(tf.cast(idx[None], tf.int64), val, tf.constant(in2))\nreturn tf.reshape(out, (-1, in2[-1][1]+1))",
                "values, indices = tf.math.top_k(in1, k=tf.shape(in1)[0])\nsparse_tensor = tf.scatter_nd(tf.reshape(indices, (-1, 1)), values, [tf.shape(in1)[0]])\ndense_tensor = tf.reshape(sparse_tensor, (tf.shape(in2)[0], tf.shape(in2)[1]))\nreturn dense_tensor"
            ],
            "target-program": "tf.sparse.to_dense(tf.SparseTensor(tf.cast(in2, tf.int64), in1, (3, 5)))",
            "description": "use the output of tf.nn.top_k to make a sparse tensor",
            "tf_operators": {
                "tf.constant": 6,
                "tf.math.top_k": 9,
                "tf.scatter_nd": 10,
                "tf.expand_dims": 4,
                "tf.reduce_max": 3,
                "tf.shape": 3,
                "tf.gather": 1,
                "tf.int64": 2,
                "tf.cast": 2,
                "tf.nn.top_k": 1,
                "tf.transpose": 1,
                "tf.ones": 1,
                "tf.reshape": 2
            },
            "coverage_percentage": 50.0,
            "total_in_target": 4,
            "total_covered": 2
        },
        "completions": [
            "values, indices = tf.math.top_k(in1, len(in1))\nreturn tf.scatter_nd(in2, values, tf.constant([3, 5]))",
            "values, indices = tf.math.top_k(in1, k=in1.shape[0])\nreturn tf.scatter_nd(tf.expand_dims(indices, 1), values, tf.constant([in1.shape[0]]))",
            "values, indices = tf.math.top_k(in1, k=in1.shape[0])\nout = tf.scatter_nd(indices, values, tf.constant([in1.shape[0], tf.reduce_max(indices)+1]))\nreturn out",
            "values, indices = tf.math.top_k(in1, k=in1.shape[0])\nsparse_tensor = tf.scatter_nd(tf.expand_dims(indices,1), values, tf.constant([in1.shape[0]]))\nreturn sparse_tensor",
            "top_values, top_indices = tf.math.top_k(in1, k=tf.shape(in1)[0])\nsparse_tensor = tf.scatter_nd(tf.expand_dims(top_indices, 1), top_values, tf.shape(in1))\ntransformed_tensor = tf.gather(sparse_tensor, in2)\nreturn transformed_tensor",
            "values, indices = tf.math.top_k(in1, len(in1))\nreturn tf.scatter_nd(tf.cast(in2, tf.int64), values, [3,5])",
            "values, indices = tf.nn.top_k(in1, len(in1))\nsparse_tensor = tf.scatter_nd(indices, values, tf.constant([tf.reduce_max(indices) + 1, len(in1)]))\nreturn sparse_tensor",
            "values, indices = tf.math.top_k(in1, k=len(in1))\nupdates = tf.ones(tf.shape(values))\nsparse_tensor = tf.scatter_nd(indices=tf.expand_dims(indices, 1), updates=updates, shape=[tf.reduce_max(indices) + 1])\nreturn tf.transpose(sparse_tensor)",
            "val, idx = tf.math.top_k(in1)\nout = tf.scatter_nd(tf.cast(idx[None], tf.int64), val, tf.constant(in2))\nreturn tf.reshape(out, (-1, in2[-1][1]+1))",
            "values, indices = tf.math.top_k(in1, k=tf.shape(in1)[0])\nsparse_tensor = tf.scatter_nd(tf.reshape(indices, (-1, 1)), values, [tf.shape(in1)[0]])\ndense_tensor = tf.reshape(sparse_tensor, (tf.shape(in2)[0], tf.shape(in2)[1]))\nreturn dense_tensor"
        ]
    },
    {
        "constants": "[]",
        "description": "copy all elements except at the given index",
        "target_program": "tf.boolean_mask(in1, tf.not_equal(tf.constant(in2), tf.range(10)))",
        "source": "https://stackoverflow.com/questions/54499051/elegant-way-to-access-python-list-and-tensor-in-tensorflow",
        "name": "stackoverflow_41",
        "examples": {
            "inputs": "[[5, 2, 8, 2, 4, 1, 1, 0, 2, 1],3,]",
            "outputs": "[5, 2, 8, 4, 1, 1, 0, 2, 1]"
        },
        "response": {
            "task_id": "stackoverflow_41",
            "completions": [
                "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, mask)",
                "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, mask)",
                "return tf.boolean_mask(in1, tf.not_equal(tf.range(tf.shape(in1)[0]), in2))",
                "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, mask)",
                "in1 = tf.constant(in1)\n     indices = tf.range(tf.shape(in1)[0])\n     mask = tf.not_equal(indices, in2)\n     out = tf.boolean_mask(in1, mask)\n     return out.numpy()",
                "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, mask)",
                "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nout = tf.boolean_mask(in1, mask)\nreturn out",
                "in1 = tf.constant(in1)\n     in2 = tf.constant(in2)\n     indices = tf.range(tf.shape(in1)[0])\n     mask = tf.not_equal(indices, in2)\n     return tf.boolean_mask(in1, mask)",
                "return tf.concat([in1[:in2], in1[in2+1:]], axis=0)",
                "indices = tf.range(tf.shape(in1)[0])\n    return tf.boolean_mask(in1, tf.not_equal(indices, in2))"
            ],
            "target-program": "tf.boolean_mask(in1, tf.not_equal(tf.constant(in2), tf.range(10)))",
            "description": "copy all elements except at the given index",
            "tf_operators": {
                "tf.shape": 9,
                "tf.range": 9,
                "tf.boolean_mask": 9,
                "tf.not_equal": 9,
                "tf.constant": 2,
                "tf.concat": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 4,
            "total_covered": 4
        },
        "completions": [
            "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, mask)",
            "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, mask)",
            "return tf.boolean_mask(in1, tf.not_equal(tf.range(tf.shape(in1)[0]), in2))",
            "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, mask)",
            "in1 = tf.constant(in1)\n     indices = tf.range(tf.shape(in1)[0])\n     mask = tf.not_equal(indices, in2)\n     out = tf.boolean_mask(in1, mask)\n     return out.numpy()",
            "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, mask)",
            "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nout = tf.boolean_mask(in1, mask)\nreturn out",
            "in1 = tf.constant(in1)\n     in2 = tf.constant(in2)\n     indices = tf.range(tf.shape(in1)[0])\n     mask = tf.not_equal(indices, in2)\n     return tf.boolean_mask(in1, mask)",
            "return tf.concat([in1[:in2], in1[in2+1:]], axis=0)",
            "indices = tf.range(tf.shape(in1)[0])\n    return tf.boolean_mask(in1, tf.not_equal(indices, in2))"
        ]
    },
    {
        "constants": "[]",
        "description": "create a binary vector where the max element is 1",
        "target_program": "tf.cast(tf.equal(in1, tf.reduce_max(in1)), tf.int32)",
        "source": "https://stackoverflow.com/questions/54493814/binary-vector-of-max",
        "name": "stackoverflow_42",
        "examples": {
            "inputs": "[[4, 6, 2, 6, 7, 3, -3],]",
            "outputs": "[0, 0, 0, 0, 1, 0, 0]"
        },
        "response": {
            "task_id": "stackoverflow_42",
            "completions": [
                "max_elem = tf.reduce_max(in1)\nequal_mask = tf.equal(in1, max_elem)\nbinary_vector = tf.cast(equal_mask, tf.int32)\nreturn binary_vector",
                "max_val = tf.reduce_max(in1)\nbinary_vec = tf.equal(in1, max_val)\nbinary_vec = tf.cast(binary_vec, tf.int32)\nreturn binary_vec",
                "max_elem = tf.reduce_max(in1)\nbinary_vector = tf.where(tf.equal(in1, max_elem), 1, 0)\nreturn binary_vector",
                "max_value_index = tf.argmax(in1, 0)\noutput = tf.one_hot(max_value_index, tf.size(in1))\nreturn output.numpy()",
                "max_elem = tf.reduce_max(in1)\nreturn tf.cast(tf.equal(in1, max_elem), tf.int32)",
                "max_val = tf.reduce_max(in1)\nresult = tf.where(tf.equal(in1, max_val), 1, 0)\nreturn result",
                "max_value = tf.reduce_max(in1)\nreturn tf.cast(tf.equal(in1, max_value), tf.int32)",
                "max_value = tf.reduce_max(in1)\nout = tf.cast(tf.equal(in1, max_value), tf.int32)\nreturn out",
                "max_val = tf.reduce_max(in1)\nbinary_vec = tf.where(tf.equal(in1, max_val), 1, 0)\nreturn binary_vec",
                "max_value = tf.reduce_max(in1)\nreturn tf.cast(tf.equal(in1, max_value), tf.int32)"
            ],
            "target-program": "tf.cast(tf.equal(in1, tf.reduce_max(in1)), tf.int32)",
            "description": "create a binary vector where the max element is 1",
            "tf_operators": {
                "tf.reduce_max": 9,
                "tf.int32": 6,
                "tf.equal": 9,
                "tf.cast": 6,
                "tf.where": 3,
                "tf.one_hot": 1,
                "tf.argmax": 1,
                "tf.size": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 4,
            "total_covered": 4
        },
        "completions": [
            "max_elem = tf.reduce_max(in1)\nequal_mask = tf.equal(in1, max_elem)\nbinary_vector = tf.cast(equal_mask, tf.int32)\nreturn binary_vector",
            "max_val = tf.reduce_max(in1)\nbinary_vec = tf.equal(in1, max_val)\nbinary_vec = tf.cast(binary_vec, tf.int32)\nreturn binary_vec",
            "max_elem = tf.reduce_max(in1)\nbinary_vector = tf.where(tf.equal(in1, max_elem), 1, 0)\nreturn binary_vector",
            "max_value_index = tf.argmax(in1, 0)\noutput = tf.one_hot(max_value_index, tf.size(in1))\nreturn output.numpy()",
            "max_elem = tf.reduce_max(in1)\nreturn tf.cast(tf.equal(in1, max_elem), tf.int32)",
            "max_val = tf.reduce_max(in1)\nresult = tf.where(tf.equal(in1, max_val), 1, 0)\nreturn result",
            "max_value = tf.reduce_max(in1)\nreturn tf.cast(tf.equal(in1, max_value), tf.int32)",
            "max_value = tf.reduce_max(in1)\nout = tf.cast(tf.equal(in1, max_value), tf.int32)\nreturn out",
            "max_val = tf.reduce_max(in1)\nbinary_vec = tf.where(tf.equal(in1, max_val), 1, 0)\nreturn binary_vec",
            "max_value = tf.reduce_max(in1)\nreturn tf.cast(tf.equal(in1, max_value), tf.int32)"
        ]
    },
    {
        "constants": "[]",
        "description": "extract elements of a tensor given row indices",
        "target_program": "tf.gather_nd(tf.transpose(in1), tf.expand_dims(in2, 1), batch_dims=1)",
        "source": "https://stackoverflow.com/questions/54455169/better-way-to-access-individual-elements-in-a-tensor",
        "name": "stackoverflow_43",
        "examples": {
            "inputs": "[[[12, 34, 56, 78, 90, 10], [99, 88, 77, 55, 44, 33], [-1, -2, -3, -4, -5, -6]],[0, 1, 1, 0, 2, 0],]",
            "outputs": "[12, 88, 77, 78, -5, 10]"
        },
        "response": {
            "task_id": "stackoverflow_43",
            "completions": [
                "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1))",
                "return tf.gather_nd(in1, tf.transpose(tf.stack([in2, tf.range(tf.shape(in2)[0])])))",
                "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=-1))",
                "return tf.gather(in1, in2, axis=1)",
                "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1))",
                "return tf.gather_nd(in1, tf.stack((tf.range(tf.shape(in2)[0]), in2), axis=-1))",
                "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1))",
                "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1))",
                "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1))",
                "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1))"
            ],
            "target-program": "tf.gather_nd(tf.transpose(in1), tf.expand_dims(in2, 1), batch_dims=1)",
            "description": "extract elements of a tensor given row indices",
            "tf_operators": {
                "tf.shape": 9,
                "tf.stack": 9,
                "tf.range": 9,
                "tf.gather_nd": 9,
                "tf.transpose": 1,
                "tf.gather": 1
            },
            "coverage_percentage": 66.66666666666666,
            "total_in_target": 3,
            "total_covered": 2
        },
        "completions": [
            "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1))",
            "return tf.gather_nd(in1, tf.transpose(tf.stack([in2, tf.range(tf.shape(in2)[0])])))",
            "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=-1))",
            "return tf.gather(in1, in2, axis=1)",
            "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1))",
            "return tf.gather_nd(in1, tf.stack((tf.range(tf.shape(in2)[0]), in2), axis=-1))",
            "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1))",
            "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1))",
            "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1))",
            "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1))"
        ]
    },
    {
        "constants": "[2]",
        "description": "sum across columns for pairs of consecutive rows",
        "target_program": "tf.squeeze(tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1))",
        "source": "https://stackoverflow.com/questions/54402389/sum-the-columns-for-each-two-consecutive-rows-of-a-tensor-of-3-dimensions",
        "name": "stackoverflow_44",
        "examples": {
            "inputs": "[[[3, 5, 2], [6, 2, 3], [8, 7, 1], [0, -3, 5], [-4, 7, 3], [2, 1, 6], [10, 20, 30], [4, 5, 6]],]",
            "outputs": "[[9, 7, 5],    [8, 4, 6],    [-2, 8, 9],    [14, 25, 36]]"
        },
        "response": {
            "task_id": "stackoverflow_44",
            "completions": [
                "pairs = tf.reshape(in1, (-1, 2, in1.shape[-1]))\nreturn tf.reduce_sum(pairs, axis=1)",
                "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
                "res = []\n     for i in range(0, len(in1), 2):\n          res.append(tf.add(in1[i], in1[i+1]))\n     return np.array(res)",
                "return tf.reduce_sum(tf.reshape(in1, [-1, 2, in1.shape[1]]), axis=1)",
                "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
                "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
                "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
                "reshaped = tf.reshape(in1, (-1, 2, in1.shape[1]))\n     return tf.reduce_sum(reshaped, axis=1)",
                "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), 1)",
                "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)"
            ],
            "target-program": "tf.squeeze(tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1))",
            "description": "sum across columns for pairs of consecutive rows",
            "tf_operators": {
                "tf.reshape": 9,
                "tf.reduce_sum": 9,
                "tf.add": 1
            },
            "coverage_percentage": 66.66666666666666,
            "total_in_target": 3,
            "total_covered": 2
        },
        "completions": [
            "pairs = tf.reshape(in1, (-1, 2, in1.shape[-1]))\nreturn tf.reduce_sum(pairs, axis=1)",
            "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
            "res = []\n     for i in range(0, len(in1), 2):\n          res.append(tf.add(in1[i], in1[i+1]))\n     return np.array(res)",
            "return tf.reduce_sum(tf.reshape(in1, [-1, 2, in1.shape[1]]), axis=1)",
            "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
            "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
            "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
            "reshaped = tf.reshape(in1, (-1, 2, in1.shape[1]))\n     return tf.reduce_sum(reshaped, axis=1)",
            "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), 1)",
            "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)"
        ]
    },
    {
        "constants": "[]",
        "description": "reverse the order in the marked rows",
        "target_program": "tf.where(tf.sequence_mask(in2), x=tf.roll(in1, 1, -1), y=in1)",
        "source": "https://stackoverflow.com/questions/54337925/reverse-order-of-some-elements-in-tensorflow",
        "name": "stackoverflow_45",
        "examples": {
            "inputs": "[[[[12, 34], [56, 78], [23, 54], [76, 78], [42, 24]]],[1, 0, 1, 0, 1],]",
            "outputs": "[[[34, 12], [56, 78], [54, 23], [76, 78], [24, 42]]]"
        },
        "response": {
            "task_id": "stackoverflow_45",
            "completions": [
                "return tf.where(tf.broadcast_to(tf.expand_dims(in2, axis=-1),tf.shape(in1)),tf.reverse(in1,[2]),in1)",
                "indices = tf.constant([[i] for i in range(len(in2))])\n    reverse_mask = tf.boolean_mask(indices, in2) \n    out1 = tf.reverse(in1[reverse_mask], [1])\n    updates = tf.where(in2, out1, in1)\n    return tf.reshape(updates, tf.shape(in1))",
                "return tf.where(tf.cast(in2, bool), tf.reverse(in1, [-1]), in1)",
                "return tf.where(tf.expand_dims(in2, -1), tf.reverse(in1, [-1]), in1)",
                "reverse_mask = tf.boolean_mask(in1, in2, axis=1)\n     reverse_mask = tf.reverse(reverse_mask, axis=[-1])\n     in1 = tf.boolean_mask(in1, tf.logical_not(in2), axis=1)\n\n     indices = tf.where(in2)\n     updates = tf.reshape(reverse_mask, [-1])\n     shape = tf.shape(in1)\n\n     return tf.tensor_scatter_nd_update(in1, indices, updates)",
                "return tf.where(tf.broadcast_to(tf.reshape(in2,(-1,1)), tf.shape(in1)), tf.reverse(in1,[-1]), in1)",
                "return tf.where(tf.expand_dims(in2, -1), tf.reverse(in1, [-1]), in1)",
                "return tf.where(tf.cast(tf.expand_dims(in2, axis=-1), tf.bool), tf.reverse(in1, axis=[-1]), in1)",
                "out = tf.where(tf.reshape(in2,(-1,1)), tf.reverse(in1,[-1]), in1)\nreturn out",
                "return tf.where(tf.broadcast_to(tf.expand_dims(in2, axis=-1), tf.shape(in1)), tf.reverse(in1, axis=[-1]), in1)"
            ],
            "target-program": "tf.where(tf.sequence_mask(in2), x=tf.roll(in1, 1, -1), y=in1)",
            "description": "reverse the order in the marked rows",
            "tf_operators": {
                "tf.shape": 5,
                "tf.broadcast_to": 3,
                "tf.where": 10,
                "tf.reverse": 10,
                "tf.expand_dims": 5,
                "tf.boolean_mask": 2,
                "tf.reshape": 4,
                "tf.constant": 1,
                "tf.cast": 2,
                "tf.logical_not": 1,
                "tf.tensor_scatter_nd_update": 1,
                "tf.bool": 1
            },
            "coverage_percentage": 33.33333333333333,
            "total_in_target": 3,
            "total_covered": 1
        },
        "completions": [
            "return tf.where(tf.broadcast_to(tf.expand_dims(in2, axis=-1),tf.shape(in1)),tf.reverse(in1,[2]),in1)",
            "indices = tf.constant([[i] for i in range(len(in2))])\n    reverse_mask = tf.boolean_mask(indices, in2) \n    out1 = tf.reverse(in1[reverse_mask], [1])\n    updates = tf.where(in2, out1, in1)\n    return tf.reshape(updates, tf.shape(in1))",
            "return tf.where(tf.cast(in2, bool), tf.reverse(in1, [-1]), in1)",
            "return tf.where(tf.expand_dims(in2, -1), tf.reverse(in1, [-1]), in1)",
            "reverse_mask = tf.boolean_mask(in1, in2, axis=1)\n     reverse_mask = tf.reverse(reverse_mask, axis=[-1])\n     in1 = tf.boolean_mask(in1, tf.logical_not(in2), axis=1)\n\n     indices = tf.where(in2)\n     updates = tf.reshape(reverse_mask, [-1])\n     shape = tf.shape(in1)\n\n     return tf.tensor_scatter_nd_update(in1, indices, updates)",
            "return tf.where(tf.broadcast_to(tf.reshape(in2,(-1,1)), tf.shape(in1)), tf.reverse(in1,[-1]), in1)",
            "return tf.where(tf.expand_dims(in2, -1), tf.reverse(in1, [-1]), in1)",
            "return tf.where(tf.cast(tf.expand_dims(in2, axis=-1), tf.bool), tf.reverse(in1, axis=[-1]), in1)",
            "out = tf.where(tf.reshape(in2,(-1,1)), tf.reverse(in1,[-1]), in1)\nreturn out",
            "return tf.where(tf.broadcast_to(tf.expand_dims(in2, axis=-1), tf.shape(in1)), tf.reverse(in1, axis=[-1]), in1)"
        ]
    },
    {
        "constants": "[]",
        "description": "convert segment lengths to segment ids",
        "target_program": "tf.cast(tf.where(tf.sequence_mask(in1))[:, 0], tf.int32)",
        "source": "https://stackoverflow.com/questions/58652161/how-to-convert-2-3-4-to-0-0-1-1-1-2-2-2-2-to-utilize-tf-math-segment-sum",
        "name": "stackoverflow_46",
        "examples": {
            "inputs": "[[3, 4, 1],]",
            "outputs": "[0, 0, 0, 1, 1, 1, 1, 2]"
        },
        "response": {
            "task_id": "stackoverflow_46",
            "completions": [
                "segment_lengths = tf.constant(in1, dtype=tf.int32)\nsegment_positions = tf.range(tf.reduce_sum(segment_lengths))\nsegment_ids = tf.minimum(tf.searchsorted(segment_lengths, segment_positions, side='right'), tf.size(segment_lengths) - 1)\nreturn segment_ids.numpy().tolist()",
                "return tf.repeat(tf.range(tf.size(in1)), in1)",
                "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
                "return tf.cumsum(tf.ones_like(in1), exclusive=True)",
                "return tf.repeat(tf.range(tf.size(in1)), in1)",
                "ids = tf.repeat(tf.range(tf.size(in1)), in1)\nreturn ids",
                "return tf.repeat(tf.range(tf.size(in1)), in1)",
                "return tf.repeat(tf.range(tf.size(in1)), in1)",
                "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
                "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)"
            ],
            "target-program": "tf.cast(tf.where(tf.sequence_mask(in1))[:, 0], tf.int32)",
            "description": "convert segment lengths to segment ids",
            "tf_operators": {
                "tf.searchsorted": 1,
                "tf.range": 9,
                "tf.size": 6,
                "tf.minimum": 1,
                "tf.int32": 1,
                "tf.constant": 1,
                "tf.reduce_sum": 1,
                "tf.repeat": 8,
                "tf.shape": 3,
                "tf.ones_like": 1,
                "tf.cumsum": 1
            },
            "coverage_percentage": 25.0,
            "total_in_target": 4,
            "total_covered": 1
        },
        "completions": [
            "segment_lengths = tf.constant(in1, dtype=tf.int32)\nsegment_positions = tf.range(tf.reduce_sum(segment_lengths))\nsegment_ids = tf.minimum(tf.searchsorted(segment_lengths, segment_positions, side='right'), tf.size(segment_lengths) - 1)\nreturn segment_ids.numpy().tolist()",
            "return tf.repeat(tf.range(tf.size(in1)), in1)",
            "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
            "return tf.cumsum(tf.ones_like(in1), exclusive=True)",
            "return tf.repeat(tf.range(tf.size(in1)), in1)",
            "ids = tf.repeat(tf.range(tf.size(in1)), in1)\nreturn ids",
            "return tf.repeat(tf.range(tf.size(in1)), in1)",
            "return tf.repeat(tf.range(tf.size(in1)), in1)",
            "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
            "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)"
        ]
    },
    {
        "constants": "[]",
        "description": "put given values into a sequence mask",
        "target_program": "tf.reshape(tf.gather(in1, tf.cumsum(tf.reshape(tf.cast(in2, tf.int32), [-1]), exclusive=True) * tf.reshape(tf.cast(in2, tf.int32), [-1])), in2.shape)",
        "source": "https://stackoverflow.com/questions/58641546/how-can-i-put-the-sequential-values-to-the-sequence-mask",
        "name": "stackoverflow_47",
        "examples": {
            "inputs": "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16],[[True, True, True, False, False], [True, True, False, False, False], [True, True, True, True, True], [True, True, True, True, False], [True, False, False, False, False], [True, True, False, False, False]],]",
            "outputs": "[[0, 1, 2, 0, 0],    [3, 4, 0, 0, 0],    [5, 6, 7, 8, 9],    [10, 11, 12, 13, 0],    [14, 0, 0, 0, 0],    [15, 16, 0, 0, 0]]"
        },
        "response": {
            "task_id": "stackoverflow_47",
            "completions": [
                "return tf.where(in2, np.reshape(tf.range(tf.size(in2)), tf.shape(in2)), 0)",
                "indices = tf.where(in2)\n     out = tf.tensor_scatter_nd_update(in2, indices, in1)\n     return tf.cast(out, tf.int32)",
                "seq_mask = tf.cast(in2, tf.int32)\ncount_mask = tf.reduce_sum(seq_mask, axis=1)\n\nindices = tf.range(tf.reduce_sum(count_mask))\n\nupdates = tf.gather(in1, indices)\n\nshape = tf.shape(in2, out_type=tf.int32)\n\nfun_output = tf.scatter_nd(tf.where(in2), updates, shape)\n\nreturn fun_output",
                "out = tf.where(in2, tf.reshape(in1, tf.shape(in2)), 0)\nreturn out",
                "sequence = tf.cast(in1, dtype=tf.int32)\nmask = tf.cast(in2, dtype=tf.bool)\nshape = tf.shape(mask)\n\n# Calculate the maximum number of elements to store in each row of the final output\nmax_vals = tf.reduce_sum(tf.cast(mask, dtype=tf.int32), axis=1)\n\n# Create indices for each element in the original input\nindices = tf.expand_dims(tf.range(tf.reduce_sum(max_vals)), axis=0)\n\n# Assign the indices to its corresponding value in the mask\nmask_indices = tf.reshape(tf.boolean_mask(indices, mask), shape)\n\n# Create placeholder for the final output, filled with zeroes\noutput = tf.fill(shape, 0)\n\n# Insert elements of the sequence into their corresponding place in the output\noutput = tf.tensor_scatter_nd_update(output, tf.where(mask), sequence)\n\nreturn output",
                "mask = tf.boolean_mask(in1, tf.reshape(in2, [-1]))\n     filled_mask = tf.tensor_scatter_nd_update(tf.zeros_like(in2, dtype=in1.dtype),\n                                               tf.where(in2),\n                                               mask)\n     return filled_mask",
                "out = tf.where(in2, tf.reshape(in1[:tf.reduce_sum(tf.cast(in2, tf.int32))], tf.shape(in2)), 0)\nreturn out",
                "mask = tf.cast(in2, tf.int32)\naccumulated_mask = tf.cumsum(mask, axis=-1)\nflattened_mask = tf.reshape(accumulated_mask, [-1])\nin1_gathered = tf.gather(in1, flattened_mask - 1)\nresult = tf.reshape(in1_gathered, tf.shape(in2))\nresult *= in2\nreturn result",
                "return tf.where(in2, tf.reshape(in1, in2.shape), 0)",
                "# find the indices where the mask is True\n  indices = tf.where(in2)\n  # Gather the required values from the input array\n  values = tf.gather(in1, indices[:, 0])\n  # Use scatter_nd to replace the True values in the mask with the gathered values\n  result = tf.scatter_nd(indices, values, tf.shape(in2))\n  return result"
            ],
            "target-program": "tf.reshape(tf.gather(in1, tf.cumsum(tf.reshape(tf.cast(in2, tf.int32), [-1]), exclusive=True) * tf.reshape(tf.cast(in2, tf.int32), [-1])), in2.shape)",
            "description": "put given values into a sequence mask",
            "tf_operators": {
                "tf.shape": 7,
                "tf.range": 3,
                "tf.size": 1,
                "tf.where": 9,
                "tf.cast": 5,
                "tf.tensor_scatter_nd_update": 3,
                "tf.int32": 5,
                "tf.gather": 3,
                "tf.scatter_nd": 2,
                "tf.reduce_sum": 3,
                "tf.reshape": 6,
                "tf.boolean_mask": 2,
                "tf.fill": 1,
                "tf.bool": 1,
                "tf.expand_dims": 1,
                "tf.zeros_like": 1,
                "tf.cumsum": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 5,
            "total_covered": 5
        },
        "completions": [
            "return tf.where(in2, np.reshape(tf.range(tf.size(in2)), tf.shape(in2)), 0)",
            "indices = tf.where(in2)\n     out = tf.tensor_scatter_nd_update(in2, indices, in1)\n     return tf.cast(out, tf.int32)",
            "seq_mask = tf.cast(in2, tf.int32)\ncount_mask = tf.reduce_sum(seq_mask, axis=1)\n\nindices = tf.range(tf.reduce_sum(count_mask))\n\nupdates = tf.gather(in1, indices)\n\nshape = tf.shape(in2, out_type=tf.int32)\n\nfun_output = tf.scatter_nd(tf.where(in2), updates, shape)\n\nreturn fun_output",
            "out = tf.where(in2, tf.reshape(in1, tf.shape(in2)), 0)\nreturn out",
            "sequence = tf.cast(in1, dtype=tf.int32)\nmask = tf.cast(in2, dtype=tf.bool)\nshape = tf.shape(mask)\n\n# Calculate the maximum number of elements to store in each row of the final output\nmax_vals = tf.reduce_sum(tf.cast(mask, dtype=tf.int32), axis=1)\n\n# Create indices for each element in the original input\nindices = tf.expand_dims(tf.range(tf.reduce_sum(max_vals)), axis=0)\n\n# Assign the indices to its corresponding value in the mask\nmask_indices = tf.reshape(tf.boolean_mask(indices, mask), shape)\n\n# Create placeholder for the final output, filled with zeroes\noutput = tf.fill(shape, 0)\n\n# Insert elements of the sequence into their corresponding place in the output\noutput = tf.tensor_scatter_nd_update(output, tf.where(mask), sequence)\n\nreturn output",
            "mask = tf.boolean_mask(in1, tf.reshape(in2, [-1]))\n     filled_mask = tf.tensor_scatter_nd_update(tf.zeros_like(in2, dtype=in1.dtype),\n                                               tf.where(in2),\n                                               mask)\n     return filled_mask",
            "out = tf.where(in2, tf.reshape(in1[:tf.reduce_sum(tf.cast(in2, tf.int32))], tf.shape(in2)), 0)\nreturn out",
            "mask = tf.cast(in2, tf.int32)\naccumulated_mask = tf.cumsum(mask, axis=-1)\nflattened_mask = tf.reshape(accumulated_mask, [-1])\nin1_gathered = tf.gather(in1, flattened_mask - 1)\nresult = tf.reshape(in1_gathered, tf.shape(in2))\nresult *= in2\nreturn result",
            "return tf.where(in2, tf.reshape(in1, in2.shape), 0)",
            "# find the indices where the mask is True\n  indices = tf.where(in2)\n  # Gather the required values from the input array\n  values = tf.gather(in1, indices[:, 0])\n  # Use scatter_nd to replace the True values in the mask with the gathered values\n  result = tf.scatter_nd(indices, values, tf.shape(in2))\n  return result"
        ]
    },
    {
        "constants": "[]",
        "description": "find the indices of all elements",
        "target_program": "tf.cast(tf.argmax(tf.cast(tf.equal(in1, tf.expand_dims(in2, 1)), tf.int32), axis=1), tf.int32)",
        "source": "https://stackoverflow.com/questions/58481332/getting-the-indices-of-several-elements-in-a-tensorflow-at-once",
        "name": "stackoverflow_48",
        "examples": {
            "inputs": "[[32, 53, 45, 38, 29, 89, 64, 23],[38, 53, 89, 38, 32, 64],]",
            "outputs": "[3, 1, 5, 3, 0, 6]"
        },
        "response": {
            "task_id": "stackoverflow_48",
            "completions": [
                "return [tf.where(tf.equal(in1, n)).numpy()[0][0] for n in in2]",
                "return [tf.where(tf.equal(in1, x))[0] for x in in2]",
                "return tf.where(tf.equal(tf.expand_dims(in1, axis=-1), in2)).numpy()[:, 1]",
                "return tf.where(tf.equal(tf.expand_dims(in1, 1), in2)).numpy()[:, 1]",
                "return tf.where(tf.equal(tf.expand_dims(in1, axis=-1), in2)).numpy()[:,1]",
                "return [tf.where(tf.equal(in1, x)).numpy()[0][0] for x in in2]",
                "return [tf.where(tf.equal(in1, x)).numpy()[0][0] for x in in2]",
                "return tf.where(tf.equal(tf.expand_dims(in1, 1), in2)).numpy()[:,1]",
                "return tf.where(tf.equal(tf.expand_dims(in1, 1), in2)).numpy().flatten().tolist()",
                "return [tf.where(tf.equal(in1, x)).numpy() for x in in2]"
            ],
            "target-program": "tf.cast(tf.argmax(tf.cast(tf.equal(in1, tf.expand_dims(in2, 1)), tf.int32), axis=1), tf.int32)",
            "description": "find the indices of all elements",
            "tf_operators": {
                "tf.equal": 10,
                "tf.where": 10,
                "tf.expand_dims": 5
            },
            "coverage_percentage": 40.0,
            "total_in_target": 5,
            "total_covered": 2
        },
        "completions": [
            "return [tf.where(tf.equal(in1, n)).numpy()[0][0] for n in in2]",
            "return [tf.where(tf.equal(in1, x))[0] for x in in2]",
            "return tf.where(tf.equal(tf.expand_dims(in1, axis=-1), in2)).numpy()[:, 1]",
            "return tf.where(tf.equal(tf.expand_dims(in1, 1), in2)).numpy()[:, 1]",
            "return tf.where(tf.equal(tf.expand_dims(in1, axis=-1), in2)).numpy()[:,1]",
            "return [tf.where(tf.equal(in1, x)).numpy()[0][0] for x in in2]",
            "return [tf.where(tf.equal(in1, x)).numpy()[0][0] for x in in2]",
            "return tf.where(tf.equal(tf.expand_dims(in1, 1), in2)).numpy()[:,1]",
            "return tf.where(tf.equal(tf.expand_dims(in1, 1), in2)).numpy().flatten().tolist()",
            "return [tf.where(tf.equal(in1, x)).numpy() for x in in2]"
        ]
    },
    {
        "constants": "[]",
        "description": "multiply tensors by scalars in a batched way",
        "target_program": "tf.transpose(tf.multiply(in2, tf.transpose(in1)))",
        "source": "https://stackoverflow.com/questions/58466562/given-a-batch-of-n-images-how-to-scalar-multiply-each-image-by-a-different-scal",
        "name": "stackoverflow_49",
        "examples": {
            "inputs": "[[[[[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]]], [[[0.8, 1.0, 0.0], [0.6, 0.4, 0.2]]], [[[0.9, 0.8, 0.7], [0.1, 0.2, 0.3]]]],[2.0, 0.5, 1.0],]",
            "outputs": "[[[[0.2, 0.4, 0.6], [0.8, 1.0, 1.2]]],    [[[0.4, 0.5, 0.0], [0.3, 0.2, 0.1]]],    [[[0.9, 0.8, 0.7], [0.1, 0.2, 0.3]]]]"
        },
        "response": {
            "task_id": "stackoverflow_49",
            "completions": [
                "return tf.multiply(in1, tf.expand_dims(tf.expand_dims(tf.expand_dims(in2, -1), -1), -1))",
                "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
                "return tf.multiply(in1, tf.expand_dims(in2, axis=[1,2,3]))",
                "in1 = tf.constant(in1)\n     in2 = tf.expand_dims(tf.expand_dims(tf.expand_dims(in2, axis=-1), axis=-1), axis=-1)\n     return tf.multiply(in1, in2)",
                "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
                "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
                "in2 = tf.reshape(in2, [-1, 1, 1, 1])\n return tf.multiply(in1, in2)",
                "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
                "return tf.multiply(in1, tf.expand_dims(tf.expand_dims(tf.expand_dims(in2, axis=-1), axis=-1), axis=-1))",
                "return tf.multiply(in1, tf.reshape(in2, (-1, 1, 1, 1)))"
            ],
            "target-program": "tf.transpose(tf.multiply(in2, tf.transpose(in1)))",
            "description": "multiply tensors by scalars in a batched way",
            "tf_operators": {
                "tf.multiply": 10,
                "tf.expand_dims": 4,
                "tf.reshape": 6,
                "tf.constant": 1
            },
            "coverage_percentage": 50.0,
            "total_in_target": 2,
            "total_covered": 1
        },
        "completions": [
            "return tf.multiply(in1, tf.expand_dims(tf.expand_dims(tf.expand_dims(in2, -1), -1), -1))",
            "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
            "return tf.multiply(in1, tf.expand_dims(in2, axis=[1,2,3]))",
            "in1 = tf.constant(in1)\n     in2 = tf.expand_dims(tf.expand_dims(tf.expand_dims(in2, axis=-1), axis=-1), axis=-1)\n     return tf.multiply(in1, in2)",
            "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
            "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
            "in2 = tf.reshape(in2, [-1, 1, 1, 1])\n return tf.multiply(in1, in2)",
            "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
            "return tf.multiply(in1, tf.expand_dims(tf.expand_dims(tf.expand_dims(in2, axis=-1), axis=-1), axis=-1))",
            "return tf.multiply(in1, tf.reshape(in2, (-1, 1, 1, 1)))"
        ]
    },
    {
        "constants": "[]",
        "description": "create a binary matrix where a specified column is set to one",
        "target_program": "tf.cast(tf.one_hot(tf.fill((in1,), in3), in2), tf.int32)",
        "source": "https://stackoverflow.com/questions/58537495/tensorflow-initialize-a-sparse-tensor-with-only-one-line-column-not-zero",
        "name": "stackoverflow_50",
        "examples": {
            "inputs": "[5]",
            "outputs": "[[0, 0, 0, 1, 0, 0],    [0, 0, 0, 1, 0, 0],    [0, 0, 0, 1, 0, 0],    [0, 0, 0, 1, 0, 0],    [0, 0, 0, 1, 0, 0]]"
        },
        "response": {
            "task_id": "stackoverflow_50",
            "completions": [
                "column = tf.constant(in1)\neye = tf.eye(5, 6)\ncolumn_vector = tf.gather(eye, column, axis=1)\nreturn tf.cast(column_vector, tf.int32)",
                "matrix = tf.zeros([5, 5], tf.int32)\nto_append = tf.ones([5, 1], tf.int32)\n\nresult = tf.concat([matrix[:,:in1], to_append, matrix[:, in1+1:]], axis=1)\nreturn result",
                "ones = tf.ones((5, 1))\nzeros_1 = tf.zeros((5, in1))\nzeros_2 = tf.zeros((5, 5-in1-1))\nreturn tf.concat([zeros_1, ones, zeros_2], axis=1)",
                "return tf.eye(5, num_columns=in1+2)[:, [in1]]",
                "return tf.transpose(tf.one_hot(in1, 5))",
                "return tf.one_hot(tf.zeros(in1, dtype=tf.int32), in1, axis=1)",
                "ten_zeros = tf.zeros([5, 6])\nten_ones = tf.ones([5, 1])\nten_zeros = tf.concat([ten_zeros[:, :in1], ten_ones, ten_zeros[:, in1+1:]], axis=1)\nreturn ten_zeros",
                "# first, create a zeros matrix of shape [in1, in1] using tf.zeros.\n# then, use tf.tensor_scatter_nd_update to update the specified column of the zeros matrix to become all ones.\ndef transform(in1):\n    zeros = tf.zeros([in1, in1])\n    indices = [[i, 3] for i in range(in1)]\n    updates = tf.ones(in1)\n    return tf.tensor_scatter_nd_update(zeros, indices, updates)",
                "return tf.one_hot(tf.zeros(5, dtype=tf.int32), in1, axis=1)",
                "matrix = tf.zeros([5, 5], dtype=tf.dtypes.int32)\nvector = tf.eye(5, dtype=tf.dtypes.int32)[:, in1]\nvector_reshaped = tf.reshape(vector, [5, 1])\nresult = tf.concat([matrix[:, :in1], vector_reshaped, matrix[:, in1+1:]], axis=1)\nreturn result"
            ],
            "target-program": "tf.cast(tf.one_hot(tf.fill((in1,), in3), in2), tf.int32)",
            "description": "create a binary matrix where a specified column is set to one",
            "tf_operators": {
                "tf.eye": 3,
                "tf.cast": 1,
                "tf.int32": 4,
                "tf.gather": 1,
                "tf.constant": 1,
                "tf.ones": 4,
                "tf.concat": 4,
                "tf.zeros": 7,
                "tf.one_hot": 3,
                "tf.transpose": 1,
                "tf.tensor_scatter_nd_update": 1,
                "tf.reshape": 1,
                "tf.dtypes.int32": 1
            },
            "coverage_percentage": 75.0,
            "total_in_target": 4,
            "total_covered": 3
        },
        "completions": [
            "column = tf.constant(in1)\neye = tf.eye(5, 6)\ncolumn_vector = tf.gather(eye, column, axis=1)\nreturn tf.cast(column_vector, tf.int32)",
            "matrix = tf.zeros([5, 5], tf.int32)\nto_append = tf.ones([5, 1], tf.int32)\n\nresult = tf.concat([matrix[:,:in1], to_append, matrix[:, in1+1:]], axis=1)\nreturn result",
            "ones = tf.ones((5, 1))\nzeros_1 = tf.zeros((5, in1))\nzeros_2 = tf.zeros((5, 5-in1-1))\nreturn tf.concat([zeros_1, ones, zeros_2], axis=1)",
            "return tf.eye(5, num_columns=in1+2)[:, [in1]]",
            "return tf.transpose(tf.one_hot(in1, 5))",
            "return tf.one_hot(tf.zeros(in1, dtype=tf.int32), in1, axis=1)",
            "ten_zeros = tf.zeros([5, 6])\nten_ones = tf.ones([5, 1])\nten_zeros = tf.concat([ten_zeros[:, :in1], ten_ones, ten_zeros[:, in1+1:]], axis=1)\nreturn ten_zeros",
            "# first, create a zeros matrix of shape [in1, in1] using tf.zeros.\n# then, use tf.tensor_scatter_nd_update to update the specified column of the zeros matrix to become all ones.\ndef transform(in1):\n    zeros = tf.zeros([in1, in1])\n    indices = [[i, 3] for i in range(in1)]\n    updates = tf.ones(in1)\n    return tf.tensor_scatter_nd_update(zeros, indices, updates)",
            "return tf.one_hot(tf.zeros(5, dtype=tf.int32), in1, axis=1)",
            "matrix = tf.zeros([5, 5], dtype=tf.dtypes.int32)\nvector = tf.eye(5, dtype=tf.dtypes.int32)[:, in1]\nvector_reshaped = tf.reshape(vector, [5, 1])\nresult = tf.concat([matrix[:, :in1], vector_reshaped, matrix[:, in1+1:]], axis=1)\nreturn result"
        ]
    }
]