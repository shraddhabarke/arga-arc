[
    {
        "constants": "[]",
        "description": "Convert index tensor into pairs for SparseTensor indexing",
        "target_program": "tf.cast(tf.where(tf.sequence_mask(tf.math.bincount(in1))), tf.int32)",
        "source": "From an internal Google chat room, 09/07/2018",
        "name": "google_01",
        "examples": {
            "inputs": "[[0, 0, 0, 1, 3, 3],]",
            "outputs": "[[0, 0], [0, 1], [0, 2], [1, 0], [3, 0], [3, 1]]"
        },
        "completions": [
            "return tf.stack([tf.math.floor_div(in1, tf.reduce_max(in1) + 1), tf.math.bincount(in1)], axis=1)",
            "indices = tf.range(tf.shape(in1)[0])\nexpanded_in1 = tf.expand_dims(in1, axis=1)\nexpanded_indices = tf.expand_dims(indices, axis=1)\nreturn tf.concat([expanded_in1, expanded_indices], axis=1)",
            "indices = tf.range(tf.shape(in1)[0])\nreturn tf.stack([in1, indices], axis=1)",
            "indices = tf.range(tf.shape(in1)[0])\nunique_elems, counts = tf.unique(in1)\ncumulative_counts = tf.math.cumsum(tf.pad(counts, [[1,0]]), exclusive=True)\nresult = tf.stack((in1, tf.gather(indices, cumulative_counts) - tf.cumsum(counts)), axis=-1)\nreturn result",
            "values_range = tf.range(tf.shape(in1)[0])\nprevious_value = tf.roll(in1, shift=1, axis=0)\nchange_mask = tf.not_equal(in1, previous_value)\nindices_1 = tf.where(change_mask, tf.zeros_like(in1), tf.cumsum(tf.cast(change_mask, tf.int32)))\nindices_2 = tf.range(tf.shape(in1)[0]) - tf.gather(indices_1, values_range)\nreturn tf.stack([in1, indices_2], axis=1)",
            "a = tf.range(tf.shape(in1)[0])\nb = tf.math.bincount(in1)\nc = tf.math.cumsum(b, exclusive=True)\nd = tf.gather(a, c)\ne = tf.expand_dims(in1, axis=-1)\nf = tf.expand_dims(d, axis=-1)\nout = tf.concat([e, f], axis=-1)\nreturn out",
            "return tf.stack([tf.math.floor_div(in1, tf.reduce_max(in1) + 1), tf.math.bincount(in1)], axis=1)",
            "indices = tf.range(tf.shape(in1)[0])\nout = tf.stack([in1, indices], axis=1)\nreturn out",
            "indices = tf.range(tf.shape(in1)[0])\nvalue = tf.ones_like(in1)\nsegments = tf.reshape(in1, [-1])\nnum_segments = tf.reduce_max(in1) + 1\nsegment_counts = tf.math.bincount(segments)\nsegment_index = tf.cumsum(segment_counts) - segment_counts\npaired_indices = tf.stack([segments, segment_index], axis=1)\nreturn paired_indices",
            "indices = tf.where(tf.sequence_mask(in1))\n     return indices"
        ],
        "response": {
            "task_id": "google_01",
            "completions": [
                "return tf.stack([tf.math.floor_div(in1, tf.reduce_max(in1) + 1), tf.math.bincount(in1)], axis=1)",
                "indices = tf.range(tf.shape(in1)[0])\nexpanded_in1 = tf.expand_dims(in1, axis=1)\nexpanded_indices = tf.expand_dims(indices, axis=1)\nreturn tf.concat([expanded_in1, expanded_indices], axis=1)",
                "indices = tf.range(tf.shape(in1)[0])\nreturn tf.stack([in1, indices], axis=1)",
                "indices = tf.range(tf.shape(in1)[0])\nunique_elems, counts = tf.unique(in1)\ncumulative_counts = tf.math.cumsum(tf.pad(counts, [[1,0]]), exclusive=True)\nresult = tf.stack((in1, tf.gather(indices, cumulative_counts) - tf.cumsum(counts)), axis=-1)\nreturn result",
                "values_range = tf.range(tf.shape(in1)[0])\nprevious_value = tf.roll(in1, shift=1, axis=0)\nchange_mask = tf.not_equal(in1, previous_value)\nindices_1 = tf.where(change_mask, tf.zeros_like(in1), tf.cumsum(tf.cast(change_mask, tf.int32)))\nindices_2 = tf.range(tf.shape(in1)[0]) - tf.gather(indices_1, values_range)\nreturn tf.stack([in1, indices_2], axis=1)",
                "a = tf.range(tf.shape(in1)[0])\nb = tf.math.bincount(in1)\nc = tf.math.cumsum(b, exclusive=True)\nd = tf.gather(a, c)\ne = tf.expand_dims(in1, axis=-1)\nf = tf.expand_dims(d, axis=-1)\nout = tf.concat([e, f], axis=-1)\nreturn out",
                "return tf.stack([tf.math.floor_div(in1, tf.reduce_max(in1) + 1), tf.math.bincount(in1)], axis=1)",
                "indices = tf.range(tf.shape(in1)[0])\nout = tf.stack([in1, indices], axis=1)\nreturn out",
                "indices = tf.range(tf.shape(in1)[0])\nvalue = tf.ones_like(in1)\nsegments = tf.reshape(in1, [-1])\nnum_segments = tf.reduce_max(in1) + 1\nsegment_counts = tf.math.bincount(segments)\nsegment_index = tf.cumsum(segment_counts) - segment_counts\npaired_indices = tf.stack([segments, segment_index], axis=1)\nreturn paired_indices",
                "indices = tf.where(tf.sequence_mask(in1))\n     return indices"
            ],
            "target-program": "tf.cast(tf.where(tf.sequence_mask(tf.math.bincount(in1))), tf.int32)",
            "description": "Convert index tensor into pairs for SparseTensor indexing",
            "tf_operators": {
                "tf.math.floor_div": 2,
                "tf.stack": 7,
                "tf.reduce_max": 3,
                "tf.math.bincount": 4,
                "tf.shape": 7,
                "tf.concat": 2,
                "tf.expand_dims": 2,
                "tf.range": 7,
                "tf.math.cumsum": 2,
                "tf.gather": 3,
                "tf.unique": 1,
                "tf.cumsum": 3,
                "tf.pad": 1,
                "tf.roll": 1,
                "tf.zeros_like": 1,
                "tf.not_equal": 1,
                "tf.int32": 1,
                "tf.cast": 1,
                "tf.where": 2,
                "tf.reshape": 1,
                "tf.ones_like": 1,
                "tf.sequence_mask": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 5,
            "total_covered": 5
        }
    },
    {
        "constants": "[]",
        "description": "Divide each row by the sum of that row",
        "target_program": "tf.divide(in1, tf.expand_dims(tf.reduce_sum(in1, axis=1), 1))",
        "source": "Real task encountered by Googler, 11/01/2018",
        "name": "google_02",
        "examples": {
            "inputs": "[[[0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 1.0, 0.0], [1.0, 1.0, 1.0, 1.0]],]",
            "outputs": "[[0.0, 1.0, 0.0, 0.0],    [0.0, 0.5, 0.5, 0.0],    [0.25, 0.25, 0.25, 0.25]]"
        },
        "completions": [
            "row_sums = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sums)",
            "return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))",
            "row_sum = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sum)",
            "row_sum = tf.reduce_sum(in1, axis=1, keepdims=True)\n     return tf.divide(in1, row_sum)",
            "row_sum = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sum)",
            "row_sums = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sums)",
            "row_sums = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sums)",
            "row_sum = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sum)",
            "row_sums = tf.reduce_sum(in1, axis=1)\nrow_sums = tf.reshape(row_sums, [-1,1])\nreturn tf.divide(in1, row_sums)",
            "row_sums = tf.reduce_sum(in1, axis=1)\nrow_sums = tf.reshape(row_sums, [-1, 1])\nreturn tf.divide(in1, row_sums)"
        ],
        "response": {
            "task_id": "google_02",
            "completions": [
                "row_sums = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sums)",
                "return tf.divide(in1, tf.reduce_sum(in1, axis=1, keepdims=True))",
                "row_sum = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sum)",
                "row_sum = tf.reduce_sum(in1, axis=1, keepdims=True)\n     return tf.divide(in1, row_sum)",
                "row_sum = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sum)",
                "row_sums = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sums)",
                "row_sums = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sums)",
                "row_sum = tf.reduce_sum(in1, axis=1, keepdims=True)\nreturn tf.divide(in1, row_sum)",
                "row_sums = tf.reduce_sum(in1, axis=1)\nrow_sums = tf.reshape(row_sums, [-1,1])\nreturn tf.divide(in1, row_sums)",
                "row_sums = tf.reduce_sum(in1, axis=1)\nrow_sums = tf.reshape(row_sums, [-1, 1])\nreturn tf.divide(in1, row_sums)"
            ],
            "target-program": "tf.divide(in1, tf.expand_dims(tf.reduce_sum(in1, axis=1), 1))",
            "description": "Divide each row by the sum of that row",
            "tf_operators": {
                "tf.reduce_sum": 10,
                "tf.divide": 10,
                "tf.reshape": 2
            },
            "coverage_percentage": 66.66666666666666,
            "total_in_target": 3,
            "total_covered": 2
        }
    },
    {
        "constants": "[]",
        "description": "Slice the first dimension of a SparseTensor",
        "target_program": "tf.divide(in1, tf.expand_dims(tf.reduce_sum(in1, axis=1), 1))",
        "source": "Real task encountered by Googler, 11/01/2018",
        "name": "google_03",
        "examples": {
            "inputs": "tf.SparseTensor(indices=[[0, 0, 0], [0, 1, 1], [1, 1, 1], [1, 1, 2]], values=[1., 1., 1., 1.], dense_shape=[2, 2, 800])",
            "outputs": "tf.SparseTensor(indices=[[0, 0, 0], [0, 1, 1]], values=[1., 1.], dense_shape=[1, 2, 800])"
        },
        "completions": [
            "# Get the indices for the first dimension\n    indices = tf.where(in1.indices[:, 0] == 0)\n\n    # Gathers the values corresponding to the indices\n    new_indices = tf.gather(in1.indices, indices)\n    new_values = tf.gather(in1.values, indices)\n\n    # Get updated dense_shape\n    dense_shape = in1.dense_shape\n    dense_shape = tf.concat([tf.constant([1]), dense_shape[1:]], 0)\n\n    return tf.SparseTensor(new_indices, new_values, dense_shape)",
            "indices = tf.boolean_mask(in1.indices, tf.equal(in1.indices[:,0], 0)) \n    values = tf.boolean_mask(in1.values, tf.equal(in1.indices[:,0], 0))\n    return tf.SparseTensor(indices=indices, values=values, dense_shape=tf.concat([[1], in1.dense_shape[1:]],0))",
            "# We first get the values from the indexes and the shape from the SparseTensor\n    indices = in1.indices\n    dense_shape = in1.dense_shape\n\n    # We then create a mask where the indexes in the first column are less than 1\n    mask = tf.less(indices[:, 0], 1)\n    \n    # We then apply the mask to the indices and values\n    new_indices = tf.boolean_mask(indices, mask)\n    new_values = tf.boolean_mask(in1.values, mask)\n    \n    # Updating the first value of the dense_shape tensor with 1\n    dense_shape = tf.tensor_scatter_nd_update(dense_shape, tf.constant([[0]]), tf.constant([1]))\n    \n    # We reconstitute the SparseTensor with the new indices, values and shape\n    return tf.sparse.SparseTensor(new_indices, new_values, dense_shape)",
            "slice_size = tf.constant([1] + in1.dense_shape.numpy()[1:].tolist())\nstart = tf.zeros_like(slice_size) \nsliced_tensor = tf.sparse.slice(in1, start, slice_size)\nsliced_tensor = tf.sparse.reset_shape(sliced_tensor, slice_size)\nreturn sliced_tensor",
            "first_dim = tf.boolean_mask(in1.indices, in1.indices[:, 0] == 0, axis=0)\nvalues = tf.gather(in1.values, tf.where(in1.indices[:, 0] == 0)[:, 0])\ndense_shape = tf.concat([[1], in1.dense_shape[1:]], 0)\nreturn tf.SparseTensor(first_dim, values, dense_shape)",
            "# find the indices where the first dimension is 0\n    condition = tf.equal(in1.indices[:, 0], 0)\n    \n    # filter the indices and values based on the condition\n    new_indices = tf.boolean_mask(in1.indices, condition)\n    new_values = tf.boolean_mask(in1.values, condition)\n    \n    # calculate the new dense shape by setting the first dimension to 1\n    new_dense_shape = tf.Tensor([1, in1.dense_shape[1], in1.dense_shape[2]], dtype=tf.int64)\n    \n    # create a new SparseTensor with the new indices, values, and dense shape\n    new_sparse_tensor = tf.SparseTensor(indices=new_indices, values=new_values, dense_shape=new_dense_shape)\n    \n    return new_sparse_tensor",
            "# Find the indices where the first dimension is 0\n    indices_to_retain = tf.equal(in1.indices[:, 0], 0)\n\n    # Retain only these indices and correspondin values in the SparseTensor\n    result = tf.sparse.retain(in1, indices_to_retain)\n\n    # Update the shape of the SparseTensor to reflect the removal of elements\n    new_shape = tf.concat([tf.constant([1]), in1.dense_shape[1:]], axis=0)\n    result = tf.sparse.reshape(result, new_shape)\n\n    return result",
            "# We will use the tf.sparse.slice function to slice the SparseTensor.\n\nin1_indices = in1.indices\nin1_values = in1.values\nin1_dense_shape = in1.dense_shape\n\n# Slice the first dimension\nsliced_tensor = tf.sparse.slice(in1, start=[0, 0, 0], size=[1, -1, -1])\n\n# Modify the first dimension of the dense shape\nnew_dense_shape = tf.concat([[1], in1_dense_shape[1:]], axis=0)\n\n# Create a new SparseTensor with the sliced indices, values, and the new dense shape\nsliced_in1 = tf.SparseTensor(sliced_tensor.indices, sliced_tensor.values, new_dense_shape)\n\nreturn sliced_in1",
            "# to get the slice of indices where first index value is 0\n    slice_indices = tf.where(tf.equal(in1.indices[:, 0], 0))\n\n    # gather the sliced indices and corresponding values\n    sliced_indices = tf.gather(in1.indices, slice_indices)\n    sliced_values = tf.gather(in1.values, slice_indices)\n\n    # reduce the dense shape in the 0th dimension by count of unique first index values \n    new_dense_shape = in1.dense_shape - tf.shape(tf.unique(in1.indices[:, 0]).y)[0]\n\n    # create a new sparse tensor with sliced indices, values and reduced dense shape\n    sliced_tensor = tf.SparseTensor(sliced_indices, sliced_values, new_dense_shape)\n\n    return sliced_tensor",
            "# First, get the indices where the first dimension is 0\n    indices = tf.where(in1.indices[:, 0] == 0)\n\n    # Extract these indices from the SparseTensor\n    new_indices = tf.gather(in1.indices, indices)\n    \n    # Decrease all indices in the first dimension by 1\n    new_indices = new_indices - [1, 0, 0]\n    \n    # Get the values at these indices\n    new_values = tf.gather(in1.values, indices)\n    \n    # Get the dense shape, but decrease the first dimension by 1\n    new_dense_shape = in1.dense_shape\n    new_dense_shape[0] = 1\n\n    # Return a new SparseTensor with the sliced data\n    return tf.SparseTensor(new_indices, new_values, new_dense_shape)"
        ],
        "response": {
            "task_id": "google_03",
            "completions": [
                "# Get the indices for the first dimension\n    indices = tf.where(in1.indices[:, 0] == 0)\n\n    # Gathers the values corresponding to the indices\n    new_indices = tf.gather(in1.indices, indices)\n    new_values = tf.gather(in1.values, indices)\n\n    # Get updated dense_shape\n    dense_shape = in1.dense_shape\n    dense_shape = tf.concat([tf.constant([1]), dense_shape[1:]], 0)\n\n    return tf.SparseTensor(new_indices, new_values, dense_shape)",
                "indices = tf.boolean_mask(in1.indices, tf.equal(in1.indices[:,0], 0)) \n    values = tf.boolean_mask(in1.values, tf.equal(in1.indices[:,0], 0))\n    return tf.SparseTensor(indices=indices, values=values, dense_shape=tf.concat([[1], in1.dense_shape[1:]],0))",
                "# We first get the values from the indexes and the shape from the SparseTensor\n    indices = in1.indices\n    dense_shape = in1.dense_shape\n\n    # We then create a mask where the indexes in the first column are less than 1\n    mask = tf.less(indices[:, 0], 1)\n    \n    # We then apply the mask to the indices and values\n    new_indices = tf.boolean_mask(indices, mask)\n    new_values = tf.boolean_mask(in1.values, mask)\n    \n    # Updating the first value of the dense_shape tensor with 1\n    dense_shape = tf.tensor_scatter_nd_update(dense_shape, tf.constant([[0]]), tf.constant([1]))\n    \n    # We reconstitute the SparseTensor with the new indices, values and shape\n    return tf.sparse.SparseTensor(new_indices, new_values, dense_shape)",
                "slice_size = tf.constant([1] + in1.dense_shape.numpy()[1:].tolist())\nstart = tf.zeros_like(slice_size) \nsliced_tensor = tf.sparse.slice(in1, start, slice_size)\nsliced_tensor = tf.sparse.reset_shape(sliced_tensor, slice_size)\nreturn sliced_tensor",
                "first_dim = tf.boolean_mask(in1.indices, in1.indices[:, 0] == 0, axis=0)\nvalues = tf.gather(in1.values, tf.where(in1.indices[:, 0] == 0)[:, 0])\ndense_shape = tf.concat([[1], in1.dense_shape[1:]], 0)\nreturn tf.SparseTensor(first_dim, values, dense_shape)",
                "# find the indices where the first dimension is 0\n    condition = tf.equal(in1.indices[:, 0], 0)\n    \n    # filter the indices and values based on the condition\n    new_indices = tf.boolean_mask(in1.indices, condition)\n    new_values = tf.boolean_mask(in1.values, condition)\n    \n    # calculate the new dense shape by setting the first dimension to 1\n    new_dense_shape = tf.Tensor([1, in1.dense_shape[1], in1.dense_shape[2]], dtype=tf.int64)\n    \n    # create a new SparseTensor with the new indices, values, and dense shape\n    new_sparse_tensor = tf.SparseTensor(indices=new_indices, values=new_values, dense_shape=new_dense_shape)\n    \n    return new_sparse_tensor",
                "# Find the indices where the first dimension is 0\n    indices_to_retain = tf.equal(in1.indices[:, 0], 0)\n\n    # Retain only these indices and correspondin values in the SparseTensor\n    result = tf.sparse.retain(in1, indices_to_retain)\n\n    # Update the shape of the SparseTensor to reflect the removal of elements\n    new_shape = tf.concat([tf.constant([1]), in1.dense_shape[1:]], axis=0)\n    result = tf.sparse.reshape(result, new_shape)\n\n    return result",
                "# We will use the tf.sparse.slice function to slice the SparseTensor.\n\nin1_indices = in1.indices\nin1_values = in1.values\nin1_dense_shape = in1.dense_shape\n\n# Slice the first dimension\nsliced_tensor = tf.sparse.slice(in1, start=[0, 0, 0], size=[1, -1, -1])\n\n# Modify the first dimension of the dense shape\nnew_dense_shape = tf.concat([[1], in1_dense_shape[1:]], axis=0)\n\n# Create a new SparseTensor with the sliced indices, values, and the new dense shape\nsliced_in1 = tf.SparseTensor(sliced_tensor.indices, sliced_tensor.values, new_dense_shape)\n\nreturn sliced_in1",
                "# to get the slice of indices where first index value is 0\n    slice_indices = tf.where(tf.equal(in1.indices[:, 0], 0))\n\n    # gather the sliced indices and corresponding values\n    sliced_indices = tf.gather(in1.indices, slice_indices)\n    sliced_values = tf.gather(in1.values, slice_indices)\n\n    # reduce the dense shape in the 0th dimension by count of unique first index values \n    new_dense_shape = in1.dense_shape - tf.shape(tf.unique(in1.indices[:, 0]).y)[0]\n\n    # create a new sparse tensor with sliced indices, values and reduced dense shape\n    sliced_tensor = tf.SparseTensor(sliced_indices, sliced_values, new_dense_shape)\n\n    return sliced_tensor",
                "# First, get the indices where the first dimension is 0\n    indices = tf.where(in1.indices[:, 0] == 0)\n\n    # Extract these indices from the SparseTensor\n    new_indices = tf.gather(in1.indices, indices)\n    \n    # Decrease all indices in the first dimension by 1\n    new_indices = new_indices - [1, 0, 0]\n    \n    # Get the values at these indices\n    new_values = tf.gather(in1.values, indices)\n    \n    # Get the dense shape, but decrease the first dimension by 1\n    new_dense_shape = in1.dense_shape\n    new_dense_shape[0] = 1\n\n    # Return a new SparseTensor with the sliced data\n    return tf.SparseTensor(new_indices, new_values, new_dense_shape)"
            ],
            "target-program": "tf.divide(in1, tf.expand_dims(tf.reduce_sum(in1, axis=1), 1))",
            "description": "Slice the first dimension of a SparseTensor",
            "tf_operators": {
                "tf.constant": 4,
                "tf.gather": 4,
                "tf.concat": 5,
                "tf.where": 4,
                "tf.SparseTensor": 7,
                "tf.boolean_mask": 4,
                "tf.equal": 4,
                "tf.tensor_scatter_nd_update": 1,
                "tf.less": 1,
                "tf.sparse.SparseTensor": 1,
                "tf.zeros_like": 1,
                "tf.sparse.reset_shape": 1,
                "tf.sparse.slice": 2,
                "tf.int64": 1,
                "tf.Tensor": 1,
                "tf.sparse.retain": 1,
                "tf.sparse.reshape": 1,
                "tf.unique": 1,
                "tf.shape": 1
            },
            "coverage_percentage": 0.0,
            "total_in_target": 3,
            "total_covered": 0
        }
    },
    {
        "constants": "[]",
        "description": "Reshape a flat array into a rank 3 tensor",
        "target_program": "tf.reshape(in1, shape=(4, 3, 2))",
        "source": "Real task encountered by Googler, 3/21/2019",
        "name": "google_04",
        "examples": {
            "inputs": "[[111, 112, 121, 122, 131, 132, 211, 212, 221, 222, 231, 232, 311, 312, 321, 322, 331, 332, 411, 412, 421, 422, 431, 432],]",
            "outputs": "[[[111, 112], [121, 122], [131, 132]],    [[211, 212], [221, 222], [231, 232]],    [[311, 312], [321, 322], [331, 332]],    [[411, 412], [421, 422], [431, 432]]]"
        },
        "completions": [
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])",
            "return tf.reshape(in1, [4, 3, 2])"
        ],
        "response": {
            "task_id": "google_04",
            "completions": [
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])",
                "return tf.reshape(in1, [4, 3, 2])"
            ],
            "target-program": "tf.reshape(in1, shape=(4, 3, 2))",
            "description": "Reshape a flat array into a rank 3 tensor",
            "tf_operators": {
                "tf.reshape": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        }
    },
    {
        "constants": "[6]",
        "description": "Repeat each input entry 6 times",
        "target_program": "tf.tile(tf.expand_dims(in1, 1), (1, 6, 1))",
        "source": "Real task encountered by Googler, 3/22/2019",
        "name": "google_05",
        "examples": {
            "inputs": "[[[1, 2, 3, 4], [5, 6, 7, 8]],]",
            "outputs": "[[[1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4],     [1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4]],    [[5, 6, 7, 8], [5, 6, 7, 8], [5, 6, 7, 8],     [5, 6, 7, 8], [5, 6, 7, 8], [5, 6, 7, 8]]]"
        },
        "completions": [
            "return tf.repeat(in1, repeats=[6], axis=0)",
            "return tf.repeat(in1, repeats=6, axis=0)",
            "return tf.repeat(in1, repeats=6, axis=0)",
            "return tf.repeat(in1, repeats=6, axis=0)",
            "return tf.repeat(in1, 6, axis=0)",
            "return tf.repeat(tf.expand_dims(in1, axis=1), repeats=6, axis=1)",
            "return tf.repeat(in1, 6, axis=0)",
            "return tf.repeat(in1, repeats=6, axis=0)",
            "return tf.repeat(in1, repeats=[6], axis=0)",
            "return tf.repeat(in1, repeats=6, axis=0)"
        ],
        "response": {
            "task_id": "google_05",
            "completions": [
                "return tf.repeat(in1, repeats=[6], axis=0)",
                "return tf.repeat(in1, repeats=6, axis=0)",
                "return tf.repeat(in1, repeats=6, axis=0)",
                "return tf.repeat(in1, repeats=6, axis=0)",
                "return tf.repeat(in1, 6, axis=0)",
                "return tf.repeat(tf.expand_dims(in1, axis=1), repeats=6, axis=1)",
                "return tf.repeat(in1, 6, axis=0)",
                "return tf.repeat(in1, repeats=6, axis=0)",
                "return tf.repeat(in1, repeats=[6], axis=0)",
                "return tf.repeat(in1, repeats=6, axis=0)"
            ],
            "target-program": "tf.tile(tf.expand_dims(in1, 1), (1, 6, 1))",
            "description": "Repeat each input entry 6 times",
            "tf_operators": {
                "tf.repeat": 10,
                "tf.expand_dims": 1
            },
            "coverage_percentage": 50.0,
            "total_in_target": 2,
            "total_covered": 1
        }
    },
    {
        "constants": "[]",
        "description": "Take the max from each group of elements",
        "target_program": "tf.math.segment_max(in2, in1)",
        "source": "Real task encountered by Googler, 3/28/2019",
        "name": "google_06",
        "examples": {
            "inputs": "[[0, 1, 1, 2, 3, 3, 3, 3],[1, 3, 4, 5, 10, 8, 9, 4],]",
            "outputs": "[1, 4, 5, 10]"
        },
        "completions": [
            "segment_ids = tf.cast(in1, tf.int32)\nvalues = tf.cast(in2, tf.int32)\nresult = tf.math.unsorted_segment_max(values, segment_ids, tf.reduce_max(segment_ids) + 1)\nreturn result",
            "return tf.math.segment_max(in2, in1)",
            "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1)+1).numpy().tolist()",
            "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1)",
            "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1)",
            "group_max = tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1)\nreturn group_max",
            "return tf.math.segment_max(in2, in1)",
            "group_max = tf.math.segment_max(in2, in1)\nreturn group_max",
            "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1)",
            "segment_ids = tf.cast(in1, tf.int32)\ndata = tf.cast(in2, tf.int32)\nreturn tf.math.segment_max(data, segment_ids)"
        ],
        "response": {
            "task_id": "google_06",
            "completions": [
                "segment_ids = tf.cast(in1, tf.int32)\nvalues = tf.cast(in2, tf.int32)\nresult = tf.math.unsorted_segment_max(values, segment_ids, tf.reduce_max(segment_ids) + 1)\nreturn result",
                "return tf.math.segment_max(in2, in1)",
                "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1)+1).numpy().tolist()",
                "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1)",
                "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1)",
                "group_max = tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1)\nreturn group_max",
                "return tf.math.segment_max(in2, in1)",
                "group_max = tf.math.segment_max(in2, in1)\nreturn group_max",
                "return tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1) + 1)",
                "segment_ids = tf.cast(in1, tf.int32)\ndata = tf.cast(in2, tf.int32)\nreturn tf.math.segment_max(data, segment_ids)"
            ],
            "target-program": "tf.math.segment_max(in2, in1)",
            "description": "Take the max from each group of elements",
            "tf_operators": {
                "tf.math.unsorted_segment_max": 6,
                "tf.reduce_max": 6,
                "tf.int32": 2,
                "tf.cast": 2,
                "tf.math.segment_max": 4
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        }
    },
    {
        "constants": "[]",
        "description": "Take the argmax of each group of elements",
        "target_program": "tf.cast(tf.argmax((tf.sequence_mask(tf.cumsum(tf.math.bincount(in1)), dtype=tf.int32) - tf.sequence_mask(tf.cumsum(tf.math.bincount(in1), exclusive=True), dtype=tf.int32, maxlen=in1.shape[0])) * in2, axis=1), tf.int32) - tf.cumsum(tf.math.bincount(in1), exclusive=True)",
        "source": "Real task encountered by Googler, 3/29/2019",
        "name": "google_07",
        "examples": {
            "inputs": "[[0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 4, 4, 5, 5],[4, 1, 8, 2, 5, 7, 9, 3, 7, 3, 1, 42, 1, 2, 4, 0],]",
            "outputs": "[2, 3, 1, 0, 1, 0]"
        },
        "completions": [
            "segment_ids = tf.cast(in1, dtype=tf.int32)\nvalues = tf.cast(in2, dtype=tf.int32)\nreturn tf.argmax(tf.math.unsorted_segment_max(values, segment_ids, tf.reduce_max(segment_ids)+1))",
            "in2_segment_max_indices = tf.math.argmax(tf.reshape(in2, (6, -1)), axis=-1)\n     return in2_segment_max_indices",
            "segments_ids = tf.cast(in1, tf.int32)\nvalues = tf.cast(in2, tf.int32)\nreturn tf.math.segment_max(values, segments_ids)",
            "max_indices = tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1)+1)\nmaxes = tf.equal(in2, tf.gather(max_indices, in1))\nreturn tf.where(maxes)[::tf.add(tf.math.bincount(in1),1)][:,0]",
            "segment_ids = tf.cast(in1, tf.int32)\nvalues = tf.cast(in2, tf.int32)\nmax_indices = tf.math.unsorted_segment_max(values, segment_ids, tf.reduce_max(segment_ids)+1)\nreturn max_indices",
            "segments = tf.cast(in1, tf.int32)\nvalues = tf.cast(in2, tf.int32)\nindices = tf.math.argmax(tf.math.unsorted_segment_max(values, segments, tf.reduce_max(segments) + 1))\nreturn indices",
            "# First, use tf.math.segment_max to find the maximum values within each segment\n# Then use tf.equal to create a boolean mask where the input matches the maximums\n# Use tf.where to find the locations of the True values in the mask\n# The segment ids are the second element of each pair in the locations\n# Use tf.gather to select the segment ids from the locations\n# Finally, use tf.math.bincount to count the number of times each id occurs and find the first occurrence in each group\n\nmaximums = tf.math.segment_max(in2, in1)\nmask = tf.equal(in2, tf.gather(maximums, in1))\nlocations = tf.where(mask)\nsegment_ids = tf.gather(locations[:, 1], tf.math.bincount(in1))\nreturn segment_ids",
            "# first identify the unique elements in in1 which are the groups\n    unique_elements = tf.unique(in1).y\n\n    # each unique_element will used as a segment to compute the segment_max\n    max_indices = []\n    for element in unique_elements:\n        # get the boolean mask where in1 is equal to the current element\n        mask = tf.equal(in1, element)\n\n        # apply the mask to in2 to get the values of in2 that belongs to the current group\n        values = tf.boolean_mask(in2, mask)\n\n        # get the index of the maximum value in the group\n        max_index = tf.argmax(values, axis=0)\n\n        max_indices.append(max_index)\n\n    # stack all max indices into a single tensor\n    max_indices = tf.stack(max_indices)\n\n    return max_indices",
            "segments = tf.constant(in1)\ndata = tf.constant(in2)\nresult = tf.argmax(tf.math.unsorted_segment_max(data,segments,tf.reduce_max(segments) + 1))\nreturn result.numpy().tolist()",
            "segment_ids = tf.convert_to_tensor(in1, dtype=tf.int32)\nvalues = tf.convert_to_tensor(in2, dtype=tf.int32)\nreturn tf.math.segment_max(values, segment_ids)"
        ],
        "response": {
            "task_id": "google_07",
            "completions": [
                "segment_ids = tf.cast(in1, dtype=tf.int32)\nvalues = tf.cast(in2, dtype=tf.int32)\nreturn tf.argmax(tf.math.unsorted_segment_max(values, segment_ids, tf.reduce_max(segment_ids)+1))",
                "in2_segment_max_indices = tf.math.argmax(tf.reshape(in2, (6, -1)), axis=-1)\n     return in2_segment_max_indices",
                "segments_ids = tf.cast(in1, tf.int32)\nvalues = tf.cast(in2, tf.int32)\nreturn tf.math.segment_max(values, segments_ids)",
                "max_indices = tf.math.unsorted_segment_max(in2, in1, tf.reduce_max(in1)+1)\nmaxes = tf.equal(in2, tf.gather(max_indices, in1))\nreturn tf.where(maxes)[::tf.add(tf.math.bincount(in1),1)][:,0]",
                "segment_ids = tf.cast(in1, tf.int32)\nvalues = tf.cast(in2, tf.int32)\nmax_indices = tf.math.unsorted_segment_max(values, segment_ids, tf.reduce_max(segment_ids)+1)\nreturn max_indices",
                "segments = tf.cast(in1, tf.int32)\nvalues = tf.cast(in2, tf.int32)\nindices = tf.math.argmax(tf.math.unsorted_segment_max(values, segments, tf.reduce_max(segments) + 1))\nreturn indices",
                "# First, use tf.math.segment_max to find the maximum values within each segment\n# Then use tf.equal to create a boolean mask where the input matches the maximums\n# Use tf.where to find the locations of the True values in the mask\n# The segment ids are the second element of each pair in the locations\n# Use tf.gather to select the segment ids from the locations\n# Finally, use tf.math.bincount to count the number of times each id occurs and find the first occurrence in each group\n\nmaximums = tf.math.segment_max(in2, in1)\nmask = tf.equal(in2, tf.gather(maximums, in1))\nlocations = tf.where(mask)\nsegment_ids = tf.gather(locations[:, 1], tf.math.bincount(in1))\nreturn segment_ids",
                "# first identify the unique elements in in1 which are the groups\n    unique_elements = tf.unique(in1).y\n\n    # each unique_element will used as a segment to compute the segment_max\n    max_indices = []\n    for element in unique_elements:\n        # get the boolean mask where in1 is equal to the current element\n        mask = tf.equal(in1, element)\n\n        # apply the mask to in2 to get the values of in2 that belongs to the current group\n        values = tf.boolean_mask(in2, mask)\n\n        # get the index of the maximum value in the group\n        max_index = tf.argmax(values, axis=0)\n\n        max_indices.append(max_index)\n\n    # stack all max indices into a single tensor\n    max_indices = tf.stack(max_indices)\n\n    return max_indices",
                "segments = tf.constant(in1)\ndata = tf.constant(in2)\nresult = tf.argmax(tf.math.unsorted_segment_max(data,segments,tf.reduce_max(segments) + 1))\nreturn result.numpy().tolist()",
                "segment_ids = tf.convert_to_tensor(in1, dtype=tf.int32)\nvalues = tf.convert_to_tensor(in2, dtype=tf.int32)\nreturn tf.math.segment_max(values, segment_ids)"
            ],
            "target-program": "tf.cast(tf.argmax((tf.sequence_mask(tf.cumsum(tf.math.bincount(in1)), dtype=tf.int32) - tf.sequence_mask(tf.cumsum(tf.math.bincount(in1), exclusive=True), dtype=tf.int32, maxlen=in1.shape[0])) * in2, axis=1), tf.int32) - tf.cumsum(tf.math.bincount(in1), exclusive=True)",
            "description": "Take the argmax of each group of elements",
            "tf_operators": {
                "tf.argmax": 3,
                "tf.math.unsorted_segment_max": 5,
                "tf.int32": 5,
                "tf.reduce_max": 5,
                "tf.cast": 4,
                "tf.math.argmax": 2,
                "tf.reshape": 1,
                "tf.math.segment_max": 3,
                "tf.gather": 2,
                "tf.math.bincount": 2,
                "tf.equal": 3,
                "tf.add": 1,
                "tf.where": 2,
                "tf.unique": 1,
                "tf.stack": 1,
                "tf.boolean_mask": 1,
                "tf.constant": 1,
                "tf.convert_to_tensor": 1
            },
            "coverage_percentage": 66.66666666666666,
            "total_in_target": 6,
            "total_covered": 4
        }
    },
    {
        "constants": "[5]",
        "description": "create a mask for sequences of the given lengths",
        "target_program": "tf.cast(tf.greater(tf.expand_dims(in1, 1), tf.range(5)), tf.int32)",
        "source": "Real task encountered by Googler, 4/11/2019",
        "name": "google_08",
        "examples": {
            "inputs": "[[3, 4, 2, 1],]",
            "outputs": "[[1, 1, 1, 0, 0],    [1, 1, 1, 1, 0],    [1, 1, 0, 0, 0],    [1, 0, 0, 0, 0]]"
        },
        "completions": [
            "return tf.sequence_mask(in1, tf.reduce_max(in1))",
            "return tf.sequence_mask(in1).numpy().astype(int)",
            "return tf.sequence_mask(in1).numpy().astype(int)",
            "return tf.sequence_mask(lengths=in1).numpy()",
            "return tf.sequence_mask(in1).numpy().astype(int)",
            "return tf.sequence_mask(in1)",
            "return tf.sequence_mask(in1).numpy().astype(int)",
            "return tf.sequence_mask(in1).numpy().astype(int)",
            "return tf.sequence_mask(in1).numpy().astype(int)",
            "return tf.sequence_mask(lengths=in1, maxlen=int(tf.reduce_max(in1))).numpy().astype(int)"
        ],
        "response": {
            "task_id": "google_08",
            "completions": [
                "return tf.sequence_mask(in1, tf.reduce_max(in1))",
                "return tf.sequence_mask(in1).numpy().astype(int)",
                "return tf.sequence_mask(in1).numpy().astype(int)",
                "return tf.sequence_mask(lengths=in1).numpy()",
                "return tf.sequence_mask(in1).numpy().astype(int)",
                "return tf.sequence_mask(in1)",
                "return tf.sequence_mask(in1).numpy().astype(int)",
                "return tf.sequence_mask(in1).numpy().astype(int)",
                "return tf.sequence_mask(in1).numpy().astype(int)",
                "return tf.sequence_mask(lengths=in1, maxlen=int(tf.reduce_max(in1))).numpy().astype(int)"
            ],
            "target-program": "tf.cast(tf.greater(tf.expand_dims(in1, 1), tf.range(5)), tf.int32)",
            "description": "create a mask for sequences of the given lengths",
            "tf_operators": {
                "tf.reduce_max": 2,
                "tf.sequence_mask": 10
            },
            "coverage_percentage": 0.0,
            "total_in_target": 5,
            "total_covered": 0
        }
    },
    {
        "constants": "[]",
        "description": "sort the segments",
        "target_program": "tf.gather(in2, tf.argsort(in1, stable=True))",
        "source": "Real task encountered by Googler, 8/9/2019",
        "name": "google_09",
        "examples": {
            "inputs": "[[1, 1, 1, 0, 0, 2],[10, 20, 30, 14, 15, 26],]",
            "outputs": "[14, 15, 10, 20, 30, 26]"
        },
        "completions": [
            "segment_ids = tf.constant(in1)\ndata = tf.constant(in2)\nsegments_max = tf.math.unsorted_segment_max(data, segment_ids, tf.reduce_max(segment_ids) + 1)\nsorted_segments = tf.gather(segments_max, tf.argsort(segment_ids))\n\nreturn sorted_segments.numpy().tolist()",
            "# sort the segments where segments are defined by 'in1' and values are 'in2'\n# the built-in function `tf.math.unsorted_segment_sort` is not available, so we have to follow these steps:\n# 1. find the start of each segment\n# 2. calculate the sorted indices for each segment\n# 3. gather the indices to get the sorted segments\n\n# create helper tensor for easier calculation\nones = tf.ones_like(in1)\n\n# calculate the accumulated sum of 1s in the same segments\naccumulated_ones = tf.math.unsorted_segment_sum(ones, in1, tf.reduce_max(in1)+1)\n\n# calculate the start index of each segment\nstart_index_of_each_seg = tf.math.cumsum(accumulated_ones, exclusive=True)\n\n# add sequential indices in the same segment\nin1_new_index_in_segment = tf.math.unsorted_segment_sum(ones, in1, tf.reduce_max(in1)+1)\n\n# normalize the index for tf.gather\nnormalized_new_index = in1_new_index_in_segment + start_index_of_each_seg\n\n# calculate the new index in sorted tensor\nnew_index = tf.argsort(normalized_new_index)\n\n# gather in2 to new index to generate the sorted tensor\nreturn tf.gather(in2, new_index)",
            "# We will use four tensorflow methods to acheive our task. \n# We will Create a segment id index to sort on, then Sort the indexes. \n# After that Expand segment ids, then Finally create a new tensor using the sorted index.\n\n# 1. Create a segment id index to sort on\nsorted_segment_ids = tf.argsort(in1)\n\n# 2. Sort the indexes\nsorted_segment_id_index = tf.argsort(sorted_segment_ids)\n\n# 3. Expand segment ids \nexpanded_segment_ids = tf.expand_dims(sorted_segment_id_index, axis=0)\n\n# 4. Finally create a new tensor using the sorted index\noutput = tf.gather_nd(in2, expanded_segment_ids)\n\nreturn output",
            "segment_ids = tf.constant(in1)\ndata = tf.constant(in2)\nnum_segments = tf.reduce_max(segment_ids) + 1\nsegments = tf.unsorted_segment_sum(data, segment_ids, num_segments)\nreturn tf.sort(segments, direction='ASCENDING')",
            "segment_ids = tf.constant(in1)\ndata = tf.constant(in2)\nnum_segments = tf.reduce_max(segment_ids) + 1\nsegment_max_data = tf.math.unsorted_segment_max(data, segment_ids, num_segments)\nsegment_sorted_indices = tf.argsort(segment_max_data)\nreturn tf.gather(data, segment_sorted_indices)",
            "segment_ids = tf.convert_to_tensor(in1, dtype=tf.int32)\ndata = tf.convert_to_tensor(in2, dtype=tf.int32)\n\nnum_segments = tf.reduce_max(segment_ids) + 1\nsegment_max = tf.math.unsorted_segment_max(data, segment_ids, num_segments)\n\nindices = tf.argsort(segment_max)\nsorted_data = tf.gather(data, indices)\n\nreturn sorted_data.numpy().tolist()",
            "segment_ids = tf.cast(in1, tf.int32)\ndata = tf.cast(in2, tf.int32)\nsegment_max = tf.math.segment_max(data, segment_ids)\noutput = tf.sort(segment_max)\nreturn output",
            "segment_ids = tf.constant(in1)\ndata = tf.constant(in2)\nlength = tf.reduce_max(segment_ids) + 1\nsegment_max = tf.math.unsorted_segment_sum(data, segment_ids, length)\nsorted_indices = tf.argsort(segment_max)\nsorted_data = tf.gather(data, sorted_indices)\nreturn sorted_data.numpy().tolist()",
            "segments_ids = tf.constant(in1)\ndata = tf.constant(in2)\nnum_segments = len(set(in1))\n\noutput = tf.math.unsorted_segment_sum(data, segments_ids, num_segments)\nsorted_indices = tf.argsort(output)\nsorted_output = tf.gather(output, sorted_indices)\n    \nreturn sorted_output.numpy()",
            "segments = tf.constant(in1)\nvalues = tf.constant(in2)\nsorted_idx = tf.argsort(values)\nsorted_segments = tf.gather(segments, sorted_idx)\nsorted_values = tf.sort(values)\nsegment_ids = tf.argsort(sorted_segments)\nreturn tf.gather(sorted_values, segment_ids).numpy().tolist()"
        ],
        "response": {
            "task_id": "google_09",
            "completions": [
                "segment_ids = tf.constant(in1)\ndata = tf.constant(in2)\nsegments_max = tf.math.unsorted_segment_max(data, segment_ids, tf.reduce_max(segment_ids) + 1)\nsorted_segments = tf.gather(segments_max, tf.argsort(segment_ids))\n\nreturn sorted_segments.numpy().tolist()",
                "# sort the segments where segments are defined by 'in1' and values are 'in2'\n# the built-in function `tf.math.unsorted_segment_sort` is not available, so we have to follow these steps:\n# 1. find the start of each segment\n# 2. calculate the sorted indices for each segment\n# 3. gather the indices to get the sorted segments\n\n# create helper tensor for easier calculation\nones = tf.ones_like(in1)\n\n# calculate the accumulated sum of 1s in the same segments\naccumulated_ones = tf.math.unsorted_segment_sum(ones, in1, tf.reduce_max(in1)+1)\n\n# calculate the start index of each segment\nstart_index_of_each_seg = tf.math.cumsum(accumulated_ones, exclusive=True)\n\n# add sequential indices in the same segment\nin1_new_index_in_segment = tf.math.unsorted_segment_sum(ones, in1, tf.reduce_max(in1)+1)\n\n# normalize the index for tf.gather\nnormalized_new_index = in1_new_index_in_segment + start_index_of_each_seg\n\n# calculate the new index in sorted tensor\nnew_index = tf.argsort(normalized_new_index)\n\n# gather in2 to new index to generate the sorted tensor\nreturn tf.gather(in2, new_index)",
                "# We will use four tensorflow methods to acheive our task. \n# We will Create a segment id index to sort on, then Sort the indexes. \n# After that Expand segment ids, then Finally create a new tensor using the sorted index.\n\n# 1. Create a segment id index to sort on\nsorted_segment_ids = tf.argsort(in1)\n\n# 2. Sort the indexes\nsorted_segment_id_index = tf.argsort(sorted_segment_ids)\n\n# 3. Expand segment ids \nexpanded_segment_ids = tf.expand_dims(sorted_segment_id_index, axis=0)\n\n# 4. Finally create a new tensor using the sorted index\noutput = tf.gather_nd(in2, expanded_segment_ids)\n\nreturn output",
                "segment_ids = tf.constant(in1)\ndata = tf.constant(in2)\nnum_segments = tf.reduce_max(segment_ids) + 1\nsegments = tf.unsorted_segment_sum(data, segment_ids, num_segments)\nreturn tf.sort(segments, direction='ASCENDING')",
                "segment_ids = tf.constant(in1)\ndata = tf.constant(in2)\nnum_segments = tf.reduce_max(segment_ids) + 1\nsegment_max_data = tf.math.unsorted_segment_max(data, segment_ids, num_segments)\nsegment_sorted_indices = tf.argsort(segment_max_data)\nreturn tf.gather(data, segment_sorted_indices)",
                "segment_ids = tf.convert_to_tensor(in1, dtype=tf.int32)\ndata = tf.convert_to_tensor(in2, dtype=tf.int32)\n\nnum_segments = tf.reduce_max(segment_ids) + 1\nsegment_max = tf.math.unsorted_segment_max(data, segment_ids, num_segments)\n\nindices = tf.argsort(segment_max)\nsorted_data = tf.gather(data, indices)\n\nreturn sorted_data.numpy().tolist()",
                "segment_ids = tf.cast(in1, tf.int32)\ndata = tf.cast(in2, tf.int32)\nsegment_max = tf.math.segment_max(data, segment_ids)\noutput = tf.sort(segment_max)\nreturn output",
                "segment_ids = tf.constant(in1)\ndata = tf.constant(in2)\nlength = tf.reduce_max(segment_ids) + 1\nsegment_max = tf.math.unsorted_segment_sum(data, segment_ids, length)\nsorted_indices = tf.argsort(segment_max)\nsorted_data = tf.gather(data, sorted_indices)\nreturn sorted_data.numpy().tolist()",
                "segments_ids = tf.constant(in1)\ndata = tf.constant(in2)\nnum_segments = len(set(in1))\n\noutput = tf.math.unsorted_segment_sum(data, segments_ids, num_segments)\nsorted_indices = tf.argsort(output)\nsorted_output = tf.gather(output, sorted_indices)\n    \nreturn sorted_output.numpy()",
                "segments = tf.constant(in1)\nvalues = tf.constant(in2)\nsorted_idx = tf.argsort(values)\nsorted_segments = tf.gather(segments, sorted_idx)\nsorted_values = tf.sort(values)\nsegment_ids = tf.argsort(sorted_segments)\nreturn tf.gather(sorted_values, segment_ids).numpy().tolist()"
            ],
            "target-program": "tf.gather(in2, tf.argsort(in1, stable=True))",
            "description": "sort the segments",
            "tf_operators": {
                "tf.gather": 7,
                "tf.argsort": 8,
                "tf.math.unsorted_segment_max": 3,
                "tf.constant": 6,
                "tf.reduce_max": 6,
                "tf.math.cumsum": 1,
                "tf.math.unsorted_segment_sort": 1,
                "tf.ones_like": 1,
                "tf.math.unsorted_segment_sum": 3,
                "tf.gather_nd": 1,
                "tf.expand_dims": 1,
                "tf.unsorted_segment_sum": 1,
                "tf.sort": 3,
                "tf.int32": 2,
                "tf.convert_to_tensor": 1,
                "tf.cast": 1,
                "tf.math.segment_max": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 2,
            "total_covered": 2
        }
    },
    {
        "constants": "[]",
        "description": "gather the marked elements",
        "target_program": "tf.boolean_mask(in1, tf.cast(in2, tf.bool))",
        "source": null,
        "name": "google_10",
        "examples": {
            "inputs": "[[10, 20, 0, 40, 0, 30],[1, 1, 0, 1, 0, 1],]",
            "outputs": "[10, 20, 40, 30]"
        },
        "completions": [
            "return tf.boolean_mask(in1, in2).numpy()",
            "return tf.boolean_mask(in1,in2)",
            "return tf.boolean_mask(in1, in2)",
            "return tf.boolean_mask(in1, in2)",
            "return tf.boolean_mask(in1, in2).numpy().tolist()",
            "return tf.boolean_mask(in1, tf.cast(in2, tf.bool)).numpy().tolist()",
            "return tf.boolean_mask(in1, in2).numpy().tolist()",
            "return tf.boolean_mask(in1, in2)",
            "return tf.boolean_mask(in1, tf.cast(in2, tf.bool))",
            "return tf.boolean_mask(in1, tf.cast(in2, tf.bool)).numpy().tolist()"
        ],
        "response": {
            "task_id": "google_10",
            "completions": [
                "return tf.boolean_mask(in1, in2).numpy()",
                "return tf.boolean_mask(in1,in2)",
                "return tf.boolean_mask(in1, in2)",
                "return tf.boolean_mask(in1, in2)",
                "return tf.boolean_mask(in1, in2).numpy().tolist()",
                "return tf.boolean_mask(in1, tf.cast(in2, tf.bool)).numpy().tolist()",
                "return tf.boolean_mask(in1, in2).numpy().tolist()",
                "return tf.boolean_mask(in1, in2)",
                "return tf.boolean_mask(in1, tf.cast(in2, tf.bool))",
                "return tf.boolean_mask(in1, tf.cast(in2, tf.bool)).numpy().tolist()"
            ],
            "target-program": "tf.boolean_mask(in1, tf.cast(in2, tf.bool))",
            "description": "gather the marked elements",
            "tf_operators": {
                "tf.boolean_mask": 10,
                "tf.bool": 3,
                "tf.cast": 3
            },
            "coverage_percentage": 100.0,
            "total_in_target": 3,
            "total_covered": 3
        }
    },
    {
        "constants": "[]",
        "description": "count the number of elements greater than 0 in each row",
        "target_program": "tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
        "source": "Real task encountered by Googler, 8/26/2019",
        "name": "google_11",
        "examples": {
            "inputs": "[[[1.0, 0.3, -4.2, 0.0, 2.1, 0.4], [-0.1, 0.0, 1.4, -1.0, 0.4, 0.0], [0.1, 0.0, 0.7, -0.3, 0.5, -0.1], [1.4, 2.5, 0.3, 0.01, 0.0, 1.2]],]",
            "outputs": "[4, 2, 3, 5]"
        },
        "completions": [
            "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
            "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
            "return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
            "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
            "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
            "return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
            "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
            "return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
            "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
            "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)"
        ],
        "response": {
            "task_id": "google_11",
            "completions": [
                "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
                "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
                "return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
                "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
                "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
                "return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
                "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
                "return tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
                "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)",
                "return tf.math.count_nonzero(tf.greater(in1, 0), axis=1)"
            ],
            "target-program": "tf.reduce_sum(tf.cast(tf.greater(in1, 0), tf.int32), axis=1)",
            "description": "count the number of elements greater than 0 in each row",
            "tf_operators": {
                "tf.math.count_nonzero": 7,
                "tf.greater": 10,
                "tf.reduce_sum": 3,
                "tf.int32": 3,
                "tf.cast": 3
            },
            "coverage_percentage": 100.0,
            "total_in_target": 4,
            "total_covered": 4
        }
    },
    {
        "constants": "[]",
        "description": "identify elements between 0 and 1",
        "target_program": "tf.cast(tf.logical_and(0 <= in1, in1 <= 1), tf.int32)",
        "source": "Real task encountered by Googler, 8/26/2019",
        "name": "google_12",
        "examples": {
            "inputs": "[[[1.0, 0.3, -4.2, 0.0, 2.1], [-0.1, 0.0, 1.4, -1.0, 0.4], [0.1, 0.0, 0.7, -0.3, 0.5], [1.4, 2.5, 0.3, -0.1, 0.0]],]",
            "outputs": "[[1, 1, 0, 1, 0],    [0, 1, 0, 0, 1],    [1, 1, 1, 0, 1],    [0, 0, 1, 0, 1]]"
        },
        "completions": [
            "return tf.cast(tf.logical_and(tf.greater_equal(in1, 0), tf.less(in1, 1)), tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater_equal(in1, 0), tf.less(in1, 1)), tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater_equal(in1,0), tf.less(in1,1)), 'int32')",
            "return tf.cast(tf.logical_and(tf.greater_equal(in1, 0), tf.less(in1, 1)), dtype=tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater_equal(in1, 0), tf.less_equal(in1, 1)), tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater_equal(in1, 0), tf.less_equal(in1, 1)), tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater_equal(in1, 0), tf.less_equal(in1, 1)), tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater_equal(in1, 0), tf.less(in1, 1)), dtype=tf.int32)",
            "return tf.cast(tf.logical_and(tf.greater_equal(in1, 0), tf.less_equal(in1, 1)), tf.int32)"
        ],
        "response": {
            "task_id": "google_12",
            "completions": [
                "return tf.cast(tf.logical_and(tf.greater_equal(in1, 0), tf.less(in1, 1)), tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater_equal(in1, 0), tf.less(in1, 1)), tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater_equal(in1,0), tf.less(in1,1)), 'int32')",
                "return tf.cast(tf.logical_and(tf.greater_equal(in1, 0), tf.less(in1, 1)), dtype=tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater_equal(in1, 0), tf.less_equal(in1, 1)), tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater_equal(in1, 0), tf.less_equal(in1, 1)), tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater_equal(in1, 0), tf.less_equal(in1, 1)), tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater(in1, 0), tf.less(in1, 1)), tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater_equal(in1, 0), tf.less(in1, 1)), dtype=tf.int32)",
                "return tf.cast(tf.logical_and(tf.greater_equal(in1, 0), tf.less_equal(in1, 1)), tf.int32)"
            ],
            "target-program": "tf.cast(tf.logical_and(0 <= in1, in1 <= 1), tf.int32)",
            "description": "identify elements between 0 and 1",
            "tf_operators": {
                "tf.greater_equal": 9,
                "tf.less": 6,
                "tf.int32": 9,
                "tf.logical_and": 10,
                "tf.cast": 10,
                "tf.less_equal": 4,
                "tf.greater": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 3,
            "total_covered": 3
        }
    },
    {
        "constants": "[]",
        "description": "Concatenate batches of sequences",
        "target_program": "tf.concat([in1, in2], axis=1)",
        "source": "Real task encountered by Googler, 9/13/2019",
        "name": "google_13",
        "examples": {
            "inputs": "[[[1, 2], [10, 20]],[[3, 4, 5], [30, 40, 50]],]",
            "outputs": "[[1, 2, 3, 4, 5], [10, 20, 30, 40, 50]]"
        },
        "completions": [
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1, in2], axis=1)",
            "return tf.concat([in1, in2], axis=-1)",
            "return tf.concat([in1, in2], axis=-1)"
        ],
        "response": {
            "task_id": "google_13",
            "completions": [
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1, in2], axis=1)",
                "return tf.concat([in1, in2], axis=-1)",
                "return tf.concat([in1, in2], axis=-1)"
            ],
            "target-program": "tf.concat([in1, in2], axis=1)",
            "description": "Concatenate batches of sequences",
            "tf_operators": {
                "tf.concat": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        }
    },
    {
        "constants": "[]",
        "description": "circular buffer",
        "target_program": "tf.roll(in1, 1, 1)",
        "source": "From internal Colab, 10/17/2019",
        "name": "google_14",
        "examples": {
            "inputs": "[[[1, 3, 2, 0, 0], [4, 6, 5, 0, 0], [8, 7, 9, 0, 0]],]",
            "outputs": "[[0, 1, 3, 2, 0], [0, 4, 6, 5, 0], [0, 8, 7, 9, 0]]"
        },
        "completions": [
            "padding = tf.constant([[0, 0], [1, 1]])\nreturn tf.pad(in1, padding)",
            "padding = tf.constant([[0, 0], [1, 0]])\nout = tf.pad(in1, padding)\nreturn out",
            "paddings = tf.constant([[0, 0], [1, 0]])\nreturn tf.pad(in1, paddings)",
            "return tf.pad(in1, [[0,0], [1,1]], \"CONSTANT\")",
            "return tf.roll(in1, shift=1, axis=1)",
            "return tf.pad(in1, [[0,0], [1,1]])",
            "return tf.pad(in1, tf.constant([[0,0],[1,1]]), mode='CONSTANT')",
            "padding = tf.constant([[0, 0], [1, 0]])\nreturn tf.pad(in1, padding)",
            "paddings = tf.constant([[0, 0], [1, 0]])\nreturn tf.pad(in1, paddings)",
            "return tf.pad(in1, [[0, 0], [1, 1]], mode='CONSTANT')"
        ],
        "response": {
            "task_id": "google_14",
            "completions": [
                "padding = tf.constant([[0, 0], [1, 1]])\nreturn tf.pad(in1, padding)",
                "padding = tf.constant([[0, 0], [1, 0]])\nout = tf.pad(in1, padding)\nreturn out",
                "paddings = tf.constant([[0, 0], [1, 0]])\nreturn tf.pad(in1, paddings)",
                "return tf.pad(in1, [[0,0], [1,1]], \"CONSTANT\")",
                "return tf.roll(in1, shift=1, axis=1)",
                "return tf.pad(in1, [[0,0], [1,1]])",
                "return tf.pad(in1, tf.constant([[0,0],[1,1]]), mode='CONSTANT')",
                "padding = tf.constant([[0, 0], [1, 0]])\nreturn tf.pad(in1, padding)",
                "paddings = tf.constant([[0, 0], [1, 0]])\nreturn tf.pad(in1, paddings)",
                "return tf.pad(in1, [[0, 0], [1, 1]], mode='CONSTANT')"
            ],
            "target-program": "tf.roll(in1, 1, 1)",
            "description": "circular buffer",
            "tf_operators": {
                "tf.pad": 9,
                "tf.constant": 6,
                "tf.roll": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        }
    },
    {
        "constants": "[]",
        "description": "pad a zero column",
        "target_program": "tf.pad(in1, [[0, 0], [0, 1]], 'CONSTANT')",
        "source": "Real task encountered by Googler, 10/23/2019",
        "name": "google_15",
        "examples": {
            "inputs": "[[[1, 3, 5, 7], [2, 4, 6, 8]],]",
            "outputs": "[[1, 3, 5, 7, 0], [2, 4, 6, 8, 0]]"
        },
        "completions": [
            "return tf.pad(in1, [[0, 0], [0, 1]])",
            "shape = tf.shape(in1)\nzeros = tf.zeros((shape[0], 1), dtype=in1.dtype)\nreturn tf.concat([in1, zeros], axis=1)",
            "pad = tf.constant([[0,0],[0,1]])\nout = tf.pad(in1, pad, \"CONSTANT\")\nreturn out",
            "padded = tf.pad(in1, [[0, 0], [0, 1]], mode='CONSTANT', constant_values=0)\nreturn padded",
            "paddings = tf.constant([[0, 0], [0, 1]])\n     return tf.pad(in1, paddings, mode='CONSTANT', constant_values=0)",
            "return tf.pad(in1, [[0, 0], [0, 1]])",
            "padding = tf.constant([[0, 0], [0, 1]])\n     return tf.pad(in1, padding, 'CONSTANT', constant_values=0)",
            "padding = tf.constant([[0, 0], [0, 1]])\n     return tf.pad(in1, padding, mode='CONSTANT', constant_values=0)",
            "zero_padding = tf.zeros((tf.shape(in1)[0], 1), dtype=in1.dtype)\nout = tf.concat([in1, zero_padding], axis=1)\nreturn out",
            "padding = tf.constant([[0, 0], [0, 1]])\nreturn tf.pad(in1, padding, mode='CONSTANT')"
        ],
        "response": {
            "task_id": "google_15",
            "completions": [
                "return tf.pad(in1, [[0, 0], [0, 1]])",
                "shape = tf.shape(in1)\nzeros = tf.zeros((shape[0], 1), dtype=in1.dtype)\nreturn tf.concat([in1, zeros], axis=1)",
                "pad = tf.constant([[0,0],[0,1]])\nout = tf.pad(in1, pad, \"CONSTANT\")\nreturn out",
                "padded = tf.pad(in1, [[0, 0], [0, 1]], mode='CONSTANT', constant_values=0)\nreturn padded",
                "paddings = tf.constant([[0, 0], [0, 1]])\n     return tf.pad(in1, paddings, mode='CONSTANT', constant_values=0)",
                "return tf.pad(in1, [[0, 0], [0, 1]])",
                "padding = tf.constant([[0, 0], [0, 1]])\n     return tf.pad(in1, padding, 'CONSTANT', constant_values=0)",
                "padding = tf.constant([[0, 0], [0, 1]])\n     return tf.pad(in1, padding, mode='CONSTANT', constant_values=0)",
                "zero_padding = tf.zeros((tf.shape(in1)[0], 1), dtype=in1.dtype)\nout = tf.concat([in1, zero_padding], axis=1)\nreturn out",
                "padding = tf.constant([[0, 0], [0, 1]])\nreturn tf.pad(in1, padding, mode='CONSTANT')"
            ],
            "target-program": "tf.pad(in1, [[0, 0], [0, 1]], 'CONSTANT')",
            "description": "pad a zero column",
            "tf_operators": {
                "tf.pad": 8,
                "tf.zeros": 2,
                "tf.concat": 2,
                "tf.shape": 2,
                "tf.constant": 5
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        }
    },
    {
        "constants": "[]",
        "description": "replicate elements a given number of times",
        "target_program": "tf.gather(in1, tf.where(tf.sequence_mask(in2))[:, 0])",
        "source": "From an internal Google forum",
        "name": "google_16",
        "examples": {
            "inputs": "[[1, 2, 0, 3],[2, 1, 2, 3],]",
            "outputs": "[1, 1, 2, 0, 0, 3, 3, 3]"
        },
        "completions": [
            "return tf.reshape(tf.repeat(in1, in2), [-1])",
            "return tf.repeat(in1, in2).numpy().tolist()",
            "return tf.reshape(tf.repeat(in1, in2), [-1])",
            "return tf.repeat(in1, in2).numpy().tolist()",
            "return tf.repeat(in1, in2).numpy()",
            "return tf.repeat(in1, in2).numpy().tolist()",
            "return tf.reshape(tf.repeat(in1, in2), [-1])",
            "return tf.repeat(in1, in2).numpy()",
            "return tf.repeat(in1, in2).numpy().tolist()",
            "return tf.repeat(in1, in2).numpy().tolist()"
        ],
        "response": {
            "task_id": "google_16",
            "completions": [
                "return tf.reshape(tf.repeat(in1, in2), [-1])",
                "return tf.repeat(in1, in2).numpy().tolist()",
                "return tf.reshape(tf.repeat(in1, in2), [-1])",
                "return tf.repeat(in1, in2).numpy().tolist()",
                "return tf.repeat(in1, in2).numpy()",
                "return tf.repeat(in1, in2).numpy().tolist()",
                "return tf.reshape(tf.repeat(in1, in2), [-1])",
                "return tf.repeat(in1, in2).numpy()",
                "return tf.repeat(in1, in2).numpy().tolist()",
                "return tf.repeat(in1, in2).numpy().tolist()"
            ],
            "target-program": "tf.gather(in1, tf.where(tf.sequence_mask(in2))[:, 0])",
            "description": "replicate elements a given number of times",
            "tf_operators": {
                "tf.reshape": 3,
                "tf.repeat": 10
            },
            "coverage_percentage": 0.0,
            "total_in_target": 3,
            "total_covered": 0
        }
    },
    {
        "constants": "[-10]",
        "description": "use bool tensor as condition",
        "target_program": "tf.where(in1, in2, tf.multiply(in2, -10))",
        "source": "From an internal Google forum",
        "name": "google_17",
        "examples": {
            "inputs": "[[True, False, False, True, False],[1, 2, 3, 4, 5],]",
            "outputs": "[1, -20, -30, 4, -50]"
        },
        "completions": [
            "return tf.where(in1, in2, in2 * -10)",
            "return tf.where(in1, in2, -10*in2)",
            "return tf.where(in1, in2, -10*in2)",
            "return tf.where(in1, in2, -10*tf.constant([2,3,4,5,6]))",
            "return tf.where(in1, in2, in2 * -10)",
            "return tf.where(in1, in2, in2*tf.constant(-10))",
            "return tf.where(in1, in2, in2* -10)",
            "# The task requires to replace all the False values in input tensor with a constant.\n# We will utilize tf.where operation for this purpose.\n    # It takes three parameters: condition, x and y\n    # If the condition is True it picks the value from x else from y.\n# We will use the in1 boolean tensor as the condition and \n# in2 tensor for x. We will create a third tensor with constant values for\n# False condition in in1.\n    \n    false_replacement = tf.fill(tf.shape(in2), -10*tf.range(1, tf.shape(in2)[0]+1))\n    \n    # Now utilize tf.where\n    result = tf.where(in1, in2, false_replacement)\n    return result",
            "return tf.where(in1, in2, in2 * -10)",
            "return tf.where(in1, in2, tf.multiply(in2, -10))"
        ],
        "response": {
            "task_id": "google_17",
            "completions": [
                "return tf.where(in1, in2, in2 * -10)",
                "return tf.where(in1, in2, -10*in2)",
                "return tf.where(in1, in2, -10*in2)",
                "return tf.where(in1, in2, -10*tf.constant([2,3,4,5,6]))",
                "return tf.where(in1, in2, in2 * -10)",
                "return tf.where(in1, in2, in2*tf.constant(-10))",
                "return tf.where(in1, in2, in2* -10)",
                "# The task requires to replace all the False values in input tensor with a constant.\n# We will utilize tf.where operation for this purpose.\n    # It takes three parameters: condition, x and y\n    # If the condition is True it picks the value from x else from y.\n# We will use the in1 boolean tensor as the condition and \n# in2 tensor for x. We will create a third tensor with constant values for\n# False condition in in1.\n    \n    false_replacement = tf.fill(tf.shape(in2), -10*tf.range(1, tf.shape(in2)[0]+1))\n    \n    # Now utilize tf.where\n    result = tf.where(in1, in2, false_replacement)\n    return result",
                "return tf.where(in1, in2, in2 * -10)",
                "return tf.where(in1, in2, tf.multiply(in2, -10))"
            ],
            "target-program": "tf.where(in1, in2, tf.multiply(in2, -10))",
            "description": "use bool tensor as condition",
            "tf_operators": {
                "tf.where": 10,
                "tf.constant": 2,
                "tf.fill": 1,
                "tf.range": 1,
                "tf.shape": 1,
                "tf.multiply": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 2,
            "total_covered": 2
        }
    },
    {
        "constants": "[]",
        "description": "(\\'sum of elements in the first tensor but partitioned by the second tensor\\')",
        "target_program": "tf.linalg.matvec(tf.cast(tf.equal(in2[:, None], in2), tf.int32), in1)",
        "source": "From an internal Google forum",
        "name": "google_18",
        "examples": {
            "inputs": "[[5, 7, -12, 10, 20],[1, 2, 3, 1, 2],]",
            "outputs": "[15, 27, -12, 15, 27]"
        },
        "completions": [
            "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1).numpy()",
            "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)",
            "segment_sum = tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + 1)\nreturn tf.gather(segment_sum, in2)",
            "indices = tf.constant([0, 1, 2, 0, 1])\n     sums = tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)\n     output = tf.gather(sums, in2)\n     return output",
            "output = tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)\nindices = tf.cast(in2, tf.int32)\nresult = tf.gather(output, indices)\nreturn result",
            "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1).numpy()[in2]",
            "result = tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + 1)\n     final_result = tf.gather(result, in2)\n     return final_result",
            "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1).numpy()[in2]",
            "indices = tf.constant([0, 1, 2, 0, 1])\n     bucket_sum = tf.math.unsorted_segment_sum(in1, indices, 3)\n     return tf.gather(bucket_sum, in2)",
            "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1).numpy().tolist()"
        ],
        "response": {
            "task_id": "google_18",
            "completions": [
                "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1).numpy()",
                "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)",
                "segment_sum = tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + 1)\nreturn tf.gather(segment_sum, in2)",
                "indices = tf.constant([0, 1, 2, 0, 1])\n     sums = tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)\n     output = tf.gather(sums, in2)\n     return output",
                "output = tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1)\nindices = tf.cast(in2, tf.int32)\nresult = tf.gather(output, indices)\nreturn result",
                "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1).numpy()[in2]",
                "result = tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2) + 1)\n     final_result = tf.gather(result, in2)\n     return final_result",
                "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1).numpy()[in2]",
                "indices = tf.constant([0, 1, 2, 0, 1])\n     bucket_sum = tf.math.unsorted_segment_sum(in1, indices, 3)\n     return tf.gather(bucket_sum, in2)",
                "return tf.math.unsorted_segment_sum(in1, in2, tf.reduce_max(in2)+1).numpy().tolist()"
            ],
            "target-program": "tf.linalg.matvec(tf.cast(tf.equal(in2[:, None], in2), tf.int32), in1)",
            "description": "(\\'sum of elements in the first tensor but partitioned by the second tensor\\')",
            "tf_operators": {
                "tf.math.unsorted_segment_sum": 10,
                "tf.reduce_max": 9,
                "tf.gather": 5,
                "tf.constant": 2,
                "tf.int32": 1,
                "tf.cast": 1
            },
            "coverage_percentage": 50.0,
            "total_in_target": 4,
            "total_covered": 2
        }
    },
    {
        "constants": "[]",
        "description": "scatter a 2-D tensor with indices",
        "target_program": "tf.gather(in1, tf.argsort(in2, axis=1), batch_dims=1)",
        "source": "From an internal Google forum",
        "name": "google_19",
        "examples": {
            "inputs": "[[[11, 12, 13], [30, 20, 10], [77, 88, 99]],[[2, 0, 1], [1, 0, 2], [0, 2, 1]],]",
            "outputs": "[[12, 13, 11],    [20, 30, 10],    [77, 99, 88]]"
        },
        "completions": [
            "return tf.gather(in1, in2, axis=1)",
            "return tf.gather(in1, in2, axis=1)",
            "return tf.gather(in1, in2, axis=1)",
            "return tf.gather(in1, in2, axis=1)",
            "return tf.gather(in1, in2, axis=1)",
            "out = tf.gather(in1, in2, axis=1)\nreturn out",
            "return tf.gather(in1, in2, axis=1)",
            "return tf.gather(in1, in2, axis=1)",
            "return tf.gather(in1, in2, axis=1)",
            "return tf.gather(in1, in2, axis=1)"
        ],
        "response": {
            "task_id": "google_19",
            "completions": [
                "return tf.gather(in1, in2, axis=1)",
                "return tf.gather(in1, in2, axis=1)",
                "return tf.gather(in1, in2, axis=1)",
                "return tf.gather(in1, in2, axis=1)",
                "return tf.gather(in1, in2, axis=1)",
                "out = tf.gather(in1, in2, axis=1)\nreturn out",
                "return tf.gather(in1, in2, axis=1)",
                "return tf.gather(in1, in2, axis=1)",
                "return tf.gather(in1, in2, axis=1)",
                "return tf.gather(in1, in2, axis=1)"
            ],
            "target-program": "tf.gather(in1, tf.argsort(in2, axis=1), batch_dims=1)",
            "description": "scatter a 2-D tensor with indices",
            "tf_operators": {
                "tf.gather": 10
            },
            "coverage_percentage": 50.0,
            "total_in_target": 2,
            "total_covered": 1
        }
    },
    {
        "constants": "[]",
        "description": "sort a tensor and return sorted index in original order",
        "target_program": "tf.cast(tf.argsort(tf.argsort(in1)), tf.int32)",
        "source": "From an internal Google forum",
        "name": "google_20",
        "examples": {
            "inputs": "[[10, 7, 4, 3, 2, 8],]",
            "outputs": "[5, 3, 2, 1, 0, 4]"
        },
        "completions": [
            "sorted_indices = tf.argsort(in1)\noutput = tf.argsort(sorted_indices)\nreturn output",
            "sorted_indices = tf.argsort(in1)\noriginal_order_indices = tf.argsort(sorted_indices)\nreturn original_order_indices",
            "sorted_indices = tf.argsort(in1)\nreturn tf.argsort(sorted_indices)",
            "return tf.argsort(tf.argsort(in1)).numpy()",
            "return tf.argsort(tf.argsort(in1)).numpy()",
            "sorted_indices = tf.argsort(in1)\nsorted_values = tf.sort(in1)\nreturn tf.argsort(sorted_values, direction='DESCENDING')",
            "sorted_indices = tf.argsort(in1)\nreverse_sorted_indices = tf.argsort(sorted_indices)\nreturn reverse_sorted_indices",
            "return tf.argsort(tf.argsort(in1)).numpy()",
            "sorted_indices = tf.argsort(in1)\nsorted_ranks = tf.argsort(sorted_indices)\nreturn sorted_ranks",
            "return tf.argsort(tf.argsort(in1)).numpy()"
        ],
        "response": {
            "task_id": "google_20",
            "completions": [
                "sorted_indices = tf.argsort(in1)\noutput = tf.argsort(sorted_indices)\nreturn output",
                "sorted_indices = tf.argsort(in1)\noriginal_order_indices = tf.argsort(sorted_indices)\nreturn original_order_indices",
                "sorted_indices = tf.argsort(in1)\nreturn tf.argsort(sorted_indices)",
                "return tf.argsort(tf.argsort(in1)).numpy()",
                "return tf.argsort(tf.argsort(in1)).numpy()",
                "sorted_indices = tf.argsort(in1)\nsorted_values = tf.sort(in1)\nreturn tf.argsort(sorted_values, direction='DESCENDING')",
                "sorted_indices = tf.argsort(in1)\nreverse_sorted_indices = tf.argsort(sorted_indices)\nreturn reverse_sorted_indices",
                "return tf.argsort(tf.argsort(in1)).numpy()",
                "sorted_indices = tf.argsort(in1)\nsorted_ranks = tf.argsort(sorted_indices)\nreturn sorted_ranks",
                "return tf.argsort(tf.argsort(in1)).numpy()"
            ],
            "target-program": "tf.cast(tf.argsort(tf.argsort(in1)), tf.int32)",
            "description": "sort a tensor and return sorted index in original order",
            "tf_operators": {
                "tf.argsort": 10,
                "tf.sort": 1
            },
            "coverage_percentage": 33.33333333333333,
            "total_in_target": 3,
            "total_covered": 1
        }
    },
    {
        "constants": "[]",
        "description": "update a tensor at the given indices",
        "target_program": "tf.tensor_scatter_nd_update(tensor, indices, tf.reshape(updates, (-1,)))",
        "source": "Real task encountered by Googler, 12/15/2020",
        "name": "google_21",
        "examples": {
            "inputs": "{'tensor': [[1, 2, 3, 4, 5], [4, 5, 6, 7, 8], [7, 8, 9, 10, 11]], 'indices': [[0, 0], [0, 2], [1, 1], [1, 3], [2, 2], [2, 4]], 'updates': [[0, -2], [-1, -3], [-2, -4]],}",
            "outputs": "[[0, 2, -2, 4, 5], [4, -1, 6, -3, 8], [7, 8, -2, 10, -4]]"
        },
        "completions": [
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
            "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])"
        ],
        "response": {
            "task_id": "google_21",
            "completions": [
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])",
                "return tf.tensor_scatter_nd_update(in1['tensor'], in1['indices'], in1['updates'])"
            ],
            "target-program": "tf.tensor_scatter_nd_update(tensor, indices, tf.reshape(updates, (-1,)))",
            "description": "update a tensor at the given indices",
            "tf_operators": {
                "tf.tensor_scatter_nd_update": 10
            },
            "coverage_percentage": 50.0,
            "total_in_target": 2,
            "total_covered": 1
        }
    },
    {
        "constants": "[]",
        "description": "pair with row index",
        "target_program": "tf.cast(tf.where(tf.reduce_max(tf.one_hot(in1, tf.reduce_max(in1) + 1), axis=1)), tf.int32)",
        "source": "Real task encountered by Googler, 12/15/2020",
        "name": "google_22",
        "examples": {
            "inputs": "[[[0, 2], [1, 3], [2, 4]],]",
            "outputs": "[[0, 0], [0, 2], [1, 1], [1, 3], [2, 2], [2, 4]]"
        },
        "completions": [
            "indices = tf.range(tf.shape(in1)[0])\n     indices = tf.expand_dims(indices, axis=-1)\n     gather_indices = tf.tile(indices, [1,tf.shape(in1)[1]])\n     gather_indices = tf.reshape(gather_indices, [-1,1])\n     return tf.concat([gather_indices, tf.reshape(in1, [-1,1])], axis=1)",
            "indices = tf.range(tf.shape(in1)[0])\n    indices = tf.expand_dims(indices, axis=-1)\n    repeated_indices = tf.tile(indices, [1, tf.shape(in1)[1]])\n    repeated_indices = tf.reshape(repeated_indices, [-1, 1])\n    reshaped_data = tf.reshape(in1, [-1, 1])\n    return tf.concat([repeated_indices, reshaped_data], axis=-1)",
            "# adding axis=1 to make the indices 2D for concatenation\n    indices = tf.expand_dims(tf.range(tf.shape(in1)[0]), axis=1)\n    # repeat the indices for each column in the input\n    indices = tf.tile(indices, [1, tf.shape(in1)[1]])\n    # unravel the indices and input vectors for stacking\n    indices = tf.reshape(indices, [-1, 1])\n    in1 = tf.reshape(in1, [-1, 1])\n    # stack the indices and inputs along the second axis\n    result = tf.concat([indices, in1], axis=1)\n    return result",
            "indices = tf.range(tf.shape(in1)[0])\nindices = tf.reshape(indices, [-1,1])\nindices = tf.tile(indices, [1, in1.shape[1]])\nin1 = tf.reshape(in1, [-1,1])\nindices = tf.reshape(indices, [-1,1])\nreturn tf.concat([indices, in1], axis=1)",
            "rows, _ = tf.shape(in1)\nindices = tf.range(rows)\nindices = tf.reshape(indices, (-1, 1))\nindices = tf.tile(indices, [1, tf.shape(in1)[1]])\nin1 = tf.expand_dims(in1, 2)\nindices = tf.expand_dims(indices, 2)\nout = tf.concat([indices, in1], axis = 2)\nout = tf.reshape(out, [-1, 2])\nreturn out",
            "indices = tf.range(tf.shape(in1)[0])\n     indices = tf.reshape(indices, [-1, 1])\n     indices = tf.tile(indices, [1, tf.shape(in1)[1]])\n     return tf.stack([indices, in1], axis=2)",
            "indices = tf.range(tf.shape(in1)[0])\n    indices = tf.expand_dims(indices, axis=-1)\n    repeated_indices = tf.tile(indices, [1, tf.shape(in1)[-1]])\n    reshaped_indices = tf.reshape(repeated_indices, [-1, 1])\n    reshaped_in1 = tf.reshape(in1, [-1, 1])\n    result = tf.concat([reshaped_indices, reshaped_in1], axis=-1)\n    return result",
            "indices = tf.range(tf.shape(in1)[0])\nindices = tf.reshape(indices, (-1, 1))\nindices = tf.broadcast_to(indices, in1.shape)\nindices = tf.expand_dims(indices, -1)\nin1 = tf.expand_dims(in1, -1)\nreturn tf.reshape(tf.concat([indices, in1], axis=-1), (-1, 2))",
            "indices = tf.range(start=0, limit=tf.shape(in1)[0])\n     indices = tf.expand_dims(indices, axis=1)\n     indices = tf.tile(indices, multiples=[1, tf.shape(in1)[1]])\n     return tf.reshape(tf.stack([indices, in1], axis=-1), shape=[-1, 2])",
            "rows = tf.shape(in1)[0]\nindices = tf.range(rows)\nindices = tf.expand_dims(indices, -1)\nindices = tf.tile(indices, [1, tf.shape(in1)[1]])\nindices = tf.reshape(indices, [-1, 1])\ninput_reshaped = tf.reshape(in1, [-1, 1])\nreturn tf.concat([indices, input_reshaped], axis=1)"
        ],
        "response": {
            "task_id": "google_22",
            "completions": [
                "indices = tf.range(tf.shape(in1)[0])\n     indices = tf.expand_dims(indices, axis=-1)\n     gather_indices = tf.tile(indices, [1,tf.shape(in1)[1]])\n     gather_indices = tf.reshape(gather_indices, [-1,1])\n     return tf.concat([gather_indices, tf.reshape(in1, [-1,1])], axis=1)",
                "indices = tf.range(tf.shape(in1)[0])\n    indices = tf.expand_dims(indices, axis=-1)\n    repeated_indices = tf.tile(indices, [1, tf.shape(in1)[1]])\n    repeated_indices = tf.reshape(repeated_indices, [-1, 1])\n    reshaped_data = tf.reshape(in1, [-1, 1])\n    return tf.concat([repeated_indices, reshaped_data], axis=-1)",
                "# adding axis=1 to make the indices 2D for concatenation\n    indices = tf.expand_dims(tf.range(tf.shape(in1)[0]), axis=1)\n    # repeat the indices for each column in the input\n    indices = tf.tile(indices, [1, tf.shape(in1)[1]])\n    # unravel the indices and input vectors for stacking\n    indices = tf.reshape(indices, [-1, 1])\n    in1 = tf.reshape(in1, [-1, 1])\n    # stack the indices and inputs along the second axis\n    result = tf.concat([indices, in1], axis=1)\n    return result",
                "indices = tf.range(tf.shape(in1)[0])\nindices = tf.reshape(indices, [-1,1])\nindices = tf.tile(indices, [1, in1.shape[1]])\nin1 = tf.reshape(in1, [-1,1])\nindices = tf.reshape(indices, [-1,1])\nreturn tf.concat([indices, in1], axis=1)",
                "rows, _ = tf.shape(in1)\nindices = tf.range(rows)\nindices = tf.reshape(indices, (-1, 1))\nindices = tf.tile(indices, [1, tf.shape(in1)[1]])\nin1 = tf.expand_dims(in1, 2)\nindices = tf.expand_dims(indices, 2)\nout = tf.concat([indices, in1], axis = 2)\nout = tf.reshape(out, [-1, 2])\nreturn out",
                "indices = tf.range(tf.shape(in1)[0])\n     indices = tf.reshape(indices, [-1, 1])\n     indices = tf.tile(indices, [1, tf.shape(in1)[1]])\n     return tf.stack([indices, in1], axis=2)",
                "indices = tf.range(tf.shape(in1)[0])\n    indices = tf.expand_dims(indices, axis=-1)\n    repeated_indices = tf.tile(indices, [1, tf.shape(in1)[-1]])\n    reshaped_indices = tf.reshape(repeated_indices, [-1, 1])\n    reshaped_in1 = tf.reshape(in1, [-1, 1])\n    result = tf.concat([reshaped_indices, reshaped_in1], axis=-1)\n    return result",
                "indices = tf.range(tf.shape(in1)[0])\nindices = tf.reshape(indices, (-1, 1))\nindices = tf.broadcast_to(indices, in1.shape)\nindices = tf.expand_dims(indices, -1)\nin1 = tf.expand_dims(in1, -1)\nreturn tf.reshape(tf.concat([indices, in1], axis=-1), (-1, 2))",
                "indices = tf.range(start=0, limit=tf.shape(in1)[0])\n     indices = tf.expand_dims(indices, axis=1)\n     indices = tf.tile(indices, multiples=[1, tf.shape(in1)[1]])\n     return tf.reshape(tf.stack([indices, in1], axis=-1), shape=[-1, 2])",
                "rows = tf.shape(in1)[0]\nindices = tf.range(rows)\nindices = tf.expand_dims(indices, -1)\nindices = tf.tile(indices, [1, tf.shape(in1)[1]])\nindices = tf.reshape(indices, [-1, 1])\ninput_reshaped = tf.reshape(in1, [-1, 1])\nreturn tf.concat([indices, input_reshaped], axis=1)"
            ],
            "target-program": "tf.cast(tf.where(tf.reduce_max(tf.one_hot(in1, tf.reduce_max(in1) + 1), axis=1)), tf.int32)",
            "description": "pair with row index",
            "tf_operators": {
                "tf.reshape": 10,
                "tf.expand_dims": 8,
                "tf.range": 10,
                "tf.tile": 9,
                "tf.concat": 8,
                "tf.shape": 10,
                "tf.stack": 2,
                "tf.broadcast_to": 1
            },
            "coverage_percentage": 0.0,
            "total_in_target": 5,
            "total_covered": 0
        }
    },
    {
        "constants": "[]",
        "description": "reshape by separating and duplicating columns",
        "target_program": "tf.transpose(tf.cast((in1, in1), tf.float32))",
        "source": "https://stackoverflow.com/questions/40441503/tensorflow-tensor-reshape",
        "name": "stackoverflow_01",
        "examples": {
            "inputs": "[[[5., 2.], [1., 3.], [0., -1.]],]",
            "outputs": "[[[5., 5.], [1., 1.], [0., 0.]],    [[2., 2.], [3., 3.], [-1., -1.]]]"
        },
        "completions": [
            "reshaped = tf.reshape(in1, (in1.shape[1], in1.shape[0], 1))\nreturn tf.tile(reshaped, [1, 1, 2])",
            "# Reshape the tensor by separating and duplicating columns.\n# 1. Transpose the tensor to transform columns into rows.\n# 2. Expand the dimensions of the tensor along the last axis.\n# 3. Duplicate the values along the last axis.\n\nimport tensorflow as tf\n\ndef transform(in1):\n    in1 = tf.transpose(in1)\n    in1 = tf.expand_dims(in1, axis=-1)\n    in1 = tf.tile(in1, multiples=[1,1,2])\n    return in1",
            "in1 = tf.expand_dims(in1, axis=0)\nin1 = tf.transpose(in1, perm=[2, 1, 0])\nin1 = tf.tile(in1, multiples=[1, 1, 2])\nreturn in1",
            "reshaped = tf.reshape(in1, [-1, 1, 1])\nreturn tf.tile(reshaped, [1, 1, 2])",
            "# First, we need to expand the dimensions of our input tensor.\n    in1_expanded = tf.expand_dims(in1, axis=-1)\n# After expanding, we should have a shape of (rows, columns, 1).\n# Now, we need to duplicate the last dimension (columns), so we use tf.tile() for this.\n    out = tf.tile(in1_expanded, [1, 1, 2])\n# The tensor is now of shape (rows, columns, 2), which is not what we want.\n# We need to transpose the tensor to get the desired output form, (columns, rows, 2)\n    out = tf.transpose(out, perm=[1, 0, 2])\n    return out",
            "in1 = tf.expand_dims(in1, axis=2)\nout = tf.tile(in1, multiples=[1,1,2])\nreturn out",
            "out1 = tf.expand_dims(in1, axis=0)\nout2 = tf.transpose(out1, perm=[2, 1, 0])\nout3 = tf.tile(out2, multiples=[1, 1, 2])\nreturn out3",
            "return tf.reshape(tf.tile(tf.expand_dims(in1, axis=0), [in1.shape[1], 1, 2]), [in1.shape[1], in1.shape[0], 2])",
            "return tf.reshape(tf.tile(tf.expand_dims(in1, axis=0), [2, 1, 2]), [2, 3, 2])",
            "# Use tf.reshape to rearrange elements of tensor for the new shape.\n# tf.tile to create a new tensor by replicating input tensor along the given axis.\n\n    in1 = tf.transpose(in1)\n    in1 = tf.expand_dims(in1, -1)\n    return tf.tile(in1, [1,1,2])"
        ],
        "response": {
            "task_id": "stackoverflow_01",
            "completions": [
                "reshaped = tf.reshape(in1, (in1.shape[1], in1.shape[0], 1))\nreturn tf.tile(reshaped, [1, 1, 2])",
                "# Reshape the tensor by separating and duplicating columns.\n# 1. Transpose the tensor to transform columns into rows.\n# 2. Expand the dimensions of the tensor along the last axis.\n# 3. Duplicate the values along the last axis.\n\nimport tensorflow as tf\n\ndef transform(in1):\n    in1 = tf.transpose(in1)\n    in1 = tf.expand_dims(in1, axis=-1)\n    in1 = tf.tile(in1, multiples=[1,1,2])\n    return in1",
                "in1 = tf.expand_dims(in1, axis=0)\nin1 = tf.transpose(in1, perm=[2, 1, 0])\nin1 = tf.tile(in1, multiples=[1, 1, 2])\nreturn in1",
                "reshaped = tf.reshape(in1, [-1, 1, 1])\nreturn tf.tile(reshaped, [1, 1, 2])",
                "# First, we need to expand the dimensions of our input tensor.\n    in1_expanded = tf.expand_dims(in1, axis=-1)\n# After expanding, we should have a shape of (rows, columns, 1).\n# Now, we need to duplicate the last dimension (columns), so we use tf.tile() for this.\n    out = tf.tile(in1_expanded, [1, 1, 2])\n# The tensor is now of shape (rows, columns, 2), which is not what we want.\n# We need to transpose the tensor to get the desired output form, (columns, rows, 2)\n    out = tf.transpose(out, perm=[1, 0, 2])\n    return out",
                "in1 = tf.expand_dims(in1, axis=2)\nout = tf.tile(in1, multiples=[1,1,2])\nreturn out",
                "out1 = tf.expand_dims(in1, axis=0)\nout2 = tf.transpose(out1, perm=[2, 1, 0])\nout3 = tf.tile(out2, multiples=[1, 1, 2])\nreturn out3",
                "return tf.reshape(tf.tile(tf.expand_dims(in1, axis=0), [in1.shape[1], 1, 2]), [in1.shape[1], in1.shape[0], 2])",
                "return tf.reshape(tf.tile(tf.expand_dims(in1, axis=0), [2, 1, 2]), [2, 3, 2])",
                "# Use tf.reshape to rearrange elements of tensor for the new shape.\n# tf.tile to create a new tensor by replicating input tensor along the given axis.\n\n    in1 = tf.transpose(in1)\n    in1 = tf.expand_dims(in1, -1)\n    return tf.tile(in1, [1,1,2])"
            ],
            "target-program": "tf.transpose(tf.cast((in1, in1), tf.float32))",
            "description": "reshape by separating and duplicating columns",
            "tf_operators": {
                "tf.tile": 10,
                "tf.reshape": 5,
                "tf.transpose": 5,
                "tf.expand_dims": 8
            },
            "coverage_percentage": 33.33333333333333,
            "total_in_target": 3,
            "total_covered": 1
        }
    },
    {
        "constants": "[1]",
        "description": "clip values that are greater than 1",
        "target_program": "tf.minimum(in1, tf.constant(1))",
        "source": "https://stackoverflow.com/questions/46408839/tensorflow-trim-values-in-tensor",
        "name": "stackoverflow_02",
        "examples": {
            "inputs": "[[5, 1, 0, 3, 0, -1, 2, -10, 2],]",
            "outputs": "[[1, 1, 0, 1, 0, -1, 1, -10, 1]]"
        },
        "completions": [
            "return tf.clip_by_value(in1, clip_value_min=-tf.float32.max, clip_value_max=1)",
            "return tf.clip_by_value(in1, clip_value_min=-np.inf, clip_value_max=1)",
            "return tf.clip_by_value(in1, -float('inf'), 1)",
            "return tf.clip_by_value(in1, clip_value_min=-float('inf'), clip_value_max=1)",
            "return tf.clip_by_value(in1, clip_value_min=-np.inf, clip_value_max=1)",
            "return tf.clip_by_value(in1, clip_value_min=-np.inf, clip_value_max=1)",
            "return tf.clip_by_value(in1, -float('inf'), 1)",
            "return tf.clip_by_value(in1, -np.inf, 1)",
            "return tf.clip_by_value(in1, clip_value_min=-float('inf'), clip_value_max=1)",
            "return tf.clip_by_value(in1, clip_value_min=-np.inf, clip_value_max=1)"
        ],
        "response": {
            "task_id": "stackoverflow_02",
            "completions": [
                "return tf.clip_by_value(in1, clip_value_min=-tf.float32.max, clip_value_max=1)",
                "return tf.clip_by_value(in1, clip_value_min=-np.inf, clip_value_max=1)",
                "return tf.clip_by_value(in1, -float('inf'), 1)",
                "return tf.clip_by_value(in1, clip_value_min=-float('inf'), clip_value_max=1)",
                "return tf.clip_by_value(in1, clip_value_min=-np.inf, clip_value_max=1)",
                "return tf.clip_by_value(in1, clip_value_min=-np.inf, clip_value_max=1)",
                "return tf.clip_by_value(in1, -float('inf'), 1)",
                "return tf.clip_by_value(in1, -np.inf, 1)",
                "return tf.clip_by_value(in1, clip_value_min=-float('inf'), clip_value_max=1)",
                "return tf.clip_by_value(in1, clip_value_min=-np.inf, clip_value_max=1)"
            ],
            "target-program": "tf.minimum(in1, tf.constant(1))",
            "description": "clip values that are greater than 1",
            "tf_operators": {
                "tf.float32.max": 1,
                "tf.clip_by_value": 10
            },
            "coverage_percentage": 0.0,
            "total_in_target": 2,
            "total_covered": 0
        }
    },
    {
        "constants": "[3, 4, 5]",
        "description": "replace certain columns with columns from the other tensor",
        "target_program": "tf.reduce_sum(tf.one_hot(tf.range(3, 5), depth=in1.shape[1], dtype=tf.int32), axis=0) * in2 + (1 - tf.reduce_sum(tf.one_hot(tf.range(3, 5), depth=in1.shape[1], dtype=tf.int32), axis=0)) * in1",
        "source": "https://stackoverflow.com/questions/44657388/how-to-replace-certain-values-in-tensorflow-tensor-with-the-values-of-the-other",
        "name": "stackoverflow_03",
        "examples": {
            "inputs": "[[[11, 22, 33, 44, 55, 66, 77], [70, 60, 50, 40, 30, 20, 10]],[[-9, -8, -7, -6, -5, -4, -3], [11, 12, 13, 14, 15, 16, 17]],]",
            "outputs": "[[[11, 22, 33, -6, -5, 66, 77], [70, 60, 50, 14, 15, 20, 10]]]"
        },
        "completions": [
            "in1 = tf.cast(in1, tf.float32)\nin2 = tf.cast(in2, tf.float32)\nindices = tf.constant([3, 4])\nupdates = tf.gather(in2, indices, axis=1)\noutput = tf.tensor_scatter_nd_update(in1, tf.expand_dims(indices, axis=1), updates)\nreturn output",
            "indices = tf.constant([3, 4], dtype=tf.int32)  \nreturn tf.tensor_scatter_nd_update(in1, tf.expand_dims(indices, 1), tf.transpose(tf.gather(tf.transpose(in2), indices)))",
            "in1 = tf.constant(in1, dtype=tf.int32)\nin2 = tf.constant(in2, dtype=tf.int32)\nindices = tf.constant([3, 4])\nreturn tf.tensor_scatter_nd_update(in1, tf.expand_dims(indices, axis=1), tf.gather(in2[1], indices))",
            "new_col = tf.gather(in2, indices=[3,4], axis=1)\nin1 = tf.gather(in1, indices=[0,1,2,5,6], axis=1)\nreturn tf.concat([in1, new_col], axis=1)",
            "return tf.tensor_scatter_nd_update(in1, [[0, 3], [0, 4], [1, 3], [1, 4]], tf.gather_nd(in2, [[0, 3], [0, 4], [1, 3], [1, 4]]))",
            "indices = tf.constant([3, 4])\n    updates = tf.gather(in2, indices, axis=1)\n    out = tf.tensor_scatter_nd_update(in1, tf.expand_dims(indices, 1), updates)\n    return out",
            "indices = tf.constant([3, 4])\n    return tf.tensor_scatter_nd_update(in1, tf.expand_dims(indices, axis=-1), tf.gather(in2, indices, axis=1))",
            "in1 = tf.cast(in1, tf.int32)\nin2 = tf.cast(in2, tf.int32)\n\n# Get the columns to replace from in2\nreplaced = tf.slice(in2, [0, 3], [2, 2])\n\n# Replace the columns in in1\nin1_t = tf.tensor_scatter_nd_update(in1, [[0, 3], [0, 4], [1, 3], [1, 4]], tf.reshape(replaced, [-1]))\n\nreturn tf.expand_dims(in1_t, 0)",
            "in1 = tf.constant(in1, dtype=tf.int32)\nin2 = tf.constant(in2, dtype=tf.int32)\nin1 = tf.unstack(in1, axis=-1)\nin2 = tf.unstack(in2, axis=-1)\nin1[3:5] = in2[3:5]\nin1 = tf.stack(in1, axis=-1)\nreturn in1",
            "in1 = tf.constant(in1)\n     in2 = tf.constant(in2)\n     in1 = tf.tensor_scatter_nd_update(in1, [[0,3],[0,4],[1,3],[1,4]], tf.gather_nd(in2, [[0,3],[0,4],[1,3],[1,4]]))\n     return in1"
        ],
        "response": {
            "task_id": "stackoverflow_03",
            "completions": [
                "in1 = tf.cast(in1, tf.float32)\nin2 = tf.cast(in2, tf.float32)\nindices = tf.constant([3, 4])\nupdates = tf.gather(in2, indices, axis=1)\noutput = tf.tensor_scatter_nd_update(in1, tf.expand_dims(indices, axis=1), updates)\nreturn output",
                "indices = tf.constant([3, 4], dtype=tf.int32)  \nreturn tf.tensor_scatter_nd_update(in1, tf.expand_dims(indices, 1), tf.transpose(tf.gather(tf.transpose(in2), indices)))",
                "in1 = tf.constant(in1, dtype=tf.int32)\nin2 = tf.constant(in2, dtype=tf.int32)\nindices = tf.constant([3, 4])\nreturn tf.tensor_scatter_nd_update(in1, tf.expand_dims(indices, axis=1), tf.gather(in2[1], indices))",
                "new_col = tf.gather(in2, indices=[3,4], axis=1)\nin1 = tf.gather(in1, indices=[0,1,2,5,6], axis=1)\nreturn tf.concat([in1, new_col], axis=1)",
                "return tf.tensor_scatter_nd_update(in1, [[0, 3], [0, 4], [1, 3], [1, 4]], tf.gather_nd(in2, [[0, 3], [0, 4], [1, 3], [1, 4]]))",
                "indices = tf.constant([3, 4])\n    updates = tf.gather(in2, indices, axis=1)\n    out = tf.tensor_scatter_nd_update(in1, tf.expand_dims(indices, 1), updates)\n    return out",
                "indices = tf.constant([3, 4])\n    return tf.tensor_scatter_nd_update(in1, tf.expand_dims(indices, axis=-1), tf.gather(in2, indices, axis=1))",
                "in1 = tf.cast(in1, tf.int32)\nin2 = tf.cast(in2, tf.int32)\n\n# Get the columns to replace from in2\nreplaced = tf.slice(in2, [0, 3], [2, 2])\n\n# Replace the columns in in1\nin1_t = tf.tensor_scatter_nd_update(in1, [[0, 3], [0, 4], [1, 3], [1, 4]], tf.reshape(replaced, [-1]))\n\nreturn tf.expand_dims(in1_t, 0)",
                "in1 = tf.constant(in1, dtype=tf.int32)\nin2 = tf.constant(in2, dtype=tf.int32)\nin1 = tf.unstack(in1, axis=-1)\nin2 = tf.unstack(in2, axis=-1)\nin1[3:5] = in2[3:5]\nin1 = tf.stack(in1, axis=-1)\nreturn in1",
                "in1 = tf.constant(in1)\n     in2 = tf.constant(in2)\n     in1 = tf.tensor_scatter_nd_update(in1, [[0,3],[0,4],[1,3],[1,4]], tf.gather_nd(in2, [[0,3],[0,4],[1,3],[1,4]]))\n     return in1"
            ],
            "target-program": "tf.reduce_sum(tf.one_hot(tf.range(3, 5), depth=in1.shape[1], dtype=tf.int32), axis=0) * in2 + (1 - tf.reduce_sum(tf.one_hot(tf.range(3, 5), depth=in1.shape[1], dtype=tf.int32), axis=0)) * in1",
            "description": "replace certain columns with columns from the other tensor",
            "tf_operators": {
                "tf.float32": 1,
                "tf.tensor_scatter_nd_update": 8,
                "tf.expand_dims": 6,
                "tf.constant": 7,
                "tf.gather": 6,
                "tf.cast": 2,
                "tf.int32": 4,
                "tf.transpose": 1,
                "tf.concat": 1,
                "tf.gather_nd": 2,
                "tf.slice": 1,
                "tf.reshape": 1,
                "tf.stack": 1,
                "tf.unstack": 1
            },
            "coverage_percentage": 25.0,
            "total_in_target": 4,
            "total_covered": 1
        }
    },
    {
        "constants": "[]",
        "description": "index into the tensor",
        "target_program": "tf.gather_nd(in1, tf.stack((in2, in3), axis=-1))",
        "source": "https://stackoverflow.com/questions/33736795/tensorflow-numpy-like-tensor-indexing",
        "name": "stackoverflow_04",
        "examples": {
            "inputs": "[  [[5., 2.], [1., 3.], [0., -1.]]]",
            "outputs": "[[[5., 5.], [1., 1.], [0., 0.]],  [[2., 2.], [3., 3.], [-1., -1.]]]"
        },
        "completions": [
            "return tf.transpose(in1)",
            "return tf.transpose([in1, in1])",
            "return tf.transpose(tf.expand_dims(in1, axis=0), perm=[1,2,0])",
            "return tf.transpose(tf.tile(tf.expand_dims(in1, axis=0), [2,1,1]))",
            "return tf.transpose(tf.tile(tf.expand_dims(in1, axis=-1),[1,1,2]))",
            "return tf.transpose(tf.tile(tf.expand_dims(in1, axis=2), [1, 1, 2]))",
            "return tf.transpose(tf.tile([in1], [2, 1, 1]), [1, 2, 0])",
            "return tf.gather(in1, tf.transpose(tf.expand_dims(tf.range(tf.shape(in1)[1]), -1)), axis=1)",
            "return tf.gather(in1, tf.transpose(tf.eye(tf.shape(in1)[1], dtype=tf.int32)), axis=1)",
            "return tf.gather(tf.expand_dims(in1, axis=0), [[0, 0], [1, 1]], axis=2)"
        ],
        "response": {
            "task_id": "stackoverflow_04",
            "completions": [
                "return tf.transpose(in1)",
                "return tf.transpose([in1, in1])",
                "return tf.transpose(tf.expand_dims(in1, axis=0), perm=[1,2,0])",
                "return tf.transpose(tf.tile(tf.expand_dims(in1, axis=0), [2,1,1]))",
                "return tf.transpose(tf.tile(tf.expand_dims(in1, axis=-1),[1,1,2]))",
                "return tf.transpose(tf.tile(tf.expand_dims(in1, axis=2), [1, 1, 2]))",
                "return tf.transpose(tf.tile([in1], [2, 1, 1]), [1, 2, 0])",
                "return tf.gather(in1, tf.transpose(tf.expand_dims(tf.range(tf.shape(in1)[1]), -1)), axis=1)",
                "return tf.gather(in1, tf.transpose(tf.eye(tf.shape(in1)[1], dtype=tf.int32)), axis=1)",
                "return tf.gather(tf.expand_dims(in1, axis=0), [[0, 0], [1, 1]], axis=2)"
            ],
            "target-program": "tf.gather_nd(in1, tf.stack((in2, in3), axis=-1))",
            "description": "index into the tensor",
            "tf_operators": {
                "tf.transpose": 9,
                "tf.expand_dims": 6,
                "tf.tile": 4,
                "tf.range": 1,
                "tf.gather": 3,
                "tf.shape": 2,
                "tf.eye": 1,
                "tf.int32": 1
            },
            "coverage_percentage": 0.0,
            "total_in_target": 2,
            "total_covered": 0
        }
    },
    {
        "constants": "[]",
        "description": "tensor multiplication like np.tensordot",
        "target_program": "tf.tensordot(in1, in2, 1)",
        "source": "https://stackoverflow.com/questions/43067338/tensor-multiplication-in-tensorflow",
        "name": "stackoverflow_05",
        "examples": {
            "inputs": "[[[4, 3, 1], [6, 5, 2]],[[[5, 5]], [[1, 5]], [[6, 0]]],]",
            "outputs": "[[[29, 35]], [[47, 55]]]"
        },
        "completions": [
            "return tf.tensordot(in1, in2, axes=[[0, 1], [0, 1]])",
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=[[1], [1]])",
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=[[0, 1], [0, 2]])",
            "return tf.tensordot(in1, in2, axes=[[1], [1]])"
        ],
        "response": {
            "task_id": "stackoverflow_05",
            "completions": [
                "return tf.tensordot(in1, in2, axes=[[0, 1], [0, 1]])",
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=[[1], [1]])",
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=[[0, 1], [0, 2]])",
                "return tf.tensordot(in1, in2, axes=[[1], [1]])"
            ],
            "target-program": "tf.tensordot(in1, in2, 1)",
            "description": "tensor multiplication like np.tensordot",
            "tf_operators": {
                "tf.tensordot": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        }
    },
    {
        "constants": "[]",
        "description": "binary tensor from vector indicating if elements are equal",
        "target_program": "tf.cast(tf.equal(in1, tf.expand_dims(in1, 1)), tf.float32)",
        "source": "https://stackoverflow.com/questions/47816231/create-binary-tensor-from-vector-in-tensorflow",
        "name": "stackoverflow_06",
        "examples": {
            "inputs": "[[3, 5, 0, 2, 3, 3, 0],]",
            "outputs": "[[1., 0., 0., 0., 1., 1., 0.],    [0., 1., 0., 0., 0., 0., 0.],    [0., 0., 1., 0., 0., 0., 1.],    [0., 0., 0., 1., 0., 0., 0.],    [1., 0., 0., 0., 1., 1., 0.],    [1., 0., 0., 0., 1., 1., 0.],    [0., 0., 1., 0., 0., 0., 1.]]"
        },
        "completions": [
            "in1 = tf.expand_dims(in1, 1)\nin2 = tf.transpose(in1)\nequal_output = tf.cast(tf.equal(in1, in2), tf.float32)\nreturn equal_output",
            "in2 = tf.expand_dims(in1, 1)\n     return tf.cast(tf.equal(in1, in2), tf.float32)",
            "# First, we expand the dimensions of in1 to make it appropriate for boolean operation\n    in1_expanded = tf.expand_dims(in1, 1)\n    # We then use the \"equal\" operator to compare the elements between original and expanded tensors\n    result = tf.equal(in1, in1_expanded)\n    # Finally, we cast the boolean results to float values for the final output\n    return tf.cast(result, tf.float32)",
            "expanded = tf.expand_dims(in1, -1)\ntransposed = tf.transpose(expanded)\nequal = tf.equal(expanded, transposed)\nreturn tf.cast(equal, dtype=float)",
            "in1 = tf.expand_dims(in1, 1)\nin2 = tf.transpose(in1)\nresult = tf.cast(tf.equal(in1, in2), dtype=tf.float32)\nreturn result",
            "return tf.cast(tf.equal(tf.expand_dims(in1, 1), in1), tf.float32)",
            "return tf.cast(tf.equal(tf.expand_dims(in1, 1), in1), tf.float32)",
            "return tf.cast(tf.equal(tf.expand_dims(in1, 1), tf.expand_dims(in1, 0)), dtype=tf.float32)",
            "return tf.cast(tf.equal(tf.expand_dims(in1, 0), tf.expand_dims(in1, 1)), tf.float32)",
            "return tf.cast(tf.equal(tf.expand_dims(in1, 1), tf.expand_dims(in1, 0)), tf.float32)"
        ],
        "response": {
            "task_id": "stackoverflow_06",
            "completions": [
                "in1 = tf.expand_dims(in1, 1)\nin2 = tf.transpose(in1)\nequal_output = tf.cast(tf.equal(in1, in2), tf.float32)\nreturn equal_output",
                "in2 = tf.expand_dims(in1, 1)\n     return tf.cast(tf.equal(in1, in2), tf.float32)",
                "# First, we expand the dimensions of in1 to make it appropriate for boolean operation\n    in1_expanded = tf.expand_dims(in1, 1)\n    # We then use the \"equal\" operator to compare the elements between original and expanded tensors\n    result = tf.equal(in1, in1_expanded)\n    # Finally, we cast the boolean results to float values for the final output\n    return tf.cast(result, tf.float32)",
                "expanded = tf.expand_dims(in1, -1)\ntransposed = tf.transpose(expanded)\nequal = tf.equal(expanded, transposed)\nreturn tf.cast(equal, dtype=float)",
                "in1 = tf.expand_dims(in1, 1)\nin2 = tf.transpose(in1)\nresult = tf.cast(tf.equal(in1, in2), dtype=tf.float32)\nreturn result",
                "return tf.cast(tf.equal(tf.expand_dims(in1, 1), in1), tf.float32)",
                "return tf.cast(tf.equal(tf.expand_dims(in1, 1), in1), tf.float32)",
                "return tf.cast(tf.equal(tf.expand_dims(in1, 1), tf.expand_dims(in1, 0)), dtype=tf.float32)",
                "return tf.cast(tf.equal(tf.expand_dims(in1, 0), tf.expand_dims(in1, 1)), tf.float32)",
                "return tf.cast(tf.equal(tf.expand_dims(in1, 1), tf.expand_dims(in1, 0)), tf.float32)"
            ],
            "target-program": "tf.cast(tf.equal(in1, tf.expand_dims(in1, 1)), tf.float32)",
            "description": "binary tensor from vector indicating if elements are equal",
            "tf_operators": {
                "tf.float32": 9,
                "tf.equal": 10,
                "tf.expand_dims": 10,
                "tf.transpose": 3,
                "tf.cast": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 4,
            "total_covered": 4
        }
    },
    {
        "constants": "[]",
        "description": "swap the first two dimensions of the tensor",
        "target_program": "tf.cast(tf.unstack(in1, axis=1), tf.int32)",
        "source": "https://stackoverflow.com/questions/38212205/swap-tensor-axes-in-tensorflow",
        "name": "stackoverflow_07",
        "examples": {
            "inputs": "[[[[8, 4, 6], [2, 12, 3]], [[11, 12, 5], [9, 12, 12]], [[9, 2, 13], [7, 0, 7]], [[2, 10, 5], [7, 1, 2]]],]",
            "outputs": "[[[8, 4, 6], [11, 12, 5], [9, 2, 13], [2, 10, 5]],    [[2, 12, 3], [9, 12, 12], [7, 0, 7], [7, 1, 2]]]"
        },
        "completions": [
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, perm=[1, 0, 2])",
            "return tf.transpose(in1, [1, 0, 2])"
        ],
        "response": {
            "task_id": "stackoverflow_07",
            "completions": [
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, perm=[1, 0, 2])",
                "return tf.transpose(in1, [1, 0, 2])"
            ],
            "target-program": "tf.cast(tf.unstack(in1, axis=1), tf.int32)",
            "description": "swap the first two dimensions of the tensor",
            "tf_operators": {
                "tf.transpose": 10
            },
            "coverage_percentage": 0.0,
            "total_in_target": 3,
            "total_covered": 0
        }
    },
    {
        "constants": "[1]",
        "description": "(\\'select the values in the second tensor where the first tensor is greater than 1\\')",
        "target_program": "tf.boolean_mask(in2, tf.greater(in1, tf.constant(1)))",
        "source": "https://stackoverflow.com/questions/33769041/tensorflow-indexing-with-boolean-tensor",
        "name": "stackoverflow_08",
        "examples": {
            "inputs": "[[-1, 0, -3, 2, 1, 3, 5, -1, -9, 2, 10],[12, 3, 45, 6, 7, 8, 9, 87, 65, 4, 32],]",
            "outputs": "[6, 8, 9, 4, 32]"
        },
        "completions": [
            "mask = tf.greater(in1, 1)\n     return tf.boolean_mask(in2, mask)",
            "condition = tf.greater(in1, 1)\n     return tf.boolean_mask(in2, condition)",
            "condition = tf.greater(in1, 1)\n     return tf.boolean_mask(in2, condition)",
            "condition = tf.greater(in1, tf.constant(1))\n return tf.boolean_mask(in2, condition)",
            "mask = tf.greater(in1, 1)\n     return tf.boolean_mask(in2, mask)",
            "condition = tf.greater(in1, 1)\nreturn tf.boolean_mask(in2, condition)",
            "return tf.boolean_mask(in2, tf.greater(in1, 1))",
            "mask = tf.greater(in1, tf.constant(1))\n     return tf.boolean_mask(in2, mask)",
            "mask = tf.greater(in1, tf.constant(1))\n     out = tf.boolean_mask(in2, mask)\n     return out",
            "condition = tf.greater(in1, 1)\nreturn tf.boolean_mask(in2, condition)"
        ],
        "response": {
            "task_id": "stackoverflow_08",
            "completions": [
                "mask = tf.greater(in1, 1)\n     return tf.boolean_mask(in2, mask)",
                "condition = tf.greater(in1, 1)\n     return tf.boolean_mask(in2, condition)",
                "condition = tf.greater(in1, 1)\n     return tf.boolean_mask(in2, condition)",
                "condition = tf.greater(in1, tf.constant(1))\n return tf.boolean_mask(in2, condition)",
                "mask = tf.greater(in1, 1)\n     return tf.boolean_mask(in2, mask)",
                "condition = tf.greater(in1, 1)\nreturn tf.boolean_mask(in2, condition)",
                "return tf.boolean_mask(in2, tf.greater(in1, 1))",
                "mask = tf.greater(in1, tf.constant(1))\n     return tf.boolean_mask(in2, mask)",
                "mask = tf.greater(in1, tf.constant(1))\n     out = tf.boolean_mask(in2, mask)\n     return out",
                "condition = tf.greater(in1, 1)\nreturn tf.boolean_mask(in2, condition)"
            ],
            "target-program": "tf.boolean_mask(in2, tf.greater(in1, tf.constant(1)))",
            "description": "(\\'select the values in the second tensor where the first tensor is greater than 1\\')",
            "tf_operators": {
                "tf.greater": 10,
                "tf.boolean_mask": 10,
                "tf.constant": 3
            },
            "coverage_percentage": 100.0,
            "total_in_target": 3,
            "total_covered": 3
        }
    },
    {
        "constants": "[]",
        "description": "group items by value and get the group indices",
        "target_program": "tf.unique_with_counts(in1)[1]",
        "source": "https://stackoverflow.com/questions/53054668/assign-values-between-0-and-n-1-for-a-vector-of-length-l-with-n-different-eleme",
        "name": "stackoverflow_09",
        "examples": {
            "inputs": "[[37, 42, 42, 37, 28, 15, 42, 15],]",
            "outputs": "[0, 1, 1, 0, 2, 3, 1, 3]"
        },
        "completions": [
            "_, idx = tf.unique(in1)\nreturn tf.gather(idx, in1)",
            "_, ids = tf.unique_with_counts(in1)\nreturn tf.gather(ids, in1)",
            "_, indices = tf.unique_with_counts(in1)\nreturn indices",
            "_, _, group_indices = tf.unique_with_counts(in1)\nreturn group_indices",
            "_, ids = tf.unique(in1)\nreturn ids",
            "_, idx = tf.unique(in1)\nreturn tf.gather(idx, in1).numpy()",
            "_, idx = tf.unique_with_counts(in1)\nreturn tf.gather(idx, in1)",
            "_, idx = tf.unique_with_counts(in1)\nres = tf.gather(idx, in1)\nreturn res",
            "_, idx = tf.unique_with_counts(in1)\nreturn tf.cast(tf.gather(idx, in1), dtype=tf.int32)",
            "_, idx, count = tf.unique_with_counts(in1)\nreturn tf.gather(idx, tf.argsort(count, stable=True))"
        ],
        "response": {
            "task_id": "stackoverflow_09",
            "completions": [
                "_, idx = tf.unique(in1)\nreturn tf.gather(idx, in1)",
                "_, ids = tf.unique_with_counts(in1)\nreturn tf.gather(ids, in1)",
                "_, indices = tf.unique_with_counts(in1)\nreturn indices",
                "_, _, group_indices = tf.unique_with_counts(in1)\nreturn group_indices",
                "_, ids = tf.unique(in1)\nreturn ids",
                "_, idx = tf.unique(in1)\nreturn tf.gather(idx, in1).numpy()",
                "_, idx = tf.unique_with_counts(in1)\nreturn tf.gather(idx, in1)",
                "_, idx = tf.unique_with_counts(in1)\nres = tf.gather(idx, in1)\nreturn res",
                "_, idx = tf.unique_with_counts(in1)\nreturn tf.cast(tf.gather(idx, in1), dtype=tf.int32)",
                "_, idx, count = tf.unique_with_counts(in1)\nreturn tf.gather(idx, tf.argsort(count, stable=True))"
            ],
            "target-program": "tf.unique_with_counts(in1)[1]",
            "description": "group items by value and get the group indices",
            "tf_operators": {
                "tf.gather": 7,
                "tf.unique": 3,
                "tf.unique_with_counts": 7,
                "tf.int32": 1,
                "tf.cast": 1,
                "tf.argsort": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        }
    },
    {
        "constants": "[]",
        "description": "perform matrix multiplication",
        "target_program": "tf.matmul(tf.expand_dims(in1, -1), tf.expand_dims(in2, 1))",
        "source": "https://stackoverflow.com/questions/53094212/tensorflow-sxn-matrix-multiply-with-sxd-matrix-to-output-sxnxd-array",
        "name": "stackoverflow_10",
        "examples": {
            "inputs": "[[[15, 10], [20, -5]],[[2, 3, 1], [-2, 5, 0]],]",
            "outputs": "[[[30, 45, 15], [20, 30, 10]],[[-40, 100, 0], [10, -25, 0]]]"
        },
        "completions": [
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in1, in2)"
        ],
        "response": {
            "task_id": "stackoverflow_10",
            "completions": [
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in1, in2)"
            ],
            "target-program": "tf.matmul(tf.expand_dims(in1, -1), tf.expand_dims(in2, 1))",
            "description": "perform matrix multiplication",
            "tf_operators": {
                "tf.matmul": 10
            },
            "coverage_percentage": 50.0,
            "total_in_target": 2,
            "total_covered": 1
        }
    },
    {
        "constants": "[]",
        "description": "count the number of occurences of each distinct number",
        "target_program": "tf.math.bincount(in1)",
        "source": "https://stackoverflow.com/questions/45194672/how-to-count-elements-in-tensorflow-tensor",
        "name": "stackoverflow_11",
        "examples": {
            "inputs": "[[4, 0, 1, 1, 0, 4, 0, 0, 3, 4, 1],]",
            "outputs": "[4, 3, 0, 1, 3]"
        },
        "completions": [
            "return tf.math.bincount(in1).numpy().tolist()",
            "return tf.math.bincount(in1).numpy()",
            "return tf.math.bincount(in1).numpy().tolist()",
            "return tf.math.bincount(in1).numpy().tolist()",
            "return tf.math.bincount(in1)",
            "return tf.math.bincount(in1)",
            "return tf.math.bincount(in1).numpy()",
            "return tf.math.bincount(in1).numpy().tolist()",
            "return tf.math.bincount(in1).numpy().tolist()",
            "return tf.math.bincount(in1).numpy().tolist()"
        ],
        "response": {
            "task_id": "stackoverflow_11",
            "completions": [
                "return tf.math.bincount(in1).numpy().tolist()",
                "return tf.math.bincount(in1).numpy()",
                "return tf.math.bincount(in1).numpy().tolist()",
                "return tf.math.bincount(in1).numpy().tolist()",
                "return tf.math.bincount(in1)",
                "return tf.math.bincount(in1)",
                "return tf.math.bincount(in1).numpy()",
                "return tf.math.bincount(in1).numpy().tolist()",
                "return tf.math.bincount(in1).numpy().tolist()",
                "return tf.math.bincount(in1).numpy().tolist()"
            ],
            "target-program": "tf.math.bincount(in1)",
            "description": "count the number of occurences of each distinct number",
            "tf_operators": {
                "tf.math.bincount": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        }
    },
    {
        "constants": "[0, 1, 2]",
        "description": "remove a column from the tensor",
        "target_program": "tf.gather(in1, (0, 2), axis=1, batch_dims=0)",
        "source": "https://stackoverflow.com/questions/47447183/remove-a-set-of-tensors-from-a-tensor-in-tensorflow",
        "name": "stackoverflow_12",
        "examples": {
            "inputs": "[[[12, 34, 56], [33, 22, 11]]]",
            "outputs": "[[12, 56], [33, 11]]"
        },
        "completions": [
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.gather(in1, [0,2], axis=1)",
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.gather(in1, [0, 2], axis=1)",
            "return tf.gather(in1, [0,2], axis=1)"
        ],
        "response": {
            "task_id": "stackoverflow_12",
            "completions": [
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.gather(in1, [0,2], axis=1)",
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.gather(in1, [0, 2], axis=1)",
                "return tf.gather(in1, [0,2], axis=1)"
            ],
            "target-program": "tf.gather(in1, (0, 2), axis=1, batch_dims=0)",
            "description": "remove a column from the tensor",
            "tf_operators": {
                "tf.gather": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        }
    },
    {
        "constants": "[]",
        "description": "multiply vectors by tensor",
        "target_program": "tf.tensordot(in1, in2, (1, 1))",
        "source": "https://stackoverflow.com/questions/50777704/n-d-tensor-matrix-multiplication-with-tensorflow",
        "name": "stackoverflow_13",
        "examples": {
            "inputs": "[[[3, 5], [10, 2]],[[[1, 0], [5, 4]], [[3, 10], [2, -2]]],]",
            "outputs": "[[[28, 20], [19, 20]], [[20, 8], [34, 96]]]"
        },
        "completions": [
            "return tf.matmul(in2, tf.transpose(in1))",
            "return tf.matmul(in2, tf.transpose(in1))",
            "return tf.matmul(in1, in2)",
            "return tf.multiply(in1, in2)",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in2, tf.expand_dims(in1, -1))[:,:,0]",
            "return tf.matmul(in1, tf.transpose(in2, perm=[0, 2, 1]))",
            "return tf.matmul(in1, in2)",
            "return tf.matmul(in2, tf.transpose(in1))",
            "return tf.matmul(in2, tf.transpose(in1))"
        ],
        "response": {
            "task_id": "stackoverflow_13",
            "completions": [
                "return tf.matmul(in2, tf.transpose(in1))",
                "return tf.matmul(in2, tf.transpose(in1))",
                "return tf.matmul(in1, in2)",
                "return tf.multiply(in1, in2)",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in2, tf.expand_dims(in1, -1))[:,:,0]",
                "return tf.matmul(in1, tf.transpose(in2, perm=[0, 2, 1]))",
                "return tf.matmul(in1, in2)",
                "return tf.matmul(in2, tf.transpose(in1))",
                "return tf.matmul(in2, tf.transpose(in1))"
            ],
            "target-program": "tf.tensordot(in1, in2, (1, 1))",
            "description": "multiply vectors by tensor",
            "tf_operators": {
                "tf.transpose": 5,
                "tf.matmul": 9,
                "tf.multiply": 1,
                "tf.expand_dims": 1
            },
            "coverage_percentage": 0.0,
            "total_in_target": 1,
            "total_covered": 0
        }
    },
    {
        "constants": "[]",
        "description": "choose True if any value in a row is True, False otherwise",
        "target_program": "tf.reduce_any(in1, axis=-1)",
        "source": "https://stackoverflow.com/questions/35657003/aggregate-each-element-of-tensor-in-tensorflow",
        "name": "stackoverflow_14",
        "examples": {
            "inputs": "[[[[False, False, True],  [False, False, False],  [True, False, True],  [False, True, False],  [False, False, False],  [True, True, True],  [True, True, False]]],]",
            "outputs": "[[True, False, True, True, False, True, True]]"
        },
        "completions": [
            "return tf.reduce_any(in1, axis=2)",
            "return tf.reduce_any(in1, axis=2)",
            "return tf.reduce_any(in1, axis=2)",
            "return tf.reduce_any(in1, axis=2)",
            "return tf.reduce_any(in1, axis=2)",
            "return tf.reduce_any(in1, axis=2)",
            "return tf.reduce_any(input_tensor=in1, axis=2)",
            "return tf.reduce_any(in1, axis=2)",
            "return tf.reduce_any(in1, axis=2)",
            "return tf.reduce_any(in1, axis=2)"
        ],
        "response": {
            "task_id": "stackoverflow_14",
            "completions": [
                "return tf.reduce_any(in1, axis=2)",
                "return tf.reduce_any(in1, axis=2)",
                "return tf.reduce_any(in1, axis=2)",
                "return tf.reduce_any(in1, axis=2)",
                "return tf.reduce_any(in1, axis=2)",
                "return tf.reduce_any(in1, axis=2)",
                "return tf.reduce_any(input_tensor=in1, axis=2)",
                "return tf.reduce_any(in1, axis=2)",
                "return tf.reduce_any(in1, axis=2)",
                "return tf.reduce_any(in1, axis=2)"
            ],
            "target-program": "tf.reduce_any(in1, axis=-1)",
            "description": "choose True if any value in a row is True, False otherwise",
            "tf_operators": {
                "tf.reduce_any": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        }
    },
    {
        "constants": "[0, 1]",
        "description": "set all instances of 1 to 0",
        "target_program": "tf.subtract(in1, tf.cast(tf.equal(in1, tf.constant(1)), tf.int32))",
        "source": "https://stackoverflow.com/questions/39045797/conditional-assignment-of-tensor-values-in-tensorflow",
        "name": "stackoverflow_15",
        "examples": {
            "inputs": "[[3, 1, 2, 0, 1, -1, 10, 1, -10],]",
            "outputs": "[3, 0, 2, 0, 0, -1, 10, 0, -10]"
        },
        "completions": [
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)",
            "return tf.where(tf.equal(in1, 1), 0, in1)"
        ],
        "response": {
            "task_id": "stackoverflow_15",
            "completions": [
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)",
                "return tf.where(tf.equal(in1, 1), 0, in1)"
            ],
            "target-program": "tf.subtract(in1, tf.cast(tf.equal(in1, tf.constant(1)), tf.int32))",
            "description": "set all instances of 1 to 0",
            "tf_operators": {
                "tf.equal": 10,
                "tf.where": 10
            },
            "coverage_percentage": 20.0,
            "total_in_target": 5,
            "total_covered": 1
        }
    },
    {
        "constants": "[]",
        "description": "multiply tensors across the first axis",
        "target_program": "tf.multiply(in1, tf.expand_dims(in2, 1))",
        "source": "https://stackoverflow.com/questions/46240646/tensor-multiply-along-axis-in-tensorflow",
        "name": "stackoverflow_16",
        "examples": {
            "inputs": "[[[2, 5], [3, 0], [8, -7]],[4, 10, -6],]",
            "outputs": "[[8, 20], [30, 0], [-48, 42]]"
        },
        "completions": [
            "return tf.multiply(in1, tf.expand_dims(in2, 1))",
            "return tf.multiply(in1, tf.expand_dims(in2, 1))",
            "return tf.multiply(in1, tf.expand_dims(in2, 1))",
            "return tf.multiply(in1, tf.expand_dims(in2, 1))",
            "return tf.multiply(in1, tf.expand_dims(in2,1))",
            "return tf.multiply(in1, tf.expand_dims(in2, 1))",
            "return tf.multiply(in1, tf.expand_dims(in2, axis=-1))",
            "return tf.multiply(in1, tf.expand_dims(in2, -1))",
            "return tf.multiply(in1, tf.expand_dims(in2, axis=1))",
            "return tf.multiply(in1, tf.expand_dims(in2, axis=-1))"
        ],
        "response": {
            "task_id": "stackoverflow_16",
            "completions": [
                "return tf.multiply(in1, tf.expand_dims(in2, 1))",
                "return tf.multiply(in1, tf.expand_dims(in2, 1))",
                "return tf.multiply(in1, tf.expand_dims(in2, 1))",
                "return tf.multiply(in1, tf.expand_dims(in2, 1))",
                "return tf.multiply(in1, tf.expand_dims(in2,1))",
                "return tf.multiply(in1, tf.expand_dims(in2, 1))",
                "return tf.multiply(in1, tf.expand_dims(in2, axis=-1))",
                "return tf.multiply(in1, tf.expand_dims(in2, -1))",
                "return tf.multiply(in1, tf.expand_dims(in2, axis=1))",
                "return tf.multiply(in1, tf.expand_dims(in2, axis=-1))"
            ],
            "target-program": "tf.multiply(in1, tf.expand_dims(in2, 1))",
            "description": "multiply tensors across the first axis",
            "tf_operators": {
                "tf.expand_dims": 10,
                "tf.multiply": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 2,
            "total_covered": 2
        }
    },
    {
        "constants": "[]",
        "description": "duplicate each element of a tensor",
        "target_program": "tf.stack((in1, in1), axis=1)",
        "source": "https://stackoverflow.com/questions/51761353/about-tensor-of-tensorflow",
        "name": "stackoverflow_17",
        "examples": {
            "inputs": "[[17, -32, 99],]",
            "outputs": "[[17, 17], [-32, -32], [99, 99]]"
        },
        "completions": [
            "return tf.repeat(in1, repeats=2, axis=1)",
            "return tf.repeat(in1, repeats = 2, axis = 1)",
            "return tf.repeat(in1, repeats=2, axis=-1)",
            "return tf.repeat(in1, repeats=2, axis=-1)",
            "return tf.repeat(in1, repeats=2, axis=-1)",
            "return tf.repeat(in1, repeats=2, axis=-1)",
            "return tf.repeat(in1, repeats=2, axis=-1)",
            "return tf.repeat(in1, repeats=2, axis=-1)",
            "return tf.repeat(in1, 2, axis=-1)",
            "return tf.repeat(in1, repeats=2, axis=-1)"
        ],
        "response": {
            "task_id": "stackoverflow_17",
            "completions": [
                "return tf.repeat(in1, repeats=2, axis=1)",
                "return tf.repeat(in1, repeats = 2, axis = 1)",
                "return tf.repeat(in1, repeats=2, axis=-1)",
                "return tf.repeat(in1, repeats=2, axis=-1)",
                "return tf.repeat(in1, repeats=2, axis=-1)",
                "return tf.repeat(in1, repeats=2, axis=-1)",
                "return tf.repeat(in1, repeats=2, axis=-1)",
                "return tf.repeat(in1, repeats=2, axis=-1)",
                "return tf.repeat(in1, 2, axis=-1)",
                "return tf.repeat(in1, repeats=2, axis=-1)"
            ],
            "target-program": "tf.stack((in1, in1), axis=1)",
            "description": "duplicate each element of a tensor",
            "tf_operators": {
                "tf.repeat": 10
            },
            "coverage_percentage": 0.0,
            "total_in_target": 1,
            "total_covered": 0
        }
    },
    {
        "constants": "[]",
        "description": "multiply 3D tensor and 2D tensor and add another tensor",
        "target_program": "tf.add(in3, tf.matmul(in1, in2))",
        "source": "https://stackoverflow.com/questions/38222126/tensorflow-efficient-way-for-tensor-multiplication",
        "name": "stackoverflow_18",
        "examples": {
            "inputs": "[[[[1, 1, 1], [1, 0, 1]], [[1, 2, 3], [4, 5, 6]]], [[1, 1, 1, 1], [1, 2, 3, 4], [5, 6, 7, 8]], [100, 200, 300, 400],]",
            "outputs": "[[[107, 209, 311, 413], [106, 207, 308, 409]], [[118, 223, 328, 433], [139, 250, 361, 472]]]"
        },
        "completions": [
            "res = tf.tensordot(in1, in2, axes=1)\nreturn tf.add(res, in3)",
            "in1 = tf.cast(in1, tf.int32)\nin2 = tf.cast(in2, tf.int32)\nin3 = tf.cast(in3, tf.int32)\n\nproduct = tf.matmul(in1, in2)\n\nsum = tf.add(product, in3)\n\nreturn sum",
            "in1_casted = tf.cast(in1, dtype=tf.int32)\nin2_casted = tf.cast(in2, dtype=tf.int32)\nin3_casted = tf.cast(in3, dtype=tf.int32)\nexpanded_in1 = tf.expand_dims(in1_casted, -1)\nmul_result = tf.matmul(expanded_in1, in2_casted)\nadd_result = tf.add(mul_result, in3_casted)\nreturn add_result",
            "product = tf.tensordot(in1, in2, axes=1)\nresult = tf.add(product, in3)\nreturn result",
            "# expand in1 from 3D to 4D tensor\n    in1_expanded = tf.expand_dims(in1, -1)\n    # use matmul to multiply 4D and 2D tensors\n    product = tf.matmul(in1_expanded, in2)\n    # remove the extra dimension\n    product_squeezed = tf.squeeze(product, -2)\n    # add in3\n    result = tf.add(product_squeezed, in3)\n    return result",
            "in1 = tf.expand_dims(in1, -1)\nmult = tf.multiply(in1, in2)\nsum = tf.add(mult, in3)\nreturn sum",
            "mult = tf.tensordot(in1, in2, axes=[[2], [0]])\nresult = tf.add(mult, in3)\nreturn result",
            "in1 = tf.cast(in1, tf.float32)\nin2 = tf.cast(in2, tf.float32)\nin3 = tf.cast(in3, tf.float32)\n\nresult = tf.tensordot(in1, in2, axes=[[2], [0]])\nresult = tf.add(result, in3)\n\nreturn result",
            "tmp = tf.tensordot(in1, in2, axes=1)\nreturn tf.add(tmp, in3)",
            "in1 = tf.expand_dims(in1, -1)\nresult = tf.add(tf.matmul(in1,in2),in3)\nreturn result"
        ],
        "response": {
            "task_id": "stackoverflow_18",
            "completions": [
                "res = tf.tensordot(in1, in2, axes=1)\nreturn tf.add(res, in3)",
                "in1 = tf.cast(in1, tf.int32)\nin2 = tf.cast(in2, tf.int32)\nin3 = tf.cast(in3, tf.int32)\n\nproduct = tf.matmul(in1, in2)\n\nsum = tf.add(product, in3)\n\nreturn sum",
                "in1_casted = tf.cast(in1, dtype=tf.int32)\nin2_casted = tf.cast(in2, dtype=tf.int32)\nin3_casted = tf.cast(in3, dtype=tf.int32)\nexpanded_in1 = tf.expand_dims(in1_casted, -1)\nmul_result = tf.matmul(expanded_in1, in2_casted)\nadd_result = tf.add(mul_result, in3_casted)\nreturn add_result",
                "product = tf.tensordot(in1, in2, axes=1)\nresult = tf.add(product, in3)\nreturn result",
                "# expand in1 from 3D to 4D tensor\n    in1_expanded = tf.expand_dims(in1, -1)\n    # use matmul to multiply 4D and 2D tensors\n    product = tf.matmul(in1_expanded, in2)\n    # remove the extra dimension\n    product_squeezed = tf.squeeze(product, -2)\n    # add in3\n    result = tf.add(product_squeezed, in3)\n    return result",
                "in1 = tf.expand_dims(in1, -1)\nmult = tf.multiply(in1, in2)\nsum = tf.add(mult, in3)\nreturn sum",
                "mult = tf.tensordot(in1, in2, axes=[[2], [0]])\nresult = tf.add(mult, in3)\nreturn result",
                "in1 = tf.cast(in1, tf.float32)\nin2 = tf.cast(in2, tf.float32)\nin3 = tf.cast(in3, tf.float32)\n\nresult = tf.tensordot(in1, in2, axes=[[2], [0]])\nresult = tf.add(result, in3)\n\nreturn result",
                "tmp = tf.tensordot(in1, in2, axes=1)\nreturn tf.add(tmp, in3)",
                "in1 = tf.expand_dims(in1, -1)\nresult = tf.add(tf.matmul(in1,in2),in3)\nreturn result"
            ],
            "target-program": "tf.add(in3, tf.matmul(in1, in2))",
            "description": "multiply 3D tensor and 2D tensor and add another tensor",
            "tf_operators": {
                "tf.add": 10,
                "tf.tensordot": 5,
                "tf.int32": 2,
                "tf.cast": 3,
                "tf.matmul": 4,
                "tf.expand_dims": 4,
                "tf.squeeze": 1,
                "tf.multiply": 1,
                "tf.float32": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 2,
            "total_covered": 2
        }
    },
    {
        "constants": "[]",
        "description": "(\\'sort a tensor considering the first column, breaking ties using the second column\\')",
        "target_program": "tf.gather(tf.gather(in1, tf.argsort(in1[:, 1], stable=True)), tf.argsort(tf.gather(in1, tf.argsort(in1[:, 1], stable=True))[:, 0], stable=True))",
        "source": "https://stackoverflow.com/questions/49399198/sort-a-tensor-based-on-two-columns-in-tensorflow",
        "name": "stackoverflow_19",
        "examples": {
            "inputs": "[[[3, 1, 2], [1, 0, 4], [1, 2, 3], [0, 5, 1], [1, 1, 2], [2, 3, 1], [2, 1, 0]],]",
            "outputs": "[[0, 5, 1],    [1, 0, 4],    [1, 1, 2],    [1, 2, 3],    [2, 1, 0],    [2, 3, 1],    [3, 1, 2]]"
        },
        "completions": [
            "# Convert the tensor to a float since arg sorting does not support integers\n    float_tensor = tf.cast(in1, tf.float32)\n\n    # Combine the first and second column\n    combined_tensor = float_tensor[:, 0] + float_tensor[:, 1]/10**7\n\n    # Argsort by the combined tensor to get the sorted indices\n    sorted_indices = tf.argsort(combined_tensor)\n\n    # Gather the original tensor by the sorted indices\n    sorted_tensor = tf.gather(float_tensor, sorted_indices)\n\n    return sorted_tensor",
            "return tf.gather(in1, tf.argsort(in1, axis=0)[:, 0])",
            "sorted_indices = tf.argsort(in1[:, :2], axis=0, stable=True)\nsorted_tensor = tf.gather(in1, sorted_indices[:, 0])\nreturn sorted_tensor",
            "# helper function to get the indices that would sort array considering the first column\n# and breaking ties using the second column\ndef sort_indices(a):\n    it = np.nditer([a[:,0], a[:,1]], flags=[\"multi_index\"])\n    index_array = np.array([[x, y, it.multi_index[0]] for x, y in it])\n    sorted_indices = np.lexsort((index_array[:,2], index_array[:,1], index_array[:,0]))\n    return sorted_indices\n\n# get sorted indices\nsorted_indices = tf.constant(sort_indices(tf.make_ndarray(in1)))\n# apply the sorted indices to the input tensor\nresult = tf.gather(in1, sorted_indices)\nreturn result",
            "# We would first generate indexes of the sorted tensor using tf.argsort. \n# As we need to consider the first column first and then break ties using the second column, \n# we would concatenate the two columns and use them as keys for sorting operations in tf.argsort.\n# Then use these indices to gather sorted rows from original tensor\n\n    sorted_indices = tf.argsort(tf.stack([in1[:, 0], -in1[:, 1]], axis=-1), axis=0, stable=True)\n    return tf.gather(in1, sorted_indices)",
            "# first, we will create a 2D tensor where the first column is the same as in the input tensor\n# and the second column is the range of the length of the input tensor.\n# this is done to preserve the original order of the rows before the sort\n# we then sort this tensor using the first column as the primary sort and the second column as the secondary sort\n# this is done using the tf.argsort function with stable=True to ensure a stable sort\n# finally, we gather the rows of the input tensor using the sorted indices \n\nin1_order = tf.stack([in1[:, 0], tf.range(tf.shape(in1)[0])], axis=-1)\nsorted_indices = tf.argsort(in1_order, axis=0, stable=True)\nsorted_in1 = tf.gather(in1, sorted_indices[:, 0])\nreturn sorted_in1",
            "sorted_indices = tf.argsort(in1, axis=0)\nreturn tf.gather(in1, sorted_indices[:,0])",
            "return tf.gather(in1, tf.argsort(in1, axis=0, stable=True))",
            "indices = tf.argsort(in1, axis=0)\nreturn tf.gather(in1, indices[:,0])",
            "indices = tf.argsort(in1, axis=0, stable=True)\nreturn tf.gather(in1, indices[:,0])"
        ],
        "response": {
            "task_id": "stackoverflow_19",
            "completions": [
                "# Convert the tensor to a float since arg sorting does not support integers\n    float_tensor = tf.cast(in1, tf.float32)\n\n    # Combine the first and second column\n    combined_tensor = float_tensor[:, 0] + float_tensor[:, 1]/10**7\n\n    # Argsort by the combined tensor to get the sorted indices\n    sorted_indices = tf.argsort(combined_tensor)\n\n    # Gather the original tensor by the sorted indices\n    sorted_tensor = tf.gather(float_tensor, sorted_indices)\n\n    return sorted_tensor",
                "return tf.gather(in1, tf.argsort(in1, axis=0)[:, 0])",
                "sorted_indices = tf.argsort(in1[:, :2], axis=0, stable=True)\nsorted_tensor = tf.gather(in1, sorted_indices[:, 0])\nreturn sorted_tensor",
                "# helper function to get the indices that would sort array considering the first column\n# and breaking ties using the second column\ndef sort_indices(a):\n    it = np.nditer([a[:,0], a[:,1]], flags=[\"multi_index\"])\n    index_array = np.array([[x, y, it.multi_index[0]] for x, y in it])\n    sorted_indices = np.lexsort((index_array[:,2], index_array[:,1], index_array[:,0]))\n    return sorted_indices\n\n# get sorted indices\nsorted_indices = tf.constant(sort_indices(tf.make_ndarray(in1)))\n# apply the sorted indices to the input tensor\nresult = tf.gather(in1, sorted_indices)\nreturn result",
                "# We would first generate indexes of the sorted tensor using tf.argsort. \n# As we need to consider the first column first and then break ties using the second column, \n# we would concatenate the two columns and use them as keys for sorting operations in tf.argsort.\n# Then use these indices to gather sorted rows from original tensor\n\n    sorted_indices = tf.argsort(tf.stack([in1[:, 0], -in1[:, 1]], axis=-1), axis=0, stable=True)\n    return tf.gather(in1, sorted_indices)",
                "# first, we will create a 2D tensor where the first column is the same as in the input tensor\n# and the second column is the range of the length of the input tensor.\n# this is done to preserve the original order of the rows before the sort\n# we then sort this tensor using the first column as the primary sort and the second column as the secondary sort\n# this is done using the tf.argsort function with stable=True to ensure a stable sort\n# finally, we gather the rows of the input tensor using the sorted indices \n\nin1_order = tf.stack([in1[:, 0], tf.range(tf.shape(in1)[0])], axis=-1)\nsorted_indices = tf.argsort(in1_order, axis=0, stable=True)\nsorted_in1 = tf.gather(in1, sorted_indices[:, 0])\nreturn sorted_in1",
                "sorted_indices = tf.argsort(in1, axis=0)\nreturn tf.gather(in1, sorted_indices[:,0])",
                "return tf.gather(in1, tf.argsort(in1, axis=0, stable=True))",
                "indices = tf.argsort(in1, axis=0)\nreturn tf.gather(in1, indices[:,0])",
                "indices = tf.argsort(in1, axis=0, stable=True)\nreturn tf.gather(in1, indices[:,0])"
            ],
            "target-program": "tf.gather(tf.gather(in1, tf.argsort(in1[:, 1], stable=True)), tf.argsort(tf.gather(in1, tf.argsort(in1[:, 1], stable=True))[:, 0], stable=True))",
            "description": "(\\'sort a tensor considering the first column, breaking ties using the second column\\')",
            "tf_operators": {
                "tf.argsort": 9,
                "tf.cast": 1,
                "tf.gather": 10,
                "tf.float32": 1,
                "tf.make_ndarray": 1,
                "tf.constant": 1,
                "tf.stack": 2,
                "tf.range": 1,
                "tf.shape": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 2,
            "total_covered": 2
        }
    },
    {
        "constants": "[]",
        "description": "compute argmax in each tensor and set it to 1",
        "target_program": "tf.cast(tf.one_hot(tf.argmax(in1, axis=1), 3), tf.int32)",
        "source": "https://stackoverflow.com/questions/44834739/argmax-on-a-tensor-and-ceiling-in-tensorflow",
        "name": "stackoverflow_20",
        "examples": {
            "inputs": "[[[0.7, 0.2, 0.1], [0.4, 0.5, 0.1], [0.4, 0.4, 0.2], [0.3, 0.4, 0.3], [0.0, 0.0, 1.0]],]",
            "outputs": "[[1, 0, 0],    [0, 1, 0],    [1, 0, 0],    [0, 1, 0],    [0, 0, 1]]"
        },
        "completions": [
            "arg_max = tf.argmax(in1, axis=-1)\none_hot = tf.one_hot(arg_max, depth=in1.shape[1])\nreturn tf.cast(one_hot, tf.int32)",
            "indices = tf.argmax(in1, axis=1)\none_hot = tf.one_hot(indices, depth=tf.shape(in1)[1])\nreturn tf.cast(one_hot, in1.dtype)",
            "indices = tf.argmax(in1, axis=1)\nout = tf.one_hot(indices, depth=in1.shape[1])\nreturn tf.cast(out, tf.int32)",
            "out1 = tf.argmax(in1, axis=1)\nout1 = tf.one_hot(out1, depth=in1.shape[1])\nreturn tf.cast(out1, tf.int32)",
            "indices = tf.argmax(in1, axis=1)\nshape = tf.shape(in1)\nout = tf.one_hot(indices, depth=shape[1])\nreturn out",
            "argmax = tf.argmax(in1, axis=1)\nindices = tf.range(tf.shape(in1)[0])\nindices = tf.stack([indices, argmax], axis=1)\nreturn tf.scatter_nd(indices, tf.ones_like(argmax), tf.shape(in1))",
            "indices_argmax = tf.argmax(in1, axis=1)\none_hot = tf.one_hot(indices_argmax, depth=tf.shape(in1)[1])\nreturn one_hot.numpy()",
            "max_indices = tf.argmax(in1, axis=-1)\nshape = tf.shape(in1)\nrow_indices = tf.range(shape[0])\nfull_indices = tf.stack([row_indices, max_indices], axis=1)\nreturn tf.scatter_nd(full_indices, tf.ones_like(max_indices), shape)",
            "# generate an empty tensor with zeros\n    zeros = tf.zeros_like(in1)\n    # get the indices of maximum values in each row\n    indices = tf.argmax(in1, axis=-1)\n    # generate a multi-hot encoded tensor from indices\n    multi_hot = tf.one_hot(indices, depth=in1.shape[1])\n    # convert the multi-hot tensor to same datatype as input\n    multi_hot = tf.cast(multi_hot, in1.dtype)\n    # replace zeros with 1 where maximum values are in the input tensor\n    out = tf.where(tf.equal(multi_hot, 1), multi_hot, zeros)\n    return out",
            "# Find the index of argmax in each tensor\n    idx = tf.argmax(in1, axis=1)\n\n    # Determine the shape of the input\n    shape = tf.shape(in1)\n\n    # Create a 2D tensor of indices for the argmax in each tensor\n    indices = tf.stack([tf.range(shape[0]), idx], axis=1)\n\n    # Create a tensor of ones, with the same shape as the input tensor\n    ones = tf.ones(shape[0], dtype=in1.dtype)\n\n    # Create a tensor of zeros, with the same shape as the input tensor\n    zeros = tf.zeros_like(in1)\n\n    # Set the argmax in each tensor to 1\n    out = tf.tensor_scatter_nd_update(zeros, indices, ones)\n\n    return out"
        ],
        "response": {
            "task_id": "stackoverflow_20",
            "completions": [
                "arg_max = tf.argmax(in1, axis=-1)\none_hot = tf.one_hot(arg_max, depth=in1.shape[1])\nreturn tf.cast(one_hot, tf.int32)",
                "indices = tf.argmax(in1, axis=1)\none_hot = tf.one_hot(indices, depth=tf.shape(in1)[1])\nreturn tf.cast(one_hot, in1.dtype)",
                "indices = tf.argmax(in1, axis=1)\nout = tf.one_hot(indices, depth=in1.shape[1])\nreturn tf.cast(out, tf.int32)",
                "out1 = tf.argmax(in1, axis=1)\nout1 = tf.one_hot(out1, depth=in1.shape[1])\nreturn tf.cast(out1, tf.int32)",
                "indices = tf.argmax(in1, axis=1)\nshape = tf.shape(in1)\nout = tf.one_hot(indices, depth=shape[1])\nreturn out",
                "argmax = tf.argmax(in1, axis=1)\nindices = tf.range(tf.shape(in1)[0])\nindices = tf.stack([indices, argmax], axis=1)\nreturn tf.scatter_nd(indices, tf.ones_like(argmax), tf.shape(in1))",
                "indices_argmax = tf.argmax(in1, axis=1)\none_hot = tf.one_hot(indices_argmax, depth=tf.shape(in1)[1])\nreturn one_hot.numpy()",
                "max_indices = tf.argmax(in1, axis=-1)\nshape = tf.shape(in1)\nrow_indices = tf.range(shape[0])\nfull_indices = tf.stack([row_indices, max_indices], axis=1)\nreturn tf.scatter_nd(full_indices, tf.ones_like(max_indices), shape)",
                "# generate an empty tensor with zeros\n    zeros = tf.zeros_like(in1)\n    # get the indices of maximum values in each row\n    indices = tf.argmax(in1, axis=-1)\n    # generate a multi-hot encoded tensor from indices\n    multi_hot = tf.one_hot(indices, depth=in1.shape[1])\n    # convert the multi-hot tensor to same datatype as input\n    multi_hot = tf.cast(multi_hot, in1.dtype)\n    # replace zeros with 1 where maximum values are in the input tensor\n    out = tf.where(tf.equal(multi_hot, 1), multi_hot, zeros)\n    return out",
                "# Find the index of argmax in each tensor\n    idx = tf.argmax(in1, axis=1)\n\n    # Determine the shape of the input\n    shape = tf.shape(in1)\n\n    # Create a 2D tensor of indices for the argmax in each tensor\n    indices = tf.stack([tf.range(shape[0]), idx], axis=1)\n\n    # Create a tensor of ones, with the same shape as the input tensor\n    ones = tf.ones(shape[0], dtype=in1.dtype)\n\n    # Create a tensor of zeros, with the same shape as the input tensor\n    zeros = tf.zeros_like(in1)\n\n    # Set the argmax in each tensor to 1\n    out = tf.tensor_scatter_nd_update(zeros, indices, ones)\n\n    return out"
            ],
            "target-program": "tf.cast(tf.one_hot(tf.argmax(in1, axis=1), 3), tf.int32)",
            "description": "compute argmax in each tensor and set it to 1",
            "tf_operators": {
                "tf.argmax": 10,
                "tf.int32": 3,
                "tf.cast": 5,
                "tf.one_hot": 7,
                "tf.shape": 6,
                "tf.scatter_nd": 2,
                "tf.ones_like": 2,
                "tf.stack": 3,
                "tf.range": 3,
                "tf.zeros_like": 2,
                "tf.equal": 1,
                "tf.where": 1,
                "tf.tensor_scatter_nd_update": 1,
                "tf.ones": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 4,
            "total_covered": 4
        }
    },
    {
        "constants": "[]",
        "description": "gather elements in a tensor along axis 1",
        "target_program": "tf.gather(in2, in1, axis=1, batch_dims=1)",
        "source": "https://stackoverflow.com/questions/51690095/how-to-gather-element-with-index-in-tensorflow",
        "name": "stackoverflow_21",
        "examples": {
            "inputs": "[[[2], [0], [1], [0]],[[0.2, 0.5, 0.3], [0.1, 0.3, 0.6], [0.1, 0.6, 0.3], [0.7, 0.0, 0.3]],]",
            "outputs": "[[0.3], [0.1], [0.6], [0.7]]"
        },
        "completions": [
            "return tf.gather(in2, in1, axis=1)",
            "return tf.gather(in2, in1, axis=1)",
            "return tf.gather(in2, in1, axis=1)",
            "return tf.gather(in2, in1, axis=1, batch_dims=1)",
            "return tf.gather(in2, in1, axis=1, batch_dims=1)",
            "return tf.gather(in2, in1, axis=1, batch_dims=1)",
            "return tf.gather(in2, in1, axis=1, batch_dims=1)",
            "return tf.gather(in2, in1, axis=1)",
            "return tf.gather(in2, in1, axis=1)",
            "return tf.gather(in2, in1, axis=1, batch_dims=1)"
        ],
        "response": {
            "task_id": "stackoverflow_21",
            "completions": [
                "return tf.gather(in2, in1, axis=1)",
                "return tf.gather(in2, in1, axis=1)",
                "return tf.gather(in2, in1, axis=1)",
                "return tf.gather(in2, in1, axis=1, batch_dims=1)",
                "return tf.gather(in2, in1, axis=1, batch_dims=1)",
                "return tf.gather(in2, in1, axis=1, batch_dims=1)",
                "return tf.gather(in2, in1, axis=1, batch_dims=1)",
                "return tf.gather(in2, in1, axis=1)",
                "return tf.gather(in2, in1, axis=1)",
                "return tf.gather(in2, in1, axis=1, batch_dims=1)"
            ],
            "target-program": "tf.gather(in2, in1, axis=1, batch_dims=1)",
            "description": "gather elements in a tensor along axis 1",
            "tf_operators": {
                "tf.gather": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        }
    },
    {
        "constants": "[]",
        "description": "multiply a vector with a matrix without reshaping the vector",
        "target_program": "tf.tensordot(tf.cast(in1, tf.float32), in2, 1)",
        "source": "https://stackoverflow.com/questions/43284897/how-can-i-multiply-a-vector-and-a-matrix-in-tensorflow-without-reshaping",
        "name": "stackoverflow_22",
        "examples": {
            "inputs": "[[3, 1, 10],[[0.6, 0.4], [0.5, 1.0], [3.0, 4.0]],]",
            "outputs": "[32.3, 42.2]"
        },
        "completions": [
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.tensordot(in1, in2, axes=1)",
            "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, in2), 0)",
            "return tf.tensordot(in1,in2, axes=1).numpy()",
            "return tf.tensordot(in1,in2,axes=1)",
            "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, in2), 0)"
        ],
        "response": {
            "task_id": "stackoverflow_22",
            "completions": [
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.tensordot(in1, in2, axes=1)",
                "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, in2), 0)",
                "return tf.tensordot(in1,in2, axes=1).numpy()",
                "return tf.tensordot(in1,in2,axes=1)",
                "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, in2), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, in2), 0)"
            ],
            "target-program": "tf.tensordot(tf.cast(in1, tf.float32), in2, 1)",
            "description": "multiply a vector with a matrix without reshaping the vector",
            "tf_operators": {
                "tf.tensordot": 4,
                "tf.reduce_sum": 6,
                "tf.multiply": 6
            },
            "coverage_percentage": 33.33333333333333,
            "total_in_target": 3,
            "total_covered": 1
        }
    },
    {
        "constants": "[]",
        "description": "place 1 at the indices in the input tensor",
        "target_program": "tf.cast(tf.reduce_max(tf.one_hot(in1, 9), axis=1), tf.int32)",
        "source": "https://stackoverflow.com/questions/53414433/tensorflow-tensor-binarization",
        "name": "stackoverflow_23",
        "examples": {
            "inputs": "[[[0, 5, 2], [3, 1, 4], [5, 1, 5]],]",
            "outputs": "[[1, 0, 1, 0, 0, 1, 0, 0, 0],    [0, 1, 0, 1, 1, 0, 0, 0, 0],    [0, 1, 0, 0, 0, 1, 0, 0, 0]]"
        },
        "completions": [
            "depth = tf.reduce_max(in1) + 1\nreturn tf.one_hot(in1, depth)",
            "out = tf.one_hot(in1, in1.shape[1]*in1.shape[0])\nreturn tf.cast(tf.reduce_sum(out, axis=-2), tf.int32)",
            "depth = tf.reduce_max(in1) + 1\nreturn tf.one_hot(in1, depth)",
            "depth = tf.reduce_max(in1) + 1\nreturn tf.one_hot(in1, depth)",
            "depth = tf.reduce_max(in1) + 1\nreturn tf.one_hot(in1, depth)",
            "depth = tf.reduce_max(in1) + 1\nreturn tf.one_hot(in1, depth)",
            "depth = tf.reduce_max(in1) + 1\nreturn tf.one_hot(in1, depth)",
            "# In order to transform the input tensor as per the output provided, we shall use tf.one_hot. It effectively places 1s at the specified indices and 0 elsewhere. The depth is the length of the 1D tensor it creates, and it should be equal to the max value in the list + 1.\n# First we need to find the maximum value from the input array, and add 1 so we cover all possible indices.\n# Then, we apply tf.one_hot to every element of the array, specify the depth (which is max_val + 1) and then cast the result to int32. \n\nmax_val = tf.reduce_max(in1)\ndepth = tf.add(max_val, 1)\nout = tf.cast(tf.one_hot(in1, depth), tf.int32)\n\nreturn out",
            "indices = tf.constant(in1)\ndepth = tf.reduce_max(indices) + 1\nreturn tf.cast(tf.one_hot(indices, depth), tf.int32)",
            "depth = tf.reduce_max(in1) + 1\n     return tf.cast(tf.one_hot(in1, depth), dtype=tf.int32)"
        ],
        "response": {
            "task_id": "stackoverflow_23",
            "completions": [
                "depth = tf.reduce_max(in1) + 1\nreturn tf.one_hot(in1, depth)",
                "out = tf.one_hot(in1, in1.shape[1]*in1.shape[0])\nreturn tf.cast(tf.reduce_sum(out, axis=-2), tf.int32)",
                "depth = tf.reduce_max(in1) + 1\nreturn tf.one_hot(in1, depth)",
                "depth = tf.reduce_max(in1) + 1\nreturn tf.one_hot(in1, depth)",
                "depth = tf.reduce_max(in1) + 1\nreturn tf.one_hot(in1, depth)",
                "depth = tf.reduce_max(in1) + 1\nreturn tf.one_hot(in1, depth)",
                "depth = tf.reduce_max(in1) + 1\nreturn tf.one_hot(in1, depth)",
                "# In order to transform the input tensor as per the output provided, we shall use tf.one_hot. It effectively places 1s at the specified indices and 0 elsewhere. The depth is the length of the 1D tensor it creates, and it should be equal to the max value in the list + 1.\n# First we need to find the maximum value from the input array, and add 1 so we cover all possible indices.\n# Then, we apply tf.one_hot to every element of the array, specify the depth (which is max_val + 1) and then cast the result to int32. \n\nmax_val = tf.reduce_max(in1)\ndepth = tf.add(max_val, 1)\nout = tf.cast(tf.one_hot(in1, depth), tf.int32)\n\nreturn out",
                "indices = tf.constant(in1)\ndepth = tf.reduce_max(indices) + 1\nreturn tf.cast(tf.one_hot(indices, depth), tf.int32)",
                "depth = tf.reduce_max(in1) + 1\n     return tf.cast(tf.one_hot(in1, depth), dtype=tf.int32)"
            ],
            "target-program": "tf.cast(tf.reduce_max(tf.one_hot(in1, 9), axis=1), tf.int32)",
            "description": "place 1 at the indices in the input tensor",
            "tf_operators": {
                "tf.reduce_max": 9,
                "tf.one_hot": 10,
                "tf.reduce_sum": 1,
                "tf.int32": 4,
                "tf.cast": 4,
                "tf.add": 1,
                "tf.constant": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 4,
            "total_covered": 4
        }
    },
    {
        "constants": "[0]",
        "description": "(\\'like tf.divide(), but when dividing by 0, return the numerator\\')",
        "target_program": "tf.where(tf.cast(in2, tf.bool), x=tf.divide(in1, in2), y=in1)",
        "source": "https://stackoverflow.com/questions/53643339/tensorflow-overriding-tf-divide-to-return-the-numerator-when-dividing-by-0",
        "name": "stackoverflow_24",
        "examples": {
            "inputs": "[[3.0, 1.0, 4.0, 5.0, 2.0, 8.0, -6.0, -7.0],[0.5, 0.0, -2.0, 0.0, 1.0, -1.0, 0.0, 2.0],]",
            "outputs": "[6.0, 1.0, -2.0, 5.0, 2.0, -8.0, -6.0, -3.5]"
        },
        "completions": [
            "return tf.math.divide_no_nan(in1, in2)",
            "return tf.math.divide_no_nan(in1, tf.where(tf.not_equal(in2, 0), in2, 1))",
            "return tf.math.divide_no_nan(in1, in2)",
            "return tf.math.divide_no_nan(in1, in2)",
            "return tf.where(tf.equal(in2, 0), in1, tf.divide(in1,in2))",
            "return tf.divide_no_nan(in1, in2)",
            "return tf.math.divide_no_nan(in1, in2)",
            "return tf.where(in2 == 0, in1, tf.divide(in1, in2))",
            "return tf.math.divide_no_nan(in1, in2)",
            "return tf.where(tf.equal(in2, 0), in1, tf.divide(in1, in2))"
        ],
        "response": {
            "task_id": "stackoverflow_24",
            "completions": [
                "return tf.math.divide_no_nan(in1, in2)",
                "return tf.math.divide_no_nan(in1, tf.where(tf.not_equal(in2, 0), in2, 1))",
                "return tf.math.divide_no_nan(in1, in2)",
                "return tf.math.divide_no_nan(in1, in2)",
                "return tf.where(tf.equal(in2, 0), in1, tf.divide(in1,in2))",
                "return tf.divide_no_nan(in1, in2)",
                "return tf.math.divide_no_nan(in1, in2)",
                "return tf.where(in2 == 0, in1, tf.divide(in1, in2))",
                "return tf.math.divide_no_nan(in1, in2)",
                "return tf.where(tf.equal(in2, 0), in1, tf.divide(in1, in2))"
            ],
            "target-program": "tf.where(tf.cast(in2, tf.bool), x=tf.divide(in1, in2), y=in1)",
            "description": "(\\'like tf.divide(), but when dividing by 0, return the numerator\\')",
            "tf_operators": {
                "tf.math.divide_no_nan": 6,
                "tf.not_equal": 1,
                "tf.where": 4,
                "tf.equal": 2,
                "tf.divide": 3,
                "tf.divide_no_nan": 1
            },
            "coverage_percentage": 50.0,
            "total_in_target": 4,
            "total_covered": 2
        }
    },
    {
        "constants": "[]",
        "description": "copy the tensor tf.eye(3), 4 times",
        "target_program": "tf.tile(tf.eye(in1), (in2, 1))",
        "source": "https://stackoverflow.com/questions/53602691/duplicate-a-tensor-n-times",
        "name": "stackoverflow_25",
        "examples": {
            "inputs": "[3,4,]",
            "outputs": "[[1.0, 0.0, 0.0],    [0.0, 1.0, 0.0],    [0.0, 0.0, 1.0],    [1.0, 0.0, 0.0],    [0.0, 1.0, 0.0],    [0.0, 0.0, 1.0],    [1.0, 0.0, 0.0],    [0.0, 1.0, 0.0],    [0.0, 0.0, 1.0],    [1.0, 0.0, 0.0],    [0.0, 1.0, 0.0],    [0.0, 0.0, 1.0]]"
        },
        "completions": [
            "return tf.tile(tf.eye(in1), [in2, 1])",
            "return tf.tile(tf.eye(in1), [in2, 1])",
            "a = tf.eye(in1)\nb = tf.tile(a, [in2, 1])\nreturn b",
            "tensor = tf.eye(in1)\n     return tf.tile(tensor, [in2, 1])",
            "return tf.tile(tf.eye(in1), [in2, 1])",
            "return tf.tile(tf.eye(in1), multiples=[in2, 1])",
            "return tf.tile(tf.eye(in1), [in2, 1])",
            "return tf.tile(tf.eye(in1), [in2, 1])",
            "return tf.tile(tf.eye(in1), [in2, 1])",
            "return tf.tile(tf.eye(in1), [in2, 1])"
        ],
        "response": {
            "task_id": "stackoverflow_25",
            "completions": [
                "return tf.tile(tf.eye(in1), [in2, 1])",
                "return tf.tile(tf.eye(in1), [in2, 1])",
                "a = tf.eye(in1)\nb = tf.tile(a, [in2, 1])\nreturn b",
                "tensor = tf.eye(in1)\n     return tf.tile(tensor, [in2, 1])",
                "return tf.tile(tf.eye(in1), [in2, 1])",
                "return tf.tile(tf.eye(in1), multiples=[in2, 1])",
                "return tf.tile(tf.eye(in1), [in2, 1])",
                "return tf.tile(tf.eye(in1), [in2, 1])",
                "return tf.tile(tf.eye(in1), [in2, 1])",
                "return tf.tile(tf.eye(in1), [in2, 1])"
            ],
            "target-program": "tf.tile(tf.eye(in1), (in2, 1))",
            "description": "copy the tensor tf.eye(3), 4 times",
            "tf_operators": {
                "tf.tile": 10,
                "tf.eye": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 2,
            "total_covered": 2
        }
    },
    {
        "constants": "[]",
        "description": "reduction operation for multiple dimensions simultaneously",
        "target_program": "tf.reduce_sum(tf.reduce_sum(in1, axis=1), axis=1)",
        "source": "https://stackoverflow.com/questions/54294780/how-to-perform-reduce-op-on-multiple-dimensions-at-once",
        "name": "stackoverflow_26",
        "examples": {
            "inputs": "[[[[3, 4], [1, 2]], [[5, -2], [-10, 3]], [[10, 20], [-4, 7]]]]",
            "outputs": "[10, -4, 33]"
        },
        "completions": [
            "return tf.reduce_sum(in1, axis=[1, 2])",
            "return tf.reduce_sum(in1, axis=[1, 2]).numpy().tolist()",
            "return tf.reduce_sum(in1, axis=[1,2]).numpy().tolist()",
            "return tf.reduce_sum(in1, axis=[1,2]).numpy().tolist()",
            "return tf.reduce_sum(in1, axis=[1,2]).numpy().tolist()",
            "return tf.reduce_sum(in1, axis=[1, 2]).numpy().tolist()",
            "return tf.reduce_sum(in1, axis=[1,2])",
            "return tf.reduce_sum(in1, axis=[1, 2]).numpy().tolist()",
            "return tf.reduce_sum(in1, axis=[1, 2])",
            "return tf.reduce_sum(in1, axis=[1,2]).numpy().tolist()"
        ],
        "response": {
            "task_id": "stackoverflow_26",
            "completions": [
                "return tf.reduce_sum(in1, axis=[1, 2])",
                "return tf.reduce_sum(in1, axis=[1, 2]).numpy().tolist()",
                "return tf.reduce_sum(in1, axis=[1,2]).numpy().tolist()",
                "return tf.reduce_sum(in1, axis=[1,2]).numpy().tolist()",
                "return tf.reduce_sum(in1, axis=[1,2]).numpy().tolist()",
                "return tf.reduce_sum(in1, axis=[1, 2]).numpy().tolist()",
                "return tf.reduce_sum(in1, axis=[1,2])",
                "return tf.reduce_sum(in1, axis=[1, 2]).numpy().tolist()",
                "return tf.reduce_sum(in1, axis=[1, 2])",
                "return tf.reduce_sum(in1, axis=[1,2]).numpy().tolist()"
            ],
            "target-program": "tf.reduce_sum(tf.reduce_sum(in1, axis=1), axis=1)",
            "description": "reduction operation for multiple dimensions simultaneously",
            "tf_operators": {
                "tf.reduce_sum": 10
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        }
    },
    {
        "constants": "[]",
        "description": "boolean tensor with 1 at the indices in the input tensor",
        "target_program": "tf.cast(tf.reduce_max(tf.one_hot(in1, in2), axis=0), tf.int32)",
        "source": "https://stackoverflow.com/questions/54225704/how-do-i-get-a-tensor-representing-the-on-positions-in-the-original-tensor",
        "name": "stackoverflow_27",
        "examples": {
            "inputs": "[[0, 3, 5, 6],8,]",
            "outputs": "[1, 0, 0, 1, 0, 1, 1, 0]"
        },
        "completions": [
            "output = tf.scatter_nd(tf.expand_dims(in1,1), tf.ones_like(in1), tf.constant([in2]))\n     return tf.squeeze(output)",
            "return tf.cast(tf.sequence_mask(in1, in2), dtype=tf.int32)",
            "return tf.cast(tf.reduce_any(tf.equal(tf.range(in2), tf.reshape(in1, [-1, 1])), axis=0), tf.int32)",
            "out = tf.scatter_nd(tf.expand_dims(in1, axis=1), tf.ones_like(in1), [in2])\n     return tf.squeeze(tf.cast(out, dtype=tf.int32))",
            "return tf.cast(tf.scatter_nd(tf.expand_dims(in1, 1), tf.ones_like(in1), [in2]), tf.int32)",
            "return tf.cast(tf.sequence_mask(in1, in2), tf.int32)",
            "indices = tf.constant(in1)\ndepth = tf.constant(in2)\nreturn tf.cast(tf.one_hot(indices, depth), dtype=tf.int32)",
            "shape = tf.constant([in2])\noutput = tf.scatter_nd(tf.expand_dims(in1, axis=1), tf.ones_like(in1), shape)\nreturn tf.cast(output, tf.int32)",
            "return tf.cast(tf.scatter_nd(tf.expand_dims(in1,1), tf.ones_like(in1), [in2]), tf.int32)",
            "out = tf.scatter_nd(tf.expand_dims(in1, 1), tf.ones_like(in1), [in2])\nreturn tf.cast(out, tf.int32)"
        ],
        "response": {
            "task_id": "stackoverflow_27",
            "completions": [
                "output = tf.scatter_nd(tf.expand_dims(in1,1), tf.ones_like(in1), tf.constant([in2]))\n     return tf.squeeze(output)",
                "return tf.cast(tf.sequence_mask(in1, in2), dtype=tf.int32)",
                "return tf.cast(tf.reduce_any(tf.equal(tf.range(in2), tf.reshape(in1, [-1, 1])), axis=0), tf.int32)",
                "out = tf.scatter_nd(tf.expand_dims(in1, axis=1), tf.ones_like(in1), [in2])\n     return tf.squeeze(tf.cast(out, dtype=tf.int32))",
                "return tf.cast(tf.scatter_nd(tf.expand_dims(in1, 1), tf.ones_like(in1), [in2]), tf.int32)",
                "return tf.cast(tf.sequence_mask(in1, in2), tf.int32)",
                "indices = tf.constant(in1)\ndepth = tf.constant(in2)\nreturn tf.cast(tf.one_hot(indices, depth), dtype=tf.int32)",
                "shape = tf.constant([in2])\noutput = tf.scatter_nd(tf.expand_dims(in1, axis=1), tf.ones_like(in1), shape)\nreturn tf.cast(output, tf.int32)",
                "return tf.cast(tf.scatter_nd(tf.expand_dims(in1,1), tf.ones_like(in1), [in2]), tf.int32)",
                "out = tf.scatter_nd(tf.expand_dims(in1, 1), tf.ones_like(in1), [in2])\nreturn tf.cast(out, tf.int32)"
            ],
            "target-program": "tf.cast(tf.reduce_max(tf.one_hot(in1, in2), axis=0), tf.int32)",
            "description": "boolean tensor with 1 at the indices in the input tensor",
            "tf_operators": {
                "tf.scatter_nd": 6,
                "tf.ones_like": 6,
                "tf.squeeze": 2,
                "tf.expand_dims": 6,
                "tf.constant": 3,
                "tf.int32": 9,
                "tf.cast": 9,
                "tf.sequence_mask": 2,
                "tf.reduce_any": 1,
                "tf.reshape": 1,
                "tf.equal": 1,
                "tf.range": 1,
                "tf.one_hot": 1
            },
            "coverage_percentage": 75.0,
            "total_in_target": 4,
            "total_covered": 3
        }
    },
    {
        "constants": "[]",
        "description": "extract columns from a 3D tensor given column indices",
        "target_program": "tf.squeeze(tf.gather(in1, tf.expand_dims(in2, 1), axis=-1, batch_dims=1))",
        "source": "https://stackoverflow.com/questions/54274074/selecting-columns-from-3d-tensor-according-to-a-1d-tensor-of-indices-tensorflow",
        "name": "stackoverflow_28",
        "examples": {
            "inputs": "[[[[5, 3],  [0, 2]], [[7, 4],  [5, 1]], [[10, 20],  [15, 30]], [[11, 16],  [14, 12]], [[-2, -7],  [-4, 6]]],[1, 0, 1, 1, 0],]",
            "outputs": "[[3, 2], [7, 5], [20, 30], [16, 12], [-2, -4]]"
        },
        "completions": [
            "indices = tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1)\nreturn tf.gather_nd(in1, indices)",
            "return tf.gather(in1, in2, axis=2, batch_dims=1)",
            "return tf.gather(in1, tf.constant(in2), batch_dims=1, axis=2)",
            "return tf.gather(in1, in2, axis=2, batch_dims=1)",
            "return tf.gather(in1, in2, axis=2, batch_dims=1)",
            "return tf.gather(in1, in2, axis=2, batch_dims=1)",
            "return tf.gather(in1, in2, axis=2, batch_dims=1)",
            "return tf.gather(in1, in2, axis=2, batch_dims=1)",
            "return tf.gather(in1, in2, axis=2, batch_dims=1)",
            "return tf.gather(in1, in2, axis=2, batch_dims=1)"
        ],
        "response": {
            "task_id": "stackoverflow_28",
            "completions": [
                "indices = tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1)\nreturn tf.gather_nd(in1, indices)",
                "return tf.gather(in1, in2, axis=2, batch_dims=1)",
                "return tf.gather(in1, tf.constant(in2), batch_dims=1, axis=2)",
                "return tf.gather(in1, in2, axis=2, batch_dims=1)",
                "return tf.gather(in1, in2, axis=2, batch_dims=1)",
                "return tf.gather(in1, in2, axis=2, batch_dims=1)",
                "return tf.gather(in1, in2, axis=2, batch_dims=1)",
                "return tf.gather(in1, in2, axis=2, batch_dims=1)",
                "return tf.gather(in1, in2, axis=2, batch_dims=1)",
                "return tf.gather(in1, in2, axis=2, batch_dims=1)"
            ],
            "target-program": "tf.squeeze(tf.gather(in1, tf.expand_dims(in2, 1), axis=-1, batch_dims=1))",
            "description": "extract columns from a 3D tensor given column indices",
            "tf_operators": {
                "tf.stack": 1,
                "tf.shape": 1,
                "tf.gather_nd": 1,
                "tf.range": 1,
                "tf.gather": 9,
                "tf.constant": 1
            },
            "coverage_percentage": 33.33333333333333,
            "total_in_target": 3,
            "total_covered": 1
        }
    },
    {
        "constants": "[]",
        "description": "place continuous values into buckets given bucket boundaries",
        "target_program": "tf.searchsorted(in1, in2, side='left')",
        "source": "https://stackoverflow.com/questions/54155085/bucketing-continous-value-tensors-in-tensorflow",
        "name": "stackoverflow_29",
        "examples": {
            "inputs": "[[-1.0, -0.8, -0.6, -0.4, -0.2, 0.0, 0.2, 0.4, 0.6, 0.8, 1.0],[0.1, -10, -0.1, 1.1, 0.41],]",
            "outputs": "[6, 0, 5, 11, 8]"
        },
        "completions": [
            "buckets = tf.constant(in1)\nvalues = tf.constant(in2)\nresult = tf.searchsorted(buckets, values)\nreturn result",
            "return tf.searchsorted(tf.constant(in1, dtype=tf.float32), tf.constant(in2, dtype=tf.float32))",
            "buckets = tf.constant(in1, dtype=tf.float32)\nvalues = tf.constant(in2, dtype=tf.float32)\nindices = tf.searchsorted(buckets, values, side='right')\nreturn indices",
            "buckets = tf.constant(in1)\nvalues = tf.constant(in2)\nindices = tf.searchsorted(buckets, values, side='right')\nreturn indices",
            "# tf.searchsorted will search how many elements in the first input (sorted_sequence) \n# should come before the elements in the second input (values). \n# This can be used to categorize continuous values into buckets.\n# The resulting indices are such that, if the input arrays were to be concatenated along that dimension, \n# the resulting array would be in sorted order.\n\nreturn tf.searchsorted(in1, in2).numpy()",
            "return tf.searchsorted(sorted_sequence=in1, values=in2, side='right').numpy().tolist()",
            "return tf.searchsorted(in1, in2, side='right').numpy().tolist()",
            "buckets = tf.constant(in1)\nvalues = tf.constant(in2)\nreturn tf.searchsorted(buckets, values, side='right')",
            "out = tf.searchsorted(in1, in2, side='right')\nreturn out",
            "return tf.searchsorted(in1, in2, side='right').numpy().tolist()"
        ],
        "response": {
            "task_id": "stackoverflow_29",
            "completions": [
                "buckets = tf.constant(in1)\nvalues = tf.constant(in2)\nresult = tf.searchsorted(buckets, values)\nreturn result",
                "return tf.searchsorted(tf.constant(in1, dtype=tf.float32), tf.constant(in2, dtype=tf.float32))",
                "buckets = tf.constant(in1, dtype=tf.float32)\nvalues = tf.constant(in2, dtype=tf.float32)\nindices = tf.searchsorted(buckets, values, side='right')\nreturn indices",
                "buckets = tf.constant(in1)\nvalues = tf.constant(in2)\nindices = tf.searchsorted(buckets, values, side='right')\nreturn indices",
                "# tf.searchsorted will search how many elements in the first input (sorted_sequence) \n# should come before the elements in the second input (values). \n# This can be used to categorize continuous values into buckets.\n# The resulting indices are such that, if the input arrays were to be concatenated along that dimension, \n# the resulting array would be in sorted order.\n\nreturn tf.searchsorted(in1, in2).numpy()",
                "return tf.searchsorted(sorted_sequence=in1, values=in2, side='right').numpy().tolist()",
                "return tf.searchsorted(in1, in2, side='right').numpy().tolist()",
                "buckets = tf.constant(in1)\nvalues = tf.constant(in2)\nreturn tf.searchsorted(buckets, values, side='right')",
                "out = tf.searchsorted(in1, in2, side='right')\nreturn out",
                "return tf.searchsorted(in1, in2, side='right').numpy().tolist()"
            ],
            "target-program": "tf.searchsorted(in1, in2, side='left')",
            "description": "place continuous values into buckets given bucket boundaries",
            "tf_operators": {
                "tf.constant": 5,
                "tf.searchsorted": 10,
                "tf.float32": 2
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        }
    },
    {
        "constants": "[]",
        "description": "compute Euclidean distance between two tensors",
        "target_program": "tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, 1), tf.expand_dims(in2, 0))), axis=2))",
        "source": "https://stackoverflow.com/questions/54147780/tensorflow-how-to-calculate-the-euclidean-distance-between-two-tensor",
        "name": "stackoverflow_30",
        "examples": {
            "inputs": "[[[1., 2.], [3., 4.], [5., 6.]],[[9., 4.], [8., 5.], [7., 6.]],]",
            "outputs": "[[math.sqrt(68), math.sqrt(58), math.sqrt(52)],    [math.sqrt(36), math.sqrt(26), math.sqrt(20)],    [math.sqrt(20), math.sqrt(10), math.sqrt(4)]]"
        },
        "completions": [
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.transpose(in2))), axis=1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.expand_dims(in2, 1))), 2))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.expand_dims(in2, 1))), axis=2))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))",
            "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))"
        ],
        "response": {
            "task_id": "stackoverflow_30",
            "completions": [
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.transpose(in2))), axis=1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.expand_dims(in2, 1))), 2))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, tf.expand_dims(in2, 1))), axis=2))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=1))",
                "return tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1, in2)), axis=-1))"
            ],
            "target-program": "tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, 1), tf.expand_dims(in2, 0))), axis=2))",
            "description": "compute Euclidean distance between two tensors",
            "tf_operators": {
                "tf.reduce_sum": 10,
                "tf.sqrt": 10,
                "tf.square": 10,
                "tf.subtract": 10,
                "tf.transpose": 1,
                "tf.expand_dims": 2
            },
            "coverage_percentage": 100.0,
            "total_in_target": 5,
            "total_covered": 5
        }
    },
    {
        "constants": "[]",
        "description": "squared error between two tensors, one being a sparse tensor",
        "target_program": "tf.reduce_sum(tf.square(tf.subtract(in2, tf.sparse.to_dense(in1))))",
        "source": "https://stackoverflow.com/questions/45032668/tensorflow-how-to-compute-the-square-error-between-a-tensor-and-a-sparse-tensor",
        "name": "stackoverflow_31",
        "examples": {
            "inputs": "tf.SparseTensor(indices=[[0, 0], [0, 1], [1, 1]], values=[1.0, 1.5, -2.0], dense_shape=[2, 2]), [[3.0, 1.0], [0.2, -1.0]],",
            "outputs": "5.29"
        },
        "completions": [
            "# Get the tensor from the SparseTensor\n    dense_in1 = tf.sparse.to_dense(in1)\n\n    # Calculate the squared difference between tensors\n    squared_diff = tf.math.squared_difference(dense_in1, in2)\n    \n    # Reduce to a scalar by summing all elements\n    error = tf.reduce_sum(squared_diff)\n    \n    return error",
            "# First, convert the input SparseTensor into a DenseTensor\ndense = tf.sparse.to_dense(in1[0])\n\n# Matmul returns a scalar result which is the sum of the element-wise product of the inputs\nmse = tf.reduce_sum(tf.square(tf.subtract(dense, in1[1])))\n\n# Return the output\nreturn mse",
            "dense_tensor = tf.sparse.to_dense(in1[0])\nsquared_error = tf.math.squared_difference(in1[1], dense_tensor)\nreturn tf.reduce_sum(squared_error).numpy()",
            "dense_tensor = tf.sparse.to_dense(in1)\n     squared_difference = tf.math.squared_difference(dense_tensor, in2)\n     return tf.reduce_sum(squared_difference)",
            "dense1 = tf.sparse.to_dense(in1[0])\n     error = tf.math.squared_difference(in1[1], dense1)\n     return tf.reduce_sum(error)",
            "dense_tensor = in1[1]\nsparse_tensor = in1[0]\nsquared_errors = tf.square(tf.subtract(tf.gather_nd(dense_tensor, sparse_tensor.indices), sparse_tensor.values))\nreturn tf.reduce_sum(squared_errors)",
            "sparse_tensor, tensor = in1\nreturn tf.reduce_sum(tf.math.squared_difference(tf.gather_nd(tensor, sparse_tensor.indices), sparse_tensor.values))",
            "dense = tf.sparse.to_dense(in1[0])\nsquared_diff = tf.math.squared_difference(dense, in1[1])\nreturn tf.reduce_sum(squared_diff).numpy()",
            "# sparse_to_dense will convert the sparse tensor to a dense tensor with the same shape\n    sparse_tensor = tf.compat.v1.sparse.to_dense(in1[0])\n\n    # we take the difference between the sparse tensor and the dense tensor in1[1]\n    error = tf.math.subtract(sparse_tensor, in1[1])\n\n    # then we square the error\n    squared_error = tf.math.square(error)\n\n    # Finally, we sum up the squared errors \n    return tf.math.reduce_sum(squared_error).numpy()",
            "dense = tf.sparse.to_dense(in1[0])\n     error = tf.math.squared_difference(in1[1], dense)\n     return tf.reduce_sum(error)"
        ],
        "response": {
            "task_id": "stackoverflow_31",
            "completions": [
                "# Get the tensor from the SparseTensor\n    dense_in1 = tf.sparse.to_dense(in1)\n\n    # Calculate the squared difference between tensors\n    squared_diff = tf.math.squared_difference(dense_in1, in2)\n    \n    # Reduce to a scalar by summing all elements\n    error = tf.reduce_sum(squared_diff)\n    \n    return error",
                "# First, convert the input SparseTensor into a DenseTensor\ndense = tf.sparse.to_dense(in1[0])\n\n# Matmul returns a scalar result which is the sum of the element-wise product of the inputs\nmse = tf.reduce_sum(tf.square(tf.subtract(dense, in1[1])))\n\n# Return the output\nreturn mse",
                "dense_tensor = tf.sparse.to_dense(in1[0])\nsquared_error = tf.math.squared_difference(in1[1], dense_tensor)\nreturn tf.reduce_sum(squared_error).numpy()",
                "dense_tensor = tf.sparse.to_dense(in1)\n     squared_difference = tf.math.squared_difference(dense_tensor, in2)\n     return tf.reduce_sum(squared_difference)",
                "dense1 = tf.sparse.to_dense(in1[0])\n     error = tf.math.squared_difference(in1[1], dense1)\n     return tf.reduce_sum(error)",
                "dense_tensor = in1[1]\nsparse_tensor = in1[0]\nsquared_errors = tf.square(tf.subtract(tf.gather_nd(dense_tensor, sparse_tensor.indices), sparse_tensor.values))\nreturn tf.reduce_sum(squared_errors)",
                "sparse_tensor, tensor = in1\nreturn tf.reduce_sum(tf.math.squared_difference(tf.gather_nd(tensor, sparse_tensor.indices), sparse_tensor.values))",
                "dense = tf.sparse.to_dense(in1[0])\nsquared_diff = tf.math.squared_difference(dense, in1[1])\nreturn tf.reduce_sum(squared_diff).numpy()",
                "# sparse_to_dense will convert the sparse tensor to a dense tensor with the same shape\n    sparse_tensor = tf.compat.v1.sparse.to_dense(in1[0])\n\n    # we take the difference between the sparse tensor and the dense tensor in1[1]\n    error = tf.math.subtract(sparse_tensor, in1[1])\n\n    # then we square the error\n    squared_error = tf.math.square(error)\n\n    # Finally, we sum up the squared errors \n    return tf.math.reduce_sum(squared_error).numpy()",
                "dense = tf.sparse.to_dense(in1[0])\n     error = tf.math.squared_difference(in1[1], dense)\n     return tf.reduce_sum(error)"
            ],
            "target-program": "tf.reduce_sum(tf.square(tf.subtract(in2, tf.sparse.to_dense(in1))))",
            "description": "squared error between two tensors, one being a sparse tensor",
            "tf_operators": {
                "tf.sparse.to_dense": 7,
                "tf.reduce_sum": 9,
                "tf.math.squared_difference": 7,
                "tf.square": 2,
                "tf.subtract": 2,
                "tf.gather_nd": 2,
                "tf.math.reduce_sum": 1,
                "tf.math.subtract": 1,
                "tf.math.square": 1,
                "tf.compat.v1.sparse.to_dense": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 4,
            "total_covered": 4
        }
    },
    {
        "constants": "[]",
        "description": "weighted sum across rows, where the column index is the weight",
        "target_program": "tf.tensordot(in1, tf.cast(tf.range(4), tf.float32), 1)",
        "source": "https://stackoverflow.com/questions/48659449/how-to-compute-the-weighted-sum-of-a-tensor-in-tensorflow",
        "name": "stackoverflow_32",
        "examples": {
            "inputs": "[[[0.1, 0.6, 0.2, 0.1], [0.3, 0.1, 0.4, 0.2], [0.2, 0.1, 0.2, 0.5]],]",
            "outputs": "[1.3, 1.5, 2.0]"
        },
        "completions": [
            "weights = tf.range(start=tf.constant(0, dtype=tf.float32), limit=tf.cast(tf.shape(in1)[1], dtype=tf.float32))\nweighted_in1 = tf.multiply(in1, weights)\nreturn tf.reduce_sum(weighted_in1, axis=1)",
            "weights = tf.range(tf.shape(in1)[1], dtype=in1.dtype)\nweighted_in1 = tf.multiply(in1, weights)\noutput = tf.reduce_sum(weighted_in1, axis=1)\nreturn output",
            "weights = tf.range(start=0, limit=tf.shape(in1)[1])\nweights = tf.cast(weights, dtype=tf.float32)\nweighted_sum = tf.reduce_sum(in1 * weights, axis=1)\nreturn weighted_sum",
            "weights = tf.range(tf.cast(tf.shape(in1)[1], dtype=tf.float32))\nreturn tf.reduce_sum(tf.multiply(in1, weights), axis=1)",
            "weights = tf.range(tf.shape(in1)[1], dtype=in1.dtype)\nreturn tf.reduce_sum(weights * in1, axis=1)",
            "weights = tf.range(tf.shape(in1)[1])\nweights = tf.cast(weights, tf.float32)\nout = tf.reduce_sum(in1*weights, axis=1)\nreturn out",
            "weights = tf.range(start=0, limit=tf.shape(in1)[1], delta=1, dtype=tf.float32)\nreturn tf.reduce_sum(tf.multiply(in1, weights), axis=-1)",
            "weights = tf.range(tf.shape(in1)[-1])\nweighted_sum = tf.reduce_sum(in1 * tf.cast(weights, in1.dtype), axis=1)\nreturn weighted_sum",
            "weights = tf.range(tf.shape(in1)[1])\nweights = tf.cast(weights, in1.dtype)\nin1 = tf.multiply(in1, weights)\nreturn tf.reduce_sum(in1, axis=1)",
            "weights = tf.range(start=0, limit=tf.shape(in1)[1], delta=1, dtype=tf.float32)\nreturn tf.reduce_sum(in1 * weights, axis=1)"
        ],
        "response": {
            "task_id": "stackoverflow_32",
            "completions": [
                "weights = tf.range(start=tf.constant(0, dtype=tf.float32), limit=tf.cast(tf.shape(in1)[1], dtype=tf.float32))\nweighted_in1 = tf.multiply(in1, weights)\nreturn tf.reduce_sum(weighted_in1, axis=1)",
                "weights = tf.range(tf.shape(in1)[1], dtype=in1.dtype)\nweighted_in1 = tf.multiply(in1, weights)\noutput = tf.reduce_sum(weighted_in1, axis=1)\nreturn output",
                "weights = tf.range(start=0, limit=tf.shape(in1)[1])\nweights = tf.cast(weights, dtype=tf.float32)\nweighted_sum = tf.reduce_sum(in1 * weights, axis=1)\nreturn weighted_sum",
                "weights = tf.range(tf.cast(tf.shape(in1)[1], dtype=tf.float32))\nreturn tf.reduce_sum(tf.multiply(in1, weights), axis=1)",
                "weights = tf.range(tf.shape(in1)[1], dtype=in1.dtype)\nreturn tf.reduce_sum(weights * in1, axis=1)",
                "weights = tf.range(tf.shape(in1)[1])\nweights = tf.cast(weights, tf.float32)\nout = tf.reduce_sum(in1*weights, axis=1)\nreturn out",
                "weights = tf.range(start=0, limit=tf.shape(in1)[1], delta=1, dtype=tf.float32)\nreturn tf.reduce_sum(tf.multiply(in1, weights), axis=-1)",
                "weights = tf.range(tf.shape(in1)[-1])\nweighted_sum = tf.reduce_sum(in1 * tf.cast(weights, in1.dtype), axis=1)\nreturn weighted_sum",
                "weights = tf.range(tf.shape(in1)[1])\nweights = tf.cast(weights, in1.dtype)\nin1 = tf.multiply(in1, weights)\nreturn tf.reduce_sum(in1, axis=1)",
                "weights = tf.range(start=0, limit=tf.shape(in1)[1], delta=1, dtype=tf.float32)\nreturn tf.reduce_sum(in1 * weights, axis=1)"
            ],
            "target-program": "tf.tensordot(in1, tf.cast(tf.range(4), tf.float32), 1)",
            "description": "weighted sum across rows, where the column index is the weight",
            "tf_operators": {
                "tf.reduce_sum": 10,
                "tf.multiply": 5,
                "tf.float32": 6,
                "tf.constant": 1,
                "tf.range": 10,
                "tf.cast": 6,
                "tf.shape": 10
            },
            "coverage_percentage": 75.0,
            "total_in_target": 4,
            "total_covered": 3
        }
    },
    {
        "constants": "[]",
        "description": "find the minimum distance between two sets of points",
        "target_program": "tf.reduce_min(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, 0), tf.expand_dims(in2, 1))), axis=2), axis=1)",
        "source": "https://stackoverflow.com/questions/40558251/computing-minimum-distance-for-each-element-in-a-tensor-relative-to-another-tens",
        "name": "stackoverflow_33",
        "examples": {
            "inputs": "[[[.3, .1, .4], [.1, .5, .9], [.2, .6, .5], [.3, .5, .8],[.9, .7, .9]],[[.3, .2, .3], [.8, .4, .6], [.2, .6, .4], [.3, .3, .8]],]",
            "outputs": "[0.02, 0.19, 0.01, 0.04]"
        },
        "completions": [
            "distances = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, 1), tf.expand_dims(in2, 0))), axis=-1)), axis=-1)\n     return distances",
            "expanded_a = tf.expand_dims(in1, axis=1)\n    expanded_b = tf.expand_dims(in2, axis=0)\n    distances = tf.reduce_sum(tf.square(tf.subtract(expanded_a, expanded_b)), axis=-1)\n    min_distance = tf.reduce_min(distances, axis=-1)\n    return min_distance",
            "in1_exp = tf.expand_dims(in1, 1)\nin2_exp = tf.expand_dims(in2, 0)\ndistance = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1_exp, in2_exp)), axis=-1)), axis=-1)\nreturn tf.squeeze(distance)",
            "distances = tf.reshape(tf.reduce_sum(tf.square(in1[:, tf.newaxis] - in2), axis=-1), (tf.shape(in1)[0], tf.shape(in2)[0]))     # Compute all pairwise distances\n     min_distances = tf.reduce_min(distances, axis=-1)     # Find minimum distance for each point in in1\n     return min_distances",
            "differences = tf.subtract(tf.expand_dims(in1, 1), tf.expand_dims(in2, 0))\n    distances = tf.sqrt(tf.reduce_sum(tf.square(differences), axis=-1))\n    min_distance = tf.reduce_min(distances, axis=-1)\n    return min_distance",
            "tmp = tf.reshape(in2, [1,-1,3]) - tf.reshape(in1, [-1,1,3])\nsq = tf.square(tmp)\nssum = tf.reduce_sum(sq, -1)\ndist = tf.sqrt(ssum)\nmin = tf.reduce_min(dist, axis=1)\nreturn min",
            "distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=1), tf.expand_dims(in2, axis=0))), axis=2))\nmin_distances = tf.reduce_min(distances, axis=1)\nreturn min_distances",
            "expanded_in1 = tf.expand_dims(in1, 1)\n    expanded_in2 = tf.expand_dims(in2, 0)\n\n    distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(expanded_in1, expanded_in2)), axis=-1))\n    min_distances = tf.reduce_min(distances, axis=-1)\n    return min_distances",
            "in1_exp = tf.expand_dims(in1, 1)\nin2_exp = tf.expand_dims(in2, 0)\n\ndiff = tf.subtract(in1_exp, in2_exp)\ndistances = tf.sqrt(tf.reduce_sum(tf.square(diff), axis=-1))\n\nmin_dist = tf.reduce_min(distances, axis=-1)\n\nreturn min_dist",
            "distances = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.expand_dims(in1, axis=1) - tf.expand_dims(in2, axis=0)), axis=-1)), axis=-1)\n     return distances"
        ],
        "response": {
            "task_id": "stackoverflow_33",
            "completions": [
                "distances = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, 1), tf.expand_dims(in2, 0))), axis=-1)), axis=-1)\n     return distances",
                "expanded_a = tf.expand_dims(in1, axis=1)\n    expanded_b = tf.expand_dims(in2, axis=0)\n    distances = tf.reduce_sum(tf.square(tf.subtract(expanded_a, expanded_b)), axis=-1)\n    min_distance = tf.reduce_min(distances, axis=-1)\n    return min_distance",
                "in1_exp = tf.expand_dims(in1, 1)\nin2_exp = tf.expand_dims(in2, 0)\ndistance = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(in1_exp, in2_exp)), axis=-1)), axis=-1)\nreturn tf.squeeze(distance)",
                "distances = tf.reshape(tf.reduce_sum(tf.square(in1[:, tf.newaxis] - in2), axis=-1), (tf.shape(in1)[0], tf.shape(in2)[0]))     # Compute all pairwise distances\n     min_distances = tf.reduce_min(distances, axis=-1)     # Find minimum distance for each point in in1\n     return min_distances",
                "differences = tf.subtract(tf.expand_dims(in1, 1), tf.expand_dims(in2, 0))\n    distances = tf.sqrt(tf.reduce_sum(tf.square(differences), axis=-1))\n    min_distance = tf.reduce_min(distances, axis=-1)\n    return min_distance",
                "tmp = tf.reshape(in2, [1,-1,3]) - tf.reshape(in1, [-1,1,3])\nsq = tf.square(tmp)\nssum = tf.reduce_sum(sq, -1)\ndist = tf.sqrt(ssum)\nmin = tf.reduce_min(dist, axis=1)\nreturn min",
                "distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, axis=1), tf.expand_dims(in2, axis=0))), axis=2))\nmin_distances = tf.reduce_min(distances, axis=1)\nreturn min_distances",
                "expanded_in1 = tf.expand_dims(in1, 1)\n    expanded_in2 = tf.expand_dims(in2, 0)\n\n    distances = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(expanded_in1, expanded_in2)), axis=-1))\n    min_distances = tf.reduce_min(distances, axis=-1)\n    return min_distances",
                "in1_exp = tf.expand_dims(in1, 1)\nin2_exp = tf.expand_dims(in2, 0)\n\ndiff = tf.subtract(in1_exp, in2_exp)\ndistances = tf.sqrt(tf.reduce_sum(tf.square(diff), axis=-1))\n\nmin_dist = tf.reduce_min(distances, axis=-1)\n\nreturn min_dist",
                "distances = tf.reduce_min(tf.sqrt(tf.reduce_sum(tf.square(tf.expand_dims(in1, axis=1) - tf.expand_dims(in2, axis=0)), axis=-1)), axis=-1)\n     return distances"
            ],
            "target-program": "tf.reduce_min(tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(in1, 0), tf.expand_dims(in2, 1))), axis=2), axis=1)",
            "description": "find the minimum distance between two sets of points",
            "tf_operators": {
                "tf.reduce_sum": 10,
                "tf.square": 10,
                "tf.sqrt": 8,
                "tf.expand_dims": 8,
                "tf.reduce_min": 10,
                "tf.subtract": 7,
                "tf.squeeze": 1,
                "tf.newaxis": 1,
                "tf.reshape": 2,
                "tf.shape": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 5,
            "total_covered": 5
        }
    },
    {
        "constants": "[]",
        "description": "compute a weighted sum of tensors",
        "target_program": "tf.tensordot(in2, in1, 1)",
        "source": "https://stackoverflow.com/questions/49532371/compute-a-linear-combination-of-tensors-in-tensorflow",
        "name": "stackoverflow_34",
        "examples": {
            "inputs": "[[[[1, 2], [3, 4]],[[5, 6], [7, 8]],[[10, 20], [30, 40]]],[3, 5, 10],]",
            "outputs": "[[128, 236], [344, 452]]"
        },
        "completions": [
            "return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, [-1, 1, 1])), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, [-1, 1, 1])), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, [-1, 1, 1])), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, [-1, 1, 1])), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, (-1, 1, 1))), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(tf.expand_dims(in2,1),2)), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(tf.expand_dims(in2, 1), 1)), axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(in2, axis=-1)), axis=0)",
            "weighted_tensors = [tf.multiply(tensor, weight) for tensor, weight in zip(in1, in2)]\nreturn tf.reduce_sum(weighted_tensors, axis=0)",
            "return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, [-1, 1, 1])), axis=0)"
        ],
        "response": {
            "task_id": "stackoverflow_34",
            "completions": [
                "return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, [-1, 1, 1])), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, [-1, 1, 1])), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, [-1, 1, 1])), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, [-1, 1, 1])), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, (-1, 1, 1))), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(tf.expand_dims(in2,1),2)), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(tf.expand_dims(in2, 1), 1)), axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, tf.expand_dims(in2, axis=-1)), axis=0)",
                "weighted_tensors = [tf.multiply(tensor, weight) for tensor, weight in zip(in1, in2)]\nreturn tf.reduce_sum(weighted_tensors, axis=0)",
                "return tf.reduce_sum(tf.multiply(in1, tf.reshape(in2, [-1, 1, 1])), axis=0)"
            ],
            "target-program": "tf.tensordot(in2, in1, 1)",
            "description": "compute a weighted sum of tensors",
            "tf_operators": {
                "tf.reduce_sum": 10,
                "tf.reshape": 6,
                "tf.multiply": 10,
                "tf.expand_dims": 3
            },
            "coverage_percentage": 0.0,
            "total_in_target": 1,
            "total_covered": 0
        }
    },
    {
        "constants": "[]",
        "description": "linear interpolation between two tensors",
        "target_program": "tf.add(in2, tf.multiply(tf.expand_dims(in3, 1), tf.subtract(in1, in2)))",
        "source": "https://stackoverflow.com/questions/49643371/keras-compute-convex-combination-of-two-tensors",
        "name": "stackoverflow_35",
        "examples": {
            "inputs": "[[[[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]], [[10., 20.], [30., 40.], [50., 60.]]],[[[9.0, 8.0], [7.0, 6.0], [5.0, 4.0]], [[90., 80.], [70., 60.], [50., 40.]]],[0.1, 0.4, 0.8],]",
            "outputs": "[[[8.2, 7.4], [5.4, 5.2], [5.0, 5.6]],    [[82., 74.], [54., 52.], [50., 56.]]]"
        },
        "completions": [
            "return in1 * (1 - tf.expand_dims(in3, -1)) + in2 * tf.expand_dims(in3, -1)",
            "return tf.add(tf.multiply(in1, tf.expand_dims(1 - in3, axis=-1)), tf.multiply(in2, tf.expand_dims(in3, axis=-1)))",
            "return in1 * (1 - tf.expand_dims(in3, axis=-1)) + in2 * tf.expand_dims(in3, axis=-1)",
            "return tf.add(tf.multiply(in1, tf.expand_dims(1. - in3, -1)), tf.multiply(in2, tf.expand_dims(in3, -1)))",
            "return tf.add(tf.multiply(in1, tf.expand_dims(tf.expand_dims(1. - in3, -1),-1)), tf.multiply(in2, tf.expand_dims(tf.expand_dims(in3, -1),-1)))",
            "return tf.add(tf.multiply(in1, tf.expand_dims(tf.expand_dims(1. - in3, -1), -1)), tf.multiply(in2, tf.expand_dims(tf.expand_dims(in3, -1), -1)))",
            "return tf.add(tf.multiply(in1, tf.expand_dims(1 - in3, axis=-1)), tf.multiply(in2, tf.expand_dims(in3, axis=-1)))",
            "return tf.add(tf.multiply(in1, tf.reshape(1 - in3, [-1, 1, 1])), tf.multiply(in2, tf.reshape(in3, [-1, 1, 1])))",
            "return tf.add(tf.multiply(in1, tf.subtract(tf.constant(1.0), tf.expand_dims(in3, axis=-1))), tf.multiply(in2, tf.expand_dims(in3, axis=-1)))",
            "return tf.add(tf.multiply(in1, tf.expand_dims(1 - in3, axis=-1)), tf.multiply(in2, tf.expand_dims(in3, axis=-1)))"
        ],
        "response": {
            "task_id": "stackoverflow_35",
            "completions": [
                "return in1 * (1 - tf.expand_dims(in3, -1)) + in2 * tf.expand_dims(in3, -1)",
                "return tf.add(tf.multiply(in1, tf.expand_dims(1 - in3, axis=-1)), tf.multiply(in2, tf.expand_dims(in3, axis=-1)))",
                "return in1 * (1 - tf.expand_dims(in3, axis=-1)) + in2 * tf.expand_dims(in3, axis=-1)",
                "return tf.add(tf.multiply(in1, tf.expand_dims(1. - in3, -1)), tf.multiply(in2, tf.expand_dims(in3, -1)))",
                "return tf.add(tf.multiply(in1, tf.expand_dims(tf.expand_dims(1. - in3, -1),-1)), tf.multiply(in2, tf.expand_dims(tf.expand_dims(in3, -1),-1)))",
                "return tf.add(tf.multiply(in1, tf.expand_dims(tf.expand_dims(1. - in3, -1), -1)), tf.multiply(in2, tf.expand_dims(tf.expand_dims(in3, -1), -1)))",
                "return tf.add(tf.multiply(in1, tf.expand_dims(1 - in3, axis=-1)), tf.multiply(in2, tf.expand_dims(in3, axis=-1)))",
                "return tf.add(tf.multiply(in1, tf.reshape(1 - in3, [-1, 1, 1])), tf.multiply(in2, tf.reshape(in3, [-1, 1, 1])))",
                "return tf.add(tf.multiply(in1, tf.subtract(tf.constant(1.0), tf.expand_dims(in3, axis=-1))), tf.multiply(in2, tf.expand_dims(in3, axis=-1)))",
                "return tf.add(tf.multiply(in1, tf.expand_dims(1 - in3, axis=-1)), tf.multiply(in2, tf.expand_dims(in3, axis=-1)))"
            ],
            "target-program": "tf.add(in2, tf.multiply(tf.expand_dims(in3, 1), tf.subtract(in1, in2)))",
            "description": "linear interpolation between two tensors",
            "tf_operators": {
                "tf.expand_dims": 9,
                "tf.add": 8,
                "tf.multiply": 8,
                "tf.reshape": 1,
                "tf.constant": 1,
                "tf.subtract": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 4,
            "total_covered": 4
        }
    },
    {
        "constants": "[]",
        "description": "divide each element by the column index",
        "target_program": "tf.cast(tf.divide(in1, tf.add(in1, tf.range(8))), tf.float32)",
        "source": "https://stackoverflow.com/questions/43306788/divide-elements-of-1-d-tensor-by-the-corrispondent-index",
        "name": "stackoverflow_36",
        "examples": {
            "inputs": "[[1, 0, 1, 1, 0, 1, 0, 1],]",
            "outputs": "[1., 0., 0.333333, 0.25, 0., 0.166667, 0., 0.125]"
        },
        "completions": [
            "# reshape the input to a 2D tensor with shape (-1,1)\n    in1 = tf.reshape(in1, [-1,1])\n\n    # generate a tensor representing the column index \n    col_indices = tf.range(tf.shape(in1)[0], dtype=in1.dtype)\n\n    # reshape the column indices to match the shape of the input tensor\n    col_indices = tf.reshape(col_indices, in1.shape)\n\n    # divide each element of the input tensor by its corresponding column index\n    return tf.divide(in1, tf.cast(col_indices, tf.float32))",
            "shape = tf.shape(in1)\nindices = tf.range(shape[0], dtype=tf.float32)\nreturn tf.divide(in1, tf.add(indices, 1))",
            "in1 = tf.cast(in1, tf.float32)  # cast the input to float to allow division\ncol_indices = tf.range(1, tf.shape(in1)[0]+1, dtype=tf.float32)  # create a tensor of column indices\nreturn tf.divide(in1, col_indices)  # divide the input by the column index",
            "# The task is to divide the given tensor by their respective index values\n# TensorFlow does not have any built-in division by index operation \n# We have to create an array of indices and then divide the tensor\n# Here is how we do it.\n\n#Step 1: calculate the length of the input tensor\nlength = tf.shape(in1)[0]\n\n#Step 2: create an array with values from 1 to length+1\nindices = tf.range(1, length+1, dtype=tf.float32)\n\n#Step 3: expand the dims of the indices tensor to ensure they have same shape as in1\nindices = tf.expand_dims(indices, axis=-1)\n\n#Step 4: divide each element of in1 by the corresponding index\nout = tf.divide(in1, indices)\n\nreturn out",
            "# Use tf.range to get an array the same length as the input and start from 1 to avoid division by zero\n# Divide each element of the input array by the corresponding element of the range array\n  \n    return tf.divide(in1, tf.range(1, tf.size(in1) + 1, dtype=tf.float32))",
            "in1 = tf.cast(in1, tf.float32)\n     col_idx = tf.range(1, tf.shape(in1)[0] + 1, dtype=tf.float32)\n     return tf.divide(in1, col_idx)",
            "shape = tf.shape(in1)\nin1 = tf.cast(in1, tf.float32)\nindexes = tf.range(1, shape[0] + 1, dtype=tf.float32)\nresult = tf.divide(in1, indexes)\nreturn result",
            "shape = tf.shape(in1)\ncol_indices = tf.range(start=1, limit=shape[0]+1, delta=1)\ncol_indices = tf.cast(col_indices, dtype=tf.float32)\nin1 = tf.cast(in1, dtype=tf.float32)\nreturn tf.divide(in1, col_indices)",
            "shape = tf.shape(in1)\ncol_indices = tf.range(1, shape[-1]+1, dtype=tf.float32)\nreturn tf.divide(in1, col_indices)",
            "shape = tf.shape(in1)\ndivisor = tf.range(1, shape[1]+1, dtype=tf.float32)\nreturn tf.divide(in1, divisor)"
        ],
        "response": {
            "task_id": "stackoverflow_36",
            "completions": [
                "# reshape the input to a 2D tensor with shape (-1,1)\n    in1 = tf.reshape(in1, [-1,1])\n\n    # generate a tensor representing the column index \n    col_indices = tf.range(tf.shape(in1)[0], dtype=in1.dtype)\n\n    # reshape the column indices to match the shape of the input tensor\n    col_indices = tf.reshape(col_indices, in1.shape)\n\n    # divide each element of the input tensor by its corresponding column index\n    return tf.divide(in1, tf.cast(col_indices, tf.float32))",
                "shape = tf.shape(in1)\nindices = tf.range(shape[0], dtype=tf.float32)\nreturn tf.divide(in1, tf.add(indices, 1))",
                "in1 = tf.cast(in1, tf.float32)  # cast the input to float to allow division\ncol_indices = tf.range(1, tf.shape(in1)[0]+1, dtype=tf.float32)  # create a tensor of column indices\nreturn tf.divide(in1, col_indices)  # divide the input by the column index",
                "# The task is to divide the given tensor by their respective index values\n# TensorFlow does not have any built-in division by index operation \n# We have to create an array of indices and then divide the tensor\n# Here is how we do it.\n\n#Step 1: calculate the length of the input tensor\nlength = tf.shape(in1)[0]\n\n#Step 2: create an array with values from 1 to length+1\nindices = tf.range(1, length+1, dtype=tf.float32)\n\n#Step 3: expand the dims of the indices tensor to ensure they have same shape as in1\nindices = tf.expand_dims(indices, axis=-1)\n\n#Step 4: divide each element of in1 by the corresponding index\nout = tf.divide(in1, indices)\n\nreturn out",
                "# Use tf.range to get an array the same length as the input and start from 1 to avoid division by zero\n# Divide each element of the input array by the corresponding element of the range array\n  \n    return tf.divide(in1, tf.range(1, tf.size(in1) + 1, dtype=tf.float32))",
                "in1 = tf.cast(in1, tf.float32)\n     col_idx = tf.range(1, tf.shape(in1)[0] + 1, dtype=tf.float32)\n     return tf.divide(in1, col_idx)",
                "shape = tf.shape(in1)\nin1 = tf.cast(in1, tf.float32)\nindexes = tf.range(1, shape[0] + 1, dtype=tf.float32)\nresult = tf.divide(in1, indexes)\nreturn result",
                "shape = tf.shape(in1)\ncol_indices = tf.range(start=1, limit=shape[0]+1, delta=1)\ncol_indices = tf.cast(col_indices, dtype=tf.float32)\nin1 = tf.cast(in1, dtype=tf.float32)\nreturn tf.divide(in1, col_indices)",
                "shape = tf.shape(in1)\ncol_indices = tf.range(1, shape[-1]+1, dtype=tf.float32)\nreturn tf.divide(in1, col_indices)",
                "shape = tf.shape(in1)\ndivisor = tf.range(1, shape[1]+1, dtype=tf.float32)\nreturn tf.divide(in1, divisor)"
            ],
            "target-program": "tf.cast(tf.divide(in1, tf.add(in1, tf.range(8))), tf.float32)",
            "description": "divide each element by the column index",
            "tf_operators": {
                "tf.float32": 10,
                "tf.divide": 10,
                "tf.reshape": 1,
                "tf.range": 10,
                "tf.cast": 5,
                "tf.shape": 9,
                "tf.add": 1,
                "tf.expand_dims": 1,
                "tf.size": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 5,
            "total_covered": 5
        }
    },
    {
        "constants": "[]",
        "description": "dot product a vector with last dimension of a tensor",
        "target_program": "tf.tensordot(in1, in2, 1)",
        "source": "https://stackoverflow.com/questions/49206051/multiply-4-d-tensor-with-1-d-tensor",
        "name": "stackoverflow_37",
        "examples": {
            "inputs": "[[[[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]],  [[1.2, 3.4, 5.6], [7.8, 9.8, 7.6]]]],[0.5, 1.0, 2.0],]",
            "outputs": "[[[8.5, 19.0], [15.2, 28.9]]]"
        },
        "completions": [
            "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
            "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
            "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
            "return tf.tensordot(in1, in2, axes=[[-1],[0]])",
            "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
            "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
            "return tf.tensordot(in1, in2, axes=[[len(tf.shape(in1)) - 1], [0]])",
            "return tf.tensordot(in1, in2, axes=-1)",
            "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
            "return tf.tensordot(in1, in2, axes=[[-1],[0]])"
        ],
        "response": {
            "task_id": "stackoverflow_37",
            "completions": [
                "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
                "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
                "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
                "return tf.tensordot(in1, in2, axes=[[-1],[0]])",
                "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
                "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
                "return tf.tensordot(in1, in2, axes=[[len(tf.shape(in1)) - 1], [0]])",
                "return tf.tensordot(in1, in2, axes=-1)",
                "return tf.tensordot(in1, in2, axes=[[-1], [0]])",
                "return tf.tensordot(in1, in2, axes=[[-1],[0]])"
            ],
            "target-program": "tf.tensordot(in1, in2, 1)",
            "description": "dot product a vector with last dimension of a tensor",
            "tf_operators": {
                "tf.tensordot": 10,
                "tf.shape": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 1,
            "total_covered": 1
        }
    },
    {
        "constants": "[]",
        "description": "compute the product of marked elements",
        "target_program": "tf.reduce_prod(tf.maximum(tf.reduce_max(in2), tf.multiply(in1, in2)), axis=1)",
        "source": "https://stackoverflow.com/questions/49511529/tensorflow-compute-multiplication-by-binary-matrix",
        "name": "stackoverflow_38",
        "examples": {
            "inputs": "[[9, 2, 5, 3, 7, 4],[[0, 0, 1, 0, 1, 0], [1, 0, 0, 0, 0, 0], [0, 1, 1, 1, 0, 1]],]",
            "outputs": "[35, 9, 120]"
        },
        "completions": [
            "mark = tf.cast(in2, tf.float32)\nproduct = tf.reduce_prod(tf.multiply(in1, mark), axis=1)\nreturn product",
            "mask = tf.cast(in2, tf.bool)\nmasked_in1 = tf.boolean_mask(in1, mask)\nproduct = tf.reduce_prod(masked_in1)\nreturn product",
            "# The problem requires us to multiply those elements in in1 array which are marked by 1 in the in2 array.\n# Here, we will:\n# 1. Use tf.boolean_mask to generate a list of lists with only elements marked by 1 in in2.\n# 2. Use tf.reduce_prod on these lists to get the product of each list. Since we are using reduce operation along axis = 1, we'll get products for each group of elements marked by 1 in in2.\n\ndef transform(in1,in2):\n    # cast inputs to tensors\n    in1 = tf.constant(in1,dtype=tf.int32)\n    in2 = tf.constant(in2,dtype=tf.bool)\n\n    masked_vals = tf.boolean_mask(in1, in2)\n    products = tf.reduce_prod(masked_vals,1)\n    return products.numpy()",
            "masked_inputs = tf.boolean_mask(in1, in2)\n     output = tf.reduce_prod(masked_inputs, axis=1)\n     return output",
            "# tf.boolean_mask is used to select the elements in the tensor that are specified by the mask. \n# Then tf.reduce_prod is used to compute the product of these elements.\n\ndef transform(in1,in2):\n   output = []\n   for row in in2:\n       mask = tf.cast(row, dtype=tf.bool)\n       selected_elements = tf.boolean_mask(in1, mask)\n       output.append(tf.reduce_prod(selected_elements))\n   return output",
            "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)",
            "masked_values = tf.boolean_mask(in1, in2)\n     segment_ids = tf.cumsum(in2, axis=-1)\n     product_values = tf.math.unsorted_segment_prod(masked_values, segment_ids - 1, tf.reduce_sum(in2))\n     return product_values",
            "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)",
            "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)",
            "masked = tf.boolean_mask(in1, in2)\n     return tf.reduce_prod(masked, axis=1)"
        ],
        "response": {
            "task_id": "stackoverflow_38",
            "completions": [
                "mark = tf.cast(in2, tf.float32)\nproduct = tf.reduce_prod(tf.multiply(in1, mark), axis=1)\nreturn product",
                "mask = tf.cast(in2, tf.bool)\nmasked_in1 = tf.boolean_mask(in1, mask)\nproduct = tf.reduce_prod(masked_in1)\nreturn product",
                "# The problem requires us to multiply those elements in in1 array which are marked by 1 in the in2 array.\n# Here, we will:\n# 1. Use tf.boolean_mask to generate a list of lists with only elements marked by 1 in in2.\n# 2. Use tf.reduce_prod on these lists to get the product of each list. Since we are using reduce operation along axis = 1, we'll get products for each group of elements marked by 1 in in2.\n\ndef transform(in1,in2):\n    # cast inputs to tensors\n    in1 = tf.constant(in1,dtype=tf.int32)\n    in2 = tf.constant(in2,dtype=tf.bool)\n\n    masked_vals = tf.boolean_mask(in1, in2)\n    products = tf.reduce_prod(masked_vals,1)\n    return products.numpy()",
                "masked_inputs = tf.boolean_mask(in1, in2)\n     output = tf.reduce_prod(masked_inputs, axis=1)\n     return output",
                "# tf.boolean_mask is used to select the elements in the tensor that are specified by the mask. \n# Then tf.reduce_prod is used to compute the product of these elements.\n\ndef transform(in1,in2):\n   output = []\n   for row in in2:\n       mask = tf.cast(row, dtype=tf.bool)\n       selected_elements = tf.boolean_mask(in1, mask)\n       output.append(tf.reduce_prod(selected_elements))\n   return output",
                "return tf.reduce_prod(tf.boolean_mask(in1, tf.cast(in2, tf.bool)), axis=1)",
                "masked_values = tf.boolean_mask(in1, in2)\n     segment_ids = tf.cumsum(in2, axis=-1)\n     product_values = tf.math.unsorted_segment_prod(masked_values, segment_ids - 1, tf.reduce_sum(in2))\n     return product_values",
                "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)",
                "return tf.reduce_prod(tf.boolean_mask(in1, in2), axis=1)",
                "masked = tf.boolean_mask(in1, in2)\n     return tf.reduce_prod(masked, axis=1)"
            ],
            "target-program": "tf.reduce_prod(tf.maximum(tf.reduce_max(in2), tf.multiply(in1, in2)), axis=1)",
            "description": "compute the product of marked elements",
            "tf_operators": {
                "tf.reduce_prod": 9,
                "tf.cast": 4,
                "tf.float32": 1,
                "tf.multiply": 1,
                "tf.bool": 4,
                "tf.boolean_mask": 9,
                "tf.int32": 1,
                "tf.constant": 1,
                "tf.cumsum": 1,
                "tf.reduce_sum": 1,
                "tf.math.unsorted_segment_prod": 1
            },
            "coverage_percentage": 50.0,
            "total_in_target": 4,
            "total_covered": 2
        }
    },
    {
        "constants": "[]",
        "description": "(\\'set to 0 the elements with absolute value less than 1, and square the other elements\\')",
        "target_program": "tf.multiply(tf.square(in1), tf.cast(tf.cast(tf.cast(in1, tf.int32), tf.bool), tf.float32))",
        "source": "https://stackoverflow.com/questions/37912161/how-can-i-compute-element-wise-conditionals-on-batches-in-tensorflow",
        "name": "stackoverflow_39",
        "examples": {
            "inputs": "[[[-1.5, 1.0, 0.9, 2.0], [1.1, 0.0, -0.1, -0.9], [-1.0, 0.1, -1.1, 2.5]],]",
            "outputs": "[[2.25, 1.0, 0.0, 4.0],    [1.21, 0.0, 0.0, 0.0],    [1.0, 0.0, 1.21, 6.25]]"
        },
        "completions": [
            "condition = tf.abs(in1) >= 1\nin1 = tf.where(condition, tf.square(in1), 0)\nreturn in1",
            "condition = tf.greater_equal(tf.abs(in1), 1)\nreturn tf.where(condition, tf.square(in1), tf.zeros_like(in1))",
            "condition = tf.greater(tf.abs(in1), 1)\nout = tf.where(condition, tf.square(in1), 0)\nreturn out",
            "mask = tf.greater_equal(tf.abs(in1), tf.constant(1.0))\nsquared = tf.square(in1)\nzeros = tf.zeros_like(in1)\nfiltered = tf.where(mask, squared, zeros)\nreturn filtered",
            "# First step: find the elements with absolute value less than 1\n    abs_less_than_1 = tf.less(tf.abs(in1), 1)\n\n    # Second step: create a tensor of the same shape with all elements being 0\n    zeros = tf.zeros_like(in1)\n\n    # Third step: replace the elements with absolute value less than 1 by 0\n    replaced = tf.where(abs_less_than_1, zeros, in1)\n\n    # Fourth step: square the other elements\n    squared = tf.square(replaced)\n\n    return squared",
            "mask = tf.greater_equal(tf.abs(in1), 1)\nsquared_tensor = tf.square(in1)\nzero_tensor = tf.zeros_like(in1)\nreturn tf.where(mask, squared_tensor, zero_tensor)",
            "condition = tf.greater_equal(tf.abs(in1), 1)\nout = tf.where(condition, tf.square(in1), 0)\nreturn out",
            "abs_in1 = tf.abs(in1)\nmask = tf.greater(abs_in1, tf.constant(1., dtype=tf.float32))\nsquared = tf.square(in1)\nresult = tf.where(mask, squared, tf.zeros_like(in1))\nreturn result",
            "# The function first uses `tf.greater_equal` to create a boolean mask where all values with absolute value >= 1 are True\n# then, it uses `tf.boolean_mask` to apply the mask to the original tensor and square these values with `tf.square`\n# then, it sets all the values that were less than 1 to 0 using `tf.tensor_scatter_nd_update`, with the indices found with `tf.where`\n\n  abs_in1 = tf.abs(in1)\n  condition = tf.greater_equal(abs_in1, 1.0)\n  squares = tf.square(tf.boolean_mask(in1, condition))\n  indices = tf.where(tf.math.logical_not(condition))\n  output = tf.tensor_scatter_nd_update(in1, indices, tf.zeros_like(indices, dtype=in1.dtype))\n  return output",
            "mask = tf.greater_equal(tf.abs(in1), 1)\nresult = tf.where(mask, tf.square(in1), 0)\nreturn result"
        ],
        "response": {
            "task_id": "stackoverflow_39",
            "completions": [
                "condition = tf.abs(in1) >= 1\nin1 = tf.where(condition, tf.square(in1), 0)\nreturn in1",
                "condition = tf.greater_equal(tf.abs(in1), 1)\nreturn tf.where(condition, tf.square(in1), tf.zeros_like(in1))",
                "condition = tf.greater(tf.abs(in1), 1)\nout = tf.where(condition, tf.square(in1), 0)\nreturn out",
                "mask = tf.greater_equal(tf.abs(in1), tf.constant(1.0))\nsquared = tf.square(in1)\nzeros = tf.zeros_like(in1)\nfiltered = tf.where(mask, squared, zeros)\nreturn filtered",
                "# First step: find the elements with absolute value less than 1\n    abs_less_than_1 = tf.less(tf.abs(in1), 1)\n\n    # Second step: create a tensor of the same shape with all elements being 0\n    zeros = tf.zeros_like(in1)\n\n    # Third step: replace the elements with absolute value less than 1 by 0\n    replaced = tf.where(abs_less_than_1, zeros, in1)\n\n    # Fourth step: square the other elements\n    squared = tf.square(replaced)\n\n    return squared",
                "mask = tf.greater_equal(tf.abs(in1), 1)\nsquared_tensor = tf.square(in1)\nzero_tensor = tf.zeros_like(in1)\nreturn tf.where(mask, squared_tensor, zero_tensor)",
                "condition = tf.greater_equal(tf.abs(in1), 1)\nout = tf.where(condition, tf.square(in1), 0)\nreturn out",
                "abs_in1 = tf.abs(in1)\nmask = tf.greater(abs_in1, tf.constant(1., dtype=tf.float32))\nsquared = tf.square(in1)\nresult = tf.where(mask, squared, tf.zeros_like(in1))\nreturn result",
                "# The function first uses `tf.greater_equal` to create a boolean mask where all values with absolute value >= 1 are True\n# then, it uses `tf.boolean_mask` to apply the mask to the original tensor and square these values with `tf.square`\n# then, it sets all the values that were less than 1 to 0 using `tf.tensor_scatter_nd_update`, with the indices found with `tf.where`\n\n  abs_in1 = tf.abs(in1)\n  condition = tf.greater_equal(abs_in1, 1.0)\n  squares = tf.square(tf.boolean_mask(in1, condition))\n  indices = tf.where(tf.math.logical_not(condition))\n  output = tf.tensor_scatter_nd_update(in1, indices, tf.zeros_like(indices, dtype=in1.dtype))\n  return output",
                "mask = tf.greater_equal(tf.abs(in1), 1)\nresult = tf.where(mask, tf.square(in1), 0)\nreturn result"
            ],
            "target-program": "tf.multiply(tf.square(in1), tf.cast(tf.cast(tf.cast(in1, tf.int32), tf.bool), tf.float32))",
            "description": "(\\'set to 0 the elements with absolute value less than 1, and square the other elements\\')",
            "tf_operators": {
                "tf.square": 10,
                "tf.abs": 10,
                "tf.where": 10,
                "tf.greater_equal": 6,
                "tf.zeros_like": 6,
                "tf.greater": 2,
                "tf.constant": 2,
                "tf.less": 1,
                "tf.float32": 1,
                "tf.math.logical_not": 1,
                "tf.tensor_scatter_nd_update": 1,
                "tf.boolean_mask": 1
            },
            "coverage_percentage": 33.33333333333333,
            "total_in_target": 6,
            "total_covered": 2
        }
    },
    {
        "constants": "[]",
        "description": "use the output of tf.nn.top_k to make a sparse tensor",
        "target_program": "tf.sparse.to_dense(tf.SparseTensor(tf.cast(in2, tf.int64), in1, (3, 5)))",
        "source": "https://stackoverflow.com/questions/43996831/make-a-sparse-tensor-based-on-the-output-of-tf-nn-top-k",
        "name": "stackoverflow_40",
        "examples": {
            "inputs": "[[4, 5, 2, 7, 8, 6],[[0, 2], [0, 4], [1, 1], [1, 3], [2, 0], [2, 3]],]",
            "outputs": "[[0, 0, 4, 0, 5],[0, 2, 0, 7, 0],[8, 0, 0, 6, 0]]"
        },
        "completions": [
            "values, indices = tf.math.top_k(in1, k=tf.shape(in1)[0])\n    \n    \n    return tf.scatter_nd(indices, values, [tf.reduce_max(in2)+1, tf.shape(in1)[0]] )",
            "top_values, top_indices = tf.math.top_k(in1, k=tf.shape(in1)[0])\nsparse_tensor = tf.scatter_nd(top_indices, top_values, tf.shape(in2))\nreturn tf.transpose(sparse_tensor)",
            "values, indices = tf.math.top_k(in1, k=in1.shape[0])\nsparse_tensor = tf.scatter_nd(indices, values, tf.shape(in2))\nreturn tf.transpose(sparse_tensor)",
            "values, indices = tf.math.top_k(in1, k=in1.shape[0])\nsparse_tensor = tf.scatter_nd(tf.expand_dims(indices, axis=1), values, [in1.shape[0]])\nreturn sparse_tensor",
            "values, indices = tf.math.top_k(in1, k=tf.size(in1))\nsparse_tensor = tf.scatter_nd(indices=tf.expand_dims(indices, axis=1), updates=values, shape=tf.shape(in1))\ndense_tensor = tf.sparse.to_dense(sparse_tensor)\nout = tf.gather(dense_tensor,in2,axis=0)\nreturn out",
            "values, indices = tf.nn.top_k(in1, k=tf.shape(in1)[-1])\nindices_flattened = tf.reshape(indices, [-1])\nvalues_flattened = tf.reshape(values, [-1])\nreturn tf.scatter_nd(in2, values_flattened, tf.reduce_max(indices)+1)",
            "values, indices = tf.math.top_k(in1, k=in1.shape[0])\nsparse_tensor = tf.scatter_nd(indices, values, [in2.shape[0], tf.reduce_max(indices)+1])\nreturn tf.cast(sparse_tensor, in1.dtype)",
            "top, indices = tf.math.top_k(in1, len(in1))\nsparse_tensor = tf.scatter_nd(tf.expand_dims(indices, 1), top, [in2.shape[0], tf.reduce_max(in2) + 1])\nreturn sparse_tensor",
            "top_values, top_indices = tf.math.top_k(in1, k=tf.shape(in1)[0])\nindices = tf.transpose(tf.expand_dims(top_indices, -1))\nsparse = tf.SparseTensor(indices=indices, values=top_values, dense_shape=tf.shape(in1))\nfinal_output = tf.sparse.to_dense(sparse)\n\nreturn final_output",
            "values, indices = tf.math.top_k(in1, k=len(in1))\nsparse_tensor = tf.scatter_nd(tf.expand_dims(indices, 1), values, [len(in1)])\nreturn sparse_tensor"
        ],
        "response": {
            "task_id": "stackoverflow_40",
            "completions": [
                "values, indices = tf.math.top_k(in1, k=tf.shape(in1)[0])\n    \n    \n    return tf.scatter_nd(indices, values, [tf.reduce_max(in2)+1, tf.shape(in1)[0]] )",
                "top_values, top_indices = tf.math.top_k(in1, k=tf.shape(in1)[0])\nsparse_tensor = tf.scatter_nd(top_indices, top_values, tf.shape(in2))\nreturn tf.transpose(sparse_tensor)",
                "values, indices = tf.math.top_k(in1, k=in1.shape[0])\nsparse_tensor = tf.scatter_nd(indices, values, tf.shape(in2))\nreturn tf.transpose(sparse_tensor)",
                "values, indices = tf.math.top_k(in1, k=in1.shape[0])\nsparse_tensor = tf.scatter_nd(tf.expand_dims(indices, axis=1), values, [in1.shape[0]])\nreturn sparse_tensor",
                "values, indices = tf.math.top_k(in1, k=tf.size(in1))\nsparse_tensor = tf.scatter_nd(indices=tf.expand_dims(indices, axis=1), updates=values, shape=tf.shape(in1))\ndense_tensor = tf.sparse.to_dense(sparse_tensor)\nout = tf.gather(dense_tensor,in2,axis=0)\nreturn out",
                "values, indices = tf.nn.top_k(in1, k=tf.shape(in1)[-1])\nindices_flattened = tf.reshape(indices, [-1])\nvalues_flattened = tf.reshape(values, [-1])\nreturn tf.scatter_nd(in2, values_flattened, tf.reduce_max(indices)+1)",
                "values, indices = tf.math.top_k(in1, k=in1.shape[0])\nsparse_tensor = tf.scatter_nd(indices, values, [in2.shape[0], tf.reduce_max(indices)+1])\nreturn tf.cast(sparse_tensor, in1.dtype)",
                "top, indices = tf.math.top_k(in1, len(in1))\nsparse_tensor = tf.scatter_nd(tf.expand_dims(indices, 1), top, [in2.shape[0], tf.reduce_max(in2) + 1])\nreturn sparse_tensor",
                "top_values, top_indices = tf.math.top_k(in1, k=tf.shape(in1)[0])\nindices = tf.transpose(tf.expand_dims(top_indices, -1))\nsparse = tf.SparseTensor(indices=indices, values=top_values, dense_shape=tf.shape(in1))\nfinal_output = tf.sparse.to_dense(sparse)\n\nreturn final_output",
                "values, indices = tf.math.top_k(in1, k=len(in1))\nsparse_tensor = tf.scatter_nd(tf.expand_dims(indices, 1), values, [len(in1)])\nreturn sparse_tensor"
            ],
            "target-program": "tf.sparse.to_dense(tf.SparseTensor(tf.cast(in2, tf.int64), in1, (3, 5)))",
            "description": "use the output of tf.nn.top_k to make a sparse tensor",
            "tf_operators": {
                "tf.reduce_max": 4,
                "tf.scatter_nd": 9,
                "tf.math.top_k": 9,
                "tf.shape": 6,
                "tf.transpose": 3,
                "tf.expand_dims": 5,
                "tf.sparse.to_dense": 2,
                "tf.size": 1,
                "tf.gather": 1,
                "tf.reshape": 1,
                "tf.nn.top_k": 1,
                "tf.cast": 1,
                "tf.SparseTensor": 1
            },
            "coverage_percentage": 75.0,
            "total_in_target": 4,
            "total_covered": 3
        }
    },
    {
        "constants": "[]",
        "description": "copy all elements except at the given index",
        "target_program": "tf.boolean_mask(in1, tf.not_equal(tf.constant(in2), tf.range(10)))",
        "source": "https://stackoverflow.com/questions/54499051/elegant-way-to-access-python-list-and-tensor-in-tensorflow",
        "name": "stackoverflow_41",
        "examples": {
            "inputs": "[[5, 2, 8, 2, 4, 1, 1, 0, 2, 1],3,]",
            "outputs": "[5, 2, 8, 4, 1, 1, 0, 2, 1]"
        },
        "completions": [
            "indices_to_keep = tf.range(tf.shape(in1)[0])\n    indices_to_keep = tf.boolean_mask(indices_to_keep, tf.not_equal(indices_to_keep, in2))\n    return tf.gather(in1, indices_to_keep)",
            "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, mask)",
            "indices = tf.range(tf.shape(in1)[0])\n    mask = tf.not_equal(indices, in2)\n    return tf.boolean_mask(in1, mask)",
            "indices = tf.range(tf.shape(in1)[0])\n    indices = tf.boolean_mask(indices, tf.not_equal(indices, in2))\n    return tf.gather(in1, indices)",
            "indices = tf.range(tf.shape(in1)[0])\nfiltered_indices = tf.boolean_mask(indices, tf.not_equal(indices, in2))\nreturn tf.gather(in1, filtered_indices)",
            "indices_to_keep = tf.where(tf.not_equal(tf.range(tf.shape(in1)[0]), in2))\n     return tf.gather(in1, indices_to_keep)",
            "indices = tf.range(start=0, limit=tf.shape(in1)[0])\nmasked = tf.not_equal(indices, in2)\nresult = tf.boolean_mask(in1, masked)\nreturn result",
            "# This task involves deleting an element at a specified index from the tensor.\n# To achieve this, we will slice the tensor into two parts: before and after the specified index. \n# Then we will concatenate these parts together, effectively skipping the element at the specified index.\n# We'll use tf.concat, tf.slice, and tf.shape operations from Tensorflow.\n\ndef transform(in1,in2):\n    length = tf.shape(in1)[0]\n    before = tf.slice(in1, [0], [in2])\n    after = tf.slice(in1, [in2+1], [length-in2-1])\n    result = tf.concat([before, after], 0)\n    return result",
            "indices = tf.range(tf.shape(in1)[0])\n    mask = tf.not_equal(indices, in2)\n    output = tf.boolean_mask(in1, mask)\n    return output",
            "indices = tf.range(tf.shape(in1)[0])\nindices_to_keep = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, indices_to_keep)"
        ],
        "response": {
            "task_id": "stackoverflow_41",
            "completions": [
                "indices_to_keep = tf.range(tf.shape(in1)[0])\n    indices_to_keep = tf.boolean_mask(indices_to_keep, tf.not_equal(indices_to_keep, in2))\n    return tf.gather(in1, indices_to_keep)",
                "indices = tf.range(tf.shape(in1)[0])\nmask = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, mask)",
                "indices = tf.range(tf.shape(in1)[0])\n    mask = tf.not_equal(indices, in2)\n    return tf.boolean_mask(in1, mask)",
                "indices = tf.range(tf.shape(in1)[0])\n    indices = tf.boolean_mask(indices, tf.not_equal(indices, in2))\n    return tf.gather(in1, indices)",
                "indices = tf.range(tf.shape(in1)[0])\nfiltered_indices = tf.boolean_mask(indices, tf.not_equal(indices, in2))\nreturn tf.gather(in1, filtered_indices)",
                "indices_to_keep = tf.where(tf.not_equal(tf.range(tf.shape(in1)[0]), in2))\n     return tf.gather(in1, indices_to_keep)",
                "indices = tf.range(start=0, limit=tf.shape(in1)[0])\nmasked = tf.not_equal(indices, in2)\nresult = tf.boolean_mask(in1, masked)\nreturn result",
                "# This task involves deleting an element at a specified index from the tensor.\n# To achieve this, we will slice the tensor into two parts: before and after the specified index. \n# Then we will concatenate these parts together, effectively skipping the element at the specified index.\n# We'll use tf.concat, tf.slice, and tf.shape operations from Tensorflow.\n\ndef transform(in1,in2):\n    length = tf.shape(in1)[0]\n    before = tf.slice(in1, [0], [in2])\n    after = tf.slice(in1, [in2+1], [length-in2-1])\n    result = tf.concat([before, after], 0)\n    return result",
                "indices = tf.range(tf.shape(in1)[0])\n    mask = tf.not_equal(indices, in2)\n    output = tf.boolean_mask(in1, mask)\n    return output",
                "indices = tf.range(tf.shape(in1)[0])\nindices_to_keep = tf.not_equal(indices, in2)\nreturn tf.boolean_mask(in1, indices_to_keep)"
            ],
            "target-program": "tf.boolean_mask(in1, tf.not_equal(tf.constant(in2), tf.range(10)))",
            "description": "copy all elements except at the given index",
            "tf_operators": {
                "tf.not_equal": 9,
                "tf.range": 9,
                "tf.gather": 4,
                "tf.boolean_mask": 8,
                "tf.shape": 10,
                "tf.where": 1,
                "tf.slice": 1,
                "tf.concat": 1
            },
            "coverage_percentage": 75.0,
            "total_in_target": 4,
            "total_covered": 3
        }
    },
    {
        "constants": "[]",
        "description": "create a binary vector where the max element is 1",
        "target_program": "tf.cast(tf.equal(in1, tf.reduce_max(in1)), tf.int32)",
        "source": "https://stackoverflow.com/questions/54493814/binary-vector-of-max",
        "name": "stackoverflow_42",
        "examples": {
            "inputs": "[[4, 6, 2, 6, 7, 3, -3],]",
            "outputs": "[0, 0, 0, 0, 1, 0, 0]"
        },
        "completions": [
            "# First, I will find the max value in the list using tf.reduce_max\n# Then, I will create a binary list with tf.equal comparing each element to the max value\n# Lastly, I will cast the boolean list back to integers with tf.cast\n\nmax_value = tf.reduce_max(in1)\nbinary_vector = tf.equal(in1, max_value)\nbinary_vector = tf.cast(binary_vector, tf.int32)\nreturn binary_vector",
            "max_val = tf.reduce_max(in1)\nbinary_vector = tf.cast(tf.equal(in1, max_val), int32)\nreturn binary_vector",
            "max_elem = tf.reduce_max(in1)\nbinary_vector = tf.cast(tf.equal(in1, max_elem), tf.int32)\nreturn binary_vector",
            "max_val = tf.reduce_max(in1)\nbinary_vector = tf.cast(tf.equal(in1, max_val), tf.int32)\nreturn binary_vector",
            "max_val = tf.reduce_max(in1)\nreturn tf.cast(tf.equal(in1, max_val), tf.int32)",
            "max_element = tf.reduce_max(in1)\nbinary_vector = tf.where(tf.equal(in1, max_element), tf.ones_like(in1), tf.zeros_like(in1))\nreturn binary_vector",
            "max_val = tf.reduce_max(in1)\nbinary_vector = tf.cast(tf.equal(in1, max_val), tf.int32)\nreturn binary_vector",
            "max_value = tf.reduce_max(in1)\nbinary_vector = tf.equal(in1, max_value)\nbinary_vector = tf.cast(binary_vector, tf.int32)\nreturn binary_vector",
            "max_val = tf.reduce_max(in1)\nout = tf.cast(tf.equal(in1, max_val), tf.int32)\nreturn out",
            "max_element = tf.reduce_max(in1)\nbin_vec = tf.cast(tf.equal(in1, max_element), tf.int32)\nreturn bin_vec"
        ],
        "response": {
            "task_id": "stackoverflow_42",
            "completions": [
                "# First, I will find the max value in the list using tf.reduce_max\n# Then, I will create a binary list with tf.equal comparing each element to the max value\n# Lastly, I will cast the boolean list back to integers with tf.cast\n\nmax_value = tf.reduce_max(in1)\nbinary_vector = tf.equal(in1, max_value)\nbinary_vector = tf.cast(binary_vector, tf.int32)\nreturn binary_vector",
                "max_val = tf.reduce_max(in1)\nbinary_vector = tf.cast(tf.equal(in1, max_val), int32)\nreturn binary_vector",
                "max_elem = tf.reduce_max(in1)\nbinary_vector = tf.cast(tf.equal(in1, max_elem), tf.int32)\nreturn binary_vector",
                "max_val = tf.reduce_max(in1)\nbinary_vector = tf.cast(tf.equal(in1, max_val), tf.int32)\nreturn binary_vector",
                "max_val = tf.reduce_max(in1)\nreturn tf.cast(tf.equal(in1, max_val), tf.int32)",
                "max_element = tf.reduce_max(in1)\nbinary_vector = tf.where(tf.equal(in1, max_element), tf.ones_like(in1), tf.zeros_like(in1))\nreturn binary_vector",
                "max_val = tf.reduce_max(in1)\nbinary_vector = tf.cast(tf.equal(in1, max_val), tf.int32)\nreturn binary_vector",
                "max_value = tf.reduce_max(in1)\nbinary_vector = tf.equal(in1, max_value)\nbinary_vector = tf.cast(binary_vector, tf.int32)\nreturn binary_vector",
                "max_val = tf.reduce_max(in1)\nout = tf.cast(tf.equal(in1, max_val), tf.int32)\nreturn out",
                "max_element = tf.reduce_max(in1)\nbin_vec = tf.cast(tf.equal(in1, max_element), tf.int32)\nreturn bin_vec"
            ],
            "target-program": "tf.cast(tf.equal(in1, tf.reduce_max(in1)), tf.int32)",
            "description": "create a binary vector where the max element is 1",
            "tf_operators": {
                "tf.reduce_max": 10,
                "tf.int32": 8,
                "tf.cast": 9,
                "tf.equal": 10,
                "tf.zeros_like": 1,
                "tf.ones_like": 1,
                "tf.where": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 4,
            "total_covered": 4
        }
    },
    {
        "constants": "[]",
        "description": "extract elements of a tensor given row indices",
        "target_program": "tf.gather_nd(tf.transpose(in1), tf.expand_dims(in2, 1), batch_dims=1)",
        "source": "https://stackoverflow.com/questions/54455169/better-way-to-access-individual-elements-in-a-tensor",
        "name": "stackoverflow_43",
        "examples": {
            "inputs": "[[[12, 34, 56, 78, 90, 10], [99, 88, 77, 55, 44, 33], [-1, -2, -3, -4, -5, -6]],[0, 1, 1, 0, 2, 0],]",
            "outputs": "[12, 88, 77, 78, -5, 10]"
        },
        "completions": [
            "return tf.gather_nd(in1, tf.transpose(tf.stack([in2, tf.range(tf.size(in2))])))",
            "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1))",
            "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1))",
            "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1))",
            "return tf.gather_nd(in1, tf.stack((tf.range(tf.size(in2)), in2), axis=1))",
            "return tf.gather(in1, in2, axis=0).numpy().tolist()",
            "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1))",
            "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1)).numpy()",
            "return tf.gather(in1, in2, axis=1)",
            "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1))"
        ],
        "response": {
            "task_id": "stackoverflow_43",
            "completions": [
                "return tf.gather_nd(in1, tf.transpose(tf.stack([in2, tf.range(tf.size(in2))])))",
                "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1))",
                "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1))",
                "return tf.gather_nd(in1, tf.stack([tf.range(tf.shape(in2)[0]), in2], axis=1))",
                "return tf.gather_nd(in1, tf.stack((tf.range(tf.size(in2)), in2), axis=1))",
                "return tf.gather(in1, in2, axis=0).numpy().tolist()",
                "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1))",
                "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1)).numpy()",
                "return tf.gather(in1, in2, axis=1)",
                "return tf.gather_nd(in1, tf.stack([in2, tf.range(tf.shape(in2)[0])], axis=1))"
            ],
            "target-program": "tf.gather_nd(tf.transpose(in1), tf.expand_dims(in2, 1), batch_dims=1)",
            "description": "extract elements of a tensor given row indices",
            "tf_operators": {
                "tf.size": 2,
                "tf.stack": 8,
                "tf.gather_nd": 8,
                "tf.transpose": 1,
                "tf.range": 8,
                "tf.shape": 6,
                "tf.gather": 2
            },
            "coverage_percentage": 66.66666666666666,
            "total_in_target": 3,
            "total_covered": 2
        }
    },
    {
        "constants": "[2]",
        "description": "sum across columns for pairs of consecutive rows",
        "target_program": "tf.squeeze(tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1))",
        "source": "https://stackoverflow.com/questions/54402389/sum-the-columns-for-each-two-consecutive-rows-of-a-tensor-of-3-dimensions",
        "name": "stackoverflow_44",
        "examples": {
            "inputs": "[[[3, 5, 2], [6, 2, 3], [8, 7, 1], [0, -3, 5], [-4, 7, 3], [2, 1, 6], [10, 20, 30], [4, 5, 6]],]",
            "outputs": "[[9, 7, 5],    [8, 4, 6],    [-2, 8, 9],    [14, 25, 36]]"
        },
        "completions": [
            "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
            "pairs = tf.reshape(in1, (-1, 2, in1.shape[1]))\nreturn tf.reduce_sum(pairs, axis=1)",
            "return tf.reduce_sum(tf.reshape(in1, (-1, 2, 3)), axis=1)",
            "return tf.reduce_sum(tf.reshape(in1, [-1, 2, in1.shape[1]]), axis=1)",
            "return tf.reduce_sum(tf.reshape(in1, (-1, 2, tf.shape(in1)[-1])), axis=1)",
            "return tf.reduce_sum(tf.reshape(in1, [-1, 2, in1.shape[1]]), axis=1)",
            "return tf.reduce_sum(tf.reshape(in1, (-1, 2, tf.shape(in1)[-1])), axis=1)",
            "# I will perform the operation in two steps:\n    # 1) Add consecutive rows using tf.add method with argument as slices of original tensor\n    # 2) Compute sum across columns using tf.reduce_sum with axis = 1\n\ndef transform(in1):\n    in1 = tf.constant(in1, dtype=tf.int32)\n    \n    row_pairs_sum = tf.add(in1[::2], in1[1::2])\n    col_sum = tf.reduce_sum(row_pairs_sum, axis=1)\n    \n    return col_sum.numpy().tolist()",
            "return tf.reduce_sum(tf.reshape(in1, (-1, 2, 3)), axis=1)",
            "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)"
        ],
        "response": {
            "task_id": "stackoverflow_44",
            "completions": [
                "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)",
                "pairs = tf.reshape(in1, (-1, 2, in1.shape[1]))\nreturn tf.reduce_sum(pairs, axis=1)",
                "return tf.reduce_sum(tf.reshape(in1, (-1, 2, 3)), axis=1)",
                "return tf.reduce_sum(tf.reshape(in1, [-1, 2, in1.shape[1]]), axis=1)",
                "return tf.reduce_sum(tf.reshape(in1, (-1, 2, tf.shape(in1)[-1])), axis=1)",
                "return tf.reduce_sum(tf.reshape(in1, [-1, 2, in1.shape[1]]), axis=1)",
                "return tf.reduce_sum(tf.reshape(in1, (-1, 2, tf.shape(in1)[-1])), axis=1)",
                "# I will perform the operation in two steps:\n    # 1) Add consecutive rows using tf.add method with argument as slices of original tensor\n    # 2) Compute sum across columns using tf.reduce_sum with axis = 1\n\ndef transform(in1):\n    in1 = tf.constant(in1, dtype=tf.int32)\n    \n    row_pairs_sum = tf.add(in1[::2], in1[1::2])\n    col_sum = tf.reduce_sum(row_pairs_sum, axis=1)\n    \n    return col_sum.numpy().tolist()",
                "return tf.reduce_sum(tf.reshape(in1, (-1, 2, 3)), axis=1)",
                "return tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1)"
            ],
            "target-program": "tf.squeeze(tf.reduce_sum(tf.reshape(in1, (-1, 2, in1.shape[1])), axis=1))",
            "description": "sum across columns for pairs of consecutive rows",
            "tf_operators": {
                "tf.reduce_sum": 10,
                "tf.reshape": 9,
                "tf.shape": 2,
                "tf.int32": 1,
                "tf.add": 1,
                "tf.constant": 1
            },
            "coverage_percentage": 66.66666666666666,
            "total_in_target": 3,
            "total_covered": 2
        }
    },
    {
        "constants": "[]",
        "description": "reverse the order in the marked rows",
        "target_program": "tf.where(tf.sequence_mask(in2), x=tf.roll(in1, 1, -1), y=in1)",
        "source": "https://stackoverflow.com/questions/54337925/reverse-order-of-some-elements-in-tensorflow",
        "name": "stackoverflow_45",
        "examples": {
            "inputs": "[[[[12, 34], [56, 78], [23, 54], [76, 78], [42, 24]]],[1, 0, 1, 0, 1],]",
            "outputs": "[[[34, 12], [56, 78], [54, 23], [76, 78], [24, 42]]]"
        },
        "completions": [
            "return tf.where(tf.expand_dims(tf.cast(in2, tf.bool), axis=-1), tf.reverse(in1,[2]), in1)",
            "return tf.where(tf.cast(tf.expand_dims(in2, axis=-1), dtype=bool), tf.reverse(in1, axis=[-1]), in1)",
            "return tf.where(tf.expand_dims(in2, axis=-1), tf.reverse(in1, axis=[-1]), in1)",
            "return tf.where(tf.expand_dims(in2, axis=-1), tf.reverse(in1, [-1]), in1)",
            "return tf.where(tf.expand_dims(in2, axis=-1), tf.reverse(in1, axis=[-1]), in1)",
            "return tf.where(in2[:,None], tf.reverse(in1, axis=[-1]), in1)",
            "return tf.where(tf.cast(tf.expand_dims(in2, axis=-1), dtype=bool), tf.reverse(in1, axis=[-1]), in1)",
            "return tf.where(tf.expand_dims(in2, -1), tf.reverse(in1, [-1]), in1)",
            "out = tf.where(tf.expand_dims(in2, axis=2), tf.reverse(in1, axis=[2]), in1)\nreturn out",
            "return tf.where(tf.expand_dims(in2, axis=-1), tf.reverse(in1, axis=[-1]), in1)"
        ],
        "response": {
            "task_id": "stackoverflow_45",
            "completions": [
                "return tf.where(tf.expand_dims(tf.cast(in2, tf.bool), axis=-1), tf.reverse(in1,[2]), in1)",
                "return tf.where(tf.cast(tf.expand_dims(in2, axis=-1), dtype=bool), tf.reverse(in1, axis=[-1]), in1)",
                "return tf.where(tf.expand_dims(in2, axis=-1), tf.reverse(in1, axis=[-1]), in1)",
                "return tf.where(tf.expand_dims(in2, axis=-1), tf.reverse(in1, [-1]), in1)",
                "return tf.where(tf.expand_dims(in2, axis=-1), tf.reverse(in1, axis=[-1]), in1)",
                "return tf.where(in2[:,None], tf.reverse(in1, axis=[-1]), in1)",
                "return tf.where(tf.cast(tf.expand_dims(in2, axis=-1), dtype=bool), tf.reverse(in1, axis=[-1]), in1)",
                "return tf.where(tf.expand_dims(in2, -1), tf.reverse(in1, [-1]), in1)",
                "out = tf.where(tf.expand_dims(in2, axis=2), tf.reverse(in1, axis=[2]), in1)\nreturn out",
                "return tf.where(tf.expand_dims(in2, axis=-1), tf.reverse(in1, axis=[-1]), in1)"
            ],
            "target-program": "tf.where(tf.sequence_mask(in2), x=tf.roll(in1, 1, -1), y=in1)",
            "description": "reverse the order in the marked rows",
            "tf_operators": {
                "tf.bool": 1,
                "tf.reverse": 10,
                "tf.expand_dims": 9,
                "tf.cast": 3,
                "tf.where": 10
            },
            "coverage_percentage": 33.33333333333333,
            "total_in_target": 3,
            "total_covered": 1
        }
    },
    {
        "constants": "[]",
        "description": "convert segment lengths to segment ids",
        "target_program": "tf.cast(tf.where(tf.sequence_mask(in1))[:, 0], tf.int32)",
        "source": "https://stackoverflow.com/questions/58652161/how-to-convert-2-3-4-to-0-0-1-1-1-2-2-2-2-to-utilize-tf-math-segment-sum",
        "name": "stackoverflow_46",
        "examples": {
            "inputs": "[[3, 4, 1],]",
            "outputs": "[0, 0, 0, 1, 1, 1, 1, 2]"
        },
        "completions": [
            "return tf.concat([tf.fill([in1[i]], i) for i in range(tf.shape(in1)[0])], 0)",
            "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
            "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
            "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
            "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
            "output = tf.repeat(tf.range(tf.shape(in1)[0]), in1)\nreturn output",
            "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
            "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
            "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
            "return tf.repeat(tf.range(len(in1)), in1)"
        ],
        "response": {
            "task_id": "stackoverflow_46",
            "completions": [
                "return tf.concat([tf.fill([in1[i]], i) for i in range(tf.shape(in1)[0])], 0)",
                "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
                "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
                "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
                "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
                "output = tf.repeat(tf.range(tf.shape(in1)[0]), in1)\nreturn output",
                "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
                "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
                "return tf.repeat(tf.range(tf.shape(in1)[0]), in1)",
                "return tf.repeat(tf.range(len(in1)), in1)"
            ],
            "target-program": "tf.cast(tf.where(tf.sequence_mask(in1))[:, 0], tf.int32)",
            "description": "convert segment lengths to segment ids",
            "tf_operators": {
                "tf.fill": 1,
                "tf.concat": 1,
                "tf.shape": 9,
                "tf.repeat": 9,
                "tf.range": 9
            },
            "coverage_percentage": 0.0,
            "total_in_target": 4,
            "total_covered": 0
        }
    },
    {
        "constants": "[]",
        "description": "put given values into a sequence mask",
        "target_program": "tf.reshape(tf.gather(in1, tf.cumsum(tf.reshape(tf.cast(in2, tf.int32), [-1]), exclusive=True) * tf.reshape(tf.cast(in2, tf.int32), [-1])), in2.shape)",
        "source": "https://stackoverflow.com/questions/58641546/how-can-i-put-the-sequential-values-to-the-sequence-mask",
        "name": "stackoverflow_47",
        "examples": {
            "inputs": "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16],[[True, True, True, False, False], [True, True, False, False, False], [True, True, True, True, True], [True, True, True, True, False], [True, False, False, False, False], [True, True, False, False, False]],]",
            "outputs": "[[0, 1, 2, 0, 0],    [3, 4, 0, 0, 0],    [5, 6, 7, 8, 9],    [10, 11, 12, 13, 0],    [14, 0, 0, 0, 0],    [15, 16, 0, 0, 0]]"
        },
        "completions": [
            "mask = tf.boolean_mask(in1, tf.reshape(in2, [-1]))\nreturn tf.reshape(mask, tf.shape(in2))",
            "seq_mask = tf.sequence_mask(tf.reduce_sum(tf.cast(in2, tf.int32), axis=1))\nmask_indices = tf.where(seq_mask)\nin1_reshaped = tf.reshape(in1, [-1])\nresult = tf.scatter_nd(mask_indices, tf.gather(in1_reshaped, mask_indices[:, 0]), tf.shape(in2))\nreturn tf.cast(result, in1_reshaped.dtype)",
            "#create a pointer to move along the values\npointer = tf.constant(0)\n\n#initialize the output as a copy of the mask with zeros instead of True\noutput = tf.zeros_like(in2)\n\n#write values function acts on a single row of the mask\ndef write_values(mask):\n    global pointer\n    #create a sequence with the same length as the mask\n    sequence = tf.range(tf.size(mask))\n    #replace True values with input values, False values remain the same\n    values = tf.where(mask, in1[pointer:pointer+tf.size(mask)], sequence)\n    #increase pointer by the number of True values in the mask\n    pointer += tf.reduce_sum(tf.cast(mask, tf.int32))\n    return values\n\n#Apply write_values on each row of the mask\noutput = tf.map_fn(write_values, in2, dtype=tf.int32)\nreturn output",
            "mask = tf.where(in2)\n     result = tf.scatter_nd(mask, tf.cast(in1, tf.int32), tf.shape(in2))\n     return result",
            "index = tf.cast(tf.cumsum(tf.cast(in2, tf.int32), axis=1) - 1, tf.int32) * tf.cast(in2, tf.int32)\n     mask_offset = tf.cumsum(tf.reduce_sum(tf.cast(in2, tf.int32), 1))\n     final_index = tf.cumsum(tf.cast(in2, tf.int32), axis=1) - 1 + tf.pad(tf.expand_dims(mask_offset[:-1], -1), [[1, 0]])\n     out = tf.where(in2, tf.gather(in1, final_index), tf.zeros_like(index))\n     return out",
            "counter = tf.constant(0)\ndef body(counter, mask_row):\n    mask_indices = tf.where(mask_row)\n    num_mask_indices = tf.shape(mask_indices)[0]\n    mask_values = tf.range(counter, counter + num_mask_indices)\n    row = tf.tensor_scatter_nd_update(tf.zeros_like(mask_row, tf.int32), mask_indices, mask_values)\n    counter += num_mask_indices\n    return counter, row\n\n_, result = tf.map_fn(lambda mask_row: body(counter, mask_row), in2, dtype=(tf.int32, tf.int32))\n\nreturn result",
            "# first we add zeros so we can select the sequence\n    mask = tf.cast(in2, tf.int32)\n    \n    # then we use sequence_mask to turn our sequence into a mask\n    seq_mask = tf.sequence_mask(mask)\n    \n    # then we gather the elements from our input using the mask\n    result = tf.boolean_mask(in1, seq_mask)\n    \n    # reshape the result to the original shape\n    result = tf.reshape(result, tf.shape(in2))\n    \n    return result",
            "counter = tf.constant([0])\n    in1 = tf.reshape(in1, [1, -1])\n    sequence_mask = tf.cast(in2, tf.int32)\n    build_tensor = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n\n    def extract_values(val, array):\n        value = tf.gather_nd(params=in1, indices=[0, tf.squeeze(val)])\n        value = tf.expand_dims(value, axis=0)\n        return tf.add(val, 1), array.write(tf.squeeze(val), value)\n\n    def insert_values(val, array):\n        value = tf.gather_nd(params=array.stack(), indices=[tf.squeeze(val)])\n        mask_indices = tf.where(sequence_mask == 1)\n        sequence_mask = tf.tensor_scatter_nd_update(tensor=sequence_mask, indices=mask_indices, updates=value)\n        return tf.add(val, 1), array\n\n    for i in range(tf.reduce_sum(sequence_mask)):\n        counter, build_tensor = tf.while_loop(cond=lambda counter, build_tensor: tf.less(counter, tf.reduce_sum(sequence_mask)),\n                                                        body=extract_values,\n                                                        loop_vars=[counter, build_tensor])\n\n    for i in range(tf.shape(sequence_mask)[0]):\n        counter, build_tensor = tf.while_loop(cond=lambda counter, build: tf.less(counter, tf.shape(sequence_mask)[0]),\n                                                        body=insert_values,\n                                                        loop_vars=[counter, build_tensor])\n\n    return sequence_mask",
            "counter = tf.constant(0)\nfinal = []\n\nfor row in in2:\n    new_row = []\n    for cell in row:\n        if cell:\n            new_row.append(in1[counter])\n            counter += 1\n        else:\n            new_row.append(0)\n    final.append(new_row)\nreturn final",
            "counter = tf.zeros_like(in2[0], dtype=tf.int32)\n     for i in range(in2.shape[0]):\n        mask = tf.cast(in2[i], tf.int32)\n        masked_values = tf.multiply(mask, in1[:tf.reduce_sum(mask)])\n        counter = tf.concat([counter, masked_values], axis=0)\n        in1 = in1[tf.reduce_sum(mask):]\n     return tf.reshape(counter[tf.size(in2[0]):], tf.shape(in2))"
        ],
        "response": {
            "task_id": "stackoverflow_47",
            "completions": [
                "mask = tf.boolean_mask(in1, tf.reshape(in2, [-1]))\nreturn tf.reshape(mask, tf.shape(in2))",
                "seq_mask = tf.sequence_mask(tf.reduce_sum(tf.cast(in2, tf.int32), axis=1))\nmask_indices = tf.where(seq_mask)\nin1_reshaped = tf.reshape(in1, [-1])\nresult = tf.scatter_nd(mask_indices, tf.gather(in1_reshaped, mask_indices[:, 0]), tf.shape(in2))\nreturn tf.cast(result, in1_reshaped.dtype)",
                "#create a pointer to move along the values\npointer = tf.constant(0)\n\n#initialize the output as a copy of the mask with zeros instead of True\noutput = tf.zeros_like(in2)\n\n#write values function acts on a single row of the mask\ndef write_values(mask):\n    global pointer\n    #create a sequence with the same length as the mask\n    sequence = tf.range(tf.size(mask))\n    #replace True values with input values, False values remain the same\n    values = tf.where(mask, in1[pointer:pointer+tf.size(mask)], sequence)\n    #increase pointer by the number of True values in the mask\n    pointer += tf.reduce_sum(tf.cast(mask, tf.int32))\n    return values\n\n#Apply write_values on each row of the mask\noutput = tf.map_fn(write_values, in2, dtype=tf.int32)\nreturn output",
                "mask = tf.where(in2)\n     result = tf.scatter_nd(mask, tf.cast(in1, tf.int32), tf.shape(in2))\n     return result",
                "index = tf.cast(tf.cumsum(tf.cast(in2, tf.int32), axis=1) - 1, tf.int32) * tf.cast(in2, tf.int32)\n     mask_offset = tf.cumsum(tf.reduce_sum(tf.cast(in2, tf.int32), 1))\n     final_index = tf.cumsum(tf.cast(in2, tf.int32), axis=1) - 1 + tf.pad(tf.expand_dims(mask_offset[:-1], -1), [[1, 0]])\n     out = tf.where(in2, tf.gather(in1, final_index), tf.zeros_like(index))\n     return out",
                "counter = tf.constant(0)\ndef body(counter, mask_row):\n    mask_indices = tf.where(mask_row)\n    num_mask_indices = tf.shape(mask_indices)[0]\n    mask_values = tf.range(counter, counter + num_mask_indices)\n    row = tf.tensor_scatter_nd_update(tf.zeros_like(mask_row, tf.int32), mask_indices, mask_values)\n    counter += num_mask_indices\n    return counter, row\n\n_, result = tf.map_fn(lambda mask_row: body(counter, mask_row), in2, dtype=(tf.int32, tf.int32))\n\nreturn result",
                "# first we add zeros so we can select the sequence\n    mask = tf.cast(in2, tf.int32)\n    \n    # then we use sequence_mask to turn our sequence into a mask\n    seq_mask = tf.sequence_mask(mask)\n    \n    # then we gather the elements from our input using the mask\n    result = tf.boolean_mask(in1, seq_mask)\n    \n    # reshape the result to the original shape\n    result = tf.reshape(result, tf.shape(in2))\n    \n    return result",
                "counter = tf.constant([0])\n    in1 = tf.reshape(in1, [1, -1])\n    sequence_mask = tf.cast(in2, tf.int32)\n    build_tensor = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n\n    def extract_values(val, array):\n        value = tf.gather_nd(params=in1, indices=[0, tf.squeeze(val)])\n        value = tf.expand_dims(value, axis=0)\n        return tf.add(val, 1), array.write(tf.squeeze(val), value)\n\n    def insert_values(val, array):\n        value = tf.gather_nd(params=array.stack(), indices=[tf.squeeze(val)])\n        mask_indices = tf.where(sequence_mask == 1)\n        sequence_mask = tf.tensor_scatter_nd_update(tensor=sequence_mask, indices=mask_indices, updates=value)\n        return tf.add(val, 1), array\n\n    for i in range(tf.reduce_sum(sequence_mask)):\n        counter, build_tensor = tf.while_loop(cond=lambda counter, build_tensor: tf.less(counter, tf.reduce_sum(sequence_mask)),\n                                                        body=extract_values,\n                                                        loop_vars=[counter, build_tensor])\n\n    for i in range(tf.shape(sequence_mask)[0]):\n        counter, build_tensor = tf.while_loop(cond=lambda counter, build: tf.less(counter, tf.shape(sequence_mask)[0]),\n                                                        body=insert_values,\n                                                        loop_vars=[counter, build_tensor])\n\n    return sequence_mask",
                "counter = tf.constant(0)\nfinal = []\n\nfor row in in2:\n    new_row = []\n    for cell in row:\n        if cell:\n            new_row.append(in1[counter])\n            counter += 1\n        else:\n            new_row.append(0)\n    final.append(new_row)\nreturn final",
                "counter = tf.zeros_like(in2[0], dtype=tf.int32)\n     for i in range(in2.shape[0]):\n        mask = tf.cast(in2[i], tf.int32)\n        masked_values = tf.multiply(mask, in1[:tf.reduce_sum(mask)])\n        counter = tf.concat([counter, masked_values], axis=0)\n        in1 = in1[tf.reduce_sum(mask):]\n     return tf.reshape(counter[tf.size(in2[0]):], tf.shape(in2))"
            ],
            "target-program": "tf.reshape(tf.gather(in1, tf.cumsum(tf.reshape(tf.cast(in2, tf.int32), [-1]), exclusive=True) * tf.reshape(tf.cast(in2, tf.int32), [-1])), in2.shape)",
            "description": "put given values into a sequence mask",
            "tf_operators": {
                "tf.reshape": 5,
                "tf.boolean_mask": 2,
                "tf.shape": 7,
                "tf.reduce_sum": 5,
                "tf.scatter_nd": 2,
                "tf.int32": 8,
                "tf.sequence_mask": 2,
                "tf.gather": 2,
                "tf.cast": 7,
                "tf.where": 6,
                "tf.zeros_like": 4,
                "tf.size": 2,
                "tf.map_fn": 2,
                "tf.constant": 4,
                "tf.range": 2,
                "tf.cumsum": 1,
                "tf.expand_dims": 2,
                "tf.pad": 1,
                "tf.tensor_scatter_nd_update": 2,
                "tf.less": 1,
                "tf.add": 1,
                "tf.squeeze": 1,
                "tf.gather_nd": 1,
                "tf.TensorArray": 1,
                "tf.while_loop": 1,
                "tf.concat": 1,
                "tf.multiply": 1
            },
            "coverage_percentage": 100.0,
            "total_in_target": 5,
            "total_covered": 5
        }
    },
    {
        "constants": "[]",
        "description": "find the indices of all elements",
        "target_program": "tf.cast(tf.argmax(tf.cast(tf.equal(in1, tf.expand_dims(in2, 1)), tf.int32), axis=1), tf.int32)",
        "source": "https://stackoverflow.com/questions/58481332/getting-the-indices-of-several-elements-in-a-tensorflow-at-once",
        "name": "stackoverflow_48",
        "examples": {
            "inputs": "[[32, 53, 45, 38, 29, 89, 64, 23],[38, 53, 89, 38, 32, 64],]",
            "outputs": "[3, 1, 5, 3, 0, 6]"
        },
        "completions": [
            "return tf.where(tf.equal(tf.expand_dims(in1, 1), in2)).numpy()[:,1]",
            "return tf.where(tf.equal(tf.expand_dims(in1, 1), in2))[1]",
            "return tf.argsort(tf.where(tf.equal(tf.expand_dims(in1, 1), in2)))[:,0]",
            "return tf.argsort(tf.argsort(tf.where(tf.equal(tf.expand_dims(in1, 1), in2))).numpy().flatten()).numpy().tolist()",
            "return tf.argsort(tf.searchsorted(in1, in2)).numpy().tolist()",
            "return [tf.where(tf.equal(in1, x))[0][0] for x in in2]",
            "return tf.argsort(tf.searchsorted(in1, in2), axis=-1).numpy().tolist()",
            "return tf.argsort(tf.searchsorted(in1, in2)).numpy().tolist()",
            "return [tf.where(tf.equal(in1, val)).numpy()[0][0] for val in in2]",
            "return [tf.where(tf.equal(in1, val))[0] for val in in2]"
        ],
        "response": {
            "task_id": "stackoverflow_48",
            "completions": [
                "return tf.where(tf.equal(tf.expand_dims(in1, 1), in2)).numpy()[:,1]",
                "return tf.where(tf.equal(tf.expand_dims(in1, 1), in2))[1]",
                "return tf.argsort(tf.where(tf.equal(tf.expand_dims(in1, 1), in2)))[:,0]",
                "return tf.argsort(tf.argsort(tf.where(tf.equal(tf.expand_dims(in1, 1), in2))).numpy().flatten()).numpy().tolist()",
                "return tf.argsort(tf.searchsorted(in1, in2)).numpy().tolist()",
                "return [tf.where(tf.equal(in1, x))[0][0] for x in in2]",
                "return tf.argsort(tf.searchsorted(in1, in2), axis=-1).numpy().tolist()",
                "return tf.argsort(tf.searchsorted(in1, in2)).numpy().tolist()",
                "return [tf.where(tf.equal(in1, val)).numpy()[0][0] for val in in2]",
                "return [tf.where(tf.equal(in1, val))[0] for val in in2]"
            ],
            "target-program": "tf.cast(tf.argmax(tf.cast(tf.equal(in1, tf.expand_dims(in2, 1)), tf.int32), axis=1), tf.int32)",
            "description": "find the indices of all elements",
            "tf_operators": {
                "tf.expand_dims": 4,
                "tf.equal": 7,
                "tf.where": 7,
                "tf.argsort": 5,
                "tf.searchsorted": 3
            },
            "coverage_percentage": 40.0,
            "total_in_target": 5,
            "total_covered": 2
        }
    },
    {
        "constants": "[]",
        "description": "multiply tensors by scalars in a batched way",
        "target_program": "tf.transpose(tf.multiply(in2, tf.transpose(in1)))",
        "source": "https://stackoverflow.com/questions/58466562/given-a-batch-of-n-images-how-to-scalar-multiply-each-image-by-a-different-scal",
        "name": "stackoverflow_49",
        "examples": {
            "inputs": "[[[[[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]]], [[[0.8, 1.0, 0.0], [0.6, 0.4, 0.2]]], [[[0.9, 0.8, 0.7], [0.1, 0.2, 0.3]]]],[2.0, 0.5, 1.0],]",
            "outputs": "[[[[0.2, 0.4, 0.6], [0.8, 1.0, 1.2]]],    [[[0.4, 0.5, 0.0], [0.3, 0.2, 0.1]]],    [[[0.9, 0.8, 0.7], [0.1, 0.2, 0.3]]]]"
        },
        "completions": [
            "return tf.multiply(in1, tf.expand_dims(tf.expand_dims(tf.expand_dims(in2, -1), -1), -1))",
            "return tf.multiply(in1, tf.reshape(in2, [-1,1,1,1]))",
            "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
            "return tf.multiply(in1, tf.reshape(in2, (-1, 1, 1, 1)))",
            "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
            "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
            "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
            "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
            "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
            "in2 = tf.reshape(in2, (-1,1,1,1))\nreturn tf.multiply(in1,in2)"
        ],
        "response": {
            "task_id": "stackoverflow_49",
            "completions": [
                "return tf.multiply(in1, tf.expand_dims(tf.expand_dims(tf.expand_dims(in2, -1), -1), -1))",
                "return tf.multiply(in1, tf.reshape(in2, [-1,1,1,1]))",
                "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
                "return tf.multiply(in1, tf.reshape(in2, (-1, 1, 1, 1)))",
                "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
                "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
                "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
                "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
                "return tf.multiply(in1, tf.reshape(in2, [-1, 1, 1, 1]))",
                "in2 = tf.reshape(in2, (-1,1,1,1))\nreturn tf.multiply(in1,in2)"
            ],
            "target-program": "tf.transpose(tf.multiply(in2, tf.transpose(in1)))",
            "description": "multiply tensors by scalars in a batched way",
            "tf_operators": {
                "tf.expand_dims": 1,
                "tf.multiply": 10,
                "tf.reshape": 9
            },
            "coverage_percentage": 50.0,
            "total_in_target": 2,
            "total_covered": 1
        }
    },
    {
        "constants": "[]",
        "description": "create a binary matrix where a specified column is set to one",
        "target_program": "tf.cast(tf.one_hot(tf.fill((in1,), in3), in2), tf.int32)",
        "source": "https://stackoverflow.com/questions/58537495/tensorflow-initialize-a-sparse-tensor-with-only-one-line-column-not-zero",
        "name": "stackoverflow_50",
        "examples": {
            "inputs": "[5]",
            "outputs": "[[0, 0, 0, 1, 0, 0],    [0, 0, 0, 1, 0, 0],    [0, 0, 0, 1, 0, 0],    [0, 0, 0, 1, 0, 0],    [0, 0, 0, 1, 0, 0]]"
        },
        "completions": [
            "# Create a 2D matrix filled with zeros\n    zeros = tf.zeros((5, 6))\n\n    # Create a 1D vector filled with ones\n    ones = tf.ones((5,))\n\n    # Expand dimensions of the ones vector\n    ones_exp = tf.expand_dims(ones, axis=1)\n\n    # Use scatter_nd to create a binary matrix where the 4th column is set to one\n    matrix = tf.tensor_scatter_nd_update(zeros, [[i, in1] for i in range(5)], ones_exp)\n\n    # Cast to int and return the resulting matrix\n    return tf.cast(matrix, tf.int32)",
            "return tf.one_hot(indices=in1, depth=6)",
            "return tf.one_hot(in1, 6, axis=1)",
            "return tf.eye(in1, num_columns = 6)[:, 3]",
            "return tf.eye(in1, dtype=tf.int32)[:, [3]]",
            "return tf.eye(in1, num_columns=6, dtype=tf.int32)[:, 3]",
            "return tf.one_hot(in1, 6)",
            "return tf.one_hot(in1, 6)",
            "return tf.one_hot(in1, 5, axis=1)",
            "return tf.one_hot(in1, 6, axis=1)"
        ],
        "response": {
            "task_id": "stackoverflow_50",
            "completions": [
                "# Create a 2D matrix filled with zeros\n    zeros = tf.zeros((5, 6))\n\n    # Create a 1D vector filled with ones\n    ones = tf.ones((5,))\n\n    # Expand dimensions of the ones vector\n    ones_exp = tf.expand_dims(ones, axis=1)\n\n    # Use scatter_nd to create a binary matrix where the 4th column is set to one\n    matrix = tf.tensor_scatter_nd_update(zeros, [[i, in1] for i in range(5)], ones_exp)\n\n    # Cast to int and return the resulting matrix\n    return tf.cast(matrix, tf.int32)",
                "return tf.one_hot(indices=in1, depth=6)",
                "return tf.one_hot(in1, 6, axis=1)",
                "return tf.eye(in1, num_columns = 6)[:, 3]",
                "return tf.eye(in1, dtype=tf.int32)[:, [3]]",
                "return tf.eye(in1, num_columns=6, dtype=tf.int32)[:, 3]",
                "return tf.one_hot(in1, 6)",
                "return tf.one_hot(in1, 6)",
                "return tf.one_hot(in1, 5, axis=1)",
                "return tf.one_hot(in1, 6, axis=1)"
            ],
            "target-program": "tf.cast(tf.one_hot(tf.fill((in1,), in3), in2), tf.int32)",
            "description": "create a binary matrix where a specified column is set to one",
            "tf_operators": {
                "tf.zeros": 1,
                "tf.tensor_scatter_nd_update": 1,
                "tf.ones": 1,
                "tf.expand_dims": 1,
                "tf.int32": 3,
                "tf.cast": 1,
                "tf.one_hot": 6,
                "tf.eye": 3
            },
            "coverage_percentage": 75.0,
            "total_in_target": 4,
            "total_covered": 3
        }
    }
]